{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_close = []\n",
    "signals_open = []\n",
    "\n",
    "file = open(\"problem3_data.txt\")\n",
    "readed = file.read().split('\\n\\n')\n",
    "\n",
    "for sig in readed:\n",
    "    sig = sig.split('\\n')\n",
    "    dick = {'1' : signals_close, '2' : signals_open}\n",
    "    arr = np.array(sig[1].split(), dtype='int16')\n",
    "    dick[sig[0]].append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getX(sig):\n",
    "    N = sig.size\n",
    "    return rfftfreq(N, 1 / 256)\n",
    "\n",
    "def getY(sig):\n",
    "    yf = rfft(sig)\n",
    "    return np.abs(yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "fig, axes = plt.subplots(n, 4, figsize=(40, 10 * n))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "axes[0, 0].set_title('Closed eyes', fontsize=40)\n",
    "axes[0, 1].set_title('Closed eyes Furie', fontsize=40)\n",
    "axes[0, 2].set_title('Opened eyes', fontsize=40)\n",
    "axes[0, 3].set_title('Opened eyes Furie', fontsize=40)\n",
    "\n",
    "for i in range(n):\n",
    "    # Close\n",
    "    axes[i, 0].plot(signals_close[i])\n",
    "    axes[i, 1].plot(getX(signals_close[i]), getY(signals_close[i]))\n",
    "    \n",
    "    # Open\n",
    "    axes[i, 2].plot(signals_open[i])\n",
    "    axes[i, 3].plot(getX(signals_open[i]), getY(signals_open[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getF(sig):\n",
    "    mY = getY(sig)\n",
    "    mX = getX(sig)\n",
    "\n",
    "    \n",
    "    features = np.concatenate([sig, mY, mX])\n",
    "\n",
    "    return np.concatenate([mY[:-1], sig])\n",
    "\n",
    "# x = np.array(list(map(getF, signals_close)) + list(map(getF, signals_open)))\n",
    "\n",
    "# a = np.full(50, 0)\n",
    "# b = np.full(49, 1)\n",
    "# y = np.concatenate([a, b])\n",
    "# y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 5ms/sample - loss: 0.7392 - acc: 0.4937 - val_loss: 0.8199 - val_acc: 0.4500\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7631 - acc: 0.4430 - val_loss: 0.7003 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7680 - acc: 0.3797 - val_loss: 0.8766 - val_acc: 0.4500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7661 - acc: 0.4304 - val_loss: 0.8176 - val_acc: 0.4500\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7619 - acc: 0.4177 - val_loss: 0.7399 - val_acc: 0.4500\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7338 - acc: 0.5190 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7445 - acc: 0.5316 - val_loss: 0.7284 - val_acc: 0.4500\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7482 - acc: 0.4304 - val_loss: 0.7696 - val_acc: 0.4500\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7326 - acc: 0.4937 - val_loss: 0.7603 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7198 - acc: 0.5570 - val_loss: 0.7696 - val_acc: 0.4500\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.7403 - acc: 0.4684\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a446b2c26464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 90\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "# INIT_LR = 0.02\n",
    "# EPOCHS = 10\n",
    "# BATCH_SIZE = 1\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, input_shape=(768,), activation=\"sigmoid\"))\n",
    "# model.add(Dense(256, activation=\"sigmoid\"))\n",
    "# model.add(Dense(128, activation=\"sigmoid\"))\n",
    "# model.add(Dense(64, activation=\"sigmoid\"))\n",
    "# model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=SGD(lr=INIT_LR), metrics=[\"accuracy\"])\n",
    "\n",
    "# H = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE)  \n",
    "\n",
    "# N = np.arange(0, EPOCHS)\n",
    "\n",
    "# scores = []\n",
    "\n",
    "# kfold = KFold(5, shuffle=True, random_state=1)\n",
    "# for train_i, test_i in kfold.split(x):\n",
    "        \n",
    "#     train_x, train_y, test_x, test_y = x[train_i], y[train_i], x[test_i], y[test_i]\n",
    "        \n",
    "#     model.fit(train_x, train_y)\n",
    "#     pred_y = model.predict(test_x)\n",
    "#     score = accuracy_score(test_y, pred_y)\n",
    "#     scores.append(score)\n",
    "        \n",
    "#     print('>%.3f' % score)\n",
    "\n",
    "# print('Final Score: %.3f' % (np.mean(scores)))\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/3000\n",
      "79/79 [==============================] - 1s 7ms/sample - loss: 0.6996 - acc: 0.4810 - val_loss: 0.6916 - val_acc: 0.5500\n",
      "Epoch 2/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6940 - acc: 0.4810 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 3/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6922 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 4/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6936 - acc: 0.4430 - val_loss: 0.7016 - val_acc: 0.4500\n",
      "Epoch 5/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6913 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 6/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6906 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 7/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6965 - acc: 0.5190 - val_loss: 0.6930 - val_acc: 0.5500\n",
      "Epoch 8/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6923 - acc: 0.4810 - val_loss: 0.6930 - val_acc: 0.5500\n",
      "Epoch 9/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6942 - acc: 0.4937 - val_loss: 0.6942 - val_acc: 0.4000\n",
      "Epoch 10/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6910 - acc: 0.5570 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 11/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6899 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4500\n",
      "Epoch 12/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 13/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6913 - acc: 0.5190 - val_loss: 0.6982 - val_acc: 0.4500\n",
      "Epoch 14/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 15/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 16/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6896 - acc: 0.5443 - val_loss: 0.6993 - val_acc: 0.4500\n",
      "Epoch 17/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6921 - acc: 0.5823 - val_loss: 0.7041 - val_acc: 0.4500\n",
      "Epoch 18/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6903 - acc: 0.5190 - val_loss: 0.7011 - val_acc: 0.4500\n",
      "Epoch 19/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6905 - acc: 0.5190 - val_loss: 0.7053 - val_acc: 0.4500\n",
      "Epoch 20/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6900 - acc: 0.5190 - val_loss: 0.7053 - val_acc: 0.4500\n",
      "Epoch 21/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6899 - acc: 0.5190 - val_loss: 0.7038 - val_acc: 0.4500\n",
      "Epoch 22/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6896 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4500\n",
      "Epoch 23/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6900 - acc: 0.5190 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 24/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.7010 - val_acc: 0.4500\n",
      "Epoch 25/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6887 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 26/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6890 - acc: 0.5190 - val_loss: 0.7019 - val_acc: 0.4500\n",
      "Epoch 27/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6896 - acc: 0.5190 - val_loss: 0.7029 - val_acc: 0.4500\n",
      "Epoch 28/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6909 - acc: 0.5190 - val_loss: 0.7015 - val_acc: 0.4500\n",
      "Epoch 29/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6892 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4500\n",
      "Epoch 30/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6952 - acc: 0.5190 - val_loss: 0.7086 - val_acc: 0.4500\n",
      "Epoch 31/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4500\n",
      "Epoch 32/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6943 - acc: 0.5190 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 33/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 34/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6881 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 35/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6902 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4500\n",
      "Epoch 36/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6891 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4500\n",
      "Epoch 37/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6890 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4500\n",
      "Epoch 38/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6883 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 39/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4500\n",
      "Epoch 40/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6888 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4500\n",
      "Epoch 41/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6917 - acc: 0.5190 - val_loss: 0.7078 - val_acc: 0.4500\n",
      "Epoch 42/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6889 - acc: 0.5190 - val_loss: 0.7052 - val_acc: 0.4500\n",
      "Epoch 43/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6890 - acc: 0.5190 - val_loss: 0.7007 - val_acc: 0.4500\n",
      "Epoch 44/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6880 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 45/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6933 - acc: 0.5190 - val_loss: 0.7009 - val_acc: 0.4500\n",
      "Epoch 46/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6884 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 47/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 48/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6877 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 49/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6898 - acc: 0.5190 - val_loss: 0.7063 - val_acc: 0.4500\n",
      "Epoch 50/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6892 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4500\n",
      "Epoch 51/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6896 - acc: 0.5190 - val_loss: 0.6995 - val_acc: 0.4500\n",
      "Epoch 52/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 53/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6887 - acc: 0.5190 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 54/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6882 - acc: 0.5570 - val_loss: 0.6994 - val_acc: 0.4500\n",
      "Epoch 55/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 56/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6916 - acc: 0.468 - 0s 158us/sample - loss: 0.6874 - acc: 0.5190 - val_loss: 0.7012 - val_acc: 0.4500\n",
      "Epoch 57/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.6995 - val_acc: 0.4500\n",
      "Epoch 58/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6869 - acc: 0.5190 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 59/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6885 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 60/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6873 - acc: 0.5823 - val_loss: 0.6953 - val_acc: 0.5000\n",
      "Epoch 61/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6892 - acc: 0.5823 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 62/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6882 - acc: 0.5823 - val_loss: 0.6937 - val_acc: 0.4000\n",
      "Epoch 63/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6876 - acc: 0.7215 - val_loss: 0.6941 - val_acc: 0.3500\n",
      "Epoch 64/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6882 - acc: 0.6962 - val_loss: 0.6976 - val_acc: 0.4500\n",
      "Epoch 65/3000\n",
      "79/79 [==============================] - 0s 178us/sample - loss: 0.6894 - acc: 0.5316 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 66/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 67/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6891 - acc: 0.5696 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 68/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6867 - acc: 0.5443 - val_loss: 0.6984 - val_acc: 0.4500\n",
      "Epoch 69/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6873 - acc: 0.5443 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 70/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 71/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6865 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4500\n",
      "Epoch 72/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6872 - acc: 0.5190 - val_loss: 0.6974 - val_acc: 0.4500\n",
      "Epoch 73/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 74/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 75/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6863 - acc: 0.5190 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 76/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.4500\n",
      "Epoch 77/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6878 - acc: 0.5443 - val_loss: 0.7017 - val_acc: 0.4500\n",
      "Epoch 78/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.7019 - val_acc: 0.4500\n",
      "Epoch 79/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4500\n",
      "Epoch 80/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.6890 - acc: 0.5190 - val_loss: 0.6993 - val_acc: 0.4500\n",
      "Epoch 81/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6862 - acc: 0.5190 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 82/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6894 - acc: 0.5443 - val_loss: 0.7037 - val_acc: 0.4500\n",
      "Epoch 83/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.7008 - val_acc: 0.4500\n",
      "Epoch 84/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 85/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 86/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6862 - acc: 0.5190 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 87/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6859 - acc: 0.5570 - val_loss: 0.6967 - val_acc: 0.4500\n",
      "Epoch 88/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6880 - acc: 0.5316 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 89/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6884 - acc: 0.5316 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 90/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6857 - acc: 0.5443 - val_loss: 0.6967 - val_acc: 0.4500\n",
      "Epoch 91/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.6857 - acc: 0.5443 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 92/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6854 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4500\n",
      "Epoch 93/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6865 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 94/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.6857 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 95/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6884 - acc: 0.5570 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 96/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6893 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 97/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6909 - acc: 0.5443 - val_loss: 0.6970 - val_acc: 0.4500\n",
      "Epoch 98/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6854 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 99/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 100/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6919 - acc: 0.5823 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 101/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5570 - val_loss: 0.6992 - val_acc: 0.4500\n",
      "Epoch 102/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6877 - acc: 0.5316 - val_loss: 0.7049 - val_acc: 0.4500\n",
      "Epoch 103/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6868 - acc: 0.5190 - val_loss: 0.7061 - val_acc: 0.4500\n",
      "Epoch 104/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6861 - acc: 0.5190 - val_loss: 0.7007 - val_acc: 0.4500\n",
      "Epoch 105/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 106/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 107/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6861 - acc: 0.5823 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 108/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6869 - acc: 0.6203 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 109/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 110/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6856 - acc: 0.5823 - val_loss: 0.6947 - val_acc: 0.5000\n",
      "Epoch 111/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6848 - acc: 0.6582 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 112/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6854 - acc: 0.6076 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 113/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 114/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6861 - acc: 0.5823 - val_loss: 0.6992 - val_acc: 0.4500\n",
      "Epoch 115/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 116/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.6851 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 117/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6850 - acc: 0.5190 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 118/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6844 - acc: 0.5823 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 119/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6847 - acc: 0.5190 - val_loss: 0.7009 - val_acc: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6845 - acc: 0.5190 - val_loss: 0.6976 - val_acc: 0.4500\n",
      "Epoch 121/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6858 - acc: 0.5696 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 122/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6859 - acc: 0.6456 - val_loss: 0.7020 - val_acc: 0.4500\n",
      "Epoch 123/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.7043 - val_acc: 0.4500\n",
      "Epoch 124/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4500\n",
      "Epoch 125/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6856 - acc: 0.5190 - val_loss: 0.7027 - val_acc: 0.4500\n",
      "Epoch 126/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6845 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4500\n",
      "Epoch 127/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6838 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4500\n",
      "Epoch 128/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6853 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 129/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6840 - acc: 0.7089 - val_loss: 0.6974 - val_acc: 0.4500\n",
      "Epoch 130/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6882 - acc: 0.5443 - val_loss: 0.7000 - val_acc: 0.4500\n",
      "Epoch 131/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6844 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4500\n",
      "Epoch 132/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.6846 - acc: 0.5190 - val_loss: 0.7044 - val_acc: 0.4500\n",
      "Epoch 133/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6853 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4500\n",
      "Epoch 134/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6841 - acc: 0.5190 - val_loss: 0.7027 - val_acc: 0.4500\n",
      "Epoch 135/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6842 - acc: 0.5190 - val_loss: 0.7016 - val_acc: 0.4500\n",
      "Epoch 136/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 137/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6836 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.4500\n",
      "Epoch 138/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6842 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 139/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6853 - acc: 0.6076 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 140/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 141/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6848 - acc: 0.5190 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 142/3000\n",
      "79/79 [==============================] - 0s 316us/sample - loss: 0.6858 - acc: 0.6076 - val_loss: 0.6922 - val_acc: 0.6000\n",
      "Epoch 143/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6864 - acc: 0.6456 - val_loss: 0.6942 - val_acc: 0.6000\n",
      "Epoch 144/3000\n",
      "79/79 [==============================] - 0s 207us/sample - loss: 0.6848 - acc: 0.6962 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 145/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6842 - acc: 0.7848 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 146/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6843 - acc: 0.7468 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 147/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6832 - acc: 0.5443 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 148/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6841 - acc: 0.5570 - val_loss: 0.6965 - val_acc: 0.4500\n",
      "Epoch 149/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6830 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 150/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6859 - acc: 0.5696 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 151/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6845 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 152/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6835 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 153/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6838 - acc: 0.5190 - val_loss: 0.7033 - val_acc: 0.4500\n",
      "Epoch 154/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.7015 - val_acc: 0.4500\n",
      "Epoch 155/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6838 - acc: 0.5190 - val_loss: 0.7039 - val_acc: 0.4500\n",
      "Epoch 156/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.7050 - val_acc: 0.4500\n",
      "Epoch 157/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.7080 - val_acc: 0.4500\n",
      "Epoch 158/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6839 - acc: 0.5190 - val_loss: 0.7032 - val_acc: 0.4500\n",
      "Epoch 159/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.7018 - val_acc: 0.4500\n",
      "Epoch 160/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6826 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4500\n",
      "Epoch 161/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6836 - acc: 0.5190 - val_loss: 0.7041 - val_acc: 0.4500\n",
      "Epoch 162/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.6830 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4500\n",
      "Epoch 163/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6834 - acc: 0.5190 - val_loss: 0.7055 - val_acc: 0.4500\n",
      "Epoch 164/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 165/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6828 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 166/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6820 - acc: 0.5316 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 167/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 168/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6822 - acc: 0.7215 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 169/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6823 - acc: 0.7342 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 170/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6841 - acc: 0.7342 - val_loss: 0.7010 - val_acc: 0.4500\n",
      "Epoch 171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6818 - acc: 0.5190 - val_loss: 0.6989 - val_acc: 0.4500\n",
      "Epoch 172/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6874 - acc: 0.5190 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 173/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6823 - acc: 0.6456 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 174/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6828 - acc: 0.7975 - val_loss: 0.6942 - val_acc: 0.6000\n",
      "Epoch 175/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6829 - acc: 0.6456 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 176/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6830 - acc: 0.6835 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 177/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6819 - acc: 0.5949 - val_loss: 0.6941 - val_acc: 0.6000\n",
      "Epoch 178/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6819 - acc: 0.7975 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 179/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6823 - acc: 0.6076 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 180/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6815 - acc: 0.7342 - val_loss: 0.6954 - val_acc: 0.4500\n",
      "Epoch 181/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6826 - acc: 0.7089 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 182/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6837 - acc: 0.5190 - val_loss: 0.6969 - val_acc: 0.4500\n",
      "Epoch 183/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6825 - acc: 0.5190 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 184/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6828 - acc: 0.7595 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 185/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6809 - acc: 0.5316 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 186/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6823 - acc: 0.5190 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 187/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6809 - acc: 0.6582 - val_loss: 0.6965 - val_acc: 0.4500\n",
      "Epoch 188/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6811 - acc: 0.5949 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 189/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6828 - acc: 0.5190 - val_loss: 0.7016 - val_acc: 0.4500\n",
      "Epoch 190/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6816 - acc: 0.5190 - val_loss: 0.7038 - val_acc: 0.4500\n",
      "Epoch 191/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6812 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 192/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.6814 - acc: 0.5190 - val_loss: 0.7030 - val_acc: 0.4500\n",
      "Epoch 193/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.6810 - acc: 0.5190 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 194/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6813 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 195/3000\n",
      "79/79 [==============================] - 0s 187us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 196/3000\n",
      "79/79 [==============================] - 0s 185us/sample - loss: 0.6810 - acc: 0.7468 - val_loss: 0.6988 - val_acc: 0.4500\n",
      "Epoch 197/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6805 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 198/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6808 - acc: 0.5823 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 199/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6672 - acc: 0.625 - 0s 171us/sample - loss: 0.6826 - acc: 0.5190 - val_loss: 0.6996 - val_acc: 0.4500\n",
      "Epoch 200/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6818 - acc: 0.5316 - val_loss: 0.7036 - val_acc: 0.4500\n",
      "Epoch 201/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.6808 - acc: 0.5190 - val_loss: 0.7005 - val_acc: 0.4500\n",
      "Epoch 202/3000\n",
      "79/79 [==============================] - 0s 214us/sample - loss: 0.6834 - acc: 0.5316 - val_loss: 0.7041 - val_acc: 0.4500\n",
      "Epoch 203/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6817 - acc: 0.5190 - val_loss: 0.7041 - val_acc: 0.4500\n",
      "Epoch 204/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6835 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 205/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6800 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 206/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.6822 - acc: 0.5190 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 207/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6812 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 208/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6800 - acc: 0.5570 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 209/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6829 - acc: 0.6203 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 210/3000\n",
      "79/79 [==============================] - 0s 193us/sample - loss: 0.6840 - acc: 0.6203 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 211/3000\n",
      "79/79 [==============================] - 0s 190us/sample - loss: 0.6814 - acc: 0.7722 - val_loss: 0.6940 - val_acc: 0.5500\n",
      "Epoch 212/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.6806 - acc: 0.8101 - val_loss: 0.6966 - val_acc: 0.4500\n",
      "Epoch 213/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6795 - acc: 0.5316 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 214/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6797 - acc: 0.6456 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 215/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.6795 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 216/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6793 - acc: 0.5316 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 217/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6806 - acc: 0.6456 - val_loss: 0.7019 - val_acc: 0.4500\n",
      "Epoch 218/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6802 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 219/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6805 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 220/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6793 - acc: 0.5823 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 221/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6798 - acc: 0.5570 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 222/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6807 - acc: 0.6203 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 223/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6793 - acc: 0.7089 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 224/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6796 - acc: 0.5570 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 225/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6800 - acc: 0.6456 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 226/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.6795 - acc: 0.5316 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 227/3000\n",
      "79/79 [==============================] - 0s 186us/sample - loss: 0.6791 - acc: 0.6456 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 228/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6789 - acc: 0.5696 - val_loss: 0.6965 - val_acc: 0.4500\n",
      "Epoch 229/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6794 - acc: 0.5696 - val_loss: 0.6982 - val_acc: 0.4500\n",
      "Epoch 230/3000\n",
      "79/79 [==============================] - 0s 227us/sample - loss: 0.6795 - acc: 0.5190 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 231/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6796 - acc: 0.6203 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 232/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6791 - acc: 0.8481 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 233/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6794 - acc: 0.7848 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 234/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6800 - acc: 0.6582 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 235/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6800 - acc: 0.5190 - val_loss: 0.6994 - val_acc: 0.4500\n",
      "Epoch 236/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6791 - acc: 0.5190 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 237/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6792 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4500\n",
      "Epoch 238/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6783 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 239/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6787 - acc: 0.5190 - val_loss: 0.7022 - val_acc: 0.4500\n",
      "Epoch 240/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6801 - acc: 0.5190 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 241/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6780 - acc: 0.5696 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 242/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6783 - acc: 0.7722 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 243/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6801 - acc: 0.5190 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 244/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6793 - acc: 0.7595 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 245/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6802 - acc: 0.5570 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 246/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6792 - acc: 0.6835 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 247/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6782 - acc: 0.7975 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 248/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6781 - acc: 0.8354 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 249/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6779 - acc: 0.8101 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 250/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6775 - acc: 0.8481 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 251/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6775 - acc: 0.7722 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 252/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6787 - acc: 0.5316 - val_loss: 0.6939 - val_acc: 0.5500\n",
      "Epoch 253/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6776 - acc: 0.8481 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 254/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6772 - acc: 0.6456 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 255/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6776 - acc: 0.5190 - val_loss: 0.7009 - val_acc: 0.4500\n",
      "Epoch 256/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.6771 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4500\n",
      "Epoch 257/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6776 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 258/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6788 - acc: 0.5570 - val_loss: 0.7019 - val_acc: 0.4500\n",
      "Epoch 259/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6800 - acc: 0.5190 - val_loss: 0.7042 - val_acc: 0.4500\n",
      "Epoch 260/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6777 - acc: 0.5190 - val_loss: 0.6992 - val_acc: 0.4500\n",
      "Epoch 261/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6766 - acc: 0.5190 - val_loss: 0.6989 - val_acc: 0.4500\n",
      "Epoch 262/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6772 - acc: 0.5190 - val_loss: 0.7014 - val_acc: 0.4500\n",
      "Epoch 263/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6779 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4500\n",
      "Epoch 264/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6772 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 265/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6830 - acc: 0.5949 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 266/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6774 - acc: 0.5316 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 267/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6771 - acc: 0.8101 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 268/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6779 - acc: 0.8354 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 269/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6763 - acc: 0.5949 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 270/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6766 - acc: 0.5190 - val_loss: 0.7012 - val_acc: 0.4500\n",
      "Epoch 271/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6763 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 272/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6760 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 273/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6761 - acc: 0.5190 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 274/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6775 - acc: 0.8354 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 275/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6759 - acc: 0.5823 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 276/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6756 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4500\n",
      "Epoch 277/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6762 - acc: 0.5190 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 278/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.6772 - acc: 0.7215 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 279/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6753 - acc: 0.5316 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 280/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6753 - acc: 0.5316 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 281/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6758 - acc: 0.5443 - val_loss: 0.7008 - val_acc: 0.4500\n",
      "Epoch 282/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6756 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 283/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6767 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 284/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6774 - acc: 0.5316 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 285/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6788 - acc: 0.6456 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 286/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.6770 - acc: 0.7089 - val_loss: 0.6996 - val_acc: 0.4500\n",
      "Epoch 287/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6762 - acc: 0.5190 - val_loss: 0.7036 - val_acc: 0.4500\n",
      "Epoch 288/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.6810 - acc: 0.5190 - val_loss: 0.7100 - val_acc: 0.4500\n",
      "Epoch 289/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4500\n",
      "Epoch 290/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6787 - acc: 0.5190 - val_loss: 0.7003 - val_acc: 0.4500\n",
      "Epoch 291/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.6758 - acc: 0.5316 - val_loss: 0.6998 - val_acc: 0.4500\n",
      "Epoch 292/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6760 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 293/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6743 - acc: 0.5316 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 294/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6742 - acc: 0.5949 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 295/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6745 - acc: 0.5443 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 296/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6790 - acc: 0.6076 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 297/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6740 - acc: 0.5949 - val_loss: 0.6966 - val_acc: 0.4500\n",
      "Epoch 298/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6742 - acc: 0.6456 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 299/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6759 - acc: 0.6203 - val_loss: 0.7028 - val_acc: 0.4500\n",
      "Epoch 300/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6751 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.4500\n",
      "Epoch 301/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6741 - acc: 0.5443 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 302/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.6739 - acc: 0.5190 - val_loss: 0.6969 - val_acc: 0.4500\n",
      "Epoch 303/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6735 - acc: 0.5316 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 304/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6736 - acc: 0.5696 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 305/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6746 - acc: 0.5190 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 306/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6745 - acc: 0.5190 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 307/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6735 - acc: 0.5316 - val_loss: 0.6965 - val_acc: 0.4500\n",
      "Epoch 308/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6759 - acc: 0.5949 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 309/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6759 - acc: 0.8354 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 310/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6740 - acc: 0.6076 - val_loss: 0.7005 - val_acc: 0.4500\n",
      "Epoch 311/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.6736 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4500\n",
      "Epoch 312/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6743 - acc: 0.5190 - val_loss: 0.7028 - val_acc: 0.4500\n",
      "Epoch 313/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6746 - acc: 0.5190 - val_loss: 0.7046 - val_acc: 0.4500\n",
      "Epoch 314/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6740 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 315/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6742 - acc: 0.5443 - val_loss: 0.7032 - val_acc: 0.4500\n",
      "Epoch 316/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6733 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4500\n",
      "Epoch 317/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6734 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 318/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6700 - acc: 0.531 - 0s 163us/sample - loss: 0.6726 - acc: 0.5570 - val_loss: 0.6989 - val_acc: 0.4500\n",
      "Epoch 319/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6733 - acc: 0.5316 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 320/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6725 - acc: 0.5949 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 321/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6741 - acc: 0.5443 - val_loss: 0.6923 - val_acc: 0.5500\n",
      "Epoch 322/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6732 - acc: 0.7848 - val_loss: 0.6918 - val_acc: 0.5500\n",
      "Epoch 323/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6729 - acc: 0.8987 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 324/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6725 - acc: 0.6835 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 325/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6719 - acc: 0.7089 - val_loss: 0.6958 - val_acc: 0.4000\n",
      "Epoch 326/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6741 - acc: 0.6203 - val_loss: 0.6921 - val_acc: 0.5500\n",
      "Epoch 327/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6731 - acc: 0.8987 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 328/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6718 - acc: 0.6835 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 329/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6733 - acc: 0.6709 - val_loss: 0.7008 - val_acc: 0.4500\n",
      "Epoch 330/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6721 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.4500\n",
      "Epoch 331/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6721 - acc: 0.5190 - val_loss: 0.7016 - val_acc: 0.4500\n",
      "Epoch 332/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6717 - acc: 0.5190 - val_loss: 0.6988 - val_acc: 0.4500\n",
      "Epoch 333/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6738 - acc: 0.5316 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 334/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6719 - acc: 0.6456 - val_loss: 0.6970 - val_acc: 0.4500\n",
      "Epoch 335/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6712 - acc: 0.5570 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 336/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6713 - acc: 0.5570 - val_loss: 0.6938 - val_acc: 0.5500\n",
      "Epoch 337/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6712 - acc: 0.8228 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 338/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6738 - acc: 0.7089 - val_loss: 0.6982 - val_acc: 0.4500\n",
      "Epoch 339/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6711 - acc: 0.5316 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 340/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6728 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 341/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6705 - acc: 0.5443 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 342/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6722 - acc: 0.5823 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 343/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6703 - acc: 0.6076 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 344/3000\n",
      "79/79 [==============================] - 0s 178us/sample - loss: 0.6713 - acc: 0.6329 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 345/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6703 - acc: 0.5443 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 346/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6711 - acc: 0.5823 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 347/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6700 - acc: 0.6709 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 348/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6700 - acc: 0.5443 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 349/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6697 - acc: 0.5949 - val_loss: 0.6953 - val_acc: 0.4000\n",
      "Epoch 350/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6699 - acc: 0.7215 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 351/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6726 - acc: 0.5949 - val_loss: 0.6996 - val_acc: 0.4500\n",
      "Epoch 352/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6700 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 353/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6696 - acc: 0.5570 - val_loss: 0.6995 - val_acc: 0.4500\n",
      "Epoch 354/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6709 - acc: 0.5443 - val_loss: 0.7034 - val_acc: 0.4500\n",
      "Epoch 355/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6708 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4500\n",
      "Epoch 356/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6706 - acc: 0.5316 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 357/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6690 - acc: 0.7468 - val_loss: 0.6958 - val_acc: 0.4000\n",
      "Epoch 358/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6708 - acc: 0.6076 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 359/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6691 - acc: 0.5696 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 360/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6700 - acc: 0.7215 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 361/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6699 - acc: 0.5316 - val_loss: 0.7005 - val_acc: 0.4500\n",
      "Epoch 362/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6691 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 363/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6689 - acc: 0.5443 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 364/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6694 - acc: 0.7595 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 365/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6684 - acc: 0.5443 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 366/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6684 - acc: 0.5570 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 367/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6692 - acc: 0.5570 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 368/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6685 - acc: 0.7722 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 369/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6682 - acc: 0.8608 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 370/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6684 - acc: 0.8101 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 371/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6687 - acc: 0.7342 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 372/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6700 - acc: 0.6076 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 373/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6680 - acc: 0.5823 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 374/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6681 - acc: 0.6076 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 375/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6681 - acc: 0.5316 - val_loss: 0.6994 - val_acc: 0.4500\n",
      "Epoch 376/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6684 - acc: 0.5570 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 377/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6685 - acc: 0.5949 - val_loss: 0.7020 - val_acc: 0.4500\n",
      "Epoch 378/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6719 - acc: 0.5190 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 379/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6680 - acc: 0.8734 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 380/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6680 - acc: 0.8734 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 381/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6667 - acc: 0.6582 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 382/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6675 - acc: 0.6329 - val_loss: 0.6976 - val_acc: 0.4500\n",
      "Epoch 383/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6683 - acc: 0.6329 - val_loss: 0.7004 - val_acc: 0.4500\n",
      "Epoch 384/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6676 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 385/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6673 - acc: 0.7722 - val_loss: 0.6984 - val_acc: 0.4500\n",
      "Epoch 386/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6689 - acc: 0.5696 - val_loss: 0.6956 - val_acc: 0.4000\n",
      "Epoch 387/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6701 - acc: 0.5823 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 388/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6732 - acc: 0.6582 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 389/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6677 - acc: 0.6582 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 390/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6667 - acc: 0.9114 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 391/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6657 - acc: 0.7975 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 392/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6664 - acc: 0.7089 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 393/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6661 - acc: 0.7975 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 394/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6658 - acc: 0.8861 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 395/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6655 - acc: 0.8354 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 396/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6653 - acc: 0.8481 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 397/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6653 - acc: 0.8354 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 398/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6711 - acc: 0.6329 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 399/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6653 - acc: 0.6582 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 400/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6661 - acc: 0.7722 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 401/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6648 - acc: 0.8354 - val_loss: 0.6953 - val_acc: 0.4000\n",
      "Epoch 402/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6647 - acc: 0.7468 - val_loss: 0.6970 - val_acc: 0.4500\n",
      "Epoch 403/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6645 - acc: 0.6456 - val_loss: 0.6982 - val_acc: 0.4500\n",
      "Epoch 404/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6661 - acc: 0.5316 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 405/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6649 - acc: 0.8228 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 406/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6641 - acc: 0.8101 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 407/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6668 - acc: 0.5949 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 408/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6650 - acc: 0.9114 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 409/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6644 - acc: 0.8228 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 410/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6640 - acc: 0.6456 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 411/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6635 - acc: 0.6456 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 412/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6648 - acc: 0.5696 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 413/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6636 - acc: 0.8101 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 414/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6637 - acc: 0.7848 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 415/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 252us/sample - loss: 0.6640 - acc: 0.5316 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 416/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6666 - acc: 0.7848 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 417/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6631 - acc: 0.7722 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 418/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6626 - acc: 0.7468 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 419/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6635 - acc: 0.6835 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 420/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6641 - acc: 0.7975 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 421/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6638 - acc: 0.8481 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 422/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6640 - acc: 0.8481 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 423/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6622 - acc: 0.8101 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 424/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6630 - acc: 0.6456 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 425/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6637 - acc: 0.8354 - val_loss: 0.6955 - val_acc: 0.4000\n",
      "Epoch 426/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6627 - acc: 0.6582 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 427/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6630 - acc: 0.7722 - val_loss: 0.6997 - val_acc: 0.4500\n",
      "Epoch 428/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.6619 - acc: 0.5443 - val_loss: 0.6969 - val_acc: 0.4500\n",
      "Epoch 429/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6617 - acc: 0.6076 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 430/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6612 - acc: 0.7595 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 431/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6618 - acc: 0.7215 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 432/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6612 - acc: 0.8734 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 433/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6614 - acc: 0.7468 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 434/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6636 - acc: 0.6329 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 435/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6613 - acc: 0.7089 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 436/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6604 - acc: 0.6203 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 437/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6605 - acc: 0.7595 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 438/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6604 - acc: 0.7722 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 439/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6609 - acc: 0.7975 - val_loss: 0.6920 - val_acc: 0.5000\n",
      "Epoch 440/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6605 - acc: 0.8228 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 441/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6610 - acc: 0.9367 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 442/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6627 - acc: 0.6835 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 443/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6614 - acc: 0.7468 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 444/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6614 - acc: 0.7595 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 445/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6627 - acc: 0.5696 - val_loss: 0.7020 - val_acc: 0.4500\n",
      "Epoch 446/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6622 - acc: 0.5190 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 447/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6599 - acc: 0.6835 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 448/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6605 - acc: 0.5949 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 449/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6587 - acc: 0.7595 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 450/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.6589 - acc: 0.8228 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 451/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6625 - acc: 0.7215 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 452/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6595 - acc: 0.8734 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 453/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6584 - acc: 0.7722 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 454/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6580 - acc: 0.6329 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 455/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6594 - acc: 0.6709 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 456/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6589 - acc: 0.8734 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 457/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6578 - acc: 0.7468 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 458/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6577 - acc: 0.6203 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 459/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6576 - acc: 0.7215 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 460/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6571 - acc: 0.7595 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 461/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6580 - acc: 0.7595 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 462/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6580 - acc: 0.8987 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 463/3000\n",
      "79/79 [==============================] - 0s 178us/sample - loss: 0.6615 - acc: 0.8861 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 464/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6575 - acc: 0.8354 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 465/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6567 - acc: 0.7215 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 466/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6593 - acc: 0.8101 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 467/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6580 - acc: 0.8228 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 468/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6580 - acc: 0.6709 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 469/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6572 - acc: 0.9494 - val_loss: 0.6894 - val_acc: 0.6000\n",
      "Epoch 470/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6569 - acc: 0.9114 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 471/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6566 - acc: 0.8481 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 472/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6577 - acc: 0.5823 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 473/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6558 - acc: 0.6835 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 474/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6571 - acc: 0.6329 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 475/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6554 - acc: 0.5823 - val_loss: 0.6977 - val_acc: 0.4500\n",
      "Epoch 476/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6550 - acc: 0.6329 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 477/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6571 - acc: 0.7089 - val_loss: 0.7023 - val_acc: 0.4500\n",
      "Epoch 478/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6586 - acc: 0.5696 - val_loss: 0.7066 - val_acc: 0.4500\n",
      "Epoch 479/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6586 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 480/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6543 - acc: 0.6076 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 481/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6546 - acc: 0.6329 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 482/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6543 - acc: 0.7848 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 483/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6550 - acc: 0.8228 - val_loss: 0.6890 - val_acc: 0.6000\n",
      "Epoch 484/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6550 - acc: 0.8987 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6539 - acc: 0.9241 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 486/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6534 - acc: 0.9114 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 487/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6597 - acc: 0.7215 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 488/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6540 - acc: 0.9114 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 489/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6530 - acc: 0.8481 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 490/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6542 - acc: 0.7975 - val_loss: 0.6956 - val_acc: 0.4000\n",
      "Epoch 491/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6540 - acc: 0.7342 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 492/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6524 - acc: 0.7848 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 493/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6535 - acc: 0.7722 - val_loss: 0.6999 - val_acc: 0.4500\n",
      "Epoch 494/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6544 - acc: 0.6582 - val_loss: 0.7017 - val_acc: 0.4500\n",
      "Epoch 495/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6534 - acc: 0.5316 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 496/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6517 - acc: 0.6076 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 497/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6529 - acc: 0.6329 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 498/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6520 - acc: 0.8481 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 499/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6537 - acc: 0.8861 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 500/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6539 - acc: 0.8608 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 501/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.6505 - acc: 0.7595 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 502/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6530 - acc: 0.6203 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 503/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6509 - acc: 0.8481 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 504/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6531 - acc: 0.8101 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 505/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6509 - acc: 0.9114 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 506/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6515 - acc: 0.6709 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 507/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6502 - acc: 0.7975 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 508/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.6496 - acc: 0.6203 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 509/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6500 - acc: 0.6962 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 510/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6503 - acc: 0.8608 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 511/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6523 - acc: 0.5696 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 512/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6506 - acc: 0.9114 - val_loss: 0.6904 - val_acc: 0.5500\n",
      "Epoch 513/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6495 - acc: 0.8354 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 514/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6519 - acc: 0.8608 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 515/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6510 - acc: 0.8354 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 516/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6482 - acc: 0.7595 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6477 - acc: 0.8481 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 518/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6478 - acc: 0.8354 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 519/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6498 - acc: 0.8228 - val_loss: 0.6993 - val_acc: 0.4500\n",
      "Epoch 520/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6498 - acc: 0.6329 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 521/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6488 - acc: 0.6329 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 522/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6477 - acc: 0.5443 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 523/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6482 - acc: 0.7215 - val_loss: 0.7000 - val_acc: 0.4500\n",
      "Epoch 524/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6474 - acc: 0.5949 - val_loss: 0.6991 - val_acc: 0.4500\n",
      "Epoch 525/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6477 - acc: 0.5823 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 526/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6476 - acc: 0.8354 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 527/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6465 - acc: 0.7722 - val_loss: 0.6955 - val_acc: 0.4000\n",
      "Epoch 528/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6459 - acc: 0.7468 - val_loss: 0.6919 - val_acc: 0.5500\n",
      "Epoch 529/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6461 - acc: 0.8861 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 530/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6453 - acc: 0.7595 - val_loss: 0.6956 - val_acc: 0.4000\n",
      "Epoch 531/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6486 - acc: 0.7722 - val_loss: 0.7029 - val_acc: 0.4500\n",
      "Epoch 532/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6468 - acc: 0.5696 - val_loss: 0.7011 - val_acc: 0.4500\n",
      "Epoch 533/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6459 - acc: 0.5696 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 534/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6447 - acc: 0.6962 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 535/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6448 - acc: 0.7342 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 536/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6471 - acc: 0.8861 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 537/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6444 - acc: 0.6962 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 538/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.6441 - acc: 0.6456 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 539/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6432 - acc: 0.7975 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 540/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.6434 - acc: 0.7595 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 541/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6435 - acc: 0.9367 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 542/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6436 - acc: 0.7468 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 543/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6452 - acc: 0.8481 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 544/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6426 - acc: 0.9241 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 545/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6428 - acc: 0.8987 - val_loss: 0.6909 - val_acc: 0.4500\n",
      "Epoch 546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6415 - acc: 0.8354 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 547/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6449 - acc: 0.8101 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 548/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6420 - acc: 0.8101 - val_loss: 0.6893 - val_acc: 0.6000\n",
      "Epoch 549/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6441 - acc: 0.8987 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 550/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6412 - acc: 0.7342 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 551/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6405 - acc: 0.7468 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 552/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6401 - acc: 0.8101 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 553/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6399 - acc: 0.8228 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 554/3000\n",
      "79/79 [==============================] - 0s 186us/sample - loss: 0.6399 - acc: 0.8228 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 555/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6419 - acc: 0.6962 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 556/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6394 - acc: 0.9241 - val_loss: 0.6915 - val_acc: 0.5500\n",
      "Epoch 557/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6388 - acc: 0.8481 - val_loss: 0.6918 - val_acc: 0.5500\n",
      "Epoch 558/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6399 - acc: 0.7848 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 559/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6401 - acc: 0.9114 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 560/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6385 - acc: 0.8101 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 561/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6388 - acc: 0.7975 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 562/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.6384 - acc: 0.7722 - val_loss: 0.6906 - val_acc: 0.4500\n",
      "Epoch 563/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6405 - acc: 0.8354 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 564/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6377 - acc: 0.9494 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 565/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6372 - acc: 0.9114 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 566/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6369 - acc: 0.9241 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 567/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6369 - acc: 0.9114 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 568/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6374 - acc: 0.8987 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 569/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6390 - acc: 0.7975 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 570/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6359 - acc: 0.8101 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 571/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6359 - acc: 0.7848 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 572/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6357 - acc: 0.8354 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 573/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6353 - acc: 0.9241 - val_loss: 0.6902 - val_acc: 0.4500\n",
      "Epoch 574/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.6391 - acc: 0.8987 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 575/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6349 - acc: 0.7975 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 576/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6348 - acc: 0.7595 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 577/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6349 - acc: 0.7975 - val_loss: 0.6902 - val_acc: 0.4500\n",
      "Epoch 578/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6341 - acc: 0.8861 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 579/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6372 - acc: 0.8228 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 580/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6350 - acc: 0.8734 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 581/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6332 - acc: 0.7975 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 582/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6328 - acc: 0.8354 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 583/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6325 - acc: 0.8861 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 584/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6346 - acc: 0.8354 - val_loss: 0.6899 - val_acc: 0.5000\n",
      "Epoch 585/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6338 - acc: 0.8354 - val_loss: 0.6860 - val_acc: 0.6000\n",
      "Epoch 586/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6326 - acc: 0.9241 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 587/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6319 - acc: 0.9367 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 588/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6327 - acc: 0.8481 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 589/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6312 - acc: 0.9367 - val_loss: 0.6882 - val_acc: 0.6000\n",
      "Epoch 590/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6311 - acc: 0.9241 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 591/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6312 - acc: 0.9114 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 592/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6305 - acc: 0.8228 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 593/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6304 - acc: 0.9241 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 594/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6314 - acc: 0.7975 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 595/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6307 - acc: 0.9114 - val_loss: 0.6850 - val_acc: 0.6000\n",
      "Epoch 596/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6300 - acc: 0.9620 - val_loss: 0.6856 - val_acc: 0.5000\n",
      "Epoch 597/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6293 - acc: 0.9367 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 598/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6303 - acc: 0.8734 - val_loss: 0.6872 - val_acc: 0.6000\n",
      "Epoch 599/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6288 - acc: 0.9114 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 600/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6287 - acc: 0.9494 - val_loss: 0.6851 - val_acc: 0.6000\n",
      "Epoch 601/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6292 - acc: 0.8987 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 602/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6279 - acc: 0.9114 - val_loss: 0.6856 - val_acc: 0.5500\n",
      "Epoch 603/3000\n",
      "79/79 [==============================] - 0s 175us/sample - loss: 0.6276 - acc: 0.9241 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 604/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6290 - acc: 0.9114 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 605/3000\n",
      "79/79 [==============================] - 0s 316us/sample - loss: 0.6292 - acc: 0.9367 - val_loss: 0.6833 - val_acc: 0.6500\n",
      "Epoch 606/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6318 - acc: 0.8734 - val_loss: 0.6867 - val_acc: 0.6000\n",
      "Epoch 607/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6272 - acc: 0.9114 - val_loss: 0.6847 - val_acc: 0.6000\n",
      "Epoch 608/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6266 - acc: 0.9620 - val_loss: 0.6843 - val_acc: 0.6000\n",
      "Epoch 609/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6263 - acc: 0.9367 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 610/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6236 - acc: 0.968 - 0s 139us/sample - loss: 0.6257 - acc: 0.9620 - val_loss: 0.6849 - val_acc: 0.5500\n",
      "Epoch 611/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6270 - acc: 0.9367 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 612/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6258 - acc: 0.9114 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 613/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6250 - acc: 0.7975 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 614/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6248 - acc: 0.7975 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 615/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.6251 - acc: 0.8608 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 616/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6253 - acc: 0.7975 - val_loss: 0.6968 - val_acc: 0.4000\n",
      "Epoch 617/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6245 - acc: 0.7215 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 618/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6235 - acc: 0.7595 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 619/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6299 - acc: 0.7089 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 620/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6223 - acc: 0.8101 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 621/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6235 - acc: 0.7722 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 622/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6232 - acc: 0.9241 - val_loss: 0.6854 - val_acc: 0.5500\n",
      "Epoch 623/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6214 - acc: 0.9241 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 624/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6214 - acc: 0.9494 - val_loss: 0.6889 - val_acc: 0.4500\n",
      "Epoch 625/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6204 - acc: 0.8861 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 626/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6210 - acc: 0.9114 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 627/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6208 - acc: 0.9114 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 628/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6206 - acc: 0.8481 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 629/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6205 - acc: 0.8101 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 630/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6208 - acc: 0.8101 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 631/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6212 - acc: 0.9367 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 632/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6183 - acc: 0.8354 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6195 - acc: 0.8987 - val_loss: 0.6853 - val_acc: 0.5500\n",
      "Epoch 634/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6190 - acc: 0.8861 - val_loss: 0.6860 - val_acc: 0.6000\n",
      "Epoch 635/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6190 - acc: 0.9114 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 636/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6187 - acc: 0.8734 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 637/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6171 - acc: 0.7975 - val_loss: 0.6903 - val_acc: 0.4500\n",
      "Epoch 638/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6194 - acc: 0.8354 - val_loss: 0.6888 - val_acc: 0.5000\n",
      "Epoch 639/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6176 - acc: 0.8481 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 640/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6155 - acc: 0.9241 - val_loss: 0.6861 - val_acc: 0.6000\n",
      "Epoch 641/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6161 - acc: 0.9114 - val_loss: 0.6847 - val_acc: 0.5500\n",
      "Epoch 642/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6155 - acc: 0.9620 - val_loss: 0.6838 - val_acc: 0.5500\n",
      "Epoch 643/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6163 - acc: 0.9367 - val_loss: 0.6865 - val_acc: 0.6000\n",
      "Epoch 644/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6146 - acc: 0.9367 - val_loss: 0.6847 - val_acc: 0.5500\n",
      "Epoch 645/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6142 - acc: 0.9620 - val_loss: 0.6858 - val_acc: 0.6000\n",
      "Epoch 646/3000\n",
      "79/79 [==============================] - 0s 303us/sample - loss: 0.6137 - acc: 0.9367 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 647/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.6140 - acc: 0.9114 - val_loss: 0.6906 - val_acc: 0.5000\n",
      "Epoch 648/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6129 - acc: 0.8481 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 649/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6131 - acc: 0.8354 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 650/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6134 - acc: 0.8608 - val_loss: 0.6861 - val_acc: 0.6000\n",
      "Epoch 651/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6119 - acc: 0.9241 - val_loss: 0.6845 - val_acc: 0.5500\n",
      "Epoch 652/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6139 - acc: 0.9241 - val_loss: 0.6828 - val_acc: 0.5500\n",
      "Epoch 653/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6112 - acc: 0.9494 - val_loss: 0.6840 - val_acc: 0.5500\n",
      "Epoch 654/3000\n",
      "79/79 [==============================] - 0s 194us/sample - loss: 0.6113 - acc: 0.9494 - val_loss: 0.6838 - val_acc: 0.5500\n",
      "Epoch 655/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6111 - acc: 0.9494 - val_loss: 0.6830 - val_acc: 0.6000\n",
      "Epoch 656/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6102 - acc: 0.9494 - val_loss: 0.6852 - val_acc: 0.6000\n",
      "Epoch 657/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6094 - acc: 0.9367 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 658/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6125 - acc: 0.8987 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 659/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6125 - acc: 0.7595 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 660/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6089 - acc: 0.8228 - val_loss: 0.6897 - val_acc: 0.4500\n",
      "Epoch 661/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6090 - acc: 0.8354 - val_loss: 0.6849 - val_acc: 0.6000\n",
      "Epoch 662/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6076 - acc: 0.9367 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 663/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6070 - acc: 0.9367 - val_loss: 0.6878 - val_acc: 0.4500\n",
      "Epoch 664/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6087 - acc: 0.9241 - val_loss: 0.6878 - val_acc: 0.4500\n",
      "Epoch 665/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6064 - acc: 0.8987 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 666/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6086 - acc: 0.8987 - val_loss: 0.6831 - val_acc: 0.5500\n",
      "Epoch 667/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6058 - acc: 0.9494 - val_loss: 0.6853 - val_acc: 0.6000\n",
      "Epoch 668/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6062 - acc: 0.8987 - val_loss: 0.6822 - val_acc: 0.6000\n",
      "Epoch 669/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6060 - acc: 0.9494 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 670/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6051 - acc: 0.9367 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 671/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6048 - acc: 0.9367 - val_loss: 0.6812 - val_acc: 0.6000\n",
      "Epoch 672/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6071 - acc: 0.9241 - val_loss: 0.6795 - val_acc: 0.6000\n",
      "Epoch 673/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6055 - acc: 0.9114 - val_loss: 0.6819 - val_acc: 0.6000\n",
      "Epoch 674/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6034 - acc: 0.9494 - val_loss: 0.6841 - val_acc: 0.6000\n",
      "Epoch 675/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6038 - acc: 0.9494 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 676/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6061 - acc: 0.8861 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 677/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6018 - acc: 0.8861 - val_loss: 0.6876 - val_acc: 0.5000\n",
      "Epoch 678/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6027 - acc: 0.8734 - val_loss: 0.6898 - val_acc: 0.4500\n",
      "Epoch 679/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6039 - acc: 0.8608 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 680/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6027 - acc: 0.8228 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 681/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6006 - acc: 0.8354 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 682/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6025 - acc: 0.7975 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 683/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.5995 - acc: 0.8734 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 684/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5986 - acc: 0.9367 - val_loss: 0.6824 - val_acc: 0.5500\n",
      "Epoch 685/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5987 - acc: 0.9494 - val_loss: 0.6860 - val_acc: 0.5500\n",
      "Epoch 686/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6000 - acc: 0.8861 - val_loss: 0.6831 - val_acc: 0.6000\n",
      "Epoch 687/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5974 - acc: 0.9494 - val_loss: 0.6850 - val_acc: 0.5500\n",
      "Epoch 688/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.5966 - acc: 0.9367 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 689/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5978 - acc: 0.8734 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 690/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5958 - acc: 0.8608 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 691/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5953 - acc: 0.8987 - val_loss: 0.6856 - val_acc: 0.5500\n",
      "Epoch 692/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5979 - acc: 0.8861 - val_loss: 0.6805 - val_acc: 0.6000\n",
      "Epoch 693/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5952 - acc: 0.9494 - val_loss: 0.6807 - val_acc: 0.5500\n",
      "Epoch 694/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5972 - acc: 0.9367 - val_loss: 0.6790 - val_acc: 0.6000\n",
      "Epoch 695/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5979 - acc: 0.8861 - val_loss: 0.6783 - val_acc: 0.6000\n",
      "Epoch 696/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5946 - acc: 0.8861 - val_loss: 0.6809 - val_acc: 0.5500\n",
      "Epoch 697/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5950 - acc: 0.9241 - val_loss: 0.6829 - val_acc: 0.5500\n",
      "Epoch 698/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5939 - acc: 0.9620 - val_loss: 0.6797 - val_acc: 0.6000\n",
      "Epoch 699/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5932 - acc: 0.9367 - val_loss: 0.6832 - val_acc: 0.6000\n",
      "Epoch 700/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5911 - acc: 0.9494 - val_loss: 0.6851 - val_acc: 0.5500\n",
      "Epoch 701/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.5919 - acc: 0.9114 - val_loss: 0.6879 - val_acc: 0.5000\n",
      "Epoch 702/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5905 - acc: 0.8987 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 703/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5933 - acc: 0.8987 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 704/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5895 - acc: 0.8987 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 705/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5890 - acc: 0.8734 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 706/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5897 - acc: 0.8734 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 707/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5941 - acc: 0.9114 - val_loss: 0.6803 - val_acc: 0.5500\n",
      "Epoch 708/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.5874 - acc: 0.9367 - val_loss: 0.6827 - val_acc: 0.6000\n",
      "Epoch 709/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5884 - acc: 0.9620 - val_loss: 0.6835 - val_acc: 0.6000\n",
      "Epoch 710/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5859 - acc: 0.9494 - val_loss: 0.6826 - val_acc: 0.6000\n",
      "Epoch 711/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5854 - acc: 0.9494 - val_loss: 0.6831 - val_acc: 0.6000\n",
      "Epoch 712/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5868 - acc: 0.9241 - val_loss: 0.6801 - val_acc: 0.6000\n",
      "Epoch 713/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5855 - acc: 0.9494 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 714/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5845 - acc: 0.9620 - val_loss: 0.6797 - val_acc: 0.5500\n",
      "Epoch 715/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5840 - acc: 0.9494 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 716/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.5829 - acc: 0.9494 - val_loss: 0.6814 - val_acc: 0.5500\n",
      "Epoch 717/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.5832 - acc: 0.9620 - val_loss: 0.6803 - val_acc: 0.6000\n",
      "Epoch 718/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5834 - acc: 0.9494 - val_loss: 0.6791 - val_acc: 0.5500\n",
      "Epoch 719/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5833 - acc: 0.9241 - val_loss: 0.6832 - val_acc: 0.6000\n",
      "Epoch 720/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5814 - acc: 0.9494 - val_loss: 0.6845 - val_acc: 0.5500\n",
      "Epoch 721/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5812 - acc: 0.9241 - val_loss: 0.6852 - val_acc: 0.6000\n",
      "Epoch 722/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5809 - acc: 0.8987 - val_loss: 0.6814 - val_acc: 0.6000\n",
      "Epoch 723/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5798 - acc: 0.9620 - val_loss: 0.6833 - val_acc: 0.6000\n",
      "Epoch 724/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5798 - acc: 0.9494 - val_loss: 0.6848 - val_acc: 0.5500\n",
      "Epoch 725/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.5796 - acc: 0.8861 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 726/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5783 - acc: 0.9241 - val_loss: 0.6795 - val_acc: 0.6000\n",
      "Epoch 727/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5776 - acc: 0.9620 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 728/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5770 - acc: 0.9620 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 729/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.5771 - acc: 0.9241 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 730/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5762 - acc: 0.9494 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 731/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5760 - acc: 0.9494 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 732/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.5783 - acc: 0.9494 - val_loss: 0.6789 - val_acc: 0.6000\n",
      "Epoch 733/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5742 - acc: 0.9494 - val_loss: 0.6778 - val_acc: 0.5500\n",
      "Epoch 734/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5743 - acc: 0.9494 - val_loss: 0.6784 - val_acc: 0.6000\n",
      "Epoch 735/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5728 - acc: 0.9620 - val_loss: 0.6783 - val_acc: 0.6000\n",
      "Epoch 736/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5721 - acc: 0.9620 - val_loss: 0.6790 - val_acc: 0.6000\n",
      "Epoch 737/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.5717 - acc: 0.9620 - val_loss: 0.6798 - val_acc: 0.6000\n",
      "Epoch 738/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5711 - acc: 0.9494 - val_loss: 0.6831 - val_acc: 0.6000\n",
      "Epoch 739/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.5707 - acc: 0.9367 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 740/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.5702 - acc: 0.9620 - val_loss: 0.6830 - val_acc: 0.6000\n",
      "Epoch 741/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5703 - acc: 0.9114 - val_loss: 0.6789 - val_acc: 0.6000\n",
      "Epoch 742/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5683 - acc: 0.9620 - val_loss: 0.6799 - val_acc: 0.5500\n",
      "Epoch 743/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5679 - acc: 0.9620 - val_loss: 0.6784 - val_acc: 0.6000\n",
      "Epoch 744/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5680 - acc: 0.9494 - val_loss: 0.6818 - val_acc: 0.6000\n",
      "Epoch 745/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5666 - acc: 0.9494 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 746/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5666 - acc: 0.9620 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "Epoch 747/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5664 - acc: 0.9367 - val_loss: 0.6822 - val_acc: 0.6000\n",
      "Epoch 748/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.5675 - acc: 0.9241 - val_loss: 0.6787 - val_acc: 0.6000\n",
      "Epoch 749/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5651 - acc: 0.9620 - val_loss: 0.6797 - val_acc: 0.6000\n",
      "Epoch 750/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5646 - acc: 0.9367 - val_loss: 0.6779 - val_acc: 0.6000\n",
      "Epoch 751/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5633 - acc: 0.9494 - val_loss: 0.6800 - val_acc: 0.6000\n",
      "Epoch 752/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5642 - acc: 0.9620 - val_loss: 0.6831 - val_acc: 0.5500\n",
      "Epoch 753/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5618 - acc: 0.9494 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 754/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5611 - acc: 0.9620 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 755/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5604 - acc: 0.9620 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "Epoch 756/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5600 - acc: 0.9367 - val_loss: 0.6830 - val_acc: 0.5500\n",
      "Epoch 757/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5604 - acc: 0.9367 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 758/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5590 - acc: 0.9494 - val_loss: 0.6772 - val_acc: 0.6000\n",
      "Epoch 759/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5583 - acc: 0.9620 - val_loss: 0.6802 - val_acc: 0.6000\n",
      "Epoch 760/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5569 - acc: 0.9494 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 761/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5570 - acc: 0.9494 - val_loss: 0.6779 - val_acc: 0.6000\n",
      "Epoch 762/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.5565 - acc: 0.9494 - val_loss: 0.6789 - val_acc: 0.6000\n",
      "Epoch 763/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5550 - acc: 0.9620 - val_loss: 0.6788 - val_acc: 0.6000\n",
      "Epoch 764/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5552 - acc: 0.9494 - val_loss: 0.6767 - val_acc: 0.6000\n",
      "Epoch 765/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.5546 - acc: 0.9367 - val_loss: 0.6777 - val_acc: 0.6000\n",
      "Epoch 766/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5545 - acc: 0.9494 - val_loss: 0.6778 - val_acc: 0.6000\n",
      "Epoch 767/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5525 - acc: 0.9620 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 768/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5515 - acc: 0.9620 - val_loss: 0.6776 - val_acc: 0.6000\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5513 - acc: 0.9620 - val_loss: 0.6760 - val_acc: 0.6000\n",
      "Epoch 770/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5522 - acc: 0.9620 - val_loss: 0.6766 - val_acc: 0.6000\n",
      "Epoch 771/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5505 - acc: 0.9620 - val_loss: 0.6754 - val_acc: 0.6000\n",
      "Epoch 772/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5494 - acc: 0.9494 - val_loss: 0.6768 - val_acc: 0.6000\n",
      "Epoch 773/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5498 - acc: 0.9367 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 774/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5511 - acc: 0.9494 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 775/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.5469 - acc: 0.9620 - val_loss: 0.6785 - val_acc: 0.6000\n",
      "Epoch 776/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5466 - acc: 0.9494 - val_loss: 0.6757 - val_acc: 0.6000\n",
      "Epoch 777/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5458 - acc: 0.9620 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 778/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5453 - acc: 0.9620 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 779/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.5445 - acc: 0.9620 - val_loss: 0.6814 - val_acc: 0.6000\n",
      "Epoch 780/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5434 - acc: 0.9494 - val_loss: 0.6810 - val_acc: 0.6000\n",
      "Epoch 781/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5425 - acc: 0.9494 - val_loss: 0.6789 - val_acc: 0.6000\n",
      "Epoch 782/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5452 - acc: 0.9494 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 783/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5470 - acc: 0.8987 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 784/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5424 - acc: 0.8861 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 785/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5398 - acc: 0.9494 - val_loss: 0.6790 - val_acc: 0.6000\n",
      "Epoch 786/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.5412 - acc: 0.9620 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 787/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5400 - acc: 0.9114 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 788/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.5401 - acc: 0.9494 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 789/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5394 - acc: 0.9241 - val_loss: 0.6833 - val_acc: 0.5500\n",
      "Epoch 790/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.5373 - acc: 0.9367 - val_loss: 0.6829 - val_acc: 0.5500\n",
      "Epoch 791/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5363 - acc: 0.9367 - val_loss: 0.6817 - val_acc: 0.6000\n",
      "Epoch 792/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.5372 - acc: 0.9367 - val_loss: 0.6750 - val_acc: 0.6000\n",
      "Epoch 793/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5361 - acc: 0.9494 - val_loss: 0.6791 - val_acc: 0.6000\n",
      "Epoch 794/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5332 - acc: 0.9620 - val_loss: 0.6760 - val_acc: 0.6000\n",
      "Epoch 795/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5321 - acc: 0.9620 - val_loss: 0.6765 - val_acc: 0.6500\n",
      "Epoch 796/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5322 - acc: 0.9620 - val_loss: 0.6742 - val_acc: 0.6000\n",
      "Epoch 797/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5319 - acc: 0.9367 - val_loss: 0.6772 - val_acc: 0.6000\n",
      "Epoch 798/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.5305 - acc: 0.9620 - val_loss: 0.6765 - val_acc: 0.6500\n",
      "Epoch 799/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5300 - acc: 0.9620 - val_loss: 0.6781 - val_acc: 0.6000\n",
      "Epoch 800/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5284 - acc: 0.9747 - val_loss: 0.6776 - val_acc: 0.6000\n",
      "Epoch 801/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5280 - acc: 0.9620 - val_loss: 0.6774 - val_acc: 0.6000\n",
      "Epoch 802/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5267 - acc: 0.9620 - val_loss: 0.6773 - val_acc: 0.6000\n",
      "Epoch 803/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5269 - acc: 0.9620 - val_loss: 0.6778 - val_acc: 0.6000\n",
      "Epoch 804/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5289 - acc: 0.9620 - val_loss: 0.6777 - val_acc: 0.6000\n",
      "Epoch 805/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5249 - acc: 0.9620 - val_loss: 0.6753 - val_acc: 0.6000\n",
      "Epoch 806/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5236 - acc: 0.9620 - val_loss: 0.6777 - val_acc: 0.6000\n",
      "Epoch 807/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.5232 - acc: 0.9747 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "Epoch 808/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5231 - acc: 0.9367 - val_loss: 0.6738 - val_acc: 0.6000\n",
      "Epoch 809/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5205 - acc: 0.9620 - val_loss: 0.6756 - val_acc: 0.6500\n",
      "Epoch 810/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5208 - acc: 0.9620 - val_loss: 0.6753 - val_acc: 0.6500\n",
      "Epoch 811/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5206 - acc: 0.9747 - val_loss: 0.6717 - val_acc: 0.6000\n",
      "Epoch 812/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5183 - acc: 0.9620 - val_loss: 0.6721 - val_acc: 0.6000\n",
      "Epoch 813/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5178 - acc: 0.9494 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "Epoch 814/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5175 - acc: 0.9620 - val_loss: 0.6743 - val_acc: 0.6000\n",
      "Epoch 815/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5157 - acc: 0.9620 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 816/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.5147 - acc: 0.9620 - val_loss: 0.6730 - val_acc: 0.6000\n",
      "Epoch 817/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5139 - acc: 0.9620 - val_loss: 0.6735 - val_acc: 0.6000\n",
      "Epoch 818/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5136 - acc: 0.9620 - val_loss: 0.6746 - val_acc: 0.6000\n",
      "Epoch 819/3000\n",
      "79/79 [==============================] - 0s 220us/sample - loss: 0.5134 - acc: 0.9620 - val_loss: 0.6734 - val_acc: 0.6000\n",
      "Epoch 820/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5118 - acc: 0.9620 - val_loss: 0.6737 - val_acc: 0.6000\n",
      "Epoch 821/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5115 - acc: 0.9620 - val_loss: 0.6774 - val_acc: 0.6000\n",
      "Epoch 822/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5100 - acc: 0.9620 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "Epoch 823/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5110 - acc: 0.9367 - val_loss: 0.6704 - val_acc: 0.6000\n",
      "Epoch 824/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5092 - acc: 0.9494 - val_loss: 0.6699 - val_acc: 0.6000\n",
      "Epoch 825/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.5082 - acc: 0.9620 - val_loss: 0.6725 - val_acc: 0.6000\n",
      "Epoch 826/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5063 - acc: 0.9620 - val_loss: 0.6730 - val_acc: 0.6000\n",
      "Epoch 827/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5053 - acc: 0.9620 - val_loss: 0.6722 - val_acc: 0.6000\n",
      "Epoch 828/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 143us/sample - loss: 0.5047 - acc: 0.9494 - val_loss: 0.6727 - val_acc: 0.6000\n",
      "Epoch 829/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.5035 - acc: 0.9620 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 830/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5030 - acc: 0.9620 - val_loss: 0.6707 - val_acc: 0.6000\n",
      "Epoch 831/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.5023 - acc: 0.9494 - val_loss: 0.6727 - val_acc: 0.6000\n",
      "Epoch 832/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5021 - acc: 0.9620 - val_loss: 0.6703 - val_acc: 0.6000\n",
      "Epoch 833/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5018 - acc: 0.9494 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 834/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5007 - acc: 0.9494 - val_loss: 0.6702 - val_acc: 0.6000\n",
      "Epoch 835/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4983 - acc: 0.9494 - val_loss: 0.6722 - val_acc: 0.6000\n",
      "Epoch 836/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4974 - acc: 0.9620 - val_loss: 0.6711 - val_acc: 0.6000\n",
      "Epoch 837/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.4968 - acc: 0.9494 - val_loss: 0.6706 - val_acc: 0.6000\n",
      "Epoch 838/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4958 - acc: 0.9620 - val_loss: 0.6698 - val_acc: 0.6000\n",
      "Epoch 839/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4951 - acc: 0.9494 - val_loss: 0.6712 - val_acc: 0.6000\n",
      "Epoch 840/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4944 - acc: 0.9620 - val_loss: 0.6695 - val_acc: 0.6000\n",
      "Epoch 841/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4938 - acc: 0.9494 - val_loss: 0.6739 - val_acc: 0.6500\n",
      "Epoch 842/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4917 - acc: 0.9620 - val_loss: 0.6749 - val_acc: 0.6000\n",
      "Epoch 843/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4908 - acc: 0.9747 - val_loss: 0.6729 - val_acc: 0.6000\n",
      "Epoch 844/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4900 - acc: 0.9620 - val_loss: 0.6750 - val_acc: 0.6000\n",
      "Epoch 845/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.4890 - acc: 0.9747 - val_loss: 0.6726 - val_acc: 0.6000\n",
      "Epoch 846/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4904 - acc: 0.9620 - val_loss: 0.6712 - val_acc: 0.6000\n",
      "Epoch 847/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.4879 - acc: 0.9494 - val_loss: 0.6756 - val_acc: 0.6000\n",
      "Epoch 848/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.4924 - acc: 0.9747 - val_loss: 0.6746 - val_acc: 0.6500\n",
      "Epoch 849/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4864 - acc: 0.9620 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "Epoch 850/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4849 - acc: 0.9620 - val_loss: 0.6725 - val_acc: 0.6000\n",
      "Epoch 851/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.4833 - acc: 0.9620 - val_loss: 0.6717 - val_acc: 0.6000\n",
      "Epoch 852/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4823 - acc: 0.9620 - val_loss: 0.6697 - val_acc: 0.6000\n",
      "Epoch 853/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4812 - acc: 0.9494 - val_loss: 0.6711 - val_acc: 0.6000\n",
      "Epoch 854/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4804 - acc: 0.9620 - val_loss: 0.6724 - val_acc: 0.6000\n",
      "Epoch 855/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4794 - acc: 0.9620 - val_loss: 0.6726 - val_acc: 0.6000\n",
      "Epoch 856/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.4786 - acc: 0.9620 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 857/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4812 - acc: 0.9494 - val_loss: 0.6694 - val_acc: 0.6000\n",
      "Epoch 858/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.4770 - acc: 0.9620 - val_loss: 0.6680 - val_acc: 0.6000\n",
      "Epoch 859/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4776 - acc: 0.9620 - val_loss: 0.6699 - val_acc: 0.6000\n",
      "Epoch 860/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.4754 - acc: 0.9620 - val_loss: 0.6691 - val_acc: 0.6000\n",
      "Epoch 861/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4736 - acc: 0.9494 - val_loss: 0.6705 - val_acc: 0.6000\n",
      "Epoch 862/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4736 - acc: 0.9747 - val_loss: 0.6673 - val_acc: 0.6000\n",
      "Epoch 863/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4726 - acc: 0.9494 - val_loss: 0.6689 - val_acc: 0.6000\n",
      "Epoch 864/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.4711 - acc: 0.9494 - val_loss: 0.6691 - val_acc: 0.6000\n",
      "Epoch 865/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4702 - acc: 0.9494 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 866/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4689 - acc: 0.9620 - val_loss: 0.6714 - val_acc: 0.6000\n",
      "Epoch 867/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.4691 - acc: 0.9620 - val_loss: 0.6743 - val_acc: 0.6000\n",
      "Epoch 868/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4683 - acc: 0.9620 - val_loss: 0.6748 - val_acc: 0.6000\n",
      "Epoch 869/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.4674 - acc: 0.9620 - val_loss: 0.6771 - val_acc: 0.6000\n",
      "Epoch 870/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.4662 - acc: 0.9620 - val_loss: 0.6742 - val_acc: 0.6500\n",
      "Epoch 871/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4640 - acc: 0.9747 - val_loss: 0.6716 - val_acc: 0.6000\n",
      "Epoch 872/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4626 - acc: 0.9620 - val_loss: 0.6720 - val_acc: 0.6000\n",
      "Epoch 873/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.4630 - acc: 0.9494 - val_loss: 0.6697 - val_acc: 0.6000\n",
      "Epoch 874/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4606 - acc: 0.9620 - val_loss: 0.6707 - val_acc: 0.6000\n",
      "Epoch 875/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4600 - acc: 0.9620 - val_loss: 0.6736 - val_acc: 0.6000\n",
      "Epoch 876/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4591 - acc: 0.9747 - val_loss: 0.6705 - val_acc: 0.6000\n",
      "Epoch 877/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4576 - acc: 0.9620 - val_loss: 0.6729 - val_acc: 0.5500\n",
      "Epoch 878/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4569 - acc: 0.9747 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 879/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4551 - acc: 0.9494 - val_loss: 0.6694 - val_acc: 0.6000\n",
      "Epoch 880/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4547 - acc: 0.9620 - val_loss: 0.6676 - val_acc: 0.6000\n",
      "Epoch 881/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4537 - acc: 0.9494 - val_loss: 0.6696 - val_acc: 0.6000\n",
      "Epoch 882/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.4525 - acc: 0.9747 - val_loss: 0.6681 - val_acc: 0.6000\n",
      "Epoch 883/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4510 - acc: 0.9494 - val_loss: 0.6682 - val_acc: 0.6000\n",
      "Epoch 884/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4502 - acc: 0.9494 - val_loss: 0.6697 - val_acc: 0.6000\n",
      "Epoch 885/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4496 - acc: 0.9620 - val_loss: 0.6684 - val_acc: 0.6000\n",
      "Epoch 886/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4474 - acc: 0.9620 - val_loss: 0.6691 - val_acc: 0.6000\n",
      "Epoch 887/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 168us/sample - loss: 0.4467 - acc: 0.9620 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 888/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4470 - acc: 0.9494 - val_loss: 0.6681 - val_acc: 0.6000\n",
      "Epoch 889/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4448 - acc: 0.9620 - val_loss: 0.6673 - val_acc: 0.6000\n",
      "Epoch 890/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.4452 - acc: 0.9620 - val_loss: 0.6733 - val_acc: 0.6000\n",
      "Epoch 891/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4428 - acc: 0.9747 - val_loss: 0.6689 - val_acc: 0.6000\n",
      "Epoch 892/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4419 - acc: 0.9747 - val_loss: 0.6661 - val_acc: 0.6000\n",
      "Epoch 893/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.4422 - acc: 0.9620 - val_loss: 0.6683 - val_acc: 0.6000\n",
      "Epoch 894/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4387 - acc: 0.9620 - val_loss: 0.6691 - val_acc: 0.6000\n",
      "Epoch 895/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4391 - acc: 0.9620 - val_loss: 0.6655 - val_acc: 0.6000\n",
      "Epoch 896/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4378 - acc: 0.9620 - val_loss: 0.6662 - val_acc: 0.6000\n",
      "Epoch 897/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4414 - acc: 0.9620 - val_loss: 0.6688 - val_acc: 0.6000\n",
      "Epoch 898/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.4355 - acc: 0.9747 - val_loss: 0.6682 - val_acc: 0.6000\n",
      "Epoch 899/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4377 - acc: 0.9620 - val_loss: 0.6691 - val_acc: 0.6000\n",
      "Epoch 900/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4338 - acc: 0.9747 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 901/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4342 - acc: 0.9620 - val_loss: 0.6637 - val_acc: 0.6000\n",
      "Epoch 902/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4320 - acc: 0.9747 - val_loss: 0.6629 - val_acc: 0.6000\n",
      "Epoch 903/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.4326 - acc: 0.9494 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 904/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4289 - acc: 0.9620 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 905/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4281 - acc: 0.9747 - val_loss: 0.6669 - val_acc: 0.6000\n",
      "Epoch 906/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4271 - acc: 0.9620 - val_loss: 0.6689 - val_acc: 0.6000\n",
      "Epoch 907/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.4263 - acc: 0.9747 - val_loss: 0.6654 - val_acc: 0.6000\n",
      "Epoch 908/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4252 - acc: 0.9494 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 909/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4233 - acc: 0.9747 - val_loss: 0.6666 - val_acc: 0.6000\n",
      "Epoch 910/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4219 - acc: 0.9620 - val_loss: 0.6658 - val_acc: 0.6000\n",
      "Epoch 911/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4215 - acc: 0.9620 - val_loss: 0.6657 - val_acc: 0.6000\n",
      "Epoch 912/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4203 - acc: 0.9747 - val_loss: 0.6664 - val_acc: 0.6000\n",
      "Epoch 913/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4243 - acc: 0.9620 - val_loss: 0.6649 - val_acc: 0.6000\n",
      "Epoch 914/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.4177 - acc: 0.9620 - val_loss: 0.6643 - val_acc: 0.6000\n",
      "Epoch 915/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4172 - acc: 0.9620 - val_loss: 0.6648 - val_acc: 0.6000\n",
      "Epoch 916/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4154 - acc: 0.9620 - val_loss: 0.6653 - val_acc: 0.6000\n",
      "Epoch 917/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4170 - acc: 0.9747 - val_loss: 0.6671 - val_acc: 0.6000\n",
      "Epoch 918/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.4030 - acc: 0.968 - 0s 139us/sample - loss: 0.4141 - acc: 0.9747 - val_loss: 0.6694 - val_acc: 0.6000\n",
      "Epoch 919/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4124 - acc: 0.9747 - val_loss: 0.6679 - val_acc: 0.6000\n",
      "Epoch 920/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4109 - acc: 0.9747 - val_loss: 0.6670 - val_acc: 0.6000\n",
      "Epoch 921/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4101 - acc: 0.9747 - val_loss: 0.6649 - val_acc: 0.6000\n",
      "Epoch 922/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.4099 - acc: 0.9747 - val_loss: 0.6662 - val_acc: 0.6000\n",
      "Epoch 923/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4080 - acc: 0.9620 - val_loss: 0.6657 - val_acc: 0.6000\n",
      "Epoch 924/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4060 - acc: 0.9747 - val_loss: 0.6663 - val_acc: 0.6000\n",
      "Epoch 925/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.4085 - acc: 0.9620 - val_loss: 0.6638 - val_acc: 0.6000\n",
      "Epoch 926/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4052 - acc: 0.9747 - val_loss: 0.6640 - val_acc: 0.6000\n",
      "Epoch 927/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4036 - acc: 0.9747 - val_loss: 0.6678 - val_acc: 0.6000\n",
      "Epoch 928/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4068 - acc: 0.9620 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "Epoch 929/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.4020 - acc: 0.9620 - val_loss: 0.6635 - val_acc: 0.6000\n",
      "Epoch 930/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3995 - acc: 0.9747 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 931/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3984 - acc: 0.9747 - val_loss: 0.6634 - val_acc: 0.6000\n",
      "Epoch 932/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.3971 - acc: 0.9747 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 933/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3960 - acc: 0.9747 - val_loss: 0.6644 - val_acc: 0.6000\n",
      "Epoch 934/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3954 - acc: 0.9747 - val_loss: 0.6678 - val_acc: 0.6000\n",
      "Epoch 935/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3940 - acc: 0.9747 - val_loss: 0.6666 - val_acc: 0.6000\n",
      "Epoch 936/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3932 - acc: 0.9620 - val_loss: 0.6661 - val_acc: 0.6000\n",
      "Epoch 937/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3916 - acc: 0.9747 - val_loss: 0.6643 - val_acc: 0.6000\n",
      "Epoch 938/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3902 - acc: 0.9747 - val_loss: 0.6653 - val_acc: 0.6000\n",
      "Epoch 939/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.3891 - acc: 0.9747 - val_loss: 0.6669 - val_acc: 0.6000\n",
      "Epoch 940/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3896 - acc: 0.9620 - val_loss: 0.6636 - val_acc: 0.6000\n",
      "Epoch 941/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3870 - acc: 0.9620 - val_loss: 0.6657 - val_acc: 0.6000\n",
      "Epoch 942/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3867 - acc: 0.9747 - val_loss: 0.6631 - val_acc: 0.6000\n",
      "Epoch 943/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3860 - acc: 0.9620 - val_loss: 0.6672 - val_acc: 0.6000\n",
      "Epoch 944/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3844 - acc: 0.9747 - val_loss: 0.6645 - val_acc: 0.6000\n",
      "Epoch 945/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3822 - acc: 0.9747 - val_loss: 0.6648 - val_acc: 0.6000\n",
      "Epoch 946/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 161us/sample - loss: 0.3823 - acc: 0.9747 - val_loss: 0.6633 - val_acc: 0.6000\n",
      "Epoch 947/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.3800 - acc: 0.9620 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 948/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3817 - acc: 0.9747 - val_loss: 0.6628 - val_acc: 0.6000\n",
      "Epoch 949/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.3789 - acc: 0.9620 - val_loss: 0.6666 - val_acc: 0.6000\n",
      "Epoch 950/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.3769 - acc: 0.9747 - val_loss: 0.6688 - val_acc: 0.6000\n",
      "Epoch 951/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3767 - acc: 0.9747 - val_loss: 0.6681 - val_acc: 0.6000\n",
      "Epoch 952/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.3753 - acc: 0.9747 - val_loss: 0.6658 - val_acc: 0.6000\n",
      "Epoch 953/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3734 - acc: 0.9747 - val_loss: 0.6653 - val_acc: 0.6000\n",
      "Epoch 954/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3721 - acc: 0.9747 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 955/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.3720 - acc: 0.9747 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 956/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3698 - acc: 0.9747 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 957/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3714 - acc: 0.9620 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 958/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.3688 - acc: 0.9747 - val_loss: 0.6710 - val_acc: 0.6000\n",
      "Epoch 959/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3671 - acc: 0.9747 - val_loss: 0.6701 - val_acc: 0.6000\n",
      "Epoch 960/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3669 - acc: 0.9873 - val_loss: 0.6701 - val_acc: 0.6000\n",
      "Epoch 961/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3643 - acc: 0.9873 - val_loss: 0.6695 - val_acc: 0.6000\n",
      "Epoch 962/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3651 - acc: 0.9747 - val_loss: 0.6688 - val_acc: 0.6000\n",
      "Epoch 963/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3623 - acc: 0.9747 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 964/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3608 - acc: 0.9747 - val_loss: 0.6693 - val_acc: 0.6000\n",
      "Epoch 965/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.3605 - acc: 0.9747 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 966/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3586 - acc: 0.9747 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 967/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.3582 - acc: 0.9873 - val_loss: 0.6721 - val_acc: 0.6000\n",
      "Epoch 968/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3570 - acc: 0.9747 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 969/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3585 - acc: 0.9873 - val_loss: 0.6649 - val_acc: 0.5500\n",
      "Epoch 970/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3563 - acc: 0.9747 - val_loss: 0.6652 - val_acc: 0.6000\n",
      "Epoch 971/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3537 - acc: 0.9620 - val_loss: 0.6669 - val_acc: 0.6000\n",
      "Epoch 972/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3517 - acc: 0.9747 - val_loss: 0.6665 - val_acc: 0.6000\n",
      "Epoch 973/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.3505 - acc: 0.9747 - val_loss: 0.6670 - val_acc: 0.6000\n",
      "Epoch 974/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3505 - acc: 0.9747 - val_loss: 0.6655 - val_acc: 0.6000\n",
      "Epoch 975/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.3490 - acc: 0.9620 - val_loss: 0.6658 - val_acc: 0.6000\n",
      "Epoch 976/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3506 - acc: 0.9747 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "Epoch 977/3000\n",
      "79/79 [==============================] - 0s 179us/sample - loss: 0.3458 - acc: 0.9747 - val_loss: 0.6680 - val_acc: 0.6000\n",
      "Epoch 978/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.3463 - acc: 0.9747 - val_loss: 0.6657 - val_acc: 0.6000\n",
      "Epoch 979/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3450 - acc: 0.9747 - val_loss: 0.6680 - val_acc: 0.6000\n",
      "Epoch 980/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3421 - acc: 0.9747 - val_loss: 0.6667 - val_acc: 0.6000\n",
      "Epoch 981/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3434 - acc: 0.9747 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 982/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.3420 - acc: 0.9620 - val_loss: 0.6652 - val_acc: 0.6000\n",
      "Epoch 983/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3391 - acc: 0.9747 - val_loss: 0.6678 - val_acc: 0.6000\n",
      "Epoch 984/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.3391 - acc: 0.9747 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 985/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3375 - acc: 0.9873 - val_loss: 0.6667 - val_acc: 0.6000\n",
      "Epoch 986/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.3389 - acc: 0.9747 - val_loss: 0.6703 - val_acc: 0.6000\n",
      "Epoch 987/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3357 - acc: 0.9873 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "Epoch 988/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3345 - acc: 0.9747 - val_loss: 0.6667 - val_acc: 0.6000\n",
      "Epoch 989/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3334 - acc: 0.9747 - val_loss: 0.6699 - val_acc: 0.6000\n",
      "Epoch 990/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3317 - acc: 0.9747 - val_loss: 0.6710 - val_acc: 0.6000\n",
      "Epoch 991/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3309 - acc: 0.9747 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3306 - acc: 0.9747 - val_loss: 0.6748 - val_acc: 0.6500\n",
      "Epoch 993/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3289 - acc: 0.9873 - val_loss: 0.6717 - val_acc: 0.6000\n",
      "Epoch 994/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3270 - acc: 0.9873 - val_loss: 0.6706 - val_acc: 0.6000\n",
      "Epoch 995/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3255 - acc: 0.9873 - val_loss: 0.6703 - val_acc: 0.6000\n",
      "Epoch 996/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.3251 - acc: 0.9873 - val_loss: 0.6669 - val_acc: 0.6000\n",
      "Epoch 997/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.3235 - acc: 0.9747 - val_loss: 0.6676 - val_acc: 0.6000\n",
      "Epoch 998/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3224 - acc: 0.9747 - val_loss: 0.6682 - val_acc: 0.6000\n",
      "Epoch 999/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3213 - acc: 0.9747 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 1000/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3206 - acc: 0.9747 - val_loss: 0.6661 - val_acc: 0.6000\n",
      "Epoch 1001/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.3196 - acc: 0.9747 - val_loss: 0.6665 - val_acc: 0.6000\n",
      "Epoch 1002/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3177 - acc: 0.9747 - val_loss: 0.6704 - val_acc: 0.6000\n",
      "Epoch 1003/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.3167 - acc: 0.9873 - val_loss: 0.6689 - val_acc: 0.6000\n",
      "Epoch 1004/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3146 - acc: 0.9747 - val_loss: 0.6690 - val_acc: 0.6000\n",
      "Epoch 1005/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 163us/sample - loss: 0.3148 - acc: 0.9747 - val_loss: 0.6717 - val_acc: 0.6000\n",
      "Epoch 1006/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3141 - acc: 0.9873 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 1007/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3121 - acc: 0.9747 - val_loss: 0.6753 - val_acc: 0.6000\n",
      "Epoch 1008/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3106 - acc: 0.9873 - val_loss: 0.6734 - val_acc: 0.6000\n",
      "Epoch 1009/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3092 - acc: 0.9873 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 1010/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3088 - acc: 0.9873 - val_loss: 0.6753 - val_acc: 0.6000\n",
      "Epoch 1011/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3083 - acc: 0.9873 - val_loss: 0.6734 - val_acc: 0.6000\n",
      "Epoch 1012/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3065 - acc: 0.9873 - val_loss: 0.6760 - val_acc: 0.6000\n",
      "Epoch 1013/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.3073 - acc: 0.9747 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 1014/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.3050 - acc: 0.9747 - val_loss: 0.6812 - val_acc: 0.6000\n",
      "Epoch 1015/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3028 - acc: 0.9873 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 1016/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.3012 - acc: 0.9873 - val_loss: 0.6784 - val_acc: 0.6000\n",
      "Epoch 1017/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2993 - acc: 0.9873 - val_loss: 0.6752 - val_acc: 0.6000\n",
      "Epoch 1018/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3114 - acc: 1.000 - 0s 139us/sample - loss: 0.2984 - acc: 0.9873 - val_loss: 0.6755 - val_acc: 0.6000\n",
      "Epoch 1019/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2985 - acc: 0.9747 - val_loss: 0.6681 - val_acc: 0.6000\n",
      "Epoch 1020/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.2966 - acc: 0.9747 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "Epoch 1021/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.2951 - acc: 0.9873 - val_loss: 0.6761 - val_acc: 0.6000\n",
      "Epoch 1022/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2946 - acc: 0.9747 - val_loss: 0.6733 - val_acc: 0.6000\n",
      "Epoch 1023/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2928 - acc: 0.9747 - val_loss: 0.6712 - val_acc: 0.6000\n",
      "Epoch 1024/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.2919 - acc: 0.9747 - val_loss: 0.6761 - val_acc: 0.6000\n",
      "Epoch 1025/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2912 - acc: 0.9747 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 1026/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2918 - acc: 0.9747 - val_loss: 0.6834 - val_acc: 0.6000\n",
      "Epoch 1027/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2892 - acc: 0.9873 - val_loss: 0.6723 - val_acc: 0.6000\n",
      "Epoch 1028/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.2875 - acc: 0.9747 - val_loss: 0.6759 - val_acc: 0.6000\n",
      "Epoch 1029/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2868 - acc: 0.9747 - val_loss: 0.6781 - val_acc: 0.6000\n",
      "Epoch 1030/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2842 - acc: 0.9873 - val_loss: 0.6787 - val_acc: 0.6000\n",
      "Epoch 1031/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2845 - acc: 0.9873 - val_loss: 0.6754 - val_acc: 0.6000\n",
      "Epoch 1032/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2826 - acc: 0.9747 - val_loss: 0.6758 - val_acc: 0.6000\n",
      "Epoch 1033/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.2819 - acc: 0.9747 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 1034/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2837 - acc: 0.9747 - val_loss: 0.6720 - val_acc: 0.6000\n",
      "Epoch 1035/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2825 - acc: 0.9747 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 1036/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.2807 - acc: 0.9747 - val_loss: 0.6735 - val_acc: 0.6000\n",
      "Epoch 1037/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.2807 - acc: 0.9747 - val_loss: 0.6765 - val_acc: 0.6000\n",
      "Epoch 1038/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.2799 - acc: 0.9747 - val_loss: 0.6798 - val_acc: 0.6000\n",
      "Epoch 1039/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.2780 - acc: 0.9873 - val_loss: 0.6751 - val_acc: 0.6000\n",
      "Epoch 1040/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.2769 - acc: 0.9747 - val_loss: 0.6798 - val_acc: 0.6000\n",
      "Epoch 1041/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2759 - acc: 0.9873 - val_loss: 0.6794 - val_acc: 0.6000\n",
      "Epoch 1042/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2737 - acc: 0.9873 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 1043/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2749 - acc: 0.9747 - val_loss: 0.6862 - val_acc: 0.6000\n",
      "Epoch 1044/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2757 - acc: 0.9873 - val_loss: 0.6793 - val_acc: 0.6000\n",
      "Epoch 1045/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.2708 - acc: 0.9873 - val_loss: 0.6776 - val_acc: 0.6000\n",
      "Epoch 1046/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.2708 - acc: 0.9747 - val_loss: 0.6787 - val_acc: 0.6000\n",
      "Epoch 1047/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2695 - acc: 0.9747 - val_loss: 0.6813 - val_acc: 0.6000\n",
      "Epoch 1048/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.2675 - acc: 0.9873 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 1049/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2668 - acc: 0.9873 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 1050/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2652 - acc: 0.9873 - val_loss: 0.6813 - val_acc: 0.6000\n",
      "Epoch 1051/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2651 - acc: 0.9873 - val_loss: 0.6803 - val_acc: 0.6000\n",
      "Epoch 1052/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2634 - acc: 0.9873 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 1053/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2626 - acc: 0.9747 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 1054/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2616 - acc: 0.9873 - val_loss: 0.6814 - val_acc: 0.6000\n",
      "Epoch 1055/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2608 - acc: 0.9873 - val_loss: 0.6834 - val_acc: 0.6000\n",
      "Epoch 1056/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.2596 - acc: 0.9873 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 1057/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2588 - acc: 0.9747 - val_loss: 0.6845 - val_acc: 0.6000\n",
      "Epoch 1058/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.2574 - acc: 0.9873 - val_loss: 0.6842 - val_acc: 0.6000\n",
      "Epoch 1059/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2570 - acc: 0.9873 - val_loss: 0.6818 - val_acc: 0.6000\n",
      "Epoch 1060/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.2554 - acc: 0.9747 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "Epoch 1061/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2550 - acc: 0.9747 - val_loss: 0.6825 - val_acc: 0.6000\n",
      "Epoch 1062/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.2539 - acc: 0.9747 - val_loss: 0.6833 - val_acc: 0.6000\n",
      "Epoch 1063/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.2526 - acc: 0.9873 - val_loss: 0.6830 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1064/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.2517 - acc: 0.9747 - val_loss: 0.6839 - val_acc: 0.6000\n",
      "Epoch 1065/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.2527 - acc: 0.9873 - val_loss: 0.6834 - val_acc: 0.6000\n",
      "Epoch 1066/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2497 - acc: 0.9747 - val_loss: 0.6845 - val_acc: 0.6000\n",
      "Epoch 1067/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2498 - acc: 0.9873 - val_loss: 0.6826 - val_acc: 0.6000\n",
      "Epoch 1068/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2498 - acc: 0.9747 - val_loss: 0.6845 - val_acc: 0.6000\n",
      "Epoch 1069/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2479 - acc: 0.9873 - val_loss: 0.6817 - val_acc: 0.6000\n",
      "Epoch 1070/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2460 - acc: 0.9873 - val_loss: 0.6815 - val_acc: 0.6000\n",
      "Epoch 1071/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.2458 - acc: 0.9873 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 1072/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.2460 - acc: 0.9747 - val_loss: 0.6812 - val_acc: 0.6000\n",
      "Epoch 1073/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2433 - acc: 0.9747 - val_loss: 0.6824 - val_acc: 0.6000\n",
      "Epoch 1074/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2428 - acc: 0.9873 - val_loss: 0.6864 - val_acc: 0.6000\n",
      "Epoch 1075/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2409 - acc: 0.9873 - val_loss: 0.6850 - val_acc: 0.6000\n",
      "Epoch 1076/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2409 - acc: 0.9873 - val_loss: 0.6882 - val_acc: 0.6000\n",
      "Epoch 1077/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.2400 - acc: 0.9873 - val_loss: 0.6936 - val_acc: 0.6000\n",
      "Epoch 1078/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2395 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.6000\n",
      "Epoch 1079/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2377 - acc: 0.9873 - val_loss: 0.6902 - val_acc: 0.6000\n",
      "Epoch 1080/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2362 - acc: 0.9873 - val_loss: 0.6920 - val_acc: 0.6000\n",
      "Epoch 1081/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.2352 - acc: 0.9873 - val_loss: 0.6932 - val_acc: 0.6000\n",
      "Epoch 1082/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.2347 - acc: 1.0000 - val_loss: 0.6923 - val_acc: 0.6000\n",
      "Epoch 1083/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2334 - acc: 0.9873 - val_loss: 0.6931 - val_acc: 0.6000\n",
      "Epoch 1084/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2333 - acc: 0.9873 - val_loss: 0.6920 - val_acc: 0.6000\n",
      "Epoch 1085/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2319 - acc: 0.9873 - val_loss: 0.6938 - val_acc: 0.6000\n",
      "Epoch 1086/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2333 - acc: 0.9873 - val_loss: 0.6923 - val_acc: 0.6500\n",
      "Epoch 1087/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.2321 - acc: 0.9747 - val_loss: 0.6950 - val_acc: 0.6000\n",
      "Epoch 1088/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.2289 - acc: 0.9873 - val_loss: 0.6966 - val_acc: 0.6000\n",
      "Epoch 1089/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2280 - acc: 1.0000 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 1090/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.2271 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.6000\n",
      "Epoch 1091/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2276 - acc: 0.9873 - val_loss: 0.6987 - val_acc: 0.6000\n",
      "Epoch 1092/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2257 - acc: 1.0000 - val_loss: 0.6972 - val_acc: 0.6000\n",
      "Epoch 1093/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2242 - acc: 1.0000 - val_loss: 0.6977 - val_acc: 0.6000\n",
      "Epoch 1094/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2235 - acc: 0.9873 - val_loss: 0.6992 - val_acc: 0.6000\n",
      "Epoch 1095/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2234 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.6000\n",
      "Epoch 1096/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2229 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.6000\n",
      "Epoch 1097/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2217 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.6000\n",
      "Epoch 1098/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2209 - acc: 1.0000 - val_loss: 0.6990 - val_acc: 0.6000\n",
      "Epoch 1099/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.2193 - acc: 0.9873 - val_loss: 0.7005 - val_acc: 0.6000\n",
      "Epoch 1100/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.2190 - acc: 1.0000 - val_loss: 0.7000 - val_acc: 0.6000\n",
      "Epoch 1101/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2179 - acc: 0.9873 - val_loss: 0.7000 - val_acc: 0.6000\n",
      "Epoch 1102/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.2170 - acc: 1.0000 - val_loss: 0.6993 - val_acc: 0.6000\n",
      "Epoch 1103/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.2160 - acc: 0.9873 - val_loss: 0.7020 - val_acc: 0.6000\n",
      "Epoch 1104/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.2151 - acc: 1.0000 - val_loss: 0.7000 - val_acc: 0.6000\n",
      "Epoch 1105/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2139 - acc: 1.0000 - val_loss: 0.7009 - val_acc: 0.6000\n",
      "Epoch 1106/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2141 - acc: 0.9873 - val_loss: 0.7009 - val_acc: 0.6000\n",
      "Epoch 1107/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2122 - acc: 0.9873 - val_loss: 0.7016 - val_acc: 0.6000\n",
      "Epoch 1108/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2114 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 0.6000\n",
      "Epoch 1109/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.2128 - acc: 1.0000 - val_loss: 0.7018 - val_acc: 0.6000\n",
      "Epoch 1110/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2109 - acc: 0.9873 - val_loss: 0.7030 - val_acc: 0.6000\n",
      "Epoch 1111/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2093 - acc: 0.9873 - val_loss: 0.7035 - val_acc: 0.6000\n",
      "Epoch 1112/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.2081 - acc: 0.9873 - val_loss: 0.7049 - val_acc: 0.6000\n",
      "Epoch 1113/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2070 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.6000\n",
      "Epoch 1114/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2060 - acc: 1.0000 - val_loss: 0.7067 - val_acc: 0.6000\n",
      "Epoch 1115/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2055 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.6000\n",
      "Epoch 1116/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2067 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.6000\n",
      "Epoch 1117/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2042 - acc: 1.0000 - val_loss: 0.7067 - val_acc: 0.6000\n",
      "Epoch 1118/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2032 - acc: 0.9873 - val_loss: 0.7074 - val_acc: 0.6000\n",
      "Epoch 1119/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2023 - acc: 1.0000 - val_loss: 0.7078 - val_acc: 0.6000\n",
      "Epoch 1120/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.2019 - acc: 0.9873 - val_loss: 0.7097 - val_acc: 0.6000\n",
      "Epoch 1121/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.2009 - acc: 1.0000 - val_loss: 0.7089 - val_acc: 0.6000\n",
      "Epoch 1122/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2002 - acc: 1.0000 - val_loss: 0.7089 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1123/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1993 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.6000\n",
      "Epoch 1124/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1984 - acc: 1.0000 - val_loss: 0.7102 - val_acc: 0.6000\n",
      "Epoch 1125/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1976 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.6000\n",
      "Epoch 1126/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1969 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.6000\n",
      "Epoch 1127/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1974 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.6000\n",
      "Epoch 1128/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.1952 - acc: 1.0000 - val_loss: 0.7134 - val_acc: 0.6000\n",
      "Epoch 1129/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1947 - acc: 1.0000 - val_loss: 0.7157 - val_acc: 0.6000\n",
      "Epoch 1130/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1944 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.6000\n",
      "Epoch 1131/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1945 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.6000\n",
      "Epoch 1132/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1933 - acc: 1.0000 - val_loss: 0.7198 - val_acc: 0.6000\n",
      "Epoch 1133/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1930 - acc: 1.0000 - val_loss: 0.7207 - val_acc: 0.6000\n",
      "Epoch 1134/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1927 - acc: 1.0000 - val_loss: 0.7216 - val_acc: 0.6000\n",
      "Epoch 1135/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1909 - acc: 1.0000 - val_loss: 0.7164 - val_acc: 0.6000\n",
      "Epoch 1136/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1908 - acc: 1.0000 - val_loss: 0.7148 - val_acc: 0.6000\n",
      "Epoch 1137/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1884 - acc: 1.0000 - val_loss: 0.7158 - val_acc: 0.6000\n",
      "Epoch 1138/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.1873 - acc: 1.0000 - val_loss: 0.7173 - val_acc: 0.6000\n",
      "Epoch 1139/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1881 - acc: 1.0000 - val_loss: 0.7210 - val_acc: 0.6000\n",
      "Epoch 1140/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1878 - acc: 1.0000 - val_loss: 0.7196 - val_acc: 0.6000\n",
      "Epoch 1141/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1857 - acc: 1.0000 - val_loss: 0.7200 - val_acc: 0.6000\n",
      "Epoch 1142/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1857 - acc: 1.0000 - val_loss: 0.7172 - val_acc: 0.6000\n",
      "Epoch 1143/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.1843 - acc: 1.0000 - val_loss: 0.7178 - val_acc: 0.6000\n",
      "Epoch 1144/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1849 - acc: 1.0000 - val_loss: 0.7179 - val_acc: 0.6000\n",
      "Epoch 1145/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1827 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.6000\n",
      "Epoch 1146/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1819 - acc: 1.0000 - val_loss: 0.7200 - val_acc: 0.6000\n",
      "Epoch 1147/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.1823 - acc: 1.0000 - val_loss: 0.7204 - val_acc: 0.6000\n",
      "Epoch 1148/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1805 - acc: 1.0000 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 1149/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1794 - acc: 1.0000 - val_loss: 0.7227 - val_acc: 0.6000\n",
      "Epoch 1150/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1787 - acc: 1.0000 - val_loss: 0.7245 - val_acc: 0.6000\n",
      "Epoch 1151/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.1785 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 0.6000\n",
      "Epoch 1152/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1756 - acc: 1.0000 - val_loss: 0.7222 - val_acc: 0.6000\n",
      "Epoch 1153/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.1740 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.6000\n",
      "Epoch 1154/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.1733 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.6000\n",
      "Epoch 1155/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1735 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.6000\n",
      "Epoch 1156/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1720 - acc: 1.0000 - val_loss: 0.7247 - val_acc: 0.6000\n",
      "Epoch 1157/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1715 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 0.6000\n",
      "Epoch 1158/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.1706 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.6000\n",
      "Epoch 1159/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1702 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.6000\n",
      "Epoch 1160/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.1691 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 0.6000\n",
      "Epoch 1161/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1691 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.6000\n",
      "Epoch 1162/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1688 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.6000\n",
      "Epoch 1163/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1678 - acc: 1.0000 - val_loss: 0.7280 - val_acc: 0.6000\n",
      "Epoch 1164/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.1665 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.6000\n",
      "Epoch 1165/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1669 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.6000\n",
      "Epoch 1166/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1651 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.6000\n",
      "Epoch 1167/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1645 - acc: 1.0000 - val_loss: 0.7294 - val_acc: 0.6000\n",
      "Epoch 1168/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1639 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.6000\n",
      "Epoch 1169/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1646 - acc: 1.0000 - val_loss: 0.7312 - val_acc: 0.6000\n",
      "Epoch 1170/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1623 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.6000\n",
      "Epoch 1171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1619 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.6000\n",
      "Epoch 1172/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1622 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.6000\n",
      "Epoch 1173/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1606 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.6000\n",
      "Epoch 1174/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1610 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.6000\n",
      "Epoch 1175/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.1591 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.6000\n",
      "Epoch 1176/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.1586 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.6000\n",
      "Epoch 1177/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1582 - acc: 1.0000 - val_loss: 0.7390 - val_acc: 0.6000\n",
      "Epoch 1178/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1572 - acc: 1.0000 - val_loss: 0.7391 - val_acc: 0.6000\n",
      "Epoch 1179/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1572 - acc: 1.0000 - val_loss: 0.7387 - val_acc: 0.6000\n",
      "Epoch 1180/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1561 - acc: 1.0000 - val_loss: 0.7390 - val_acc: 0.6000\n",
      "Epoch 1181/3000\n",
      "79/79 [==============================] - 0s 252us/sample - loss: 0.1556 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1182/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.1548 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.6000\n",
      "Epoch 1183/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1540 - acc: 1.0000 - val_loss: 0.7403 - val_acc: 0.6000\n",
      "Epoch 1184/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1532 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.6000\n",
      "Epoch 1185/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.1527 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 0.6000\n",
      "Epoch 1186/3000\n",
      "79/79 [==============================] - 0s 185us/sample - loss: 0.1522 - acc: 1.0000 - val_loss: 0.7425 - val_acc: 0.6000\n",
      "Epoch 1187/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1521 - acc: 1.0000 - val_loss: 0.7428 - val_acc: 0.6000\n",
      "Epoch 1188/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1512 - acc: 1.0000 - val_loss: 0.7434 - val_acc: 0.6000\n",
      "Epoch 1189/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.1508 - acc: 1.0000 - val_loss: 0.7440 - val_acc: 0.6000\n",
      "Epoch 1190/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1496 - acc: 1.0000 - val_loss: 0.7448 - val_acc: 0.6000\n",
      "Epoch 1191/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.1490 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.6000\n",
      "Epoch 1192/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1484 - acc: 1.0000 - val_loss: 0.7460 - val_acc: 0.6000\n",
      "Epoch 1193/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1480 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.6000\n",
      "Epoch 1194/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.1473 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.6000\n",
      "Epoch 1195/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1466 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.6000\n",
      "Epoch 1196/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1459 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.6000\n",
      "Epoch 1197/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1455 - acc: 1.0000 - val_loss: 0.7482 - val_acc: 0.6000\n",
      "Epoch 1198/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1449 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 0.6000\n",
      "Epoch 1199/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.1445 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.6000\n",
      "Epoch 1200/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1436 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.6000\n",
      "Epoch 1201/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1431 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.6000\n",
      "Epoch 1202/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1425 - acc: 1.0000 - val_loss: 0.7513 - val_acc: 0.6000\n",
      "Epoch 1203/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1422 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.6000\n",
      "Epoch 1204/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.1414 - acc: 1.0000 - val_loss: 0.7518 - val_acc: 0.6000\n",
      "Epoch 1205/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1409 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.6000\n",
      "Epoch 1206/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1410 - acc: 1.0000 - val_loss: 0.7528 - val_acc: 0.6000\n",
      "Epoch 1207/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1396 - acc: 1.0000 - val_loss: 0.7532 - val_acc: 0.6000\n",
      "Epoch 1208/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1390 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.6000\n",
      "Epoch 1209/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.1384 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.6000\n",
      "Epoch 1210/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1378 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.6000\n",
      "Epoch 1211/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.1379 - acc: 1.0000 - val_loss: 0.7572 - val_acc: 0.6000\n",
      "Epoch 1212/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1370 - acc: 1.0000 - val_loss: 0.7572 - val_acc: 0.6000\n",
      "Epoch 1213/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1364 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.6000\n",
      "Epoch 1214/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1359 - acc: 1.0000 - val_loss: 0.7581 - val_acc: 0.6000\n",
      "Epoch 1215/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1351 - acc: 1.0000 - val_loss: 0.7585 - val_acc: 0.6000\n",
      "Epoch 1216/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1352 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.6000\n",
      "Epoch 1217/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1345 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.6000\n",
      "Epoch 1218/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.1340 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.6000\n",
      "Epoch 1219/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1331 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.6000\n",
      "Epoch 1220/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1328 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.6000\n",
      "Epoch 1221/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1320 - acc: 1.0000 - val_loss: 0.7622 - val_acc: 0.6000\n",
      "Epoch 1222/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1313 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.6000\n",
      "Epoch 1223/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1307 - acc: 1.0000 - val_loss: 0.7631 - val_acc: 0.6000\n",
      "Epoch 1224/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.6000\n",
      "Epoch 1225/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1301 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.6000\n",
      "Epoch 1226/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.6000\n",
      "Epoch 1227/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1289 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.6000\n",
      "Epoch 1228/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1281 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 0.6000\n",
      "Epoch 1229/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1277 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.6000\n",
      "Epoch 1230/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.1276 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.6000\n",
      "Epoch 1231/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.1267 - acc: 1.0000 - val_loss: 0.7673 - val_acc: 0.6000\n",
      "Epoch 1232/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.1265 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.6000\n",
      "Epoch 1233/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1261 - acc: 1.0000 - val_loss: 0.7683 - val_acc: 0.6000\n",
      "Epoch 1234/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1259 - acc: 1.0000 - val_loss: 0.7689 - val_acc: 0.6000\n",
      "Epoch 1235/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1246 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.6000\n",
      "Epoch 1236/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1243 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.6000\n",
      "Epoch 1237/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1236 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.6000\n",
      "Epoch 1238/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1240 - acc: 1.0000 - val_loss: 0.7710 - val_acc: 0.6000\n",
      "Epoch 1239/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1236 - acc: 1.0000 - val_loss: 0.7716 - val_acc: 0.6000\n",
      "Epoch 1240/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.1225 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1241/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1219 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.6000\n",
      "Epoch 1242/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1218 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.6000\n",
      "Epoch 1243/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1219 - acc: 1.0000 - val_loss: 0.7738 - val_acc: 0.6000\n",
      "Epoch 1244/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1206 - acc: 1.0000 - val_loss: 0.7744 - val_acc: 0.6000\n",
      "Epoch 1245/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.1200 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 0.6000\n",
      "Epoch 1246/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1194 - acc: 1.0000 - val_loss: 0.7758 - val_acc: 0.6000\n",
      "Epoch 1247/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1188 - acc: 1.0000 - val_loss: 0.7760 - val_acc: 0.6000\n",
      "Epoch 1248/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1187 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.6000\n",
      "Epoch 1249/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.1180 - acc: 1.0000 - val_loss: 0.7771 - val_acc: 0.6000\n",
      "Epoch 1250/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.1172 - acc: 1.0000 - val_loss: 0.7770 - val_acc: 0.6000\n",
      "Epoch 1251/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1168 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.6000\n",
      "Epoch 1252/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.1170 - acc: 1.0000 - val_loss: 0.7778 - val_acc: 0.6000\n",
      "Epoch 1253/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1158 - acc: 1.0000 - val_loss: 0.7783 - val_acc: 0.6000\n",
      "Epoch 1254/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1155 - acc: 1.0000 - val_loss: 0.7793 - val_acc: 0.6000\n",
      "Epoch 1255/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1150 - acc: 1.0000 - val_loss: 0.7796 - val_acc: 0.6000\n",
      "Epoch 1256/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1150 - acc: 1.0000 - val_loss: 0.7795 - val_acc: 0.5500\n",
      "Epoch 1257/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.1152 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 0.5500\n",
      "Epoch 1258/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.1144 - acc: 1.0000 - val_loss: 0.7826 - val_acc: 0.6000\n",
      "Epoch 1259/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1143 - acc: 1.0000 - val_loss: 0.7828 - val_acc: 0.6000\n",
      "Epoch 1260/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1125 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.6000\n",
      "Epoch 1261/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 0.7841 - val_acc: 0.6000\n",
      "Epoch 1262/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1118 - acc: 1.0000 - val_loss: 0.7849 - val_acc: 0.6000\n",
      "Epoch 1263/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 0.7855 - val_acc: 0.5500\n",
      "Epoch 1264/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.7857 - val_acc: 0.5500\n",
      "Epoch 1265/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.5500\n",
      "Epoch 1266/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.7871 - val_acc: 0.5500\n",
      "Epoch 1267/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.1097 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.5500\n",
      "Epoch 1268/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1092 - acc: 1.0000 - val_loss: 0.7881 - val_acc: 0.5500\n",
      "Epoch 1269/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.1091 - acc: 1.0000 - val_loss: 0.7890 - val_acc: 0.5500\n",
      "Epoch 1270/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1093 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 0.6000\n",
      "Epoch 1271/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1083 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 0.5500\n",
      "Epoch 1272/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1085 - acc: 1.0000 - val_loss: 0.7902 - val_acc: 0.5500\n",
      "Epoch 1273/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.1070 - acc: 1.0000 - val_loss: 0.7906 - val_acc: 0.6000\n",
      "Epoch 1274/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.1069 - acc: 1.0000 - val_loss: 0.7914 - val_acc: 0.5500\n",
      "Epoch 1275/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1066 - acc: 1.0000 - val_loss: 0.7919 - val_acc: 0.5500\n",
      "Epoch 1276/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1057 - acc: 1.0000 - val_loss: 0.7937 - val_acc: 0.5500\n",
      "Epoch 1277/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1053 - acc: 1.0000 - val_loss: 0.7918 - val_acc: 0.6000\n",
      "Epoch 1278/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.1051 - acc: 1.0000 - val_loss: 0.7924 - val_acc: 0.5500\n",
      "Epoch 1279/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1057 - acc: 1.0000 - val_loss: 0.7928 - val_acc: 0.5500\n",
      "Epoch 1280/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1045 - acc: 1.0000 - val_loss: 0.7934 - val_acc: 0.6000\n",
      "Epoch 1281/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.1038 - acc: 1.0000 - val_loss: 0.7944 - val_acc: 0.5500\n",
      "Epoch 1282/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1033 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.6000\n",
      "Epoch 1283/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1029 - acc: 1.0000 - val_loss: 0.7956 - val_acc: 0.6000\n",
      "Epoch 1284/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1023 - acc: 1.0000 - val_loss: 0.7962 - val_acc: 0.6000\n",
      "Epoch 1285/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1022 - acc: 1.0000 - val_loss: 0.7972 - val_acc: 0.6000\n",
      "Epoch 1286/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1017 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.6000\n",
      "Epoch 1287/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1012 - acc: 1.0000 - val_loss: 0.7982 - val_acc: 0.6000\n",
      "Epoch 1288/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.1008 - acc: 1.0000 - val_loss: 0.7989 - val_acc: 0.6000\n",
      "Epoch 1289/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.1013 - acc: 1.0000 - val_loss: 0.7992 - val_acc: 0.6000\n",
      "Epoch 1290/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0999 - acc: 1.0000 - val_loss: 0.7997 - val_acc: 0.6000\n",
      "Epoch 1291/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0996 - acc: 1.0000 - val_loss: 0.8003 - val_acc: 0.6000\n",
      "Epoch 1292/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0998 - acc: 1.0000 - val_loss: 0.8010 - val_acc: 0.5500\n",
      "Epoch 1293/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0993 - acc: 1.0000 - val_loss: 0.8019 - val_acc: 0.5500\n",
      "Epoch 1294/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0991 - acc: 1.0000 - val_loss: 0.8041 - val_acc: 0.5500\n",
      "Epoch 1295/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0986 - acc: 1.0000 - val_loss: 0.8041 - val_acc: 0.5500\n",
      "Epoch 1296/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0979 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 0.5500\n",
      "Epoch 1297/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0974 - acc: 1.0000 - val_loss: 0.8054 - val_acc: 0.6000\n",
      "Epoch 1298/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0975 - acc: 1.0000 - val_loss: 0.8060 - val_acc: 0.6000\n",
      "Epoch 1299/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0966 - acc: 1.0000 - val_loss: 0.8068 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1300/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0970 - acc: 1.0000 - val_loss: 0.8074 - val_acc: 0.5500\n",
      "Epoch 1301/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0962 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.6000\n",
      "Epoch 1302/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0957 - acc: 1.0000 - val_loss: 0.8084 - val_acc: 0.6000\n",
      "Epoch 1303/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0951 - acc: 1.0000 - val_loss: 0.8086 - val_acc: 0.6000\n",
      "Epoch 1304/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.0946 - acc: 1.0000 - val_loss: 0.8091 - val_acc: 0.5500\n",
      "Epoch 1305/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0942 - acc: 1.0000 - val_loss: 0.8096 - val_acc: 0.6000\n",
      "Epoch 1306/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0942 - acc: 1.0000 - val_loss: 0.8104 - val_acc: 0.6000\n",
      "Epoch 1307/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0936 - acc: 1.0000 - val_loss: 0.8111 - val_acc: 0.6000\n",
      "Epoch 1308/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0944 - acc: 1.0000 - val_loss: 0.8126 - val_acc: 0.6000\n",
      "Epoch 1309/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0935 - acc: 1.0000 - val_loss: 0.8128 - val_acc: 0.6000\n",
      "Epoch 1310/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0931 - acc: 1.0000 - val_loss: 0.8137 - val_acc: 0.6000\n",
      "Epoch 1311/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0927 - acc: 1.0000 - val_loss: 0.8137 - val_acc: 0.6000\n",
      "Epoch 1312/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.8145 - val_acc: 0.6000\n",
      "Epoch 1313/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0917 - acc: 1.0000 - val_loss: 0.8141 - val_acc: 0.6000\n",
      "Epoch 1314/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0910 - acc: 1.0000 - val_loss: 0.8147 - val_acc: 0.6000\n",
      "Epoch 1315/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0907 - acc: 1.0000 - val_loss: 0.8152 - val_acc: 0.5500\n",
      "Epoch 1316/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0905 - acc: 1.0000 - val_loss: 0.8159 - val_acc: 0.6000\n",
      "Epoch 1317/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0900 - acc: 1.0000 - val_loss: 0.8163 - val_acc: 0.6000\n",
      "Epoch 1318/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0899 - acc: 1.0000 - val_loss: 0.8170 - val_acc: 0.5500\n",
      "Epoch 1319/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0894 - acc: 1.0000 - val_loss: 0.8177 - val_acc: 0.5500\n",
      "Epoch 1320/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0894 - acc: 1.0000 - val_loss: 0.8180 - val_acc: 0.5500\n",
      "Epoch 1321/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0886 - acc: 1.0000 - val_loss: 0.8185 - val_acc: 0.5500\n",
      "Epoch 1322/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0884 - acc: 1.0000 - val_loss: 0.8192 - val_acc: 0.6000\n",
      "Epoch 1323/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0880 - acc: 1.0000 - val_loss: 0.8197 - val_acc: 0.6000\n",
      "Epoch 1324/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0876 - acc: 1.0000 - val_loss: 0.8202 - val_acc: 0.6000\n",
      "Epoch 1325/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0873 - acc: 1.0000 - val_loss: 0.8208 - val_acc: 0.5500\n",
      "Epoch 1326/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0871 - acc: 1.0000 - val_loss: 0.8213 - val_acc: 0.5500\n",
      "Epoch 1327/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0871 - acc: 1.0000 - val_loss: 0.8223 - val_acc: 0.5500\n",
      "Epoch 1328/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0906 - acc: 1.000 - 0s 139us/sample - loss: 0.0863 - acc: 1.0000 - val_loss: 0.8226 - val_acc: 0.5500\n",
      "Epoch 1329/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0859 - acc: 1.0000 - val_loss: 0.8230 - val_acc: 0.5500\n",
      "Epoch 1330/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0856 - acc: 1.0000 - val_loss: 0.8235 - val_acc: 0.5500\n",
      "Epoch 1331/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0857 - acc: 1.0000 - val_loss: 0.8241 - val_acc: 0.5500\n",
      "Epoch 1332/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.8245 - val_acc: 0.6000\n",
      "Epoch 1333/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0846 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.6000\n",
      "Epoch 1334/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0843 - acc: 1.0000 - val_loss: 0.8255 - val_acc: 0.6000\n",
      "Epoch 1335/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0841 - acc: 1.0000 - val_loss: 0.8262 - val_acc: 0.5500\n",
      "Epoch 1336/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0839 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.6000\n",
      "Epoch 1337/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0833 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.6000\n",
      "Epoch 1338/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0835 - acc: 1.0000 - val_loss: 0.8280 - val_acc: 0.5500\n",
      "Epoch 1339/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0830 - acc: 1.0000 - val_loss: 0.8285 - val_acc: 0.5500\n",
      "Epoch 1340/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0826 - acc: 1.0000 - val_loss: 0.8288 - val_acc: 0.5500\n",
      "Epoch 1341/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0823 - acc: 1.0000 - val_loss: 0.8293 - val_acc: 0.5500\n",
      "Epoch 1342/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0818 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.6000\n",
      "Epoch 1343/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0817 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.6000\n",
      "Epoch 1344/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0812 - acc: 1.0000 - val_loss: 0.8309 - val_acc: 0.5500\n",
      "Epoch 1345/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0810 - acc: 1.0000 - val_loss: 0.8316 - val_acc: 0.5500\n",
      "Epoch 1346/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0810 - acc: 1.0000 - val_loss: 0.8320 - val_acc: 0.5500\n",
      "Epoch 1347/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0803 - acc: 1.0000 - val_loss: 0.8325 - val_acc: 0.5500\n",
      "Epoch 1348/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.8330 - val_acc: 0.5500\n",
      "Epoch 1349/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.8342 - val_acc: 0.5500\n",
      "Epoch 1350/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0800 - acc: 1.0000 - val_loss: 0.8347 - val_acc: 0.5500\n",
      "Epoch 1351/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0794 - acc: 1.0000 - val_loss: 0.8352 - val_acc: 0.5500\n",
      "Epoch 1352/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0791 - acc: 1.0000 - val_loss: 0.8352 - val_acc: 0.5500\n",
      "Epoch 1353/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.8357 - val_acc: 0.5500\n",
      "Epoch 1354/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0783 - acc: 1.0000 - val_loss: 0.8362 - val_acc: 0.5500\n",
      "Epoch 1355/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0782 - acc: 1.0000 - val_loss: 0.8366 - val_acc: 0.6000\n",
      "Epoch 1356/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0778 - acc: 1.0000 - val_loss: 0.8372 - val_acc: 0.6000\n",
      "Epoch 1357/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0776 - acc: 1.0000 - val_loss: 0.8387 - val_acc: 0.6000\n",
      "Epoch 1358/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0774 - acc: 1.0000 - val_loss: 0.8392 - val_acc: 0.5500\n",
      "Epoch 1359/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0771 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.5500\n",
      "Epoch 1360/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0769 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.5500\n",
      "Epoch 1361/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0767 - acc: 1.0000 - val_loss: 0.8408 - val_acc: 0.5500\n",
      "Epoch 1362/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.8413 - val_acc: 0.5500\n",
      "Epoch 1363/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0757 - acc: 1.0000 - val_loss: 0.8419 - val_acc: 0.5500\n",
      "Epoch 1364/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0757 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.5500\n",
      "Epoch 1365/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0752 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.5500\n",
      "Epoch 1366/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0749 - acc: 1.0000 - val_loss: 0.8435 - val_acc: 0.5500\n",
      "Epoch 1367/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.8441 - val_acc: 0.5500\n",
      "Epoch 1368/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.8449 - val_acc: 0.5500\n",
      "Epoch 1369/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.8449 - val_acc: 0.5500\n",
      "Epoch 1370/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0740 - acc: 1.0000 - val_loss: 0.8453 - val_acc: 0.5500\n",
      "Epoch 1371/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0738 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.5500\n",
      "Epoch 1372/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.8462 - val_acc: 0.5500\n",
      "Epoch 1373/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0731 - acc: 1.0000 - val_loss: 0.8466 - val_acc: 0.5500\n",
      "Epoch 1374/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0732 - acc: 1.0000 - val_loss: 0.8472 - val_acc: 0.6000\n",
      "Epoch 1375/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0727 - acc: 1.0000 - val_loss: 0.8477 - val_acc: 0.6000\n",
      "Epoch 1376/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.8483 - val_acc: 0.5500\n",
      "Epoch 1377/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.5500\n",
      "Epoch 1378/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0717 - acc: 1.0000 - val_loss: 0.8494 - val_acc: 0.5500\n",
      "Epoch 1379/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0717 - acc: 1.0000 - val_loss: 0.8499 - val_acc: 0.5500\n",
      "Epoch 1380/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.8505 - val_acc: 0.5500\n",
      "Epoch 1381/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0710 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.5500\n",
      "Epoch 1382/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0711 - acc: 1.0000 - val_loss: 0.8515 - val_acc: 0.6000\n",
      "Epoch 1383/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0708 - acc: 1.0000 - val_loss: 0.8522 - val_acc: 0.6000\n",
      "Epoch 1384/3000\n",
      "79/79 [==============================] - 0s 505us/sample - loss: 0.0709 - acc: 1.0000 - val_loss: 0.8526 - val_acc: 0.5500\n",
      "Epoch 1385/3000\n",
      "79/79 [==============================] - 0s 240us/sample - loss: 0.0701 - acc: 1.0000 - val_loss: 0.8536 - val_acc: 0.5500\n",
      "Epoch 1386/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0698 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.5500\n",
      "Epoch 1387/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0706 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.5500\n",
      "Epoch 1388/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0693 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.5500\n",
      "Epoch 1389/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.8558 - val_acc: 0.5500\n",
      "Epoch 1390/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0687 - acc: 1.0000 - val_loss: 0.8563 - val_acc: 0.5500\n",
      "Epoch 1391/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0687 - acc: 1.0000 - val_loss: 0.8569 - val_acc: 0.5500\n",
      "Epoch 1392/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0589 - acc: 1.000 - 0s 139us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.5500\n",
      "Epoch 1393/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0680 - acc: 1.0000 - val_loss: 0.8580 - val_acc: 0.5500\n",
      "Epoch 1394/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0678 - acc: 1.0000 - val_loss: 0.8585 - val_acc: 0.5500\n",
      "Epoch 1395/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0678 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.5500\n",
      "Epoch 1396/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0677 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.5500\n",
      "Epoch 1397/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0674 - acc: 1.0000 - val_loss: 0.8604 - val_acc: 0.5500\n",
      "Epoch 1398/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0668 - acc: 1.0000 - val_loss: 0.8608 - val_acc: 0.5500\n",
      "Epoch 1399/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0666 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.5500\n",
      "Epoch 1400/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0663 - acc: 1.0000 - val_loss: 0.8612 - val_acc: 0.5500\n",
      "Epoch 1401/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.8617 - val_acc: 0.5500\n",
      "Epoch 1402/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.8622 - val_acc: 0.5500\n",
      "Epoch 1403/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0656 - acc: 1.0000 - val_loss: 0.8630 - val_acc: 0.5500\n",
      "Epoch 1404/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0653 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.5500\n",
      "Epoch 1405/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0654 - acc: 1.0000 - val_loss: 0.8636 - val_acc: 0.5500\n",
      "Epoch 1406/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0651 - acc: 1.0000 - val_loss: 0.8641 - val_acc: 0.5500\n",
      "Epoch 1407/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0682 - acc: 1.000 - 0s 139us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.8649 - val_acc: 0.5500\n",
      "Epoch 1408/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.5500\n",
      "Epoch 1409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0642 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.5500\n",
      "Epoch 1410/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.8665 - val_acc: 0.5500\n",
      "Epoch 1411/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0638 - acc: 1.0000 - val_loss: 0.8670 - val_acc: 0.5500\n",
      "Epoch 1412/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0642 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.5500\n",
      "Epoch 1413/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0637 - acc: 1.0000 - val_loss: 0.8679 - val_acc: 0.5500\n",
      "Epoch 1414/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.8685 - val_acc: 0.5500\n",
      "Epoch 1415/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0630 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.5500\n",
      "Epoch 1416/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.8695 - val_acc: 0.5500\n",
      "Epoch 1417/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0625 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.5500\n",
      "Epoch 1418/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0626 - acc: 1.0000 - val_loss: 0.8714 - val_acc: 0.5500\n",
      "Epoch 1419/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0621 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.5500\n",
      "Epoch 1420/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0623 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.5500\n",
      "Epoch 1421/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.5500\n",
      "Epoch 1422/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.8727 - val_acc: 0.5500\n",
      "Epoch 1423/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0615 - acc: 1.0000 - val_loss: 0.8734 - val_acc: 0.5500\n",
      "Epoch 1424/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0611 - acc: 1.0000 - val_loss: 0.8735 - val_acc: 0.5500\n",
      "Epoch 1425/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0611 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 0.5500\n",
      "Epoch 1426/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0606 - acc: 1.0000 - val_loss: 0.8747 - val_acc: 0.5500\n",
      "Epoch 1427/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.8753 - val_acc: 0.5500\n",
      "Epoch 1428/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.8755 - val_acc: 0.5500\n",
      "Epoch 1429/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.5500\n",
      "Epoch 1430/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0603 - acc: 1.0000 - val_loss: 0.8768 - val_acc: 0.5500\n",
      "Epoch 1431/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0598 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.5500\n",
      "Epoch 1432/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.5500\n",
      "Epoch 1433/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.8785 - val_acc: 0.5500\n",
      "Epoch 1434/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.5500\n",
      "Epoch 1435/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.8791 - val_acc: 0.5500\n",
      "Epoch 1436/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0586 - acc: 1.0000 - val_loss: 0.8796 - val_acc: 0.5500\n",
      "Epoch 1437/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.8801 - val_acc: 0.5500\n",
      "Epoch 1438/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.8806 - val_acc: 0.5500\n",
      "Epoch 1439/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0581 - acc: 1.0000 - val_loss: 0.8810 - val_acc: 0.5500\n",
      "Epoch 1440/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.5500\n",
      "Epoch 1441/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.8821 - val_acc: 0.5500\n",
      "Epoch 1442/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0576 - acc: 1.0000 - val_loss: 0.8832 - val_acc: 0.5500\n",
      "Epoch 1443/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.5500\n",
      "Epoch 1444/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.5500\n",
      "Epoch 1445/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.8846 - val_acc: 0.5500\n",
      "Epoch 1446/3000\n",
      "79/79 [==============================] - 0s 227us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.8852 - val_acc: 0.5500\n",
      "Epoch 1447/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0572 - acc: 1.0000 - val_loss: 0.8849 - val_acc: 0.5500\n",
      "Epoch 1448/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0564 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.5500\n",
      "Epoch 1449/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0563 - acc: 1.0000 - val_loss: 0.8860 - val_acc: 0.5500\n",
      "Epoch 1450/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.8865 - val_acc: 0.5500\n",
      "Epoch 1451/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0558 - acc: 1.0000 - val_loss: 0.8869 - val_acc: 0.5500\n",
      "Epoch 1452/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.8874 - val_acc: 0.5500\n",
      "Epoch 1453/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.8881 - val_acc: 0.5500\n",
      "Epoch 1454/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0554 - acc: 1.0000 - val_loss: 0.8888 - val_acc: 0.5500\n",
      "Epoch 1455/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.0550 - acc: 1.0000 - val_loss: 0.8891 - val_acc: 0.5500\n",
      "Epoch 1456/3000\n",
      "79/79 [==============================] - 0s 192us/sample - loss: 0.0548 - acc: 1.0000 - val_loss: 0.8895 - val_acc: 0.5500\n",
      "Epoch 1457/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.8898 - val_acc: 0.5500\n",
      "Epoch 1458/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.8905 - val_acc: 0.5500\n",
      "Epoch 1459/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0545 - acc: 1.0000 - val_loss: 0.8913 - val_acc: 0.5500\n",
      "Epoch 1460/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.8919 - val_acc: 0.5500\n",
      "Epoch 1461/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 0.8927 - val_acc: 0.5500\n",
      "Epoch 1462/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 0.8934 - val_acc: 0.5500\n",
      "Epoch 1463/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.8938 - val_acc: 0.5500\n",
      "Epoch 1464/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.8941 - val_acc: 0.5500\n",
      "Epoch 1465/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 0.8943 - val_acc: 0.5500\n",
      "Epoch 1466/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.8949 - val_acc: 0.5500\n",
      "Epoch 1467/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.8961 - val_acc: 0.5500\n",
      "Epoch 1468/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0528 - acc: 1.0000 - val_loss: 0.8965 - val_acc: 0.5500\n",
      "Epoch 1469/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.5500\n",
      "Epoch 1470/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0524 - acc: 1.0000 - val_loss: 0.8971 - val_acc: 0.5500\n",
      "Epoch 1471/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.8977 - val_acc: 0.5500\n",
      "Epoch 1472/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.0519 - acc: 1.0000 - val_loss: 0.8982 - val_acc: 0.5500\n",
      "Epoch 1473/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0519 - acc: 1.0000 - val_loss: 0.8981 - val_acc: 0.5500\n",
      "Epoch 1474/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.8988 - val_acc: 0.5500\n",
      "Epoch 1475/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.8990 - val_acc: 0.5500\n",
      "Epoch 1476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.8994 - val_acc: 0.5500\n",
      "Epoch 1477/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.9001 - val_acc: 0.5500\n",
      "Epoch 1478/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.5500\n",
      "Epoch 1479/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0507 - acc: 1.0000 - val_loss: 0.9008 - val_acc: 0.5500\n",
      "Epoch 1480/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0507 - acc: 1.0000 - val_loss: 0.9015 - val_acc: 0.5500\n",
      "Epoch 1481/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0507 - acc: 1.0000 - val_loss: 0.9017 - val_acc: 0.5500\n",
      "Epoch 1482/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.9024 - val_acc: 0.5500\n",
      "Epoch 1483/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.9028 - val_acc: 0.5500\n",
      "Epoch 1484/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.9034 - val_acc: 0.5500\n",
      "Epoch 1485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0498 - acc: 1.0000 - val_loss: 0.9037 - val_acc: 0.5500\n",
      "Epoch 1486/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.9046 - val_acc: 0.5500\n",
      "Epoch 1487/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.5500\n",
      "Epoch 1488/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0496 - acc: 1.0000 - val_loss: 0.9054 - val_acc: 0.5500\n",
      "Epoch 1489/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.9060 - val_acc: 0.5500\n",
      "Epoch 1490/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.9070 - val_acc: 0.5500\n",
      "Epoch 1491/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.9075 - val_acc: 0.5500\n",
      "Epoch 1492/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.9075 - val_acc: 0.5500\n",
      "Epoch 1493/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.9083 - val_acc: 0.5500\n",
      "Epoch 1494/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.9107 - val_acc: 0.5500\n",
      "Epoch 1495/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.5500\n",
      "Epoch 1496/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.9112 - val_acc: 0.5500\n",
      "Epoch 1497/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.9125 - val_acc: 0.5500\n",
      "Epoch 1498/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 0.9132 - val_acc: 0.5500\n",
      "Epoch 1499/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.9145 - val_acc: 0.5500\n",
      "Epoch 1500/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0475 - acc: 1.0000 - val_loss: 0.9153 - val_acc: 0.5500\n",
      "Epoch 1501/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.9157 - val_acc: 0.5500\n",
      "Epoch 1502/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.9158 - val_acc: 0.5500\n",
      "Epoch 1503/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.9165 - val_acc: 0.5500\n",
      "Epoch 1504/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0468 - acc: 1.0000 - val_loss: 0.9157 - val_acc: 0.5500\n",
      "Epoch 1505/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.9166 - val_acc: 0.5500\n",
      "Epoch 1506/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.9179 - val_acc: 0.5500\n",
      "Epoch 1507/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.5500\n",
      "Epoch 1508/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.9180 - val_acc: 0.5500\n",
      "Epoch 1509/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.9189 - val_acc: 0.5500\n",
      "Epoch 1510/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0459 - acc: 1.0000 - val_loss: 0.9193 - val_acc: 0.5500\n",
      "Epoch 1511/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.5500\n",
      "Epoch 1512/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.5500\n",
      "Epoch 1513/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.9220 - val_acc: 0.5500\n",
      "Epoch 1514/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.9226 - val_acc: 0.5500\n",
      "Epoch 1515/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.9235 - val_acc: 0.5500\n",
      "Epoch 1516/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.9234 - val_acc: 0.5500\n",
      "Epoch 1517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.9239 - val_acc: 0.5500\n",
      "Epoch 1518/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.9242 - val_acc: 0.5500\n",
      "Epoch 1519/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.9250 - val_acc: 0.5500\n",
      "Epoch 1520/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.9246 - val_acc: 0.5500\n",
      "Epoch 1521/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.9248 - val_acc: 0.5500\n",
      "Epoch 1522/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0443 - acc: 1.0000 - val_loss: 0.9258 - val_acc: 0.5500\n",
      "Epoch 1523/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.9261 - val_acc: 0.5500\n",
      "Epoch 1524/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 0.9263 - val_acc: 0.5500\n",
      "Epoch 1525/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.9273 - val_acc: 0.5500\n",
      "Epoch 1526/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.9280 - val_acc: 0.5500\n",
      "Epoch 1527/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.9289 - val_acc: 0.5500\n",
      "Epoch 1528/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.9298 - val_acc: 0.5500\n",
      "Epoch 1529/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.9294 - val_acc: 0.5500\n",
      "Epoch 1530/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0431 - acc: 1.0000 - val_loss: 0.9294 - val_acc: 0.5500\n",
      "Epoch 1531/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.9299 - val_acc: 0.5500\n",
      "Epoch 1532/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0428 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.5500\n",
      "Epoch 1533/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.9306 - val_acc: 0.5500\n",
      "Epoch 1534/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.9307 - val_acc: 0.5500\n",
      "Epoch 1535/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.9312 - val_acc: 0.5500\n",
      "Epoch 1536/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.9321 - val_acc: 0.5500\n",
      "Epoch 1537/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.9325 - val_acc: 0.5500\n",
      "Epoch 1538/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.9324 - val_acc: 0.5500\n",
      "Epoch 1539/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.9328 - val_acc: 0.5500\n",
      "Epoch 1540/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.9335 - val_acc: 0.5500\n",
      "Epoch 1541/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.5500\n",
      "Epoch 1542/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.5500\n",
      "Epoch 1543/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.5500\n",
      "Epoch 1544/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.9349 - val_acc: 0.5500\n",
      "Epoch 1545/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.9355 - val_acc: 0.5500\n",
      "Epoch 1546/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.9360 - val_acc: 0.5500\n",
      "Epoch 1547/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.9370 - val_acc: 0.5500\n",
      "Epoch 1548/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.9368 - val_acc: 0.5500\n",
      "Epoch 1549/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 0.9376 - val_acc: 0.5500\n",
      "Epoch 1550/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 0.9376 - val_acc: 0.5500\n",
      "Epoch 1551/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.9385 - val_acc: 0.5500\n",
      "Epoch 1552/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.9395 - val_acc: 0.5500\n",
      "Epoch 1553/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.9399 - val_acc: 0.5500\n",
      "Epoch 1554/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.9399 - val_acc: 0.5500\n",
      "Epoch 1555/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.9404 - val_acc: 0.5500\n",
      "Epoch 1556/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.5500\n",
      "Epoch 1557/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.9412 - val_acc: 0.5500\n",
      "Epoch 1558/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0396 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5500\n",
      "Epoch 1559/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.9420 - val_acc: 0.5500\n",
      "Epoch 1560/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.9440 - val_acc: 0.5500\n",
      "Epoch 1561/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.5500\n",
      "Epoch 1562/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.9460 - val_acc: 0.5500\n",
      "Epoch 1563/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0390 - acc: 1.0000 - val_loss: 0.9484 - val_acc: 0.5500\n",
      "Epoch 1564/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.9490 - val_acc: 0.5500\n",
      "Epoch 1565/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.5500\n",
      "Epoch 1566/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.5500\n",
      "Epoch 1567/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.5500\n",
      "Epoch 1568/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.5500\n",
      "Epoch 1569/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.9514 - val_acc: 0.5500\n",
      "Epoch 1570/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.9518 - val_acc: 0.5500\n",
      "Epoch 1571/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.9519 - val_acc: 0.5500\n",
      "Epoch 1572/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.9530 - val_acc: 0.5500\n",
      "Epoch 1573/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.9536 - val_acc: 0.5500\n",
      "Epoch 1574/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.9538 - val_acc: 0.5500\n",
      "Epoch 1575/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.9542 - val_acc: 0.5500\n",
      "Epoch 1576/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.9550 - val_acc: 0.5500\n",
      "Epoch 1577/3000\n",
      "79/79 [==============================] - 0s 195us/sample - loss: 0.0374 - acc: 1.0000 - val_loss: 0.9552 - val_acc: 0.5500\n",
      "Epoch 1578/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.9546 - val_acc: 0.5500\n",
      "Epoch 1579/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.5500\n",
      "Epoch 1580/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.9553 - val_acc: 0.5500\n",
      "Epoch 1581/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.9557 - val_acc: 0.5500\n",
      "Epoch 1582/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.9563 - val_acc: 0.5500\n",
      "Epoch 1583/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.9560 - val_acc: 0.5500\n",
      "Epoch 1584/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.9564 - val_acc: 0.5500\n",
      "Epoch 1585/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.9567 - val_acc: 0.5500\n",
      "Epoch 1586/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.9576 - val_acc: 0.5500\n",
      "Epoch 1587/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.9577 - val_acc: 0.5500\n",
      "Epoch 1588/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0357 - acc: 1.0000 - val_loss: 0.9579 - val_acc: 0.5500\n",
      "Epoch 1589/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.9583 - val_acc: 0.5500\n",
      "Epoch 1590/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.9585 - val_acc: 0.5500\n",
      "Epoch 1591/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.9589 - val_acc: 0.5500\n",
      "Epoch 1592/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.9592 - val_acc: 0.5500\n",
      "Epoch 1593/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.9599 - val_acc: 0.5500\n",
      "Epoch 1594/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.9606 - val_acc: 0.5500\n",
      "Epoch 1595/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.9608 - val_acc: 0.5500\n",
      "Epoch 1596/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.9611 - val_acc: 0.5500\n",
      "Epoch 1597/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0349 - acc: 1.0000 - val_loss: 0.9616 - val_acc: 0.5500\n",
      "Epoch 1598/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.9620 - val_acc: 0.5500\n",
      "Epoch 1599/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.9623 - val_acc: 0.5500\n",
      "Epoch 1600/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.9624 - val_acc: 0.5500\n",
      "Epoch 1601/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.9626 - val_acc: 0.5500\n",
      "Epoch 1602/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.9631 - val_acc: 0.5500\n",
      "Epoch 1603/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.9641 - val_acc: 0.5500\n",
      "Epoch 1604/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.9649 - val_acc: 0.5500\n",
      "Epoch 1605/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.9654 - val_acc: 0.5500\n",
      "Epoch 1606/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.9660 - val_acc: 0.5500\n",
      "Epoch 1607/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.9667 - val_acc: 0.5500\n",
      "Epoch 1608/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.9671 - val_acc: 0.5500\n",
      "Epoch 1609/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.5500\n",
      "Epoch 1610/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.9676 - val_acc: 0.5500\n",
      "Epoch 1611/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.9682 - val_acc: 0.5500\n",
      "Epoch 1612/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.9685 - val_acc: 0.5500\n",
      "Epoch 1613/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.9687 - val_acc: 0.5500\n",
      "Epoch 1614/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0333 - acc: 1.0000 - val_loss: 0.9696 - val_acc: 0.5500\n",
      "Epoch 1615/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.5500\n",
      "Epoch 1616/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.5500\n",
      "Epoch 1617/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.9698 - val_acc: 0.5500\n",
      "Epoch 1618/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.9664 - val_acc: 0.5500\n",
      "Epoch 1619/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.9713 - val_acc: 0.5500\n",
      "Epoch 1620/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.5500\n",
      "Epoch 1621/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.9675 - val_acc: 0.5500\n",
      "Epoch 1622/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.9683 - val_acc: 0.5500\n",
      "Epoch 1623/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.9693 - val_acc: 0.5500\n",
      "Epoch 1624/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.5500\n",
      "Epoch 1625/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.9714 - val_acc: 0.5500\n",
      "Epoch 1626/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.9720 - val_acc: 0.5500\n",
      "Epoch 1627/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.9719 - val_acc: 0.5500\n",
      "Epoch 1628/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.5500\n",
      "Epoch 1629/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.9732 - val_acc: 0.5500\n",
      "Epoch 1630/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.9731 - val_acc: 0.5500\n",
      "Epoch 1631/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.5500\n",
      "Epoch 1632/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.9732 - val_acc: 0.5500\n",
      "Epoch 1633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.9735 - val_acc: 0.5500\n",
      "Epoch 1634/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.9738 - val_acc: 0.5500\n",
      "Epoch 1635/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.5500\n",
      "Epoch 1636/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.9747 - val_acc: 0.5500\n",
      "Epoch 1637/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.9748 - val_acc: 0.5500\n",
      "Epoch 1638/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.5500\n",
      "Epoch 1639/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.9761 - val_acc: 0.5500\n",
      "Epoch 1640/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.9758 - val_acc: 0.5500\n",
      "Epoch 1641/3000\n",
      "79/79 [==============================] - 0s 175us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.9759 - val_acc: 0.5500\n",
      "Epoch 1642/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.9765 - val_acc: 0.5500\n",
      "Epoch 1643/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.9766 - val_acc: 0.5500\n",
      "Epoch 1644/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.9774 - val_acc: 0.5500\n",
      "Epoch 1645/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.9777 - val_acc: 0.5500\n",
      "Epoch 1646/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.5500\n",
      "Epoch 1647/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.9791 - val_acc: 0.5500\n",
      "Epoch 1648/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.9795 - val_acc: 0.5500\n",
      "Epoch 1649/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.9796 - val_acc: 0.5500\n",
      "Epoch 1650/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.9796 - val_acc: 0.5500\n",
      "Epoch 1651/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.9800 - val_acc: 0.5500\n",
      "Epoch 1652/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.9804 - val_acc: 0.5500\n",
      "Epoch 1653/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.5500\n",
      "Epoch 1654/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.9819 - val_acc: 0.5500\n",
      "Epoch 1655/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.5500\n",
      "Epoch 1656/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.9831 - val_acc: 0.5500\n",
      "Epoch 1657/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.9839 - val_acc: 0.5500\n",
      "Epoch 1658/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.9844 - val_acc: 0.5500\n",
      "Epoch 1659/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.9835 - val_acc: 0.5500\n",
      "Epoch 1660/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.5500\n",
      "Epoch 1661/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.9834 - val_acc: 0.5500\n",
      "Epoch 1662/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.5500\n",
      "Epoch 1663/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.5500\n",
      "Epoch 1664/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.5500\n",
      "Epoch 1665/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.9849 - val_acc: 0.5500\n",
      "Epoch 1666/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.5500\n",
      "Epoch 1667/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.9860 - val_acc: 0.5500\n",
      "Epoch 1668/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.5500\n",
      "Epoch 1669/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.5500\n",
      "Epoch 1670/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.5500\n",
      "Epoch 1671/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.5500\n",
      "Epoch 1672/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.9892 - val_acc: 0.5500\n",
      "Epoch 1673/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.5500\n",
      "Epoch 1674/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.5500\n",
      "Epoch 1675/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.5500\n",
      "Epoch 1676/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.9890 - val_acc: 0.5500\n",
      "Epoch 1677/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.9893 - val_acc: 0.5500\n",
      "Epoch 1678/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.9898 - val_acc: 0.5500\n",
      "Epoch 1679/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.9905 - val_acc: 0.5500\n",
      "Epoch 1680/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.5500\n",
      "Epoch 1681/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.5500\n",
      "Epoch 1682/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.9911 - val_acc: 0.5500\n",
      "Epoch 1683/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.5500\n",
      "Epoch 1684/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.5500\n",
      "Epoch 1685/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.5500\n",
      "Epoch 1686/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.5500\n",
      "Epoch 1687/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.9938 - val_acc: 0.5500\n",
      "Epoch 1688/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.5500\n",
      "Epoch 1689/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.5500\n",
      "Epoch 1690/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.5500\n",
      "Epoch 1691/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.5500\n",
      "Epoch 1692/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.9960 - val_acc: 0.5500\n",
      "Epoch 1693/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.9970 - val_acc: 0.5500\n",
      "Epoch 1694/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.9971 - val_acc: 0.5500\n",
      "Epoch 1695/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.9972 - val_acc: 0.5500\n",
      "Epoch 1696/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.9977 - val_acc: 0.5500\n",
      "Epoch 1697/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.9978 - val_acc: 0.5500\n",
      "Epoch 1698/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.9980 - val_acc: 0.5500\n",
      "Epoch 1699/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.9991 - val_acc: 0.5500\n",
      "Epoch 1700/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.9991 - val_acc: 0.5500\n",
      "Epoch 1701/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.9989 - val_acc: 0.5500\n",
      "Epoch 1702/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.9995 - val_acc: 0.5500\n",
      "Epoch 1703/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.9997 - val_acc: 0.5500\n",
      "Epoch 1704/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.9999 - val_acc: 0.5500\n",
      "Epoch 1705/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 1.0005 - val_acc: 0.5500\n",
      "Epoch 1706/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 1.0015 - val_acc: 0.5500\n",
      "Epoch 1707/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 1.0017 - val_acc: 0.5500\n",
      "Epoch 1708/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 1.0026 - val_acc: 0.5500\n",
      "Epoch 1709/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 1.0028 - val_acc: 0.5500\n",
      "Epoch 1710/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 1.0032 - val_acc: 0.5500\n",
      "Epoch 1711/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 1.0034 - val_acc: 0.5500\n",
      "Epoch 1712/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 1.0033 - val_acc: 0.5500\n",
      "Epoch 1713/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 1.0039 - val_acc: 0.5500\n",
      "Epoch 1714/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 1.0042 - val_acc: 0.5500\n",
      "Epoch 1715/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 1.0049 - val_acc: 0.5500\n",
      "Epoch 1716/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 1.0050 - val_acc: 0.5500\n",
      "Epoch 1717/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 1.0056 - val_acc: 0.5500\n",
      "Epoch 1718/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 1.0062 - val_acc: 0.5500\n",
      "Epoch 1719/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 1.0074 - val_acc: 0.5500\n",
      "Epoch 1720/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 1.0068 - val_acc: 0.5500\n",
      "Epoch 1721/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 1.0071 - val_acc: 0.5500\n",
      "Epoch 1722/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 1.0077 - val_acc: 0.5500\n",
      "Epoch 1723/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 1.0081 - val_acc: 0.5500\n",
      "Epoch 1724/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 1.0081 - val_acc: 0.5500\n",
      "Epoch 1725/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 1.0088 - val_acc: 0.5500\n",
      "Epoch 1726/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 1.0094 - val_acc: 0.5500\n",
      "Epoch 1727/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 1.0097 - val_acc: 0.5500\n",
      "Epoch 1728/3000\n",
      "79/79 [==============================] - 0s 185us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 1.0096 - val_acc: 0.5500\n",
      "Epoch 1729/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 1.0097 - val_acc: 0.5500\n",
      "Epoch 1730/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 1.0106 - val_acc: 0.5500\n",
      "Epoch 1731/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.5500\n",
      "Epoch 1732/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 1.0110 - val_acc: 0.5500\n",
      "Epoch 1733/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 1.0117 - val_acc: 0.5500\n",
      "Epoch 1734/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 1.0120 - val_acc: 0.5500\n",
      "Epoch 1735/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 1.0126 - val_acc: 0.5500\n",
      "Epoch 1736/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 1.0128 - val_acc: 0.5500\n",
      "Epoch 1737/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 1.0133 - val_acc: 0.5500\n",
      "Epoch 1738/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 1.0135 - val_acc: 0.5500\n",
      "Epoch 1739/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 1.0139 - val_acc: 0.5500\n",
      "Epoch 1740/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 1.0141 - val_acc: 0.5500\n",
      "Epoch 1741/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 1.0148 - val_acc: 0.5500\n",
      "Epoch 1742/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 1.0156 - val_acc: 0.5500\n",
      "Epoch 1743/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 1.0157 - val_acc: 0.5500\n",
      "Epoch 1744/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 1.0157 - val_acc: 0.5500\n",
      "Epoch 1745/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 1.0161 - val_acc: 0.5500\n",
      "Epoch 1746/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 1.0162 - val_acc: 0.5500\n",
      "Epoch 1747/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 1.0159 - val_acc: 0.5500\n",
      "Epoch 1748/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 1.0165 - val_acc: 0.5500\n",
      "Epoch 1749/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 1.0164 - val_acc: 0.5500\n",
      "Epoch 1750/3000\n",
      "79/79 [==============================] - 0s 192us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 1.0167 - val_acc: 0.5500\n",
      "Epoch 1751/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0173 - acc: 1.000 - 0s 151us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 1.0172 - val_acc: 0.5500\n",
      "Epoch 1752/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.5500\n",
      "Epoch 1753/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.5500\n",
      "Epoch 1754/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.5500\n",
      "Epoch 1755/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 1.0182 - val_acc: 0.5500\n",
      "Epoch 1756/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 1.0185 - val_acc: 0.5500\n",
      "Epoch 1757/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 1.0183 - val_acc: 0.5500\n",
      "Epoch 1758/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 1.0186 - val_acc: 0.5500\n",
      "Epoch 1759/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 1.0194 - val_acc: 0.5500\n",
      "Epoch 1760/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 1.0199 - val_acc: 0.5500\n",
      "Epoch 1761/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 1.0206 - val_acc: 0.5500\n",
      "Epoch 1762/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 1.0205 - val_acc: 0.5500\n",
      "Epoch 1763/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 1.0210 - val_acc: 0.5500\n",
      "Epoch 1764/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 1.0216 - val_acc: 0.5500\n",
      "Epoch 1765/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 1.0226 - val_acc: 0.5500\n",
      "Epoch 1766/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 1.0229 - val_acc: 0.5500\n",
      "Epoch 1767/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 1.0230 - val_acc: 0.5500\n",
      "Epoch 1768/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 1.0235 - val_acc: 0.5500\n",
      "Epoch 1769/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 1.0236 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1770/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 1.0235 - val_acc: 0.5500\n",
      "Epoch 1771/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 1.0240 - val_acc: 0.5500\n",
      "Epoch 1772/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 1.0243 - val_acc: 0.5500\n",
      "Epoch 1773/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 1.0251 - val_acc: 0.5500\n",
      "Epoch 1774/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 1.0252 - val_acc: 0.5500\n",
      "Epoch 1775/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.0256 - val_acc: 0.5500\n",
      "Epoch 1776/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.0255 - val_acc: 0.5500\n",
      "Epoch 1777/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.0256 - val_acc: 0.5500\n",
      "Epoch 1778/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 1.0261 - val_acc: 0.5500\n",
      "Epoch 1779/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.0277 - val_acc: 0.5500\n",
      "Epoch 1780/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 1.0276 - val_acc: 0.5500\n",
      "Epoch 1781/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 1.0278 - val_acc: 0.5500\n",
      "Epoch 1782/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 1.0286 - val_acc: 0.5500\n",
      "Epoch 1783/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.5500\n",
      "Epoch 1784/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.5500\n",
      "Epoch 1785/3000\n",
      "79/79 [==============================] - 0s 180us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.5500\n",
      "Epoch 1786/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.5500\n",
      "Epoch 1787/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.5500\n",
      "Epoch 1788/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 1.0301 - val_acc: 0.5500\n",
      "Epoch 1789/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 1790/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 1.0304 - val_acc: 0.5500\n",
      "Epoch 1791/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 1792/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 1.0313 - val_acc: 0.5500\n",
      "Epoch 1793/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 1.0315 - val_acc: 0.5500\n",
      "Epoch 1794/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 1.0315 - val_acc: 0.5500\n",
      "Epoch 1795/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 1.0319 - val_acc: 0.5500\n",
      "Epoch 1796/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 1.0320 - val_acc: 0.5500\n",
      "Epoch 1797/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 1.0324 - val_acc: 0.5500\n",
      "Epoch 1798/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 1.0330 - val_acc: 0.5500\n",
      "Epoch 1799/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 1.0342 - val_acc: 0.5500\n",
      "Epoch 1800/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 1.0348 - val_acc: 0.5500\n",
      "Epoch 1801/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.5500\n",
      "Epoch 1802/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 1.0356 - val_acc: 0.5500\n",
      "Epoch 1803/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.5500\n",
      "Epoch 1804/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 1.0364 - val_acc: 0.5500\n",
      "Epoch 1805/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 1.0367 - val_acc: 0.5500\n",
      "Epoch 1806/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 1.0364 - val_acc: 0.5500\n",
      "Epoch 1807/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 1.0373 - val_acc: 0.5500\n",
      "Epoch 1808/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 1.0372 - val_acc: 0.5500\n",
      "Epoch 1809/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 1.0369 - val_acc: 0.5500\n",
      "Epoch 1810/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 1.0375 - val_acc: 0.5500\n",
      "Epoch 1811/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 1.0379 - val_acc: 0.5500\n",
      "Epoch 1812/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 1.0376 - val_acc: 0.5500\n",
      "Epoch 1813/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 1.0379 - val_acc: 0.5500\n",
      "Epoch 1814/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 1.0381 - val_acc: 0.5500\n",
      "Epoch 1815/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 1.0381 - val_acc: 0.5500\n",
      "Epoch 1816/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 1.0385 - val_acc: 0.5500\n",
      "Epoch 1817/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 1.0388 - val_acc: 0.5500\n",
      "Epoch 1818/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.5500\n",
      "Epoch 1819/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 1.0398 - val_acc: 0.5500\n",
      "Epoch 1820/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 1.0396 - val_acc: 0.5500\n",
      "Epoch 1821/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.5500\n",
      "Epoch 1822/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.5500\n",
      "Epoch 1823/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 1.0410 - val_acc: 0.5500\n",
      "Epoch 1824/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 1.0413 - val_acc: 0.5500\n",
      "Epoch 1825/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 1.0423 - val_acc: 0.5500\n",
      "Epoch 1826/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 1.0423 - val_acc: 0.5500\n",
      "Epoch 1827/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 1.0427 - val_acc: 0.5500\n",
      "Epoch 1828/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 1.0428 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1829/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 1.0428 - val_acc: 0.5500\n",
      "Epoch 1830/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.5500\n",
      "Epoch 1831/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.5500\n",
      "Epoch 1832/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 1.0450 - val_acc: 0.5500\n",
      "Epoch 1833/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 1.0461 - val_acc: 0.5500\n",
      "Epoch 1834/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 1.0469 - val_acc: 0.5500\n",
      "Epoch 1835/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 1.0471 - val_acc: 0.5500\n",
      "Epoch 1836/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 1.0475 - val_acc: 0.5500\n",
      "Epoch 1837/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 1.0475 - val_acc: 0.5500\n",
      "Epoch 1838/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.5500\n",
      "Epoch 1839/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.5500\n",
      "Epoch 1840/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 1.0490 - val_acc: 0.5500\n",
      "Epoch 1841/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 1.0489 - val_acc: 0.5500\n",
      "Epoch 1842/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 1.0483 - val_acc: 0.5500\n",
      "Epoch 1843/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.5500\n",
      "Epoch 1844/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 1.0494 - val_acc: 0.5500\n",
      "Epoch 1845/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.5500\n",
      "Epoch 1846/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.5500\n",
      "Epoch 1847/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 1.0497 - val_acc: 0.5500\n",
      "Epoch 1848/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.5500\n",
      "Epoch 1849/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 1.0496 - val_acc: 0.5500\n",
      "Epoch 1850/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.5500\n",
      "Epoch 1851/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 1.0497 - val_acc: 0.5500\n",
      "Epoch 1852/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 1.0504 - val_acc: 0.5500\n",
      "Epoch 1853/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 1.0508 - val_acc: 0.5500\n",
      "Epoch 1854/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.5500\n",
      "Epoch 1855/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 1.0515 - val_acc: 0.5500\n",
      "Epoch 1856/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 1.0517 - val_acc: 0.5500\n",
      "Epoch 1857/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 1.0524 - val_acc: 0.5500\n",
      "Epoch 1858/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 1.0525 - val_acc: 0.5500\n",
      "Epoch 1859/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 1.0528 - val_acc: 0.5500\n",
      "Epoch 1860/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 1.0528 - val_acc: 0.5500\n",
      "Epoch 1861/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.5500\n",
      "Epoch 1862/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 1.0534 - val_acc: 0.5500\n",
      "Epoch 1863/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 1.0540 - val_acc: 0.5500\n",
      "Epoch 1864/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.5500\n",
      "Epoch 1865/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 1.0540 - val_acc: 0.5500\n",
      "Epoch 1866/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 1.0546 - val_acc: 0.5500\n",
      "Epoch 1867/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 1.0553 - val_acc: 0.5500\n",
      "Epoch 1868/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 1.0557 - val_acc: 0.5500\n",
      "Epoch 1869/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 1.0558 - val_acc: 0.5500\n",
      "Epoch 1870/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 1.0561 - val_acc: 0.5500\n",
      "Epoch 1871/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.5500\n",
      "Epoch 1872/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 1.0564 - val_acc: 0.5500\n",
      "Epoch 1873/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 1.0567 - val_acc: 0.5500\n",
      "Epoch 1874/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 1.0574 - val_acc: 0.5500\n",
      "Epoch 1875/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 1.0575 - val_acc: 0.5500\n",
      "Epoch 1876/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 1.0579 - val_acc: 0.5500\n",
      "Epoch 1877/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 1.0586 - val_acc: 0.5500\n",
      "Epoch 1878/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 1.0591 - val_acc: 0.5500\n",
      "Epoch 1879/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 1.0601 - val_acc: 0.5500\n",
      "Epoch 1880/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 1.0607 - val_acc: 0.5500\n",
      "Epoch 1881/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 1.0610 - val_acc: 0.5500\n",
      "Epoch 1882/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 1.0611 - val_acc: 0.5500\n",
      "Epoch 1883/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 1.0612 - val_acc: 0.5500\n",
      "Epoch 1884/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 1.0612 - val_acc: 0.5500\n",
      "Epoch 1885/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 1.0613 - val_acc: 0.5500\n",
      "Epoch 1886/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 1.0619 - val_acc: 0.5500\n",
      "Epoch 1887/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 1.0623 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 1.0630 - val_acc: 0.5500\n",
      "Epoch 1889/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 1.0632 - val_acc: 0.5500\n",
      "Epoch 1890/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 1.0637 - val_acc: 0.5500\n",
      "Epoch 1891/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 1.0639 - val_acc: 0.5500\n",
      "Epoch 1892/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.5500\n",
      "Epoch 1893/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.5500\n",
      "Epoch 1894/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 1.0642 - val_acc: 0.5500\n",
      "Epoch 1895/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0642 - val_acc: 0.5500\n",
      "Epoch 1896/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0647 - val_acc: 0.5500\n",
      "Epoch 1897/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.5500\n",
      "Epoch 1898/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 1.0652 - val_acc: 0.5500\n",
      "Epoch 1899/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0655 - val_acc: 0.5500\n",
      "Epoch 1900/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.5500\n",
      "Epoch 1901/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 1.0657 - val_acc: 0.5500\n",
      "Epoch 1902/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 1.0660 - val_acc: 0.5500\n",
      "Epoch 1903/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 1.0660 - val_acc: 0.5500\n",
      "Epoch 1904/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 1.0663 - val_acc: 0.5500\n",
      "Epoch 1905/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 1.0666 - val_acc: 0.5500\n",
      "Epoch 1906/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 1.0673 - val_acc: 0.5500\n",
      "Epoch 1907/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 1.0680 - val_acc: 0.5500\n",
      "Epoch 1908/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 1.0682 - val_acc: 0.5500\n",
      "Epoch 1909/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 1.0675 - val_acc: 0.5500\n",
      "Epoch 1910/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.5500\n",
      "Epoch 1911/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 1.0683 - val_acc: 0.5500\n",
      "Epoch 1912/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 1.0685 - val_acc: 0.5500\n",
      "Epoch 1913/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 1.0688 - val_acc: 0.5500\n",
      "Epoch 1914/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 1.0691 - val_acc: 0.5500\n",
      "Epoch 1915/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 1.0700 - val_acc: 0.5500\n",
      "Epoch 1916/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 1.0703 - val_acc: 0.5500\n",
      "Epoch 1917/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 1.0707 - val_acc: 0.5500\n",
      "Epoch 1918/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.5500\n",
      "Epoch 1919/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0715 - val_acc: 0.5500\n",
      "Epoch 1920/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0717 - val_acc: 0.5500\n",
      "Epoch 1921/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0720 - val_acc: 0.5500\n",
      "Epoch 1922/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0729 - val_acc: 0.5500\n",
      "Epoch 1923/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 1.0729 - val_acc: 0.5500\n",
      "Epoch 1924/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 1.0730 - val_acc: 0.5500\n",
      "Epoch 1925/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 1.0730 - val_acc: 0.5500\n",
      "Epoch 1926/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.5500\n",
      "Epoch 1927/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0741 - val_acc: 0.5500\n",
      "Epoch 1928/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.5500\n",
      "Epoch 1929/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0744 - val_acc: 0.5500\n",
      "Epoch 1930/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0753 - val_acc: 0.5500\n",
      "Epoch 1931/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0756 - val_acc: 0.5500\n",
      "Epoch 1932/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0756 - val_acc: 0.5500\n",
      "Epoch 1933/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0759 - val_acc: 0.5500\n",
      "Epoch 1934/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0578 - val_acc: 0.5500\n",
      "Epoch 1935/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.5500\n",
      "Epoch 1936/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 1.0874 - val_acc: 0.5500\n",
      "Epoch 1937/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.5500\n",
      "Epoch 1938/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0735 - val_acc: 0.5500\n",
      "Epoch 1939/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 1.0734 - val_acc: 0.5500\n",
      "Epoch 1940/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 1.0731 - val_acc: 0.5500\n",
      "Epoch 1941/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 1.0727 - val_acc: 0.5500\n",
      "Epoch 1942/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0788 - val_acc: 0.5500\n",
      "Epoch 1943/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 1.0894 - val_acc: 0.5500\n",
      "Epoch 1944/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.5500\n",
      "Epoch 1945/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.5500\n",
      "Epoch 1946/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0723 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1947/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 1.0718 - val_acc: 0.5500\n",
      "Epoch 1948/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0711 - val_acc: 0.5500\n",
      "Epoch 1949/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0689 - val_acc: 0.5500\n",
      "Epoch 1950/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0602 - val_acc: 0.5500\n",
      "Epoch 1951/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0189 - acc: 1.000 - 0s 132us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0713 - val_acc: 0.5500\n",
      "Epoch 1952/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 1.0587 - val_acc: 0.5500\n",
      "Epoch 1953/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0765 - val_acc: 0.5500\n",
      "Epoch 1954/3000\n",
      "79/79 [==============================] - 0s 290us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0933 - val_acc: 0.5500\n",
      "Epoch 1955/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 1.0922 - val_acc: 0.5500\n",
      "Epoch 1956/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.5500\n",
      "Epoch 1957/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 1.0602 - val_acc: 0.5500\n",
      "Epoch 1958/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 1.0607 - val_acc: 0.5500\n",
      "Epoch 1959/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 1.0605 - val_acc: 0.5500\n",
      "Epoch 1960/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 1.0606 - val_acc: 0.5500\n",
      "Epoch 1961/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 1.0609 - val_acc: 0.5500\n",
      "Epoch 1962/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 1.0609 - val_acc: 0.5500\n",
      "Epoch 1963/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 1.0609 - val_acc: 0.5500\n",
      "Epoch 1964/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.000 - 0s 164us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 1.0609 - val_acc: 0.5500\n",
      "Epoch 1965/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0610 - val_acc: 0.5500\n",
      "Epoch 1966/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0612 - val_acc: 0.5500\n",
      "Epoch 1967/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0615 - val_acc: 0.5500\n",
      "Epoch 1968/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0622 - val_acc: 0.5500\n",
      "Epoch 1969/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 1.0623 - val_acc: 0.5500\n",
      "Epoch 1970/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 1.0627 - val_acc: 0.5500\n",
      "Epoch 1971/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 1.0628 - val_acc: 0.5500\n",
      "Epoch 1972/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 1.0634 - val_acc: 0.5500\n",
      "Epoch 1973/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 1.0632 - val_acc: 0.5500\n",
      "Epoch 1974/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 1.0632 - val_acc: 0.5500\n",
      "Epoch 1975/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.5500\n",
      "Epoch 1976/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 1.0642 - val_acc: 0.5500\n",
      "Epoch 1977/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.5500\n",
      "Epoch 1978/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 1.0649 - val_acc: 0.5500\n",
      "Epoch 1979/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 1.0650 - val_acc: 0.5500\n",
      "Epoch 1980/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.5500\n",
      "Epoch 1981/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 1.0655 - val_acc: 0.5500\n",
      "Epoch 1982/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 1.0658 - val_acc: 0.5500\n",
      "Epoch 1983/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 1.0663 - val_acc: 0.5500\n",
      "Epoch 1984/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 1.0665 - val_acc: 0.5500\n",
      "Epoch 1985/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.0669 - val_acc: 0.5500\n",
      "Epoch 1986/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.0674 - val_acc: 0.5500\n",
      "Epoch 1987/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.5500\n",
      "Epoch 1988/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.0674 - val_acc: 0.5500\n",
      "Epoch 1989/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 1.0678 - val_acc: 0.5500\n",
      "Epoch 1990/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 1.0680 - val_acc: 0.5500\n",
      "Epoch 1991/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 1.0684 - val_acc: 0.5500\n",
      "Epoch 1992/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 1.0687 - val_acc: 0.5500\n",
      "Epoch 1993/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 1.0693 - val_acc: 0.5500\n",
      "Epoch 1994/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 1.0695 - val_acc: 0.5500\n",
      "Epoch 1995/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 1.0698 - val_acc: 0.5500\n",
      "Epoch 1996/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 1.0702 - val_acc: 0.5500\n",
      "Epoch 1997/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 1.0703 - val_acc: 0.5500\n",
      "Epoch 1998/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 1.0709 - val_acc: 0.5500\n",
      "Epoch 1999/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 1.0719 - val_acc: 0.5500\n",
      "Epoch 2000/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.0719 - val_acc: 0.5500\n",
      "Epoch 2001/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.0716 - val_acc: 0.5500\n",
      "Epoch 2002/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.5500\n",
      "Epoch 2003/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.5500\n",
      "Epoch 2004/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 1.0719 - val_acc: 0.5500\n",
      "Epoch 2005/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 1.0722 - val_acc: 0.5500\n",
      "Epoch 2006/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 1.0722 - val_acc: 0.5500\n",
      "Epoch 2007/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 1.0730 - val_acc: 0.5500\n",
      "Epoch 2008/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 1.0734 - val_acc: 0.5500\n",
      "Epoch 2009/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 1.0735 - val_acc: 0.5500\n",
      "Epoch 2010/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 1.0738 - val_acc: 0.5500\n",
      "Epoch 2011/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 1.0746 - val_acc: 0.5500\n",
      "Epoch 2012/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 1.0750 - val_acc: 0.5500\n",
      "Epoch 2013/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 1.0754 - val_acc: 0.5500\n",
      "Epoch 2014/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 1.0753 - val_acc: 0.5500\n",
      "Epoch 2015/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 1.0756 - val_acc: 0.5500\n",
      "Epoch 2016/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 1.0762 - val_acc: 0.5500\n",
      "Epoch 2017/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 1.0768 - val_acc: 0.5500\n",
      "Epoch 2018/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 1.0778 - val_acc: 0.5500\n",
      "Epoch 2019/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 1.0814 - val_acc: 0.5500\n",
      "Epoch 2020/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 1.0766 - val_acc: 0.5500\n",
      "Epoch 2021/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 1.0847 - val_acc: 0.5500\n",
      "Epoch 2022/3000\n",
      "79/79 [==============================] - 0s 240us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 1.0831 - val_acc: 0.5500\n",
      "Epoch 2023/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0833 - val_acc: 0.5500\n",
      "Epoch 2024/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0832 - val_acc: 0.5500\n",
      "Epoch 2025/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0833 - val_acc: 0.5500\n",
      "Epoch 2026/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0836 - val_acc: 0.5500\n",
      "Epoch 2027/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 1.0837 - val_acc: 0.5500\n",
      "Epoch 2028/3000\n",
      "79/79 [==============================] - 0s 184us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0833 - val_acc: 0.5500\n",
      "Epoch 2029/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 1.0834 - val_acc: 0.5500\n",
      "Epoch 2030/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 1.0838 - val_acc: 0.5500\n",
      "Epoch 2031/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 1.0839 - val_acc: 0.5500\n",
      "Epoch 2032/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.5500\n",
      "Epoch 2033/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 1.0841 - val_acc: 0.5500\n",
      "Epoch 2034/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.5500\n",
      "Epoch 2035/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 1.0846 - val_acc: 0.5500\n",
      "Epoch 2036/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 1.0851 - val_acc: 0.5500\n",
      "Epoch 2037/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 1.0857 - val_acc: 0.5500\n",
      "Epoch 2038/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 1.0862 - val_acc: 0.5500\n",
      "Epoch 2039/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.5500\n",
      "Epoch 2040/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.0868 - val_acc: 0.5500\n",
      "Epoch 2041/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.0869 - val_acc: 0.5500\n",
      "Epoch 2042/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.0869 - val_acc: 0.5500\n",
      "Epoch 2043/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.5500\n",
      "Epoch 2044/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.5500\n",
      "Epoch 2045/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 1.0878 - val_acc: 0.5500\n",
      "Epoch 2046/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 1.0885 - val_acc: 0.5500\n",
      "Epoch 2047/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.5500\n",
      "Epoch 2048/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.5500\n",
      "Epoch 2049/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 1.0893 - val_acc: 0.5500\n",
      "Epoch 2050/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 1.0896 - val_acc: 0.5500\n",
      "Epoch 2051/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.5500\n",
      "Epoch 2052/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.5500\n",
      "Epoch 2053/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.5500\n",
      "Epoch 2054/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.5500\n",
      "Epoch 2055/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.5500\n",
      "Epoch 2056/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 1.0904 - val_acc: 0.5500\n",
      "Epoch 2057/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 1.0909 - val_acc: 0.5500\n",
      "Epoch 2058/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 1.0911 - val_acc: 0.5500\n",
      "Epoch 2059/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 1.0911 - val_acc: 0.5500\n",
      "Epoch 2060/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.5500\n",
      "Epoch 2061/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 1.0916 - val_acc: 0.5500\n",
      "Epoch 2062/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.5500\n",
      "Epoch 2063/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.5500\n",
      "Epoch 2064/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 1.0923 - val_acc: 0.5500\n",
      "Epoch 2065/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 1.0923 - val_acc: 0.5500\n",
      "Epoch 2066/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 1.0929 - val_acc: 0.5500\n",
      "Epoch 2067/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.5500\n",
      "Epoch 2068/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0931 - val_acc: 0.5500\n",
      "Epoch 2069/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0935 - val_acc: 0.5500\n",
      "Epoch 2070/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0937 - val_acc: 0.5500\n",
      "Epoch 2071/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.5500\n",
      "Epoch 2072/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.5500\n",
      "Epoch 2073/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 1.0939 - val_acc: 0.5500\n",
      "Epoch 2074/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 1.0942 - val_acc: 0.5500\n",
      "Epoch 2075/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 1.0942 - val_acc: 0.5500\n",
      "Epoch 2076/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 1.0947 - val_acc: 0.5500\n",
      "Epoch 2077/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 1.0947 - val_acc: 0.5500\n",
      "Epoch 2078/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 1.0949 - val_acc: 0.5500\n",
      "Epoch 2079/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 1.0954 - val_acc: 0.5500\n",
      "Epoch 2080/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 1.0955 - val_acc: 0.5500\n",
      "Epoch 2081/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0956 - val_acc: 0.5500\n",
      "Epoch 2082/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0956 - val_acc: 0.5500\n",
      "Epoch 2083/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0960 - val_acc: 0.5500\n",
      "Epoch 2084/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0966 - val_acc: 0.5500\n",
      "Epoch 2085/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0966 - val_acc: 0.5500\n",
      "Epoch 2086/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0975 - val_acc: 0.5500\n",
      "Epoch 2087/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.0978 - val_acc: 0.5500\n",
      "Epoch 2088/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.0983 - val_acc: 0.5500\n",
      "Epoch 2089/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.0983 - val_acc: 0.5500\n",
      "Epoch 2090/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.0990 - val_acc: 0.5500\n",
      "Epoch 2091/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 1.0989 - val_acc: 0.5500\n",
      "Epoch 2092/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 1.0995 - val_acc: 0.5500\n",
      "Epoch 2093/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.0996 - val_acc: 0.5500\n",
      "Epoch 2094/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 1.0995 - val_acc: 0.5500\n",
      "Epoch 2095/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 1.1002 - val_acc: 0.5500\n",
      "Epoch 2096/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1005 - val_acc: 0.5500\n",
      "Epoch 2097/3000\n",
      "79/79 [==============================] - 0s 194us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1004 - val_acc: 0.5500\n",
      "Epoch 2098/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1006 - val_acc: 0.5500\n",
      "Epoch 2099/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1011 - val_acc: 0.5500\n",
      "Epoch 2100/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1012 - val_acc: 0.5500\n",
      "Epoch 2101/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.1011 - val_acc: 0.5500\n",
      "Epoch 2102/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.1013 - val_acc: 0.5500\n",
      "Epoch 2103/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.1011 - val_acc: 0.5500\n",
      "Epoch 2104/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.5500\n",
      "Epoch 2105/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.5500\n",
      "Epoch 2106/3000\n",
      "79/79 [==============================] - 0s 178us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1019 - val_acc: 0.5500\n",
      "Epoch 2107/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1021 - val_acc: 0.5500\n",
      "Epoch 2108/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1023 - val_acc: 0.5500\n",
      "Epoch 2109/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1027 - val_acc: 0.5500\n",
      "Epoch 2110/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1025 - val_acc: 0.5500\n",
      "Epoch 2111/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1023 - val_acc: 0.5500\n",
      "Epoch 2112/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1027 - val_acc: 0.5500\n",
      "Epoch 2113/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1028 - val_acc: 0.5500\n",
      "Epoch 2114/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1029 - val_acc: 0.5500\n",
      "Epoch 2115/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1032 - val_acc: 0.5500\n",
      "Epoch 2116/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.1033 - val_acc: 0.5500\n",
      "Epoch 2117/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 1.1037 - val_acc: 0.5500\n",
      "Epoch 2118/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 1.1039 - val_acc: 0.5500\n",
      "Epoch 2119/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 1.1038 - val_acc: 0.5500\n",
      "Epoch 2120/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 1.1038 - val_acc: 0.5500\n",
      "Epoch 2121/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 1.1036 - val_acc: 0.5500\n",
      "Epoch 2122/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 1.1043 - val_acc: 0.5500\n",
      "Epoch 2123/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 1.1047 - val_acc: 0.5500\n",
      "Epoch 2124/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 1.1049 - val_acc: 0.5500\n",
      "Epoch 2125/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 1.1054 - val_acc: 0.5500\n",
      "Epoch 2126/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1055 - val_acc: 0.5500\n",
      "Epoch 2127/3000\n",
      "79/79 [==============================] - 0s 176us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1054 - val_acc: 0.5500\n",
      "Epoch 2128/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1060 - val_acc: 0.5500\n",
      "Epoch 2129/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1066 - val_acc: 0.5500\n",
      "Epoch 2130/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1067 - val_acc: 0.5500\n",
      "Epoch 2131/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1070 - val_acc: 0.5500\n",
      "Epoch 2132/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0116 - acc: 1.000 - 0s 157us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 1.1080 - val_acc: 0.5500\n",
      "Epoch 2133/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 1.1077 - val_acc: 0.5500\n",
      "Epoch 2134/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 1.1080 - val_acc: 0.5500\n",
      "Epoch 2135/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 1.1086 - val_acc: 0.5500\n",
      "Epoch 2136/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 1.1090 - val_acc: 0.5500\n",
      "Epoch 2137/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1089 - val_acc: 0.5500\n",
      "Epoch 2138/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1089 - val_acc: 0.5500\n",
      "Epoch 2139/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1093 - val_acc: 0.5500\n",
      "Epoch 2140/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1095 - val_acc: 0.5500\n",
      "Epoch 2141/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1098 - val_acc: 0.5500\n",
      "Epoch 2142/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1097 - val_acc: 0.5500\n",
      "Epoch 2143/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 1.1097 - val_acc: 0.5500\n",
      "Epoch 2144/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1099 - val_acc: 0.5500\n",
      "Epoch 2145/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1099 - val_acc: 0.5500\n",
      "Epoch 2146/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1098 - val_acc: 0.5500\n",
      "Epoch 2147/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1099 - val_acc: 0.5500\n",
      "Epoch 2148/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1103 - val_acc: 0.5500\n",
      "Epoch 2149/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 1.1106 - val_acc: 0.5500\n",
      "Epoch 2150/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 1.1111 - val_acc: 0.5500\n",
      "Epoch 2151/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 1.1113 - val_acc: 0.5500\n",
      "Epoch 2152/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 1.1119 - val_acc: 0.5500\n",
      "Epoch 2153/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 1.1121 - val_acc: 0.5500\n",
      "Epoch 2154/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 1.1123 - val_acc: 0.5500\n",
      "Epoch 2155/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 1.1126 - val_acc: 0.5500\n",
      "Epoch 2156/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 1.1127 - val_acc: 0.5500\n",
      "Epoch 2157/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 1.1131 - val_acc: 0.5500\n",
      "Epoch 2158/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1136 - val_acc: 0.5500\n",
      "Epoch 2159/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.5500\n",
      "Epoch 2160/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.5500\n",
      "Epoch 2161/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1137 - val_acc: 0.5500\n",
      "Epoch 2162/3000\n",
      "79/79 [==============================] - 0s 220us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1142 - val_acc: 0.5500\n",
      "Epoch 2163/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.5500\n",
      "Epoch 2164/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1150 - val_acc: 0.5500\n",
      "Epoch 2165/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.5500\n",
      "Epoch 2166/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1152 - val_acc: 0.5500\n",
      "Epoch 2167/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1153 - val_acc: 0.5500\n",
      "Epoch 2168/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1156 - val_acc: 0.5500\n",
      "Epoch 2169/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 1.1160 - val_acc: 0.5500\n",
      "Epoch 2170/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1159 - val_acc: 0.5500\n",
      "Epoch 2171/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1159 - val_acc: 0.5500\n",
      "Epoch 2172/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1162 - val_acc: 0.5500\n",
      "Epoch 2173/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1158 - val_acc: 0.5500\n",
      "Epoch 2174/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1161 - val_acc: 0.5500\n",
      "Epoch 2175/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 1.1159 - val_acc: 0.5500\n",
      "Epoch 2176/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1161 - val_acc: 0.5500\n",
      "Epoch 2177/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1165 - val_acc: 0.5500\n",
      "Epoch 2178/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1168 - val_acc: 0.5500\n",
      "Epoch 2179/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1174 - val_acc: 0.5500\n",
      "Epoch 2180/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1173 - val_acc: 0.5500\n",
      "Epoch 2181/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1177 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2182/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1182 - val_acc: 0.5500\n",
      "Epoch 2183/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1185 - val_acc: 0.5500\n",
      "Epoch 2184/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1186 - val_acc: 0.5500\n",
      "Epoch 2185/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1187 - val_acc: 0.5500\n",
      "Epoch 2186/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1188 - val_acc: 0.5500\n",
      "Epoch 2187/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1188 - val_acc: 0.5500\n",
      "Epoch 2188/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 1.1193 - val_acc: 0.5500\n",
      "Epoch 2189/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1197 - val_acc: 0.5500\n",
      "Epoch 2190/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1200 - val_acc: 0.5500\n",
      "Epoch 2191/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1204 - val_acc: 0.5500\n",
      "Epoch 2192/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1204 - val_acc: 0.5500\n",
      "Epoch 2193/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1206 - val_acc: 0.5500\n",
      "Epoch 2194/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1211 - val_acc: 0.5500\n",
      "Epoch 2195/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1216 - val_acc: 0.5500\n",
      "Epoch 2196/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1221 - val_acc: 0.5500\n",
      "Epoch 2197/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1225 - val_acc: 0.5500\n",
      "Epoch 2198/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1228 - val_acc: 0.5500\n",
      "Epoch 2199/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1228 - val_acc: 0.5500\n",
      "Epoch 2200/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1233 - val_acc: 0.5500\n",
      "Epoch 2201/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1234 - val_acc: 0.5500\n",
      "Epoch 2202/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1235 - val_acc: 0.5500\n",
      "Epoch 2203/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1238 - val_acc: 0.5500\n",
      "Epoch 2204/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1237 - val_acc: 0.5500\n",
      "Epoch 2205/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1242 - val_acc: 0.5500\n",
      "Epoch 2206/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1243 - val_acc: 0.5500\n",
      "Epoch 2207/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1248 - val_acc: 0.5500\n",
      "Epoch 2208/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 1.1248 - val_acc: 0.5500\n",
      "Epoch 2209/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1248 - val_acc: 0.5500\n",
      "Epoch 2210/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1250 - val_acc: 0.5500\n",
      "Epoch 2211/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1253 - val_acc: 0.5500\n",
      "Epoch 2212/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1255 - val_acc: 0.5500\n",
      "Epoch 2213/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1253 - val_acc: 0.5500\n",
      "Epoch 2214/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1259 - val_acc: 0.5500\n",
      "Epoch 2215/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1258 - val_acc: 0.5500\n",
      "Epoch 2216/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1262 - val_acc: 0.5500\n",
      "Epoch 2217/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1263 - val_acc: 0.5500\n",
      "Epoch 2218/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1262 - val_acc: 0.5500\n",
      "Epoch 2219/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1265 - val_acc: 0.5500\n",
      "Epoch 2220/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1270 - val_acc: 0.5500\n",
      "Epoch 2221/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1268 - val_acc: 0.5500\n",
      "Epoch 2222/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1268 - val_acc: 0.5500\n",
      "Epoch 2223/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1272 - val_acc: 0.5500\n",
      "Epoch 2224/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1275 - val_acc: 0.5500\n",
      "Epoch 2225/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1275 - val_acc: 0.5500\n",
      "Epoch 2226/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1280 - val_acc: 0.5500\n",
      "Epoch 2227/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1279 - val_acc: 0.5500\n",
      "Epoch 2228/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1279 - val_acc: 0.5500\n",
      "Epoch 2229/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1278 - val_acc: 0.5500\n",
      "Epoch 2230/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 1.1280 - val_acc: 0.5500\n",
      "Epoch 2231/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1282 - val_acc: 0.5500\n",
      "Epoch 2232/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1284 - val_acc: 0.5500\n",
      "Epoch 2233/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1285 - val_acc: 0.5500\n",
      "Epoch 2234/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1285 - val_acc: 0.5500\n",
      "Epoch 2235/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1291 - val_acc: 0.5500\n",
      "Epoch 2236/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1292 - val_acc: 0.5500\n",
      "Epoch 2237/3000\n",
      "79/79 [==============================] - 0s 190us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1296 - val_acc: 0.5500\n",
      "Epoch 2238/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1301 - val_acc: 0.5500\n",
      "Epoch 2239/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1309 - val_acc: 0.5500\n",
      "Epoch 2240/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1311 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2241/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1312 - val_acc: 0.5500\n",
      "Epoch 2242/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1311 - val_acc: 0.5500\n",
      "Epoch 2243/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 1.1306 - val_acc: 0.5500\n",
      "Epoch 2244/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1308 - val_acc: 0.5500\n",
      "Epoch 2245/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1308 - val_acc: 0.5500\n",
      "Epoch 2246/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1314 - val_acc: 0.5500\n",
      "Epoch 2247/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1311 - val_acc: 0.5500\n",
      "Epoch 2248/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1312 - val_acc: 0.5500\n",
      "Epoch 2249/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1316 - val_acc: 0.5500\n",
      "Epoch 2250/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1318 - val_acc: 0.5500\n",
      "Epoch 2251/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 1.1315 - val_acc: 0.5500\n",
      "Epoch 2252/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1320 - val_acc: 0.5500\n",
      "Epoch 2253/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1320 - val_acc: 0.5500\n",
      "Epoch 2254/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1318 - val_acc: 0.5500\n",
      "Epoch 2255/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1322 - val_acc: 0.5500\n",
      "Epoch 2256/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1324 - val_acc: 0.5500\n",
      "Epoch 2257/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1330 - val_acc: 0.5500\n",
      "Epoch 2258/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1335 - val_acc: 0.5500\n",
      "Epoch 2259/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1339 - val_acc: 0.5500\n",
      "Epoch 2260/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1339 - val_acc: 0.5500\n",
      "Epoch 2261/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1336 - val_acc: 0.5500\n",
      "Epoch 2262/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1340 - val_acc: 0.5500\n",
      "Epoch 2263/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1348 - val_acc: 0.5500\n",
      "Epoch 2264/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1345 - val_acc: 0.5500\n",
      "Epoch 2265/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1350 - val_acc: 0.5500\n",
      "Epoch 2266/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 1.1354 - val_acc: 0.5500\n",
      "Epoch 2267/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1352 - val_acc: 0.5500\n",
      "Epoch 2268/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1356 - val_acc: 0.5500\n",
      "Epoch 2269/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1361 - val_acc: 0.5500\n",
      "Epoch 2270/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1365 - val_acc: 0.5500\n",
      "Epoch 2271/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1366 - val_acc: 0.5500\n",
      "Epoch 2272/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1372 - val_acc: 0.5500\n",
      "Epoch 2273/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1374 - val_acc: 0.5500\n",
      "Epoch 2274/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1375 - val_acc: 0.5500\n",
      "Epoch 2275/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1373 - val_acc: 0.5500\n",
      "Epoch 2276/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1379 - val_acc: 0.5500\n",
      "Epoch 2277/3000\n",
      "79/79 [==============================] - 0s 240us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1381 - val_acc: 0.5500\n",
      "Epoch 2278/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1379 - val_acc: 0.5500\n",
      "Epoch 2279/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1382 - val_acc: 0.5500\n",
      "Epoch 2280/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1383 - val_acc: 0.5500\n",
      "Epoch 2281/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.5500\n",
      "Epoch 2282/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.5500\n",
      "Epoch 2283/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1382 - val_acc: 0.5500\n",
      "Epoch 2284/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.5500\n",
      "Epoch 2285/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1389 - val_acc: 0.5500\n",
      "Epoch 2286/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1393 - val_acc: 0.5500\n",
      "Epoch 2287/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1396 - val_acc: 0.5500\n",
      "Epoch 2288/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1396 - val_acc: 0.5500\n",
      "Epoch 2289/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.1395 - val_acc: 0.5500\n",
      "Epoch 2290/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1395 - val_acc: 0.5500\n",
      "Epoch 2291/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1402 - val_acc: 0.5500\n",
      "Epoch 2292/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1403 - val_acc: 0.5500\n",
      "Epoch 2293/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1408 - val_acc: 0.5500\n",
      "Epoch 2294/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1410 - val_acc: 0.5500\n",
      "Epoch 2295/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1413 - val_acc: 0.5500\n",
      "Epoch 2296/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.5500\n",
      "Epoch 2297/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.5500\n",
      "Epoch 2298/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1424 - val_acc: 0.5500\n",
      "Epoch 2299/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1424 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2300/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1426 - val_acc: 0.5500\n",
      "Epoch 2301/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1429 - val_acc: 0.5500\n",
      "Epoch 2302/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1427 - val_acc: 0.5500\n",
      "Epoch 2303/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1431 - val_acc: 0.5500\n",
      "Epoch 2304/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1434 - val_acc: 0.5500\n",
      "Epoch 2305/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 1.1438 - val_acc: 0.5500\n",
      "Epoch 2306/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1444 - val_acc: 0.5500\n",
      "Epoch 2307/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1442 - val_acc: 0.5500\n",
      "Epoch 2308/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1444 - val_acc: 0.5500\n",
      "Epoch 2309/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1445 - val_acc: 0.5500\n",
      "Epoch 2310/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1447 - val_acc: 0.5500\n",
      "Epoch 2311/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1448 - val_acc: 0.5500\n",
      "Epoch 2312/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1449 - val_acc: 0.5500\n",
      "Epoch 2313/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1448 - val_acc: 0.5500\n",
      "Epoch 2314/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1449 - val_acc: 0.5500\n",
      "Epoch 2315/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1451 - val_acc: 0.5500\n",
      "Epoch 2316/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1453 - val_acc: 0.5500\n",
      "Epoch 2317/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1452 - val_acc: 0.5500\n",
      "Epoch 2318/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1454 - val_acc: 0.5500\n",
      "Epoch 2319/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1458 - val_acc: 0.5500\n",
      "Epoch 2320/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.5500\n",
      "Epoch 2321/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1467 - val_acc: 0.5500\n",
      "Epoch 2322/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1470 - val_acc: 0.5500\n",
      "Epoch 2323/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1468 - val_acc: 0.5500\n",
      "Epoch 2324/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.000 - 0s 145us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1474 - val_acc: 0.5500\n",
      "Epoch 2325/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1476 - val_acc: 0.5500\n",
      "Epoch 2326/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1478 - val_acc: 0.5500\n",
      "Epoch 2327/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1482 - val_acc: 0.5500\n",
      "Epoch 2328/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1482 - val_acc: 0.5500\n",
      "Epoch 2329/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1487 - val_acc: 0.5500\n",
      "Epoch 2330/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1489 - val_acc: 0.5500\n",
      "Epoch 2331/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.5500\n",
      "Epoch 2332/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1491 - val_acc: 0.5500\n",
      "Epoch 2333/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1491 - val_acc: 0.5500\n",
      "Epoch 2334/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.5500\n",
      "Epoch 2335/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1496 - val_acc: 0.5500\n",
      "Epoch 2336/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1504 - val_acc: 0.5500\n",
      "Epoch 2337/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1503 - val_acc: 0.5500\n",
      "Epoch 2338/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1507 - val_acc: 0.5500\n",
      "Epoch 2339/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1505 - val_acc: 0.5500\n",
      "Epoch 2340/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1508 - val_acc: 0.5500\n",
      "Epoch 2341/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1508 - val_acc: 0.5500\n",
      "Epoch 2342/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1513 - val_acc: 0.5500\n",
      "Epoch 2343/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1517 - val_acc: 0.5500\n",
      "Epoch 2344/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1517 - val_acc: 0.5500\n",
      "Epoch 2345/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1525 - val_acc: 0.6000\n",
      "Epoch 2346/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1530 - val_acc: 0.6000\n",
      "Epoch 2347/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1531 - val_acc: 0.6000\n",
      "Epoch 2348/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1535 - val_acc: 0.6000\n",
      "Epoch 2349/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 1.1528 - val_acc: 0.5500\n",
      "Epoch 2350/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1529 - val_acc: 0.5500\n",
      "Epoch 2351/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1533 - val_acc: 0.5500\n",
      "Epoch 2352/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1535 - val_acc: 0.5500\n",
      "Epoch 2353/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1539 - val_acc: 0.5500\n",
      "Epoch 2354/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1538 - val_acc: 0.5500\n",
      "Epoch 2355/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1537 - val_acc: 0.5500\n",
      "Epoch 2356/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1537 - val_acc: 0.5500\n",
      "Epoch 2357/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1541 - val_acc: 0.5500\n",
      "Epoch 2358/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1544 - val_acc: 0.5500\n",
      "Epoch 2359/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1546 - val_acc: 0.5500\n",
      "Epoch 2360/3000\n",
      "79/79 [==============================] - 0s 233us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1547 - val_acc: 0.5500\n",
      "Epoch 2361/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1545 - val_acc: 0.5500\n",
      "Epoch 2362/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1548 - val_acc: 0.5500\n",
      "Epoch 2363/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1552 - val_acc: 0.5500\n",
      "Epoch 2364/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1555 - val_acc: 0.5500\n",
      "Epoch 2365/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1560 - val_acc: 0.5500\n",
      "Epoch 2366/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1560 - val_acc: 0.5500\n",
      "Epoch 2367/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1563 - val_acc: 0.5500\n",
      "Epoch 2368/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1560 - val_acc: 0.5500\n",
      "Epoch 2369/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1561 - val_acc: 0.5500\n",
      "Epoch 2370/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1564 - val_acc: 0.5500\n",
      "Epoch 2371/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1563 - val_acc: 0.5500\n",
      "Epoch 2372/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1570 - val_acc: 0.5500\n",
      "Epoch 2373/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1570 - val_acc: 0.5500\n",
      "Epoch 2374/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1570 - val_acc: 0.5500\n",
      "Epoch 2375/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1574 - val_acc: 0.5500\n",
      "Epoch 2376/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1573 - val_acc: 0.5500\n",
      "Epoch 2377/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1579 - val_acc: 0.5500\n",
      "Epoch 2378/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1580 - val_acc: 0.5500\n",
      "Epoch 2379/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1581 - val_acc: 0.5500\n",
      "Epoch 2380/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1582 - val_acc: 0.5500\n",
      "Epoch 2381/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1583 - val_acc: 0.5500\n",
      "Epoch 2382/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1584 - val_acc: 0.5500\n",
      "Epoch 2383/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1579 - val_acc: 0.5500\n",
      "Epoch 2384/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1584 - val_acc: 0.5500\n",
      "Epoch 2385/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.1586 - val_acc: 0.5500\n",
      "Epoch 2386/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1587 - val_acc: 0.5500\n",
      "Epoch 2387/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1588 - val_acc: 0.5500\n",
      "Epoch 2388/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1593 - val_acc: 0.5500\n",
      "Epoch 2389/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1596 - val_acc: 0.5500\n",
      "Epoch 2390/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1597 - val_acc: 0.5500\n",
      "Epoch 2391/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.5500\n",
      "Epoch 2392/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.5500\n",
      "Epoch 2393/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.5500\n",
      "Epoch 2394/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1603 - val_acc: 0.5500\n",
      "Epoch 2395/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1603 - val_acc: 0.5500\n",
      "Epoch 2396/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1606 - val_acc: 0.5500\n",
      "Epoch 2397/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1608 - val_acc: 0.5500\n",
      "Epoch 2398/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1604 - val_acc: 0.5500\n",
      "Epoch 2399/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1605 - val_acc: 0.5500\n",
      "Epoch 2400/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1610 - val_acc: 0.5500\n",
      "Epoch 2401/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1611 - val_acc: 0.5500\n",
      "Epoch 2402/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.5500\n",
      "Epoch 2403/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.5500\n",
      "Epoch 2404/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1616 - val_acc: 0.5500\n",
      "Epoch 2405/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.1621 - val_acc: 0.5500\n",
      "Epoch 2406/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1624 - val_acc: 0.5500\n",
      "Epoch 2407/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1627 - val_acc: 0.5500\n",
      "Epoch 2408/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1628 - val_acc: 0.5500\n",
      "Epoch 2409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1629 - val_acc: 0.5500\n",
      "Epoch 2410/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0086 - acc: 1.000 - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1634 - val_acc: 0.5500\n",
      "Epoch 2411/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.5500\n",
      "Epoch 2412/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.5500\n",
      "Epoch 2413/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1645 - val_acc: 0.5500\n",
      "Epoch 2414/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1646 - val_acc: 0.5500\n",
      "Epoch 2415/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 1.1649 - val_acc: 0.5500\n",
      "Epoch 2416/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1653 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2417/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1653 - val_acc: 0.5500\n",
      "Epoch 2418/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1655 - val_acc: 0.5500\n",
      "Epoch 2419/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1657 - val_acc: 0.5500\n",
      "Epoch 2420/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1660 - val_acc: 0.5500\n",
      "Epoch 2421/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1660 - val_acc: 0.5500\n",
      "Epoch 2422/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1662 - val_acc: 0.5500\n",
      "Epoch 2423/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1667 - val_acc: 0.5500\n",
      "Epoch 2424/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1669 - val_acc: 0.5500\n",
      "Epoch 2425/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1670 - val_acc: 0.5500\n",
      "Epoch 2426/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 1.1675 - val_acc: 0.5500\n",
      "Epoch 2427/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1677 - val_acc: 0.5500\n",
      "Epoch 2428/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1680 - val_acc: 0.5500\n",
      "Epoch 2429/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1679 - val_acc: 0.5500\n",
      "Epoch 2430/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1678 - val_acc: 0.5500\n",
      "Epoch 2431/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1682 - val_acc: 0.5500\n",
      "Epoch 2432/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1683 - val_acc: 0.5500\n",
      "Epoch 2433/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1683 - val_acc: 0.5500\n",
      "Epoch 2434/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1688 - val_acc: 0.5500\n",
      "Epoch 2435/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1687 - val_acc: 0.5500\n",
      "Epoch 2436/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1688 - val_acc: 0.5500\n",
      "Epoch 2437/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1689 - val_acc: 0.5500\n",
      "Epoch 2438/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.1690 - val_acc: 0.5500\n",
      "Epoch 2439/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1694 - val_acc: 0.5500\n",
      "Epoch 2440/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1698 - val_acc: 0.5500\n",
      "Epoch 2441/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1699 - val_acc: 0.5500\n",
      "Epoch 2442/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1703 - val_acc: 0.5500\n",
      "Epoch 2443/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1698 - val_acc: 0.5500\n",
      "Epoch 2444/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1700 - val_acc: 0.5500\n",
      "Epoch 2445/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1703 - val_acc: 0.5500\n",
      "Epoch 2446/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1705 - val_acc: 0.5500\n",
      "Epoch 2447/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.1707 - val_acc: 0.5500\n",
      "Epoch 2448/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1711 - val_acc: 0.5500\n",
      "Epoch 2449/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1713 - val_acc: 0.5500\n",
      "Epoch 2450/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1715 - val_acc: 0.5500\n",
      "Epoch 2451/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1716 - val_acc: 0.5500\n",
      "Epoch 2452/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1717 - val_acc: 0.5500\n",
      "Epoch 2453/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1715 - val_acc: 0.5500\n",
      "Epoch 2454/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1720 - val_acc: 0.5500\n",
      "Epoch 2455/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1721 - val_acc: 0.5500\n",
      "Epoch 2456/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1725 - val_acc: 0.5500\n",
      "Epoch 2457/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1729 - val_acc: 0.5500\n",
      "Epoch 2458/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1734 - val_acc: 0.6000\n",
      "Epoch 2459/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1739 - val_acc: 0.6000\n",
      "Epoch 2460/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1745 - val_acc: 0.6000\n",
      "Epoch 2461/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1744 - val_acc: 0.6000\n",
      "Epoch 2462/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1747 - val_acc: 0.6000\n",
      "Epoch 2463/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1748 - val_acc: 0.6000\n",
      "Epoch 2464/3000\n",
      "79/79 [==============================] - 0s 197us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1748 - val_acc: 0.6000\n",
      "Epoch 2465/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1748 - val_acc: 0.6000\n",
      "Epoch 2466/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.6000\n",
      "Epoch 2467/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1754 - val_acc: 0.6000\n",
      "Epoch 2468/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1752 - val_acc: 0.6000\n",
      "Epoch 2469/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.6000\n",
      "Epoch 2470/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.5500\n",
      "Epoch 2471/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1752 - val_acc: 0.5500\n",
      "Epoch 2472/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1753 - val_acc: 0.5500\n",
      "Epoch 2473/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1750 - val_acc: 0.5500\n",
      "Epoch 2474/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1753 - val_acc: 0.5500\n",
      "Epoch 2475/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2476/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1757 - val_acc: 0.5500\n",
      "Epoch 2477/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1761 - val_acc: 0.5500\n",
      "Epoch 2478/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1765 - val_acc: 0.6000\n",
      "Epoch 2479/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1769 - val_acc: 0.6000\n",
      "Epoch 2480/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1769 - val_acc: 0.6000\n",
      "Epoch 2481/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1771 - val_acc: 0.6000\n",
      "Epoch 2482/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.1773 - val_acc: 0.6000\n",
      "Epoch 2483/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1773 - val_acc: 0.5500\n",
      "Epoch 2484/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1777 - val_acc: 0.6000\n",
      "Epoch 2485/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1779 - val_acc: 0.6000\n",
      "Epoch 2486/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1780 - val_acc: 0.6000\n",
      "Epoch 2487/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1783 - val_acc: 0.6000\n",
      "Epoch 2488/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1784 - val_acc: 0.6000\n",
      "Epoch 2489/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1790 - val_acc: 0.6000\n",
      "Epoch 2490/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1790 - val_acc: 0.6000\n",
      "Epoch 2491/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1792 - val_acc: 0.6000\n",
      "Epoch 2492/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1790 - val_acc: 0.6000\n",
      "Epoch 2493/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1792 - val_acc: 0.6000\n",
      "Epoch 2494/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1790 - val_acc: 0.5500\n",
      "Epoch 2495/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1793 - val_acc: 0.6000\n",
      "Epoch 2496/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1795 - val_acc: 0.6000\n",
      "Epoch 2497/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1794 - val_acc: 0.5500\n",
      "Epoch 2498/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1793 - val_acc: 0.5500\n",
      "Epoch 2499/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1796 - val_acc: 0.5500\n",
      "Epoch 2500/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1801 - val_acc: 0.6000\n",
      "Epoch 2501/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1800 - val_acc: 0.5500\n",
      "Epoch 2502/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1804 - val_acc: 0.6000\n",
      "Epoch 2503/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1809 - val_acc: 0.6000\n",
      "Epoch 2504/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1815 - val_acc: 0.6000\n",
      "Epoch 2505/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1812 - val_acc: 0.6000\n",
      "Epoch 2506/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.1812 - val_acc: 0.6000\n",
      "Epoch 2507/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1812 - val_acc: 0.6000\n",
      "Epoch 2508/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1811 - val_acc: 0.5500\n",
      "Epoch 2509/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1810 - val_acc: 0.5500\n",
      "Epoch 2510/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1808 - val_acc: 0.5500\n",
      "Epoch 2511/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1813 - val_acc: 0.5500\n",
      "Epoch 2512/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1813 - val_acc: 0.5500\n",
      "Epoch 2513/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1816 - val_acc: 0.5500\n",
      "Epoch 2514/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1818 - val_acc: 0.5500\n",
      "Epoch 2515/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1819 - val_acc: 0.5500\n",
      "Epoch 2516/3000\n",
      "79/79 [==============================] - 0s 185us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1822 - val_acc: 0.5500\n",
      "Epoch 2517/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1828 - val_acc: 0.6000\n",
      "Epoch 2518/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1828 - val_acc: 0.5500\n",
      "Epoch 2519/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.1836 - val_acc: 0.6000\n",
      "Epoch 2520/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1840 - val_acc: 0.6000\n",
      "Epoch 2521/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.6000\n",
      "Epoch 2522/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1841 - val_acc: 0.6000\n",
      "Epoch 2523/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1844 - val_acc: 0.6000\n",
      "Epoch 2524/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1847 - val_acc: 0.6000\n",
      "Epoch 2525/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1848 - val_acc: 0.6000\n",
      "Epoch 2526/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1852 - val_acc: 0.6000\n",
      "Epoch 2527/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1851 - val_acc: 0.6000\n",
      "Epoch 2528/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1851 - val_acc: 0.6000\n",
      "Epoch 2529/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1850 - val_acc: 0.6000\n",
      "Epoch 2530/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1852 - val_acc: 0.6000\n",
      "Epoch 2531/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1853 - val_acc: 0.6000\n",
      "Epoch 2532/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1856 - val_acc: 0.6000\n",
      "Epoch 2533/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1856 - val_acc: 0.6000\n",
      "Epoch 2534/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1858 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2535/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1862 - val_acc: 0.6000\n",
      "Epoch 2536/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1862 - val_acc: 0.6000\n",
      "Epoch 2537/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1858 - val_acc: 0.5500\n",
      "Epoch 2538/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1860 - val_acc: 0.5500\n",
      "Epoch 2539/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1856 - val_acc: 0.5500\n",
      "Epoch 2540/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1859 - val_acc: 0.5500\n",
      "Epoch 2541/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1859 - val_acc: 0.5500\n",
      "Epoch 2542/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1862 - val_acc: 0.5500\n",
      "Epoch 2543/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1864 - val_acc: 0.5500\n",
      "Epoch 2544/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1862 - val_acc: 0.5500\n",
      "Epoch 2545/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1865 - val_acc: 0.5500\n",
      "Epoch 2546/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1867 - val_acc: 0.5500\n",
      "Epoch 2547/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1868 - val_acc: 0.5500\n",
      "Epoch 2548/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1873 - val_acc: 0.5500\n",
      "Epoch 2549/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1877 - val_acc: 0.5500\n",
      "Epoch 2550/3000\n",
      "79/79 [==============================] - 0s 252us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1880 - val_acc: 0.6000\n",
      "Epoch 2551/3000\n",
      "79/79 [==============================] - 0s 178us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1882 - val_acc: 0.6000\n",
      "Epoch 2552/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1888 - val_acc: 0.6000\n",
      "Epoch 2553/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1890 - val_acc: 0.6000\n",
      "Epoch 2554/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1892 - val_acc: 0.6000\n",
      "Epoch 2555/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1894 - val_acc: 0.6000\n",
      "Epoch 2556/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1896 - val_acc: 0.6000\n",
      "Epoch 2557/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1897 - val_acc: 0.6000\n",
      "Epoch 2558/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.1895 - val_acc: 0.6000\n",
      "Epoch 2559/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1899 - val_acc: 0.6000\n",
      "Epoch 2560/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.6000\n",
      "Epoch 2561/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1898 - val_acc: 0.6000\n",
      "Epoch 2562/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.6000\n",
      "Epoch 2563/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1900 - val_acc: 0.6000\n",
      "Epoch 2564/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1903 - val_acc: 0.6000\n",
      "Epoch 2565/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.5500\n",
      "Epoch 2566/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1906 - val_acc: 0.6000\n",
      "Epoch 2567/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1903 - val_acc: 0.5500\n",
      "Epoch 2568/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1904 - val_acc: 0.5500\n",
      "Epoch 2569/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.5500\n",
      "Epoch 2570/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.5500\n",
      "Epoch 2571/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1908 - val_acc: 0.5500\n",
      "Epoch 2572/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.1911 - val_acc: 0.5500\n",
      "Epoch 2573/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1913 - val_acc: 0.5500\n",
      "Epoch 2574/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1913 - val_acc: 0.5500\n",
      "Epoch 2575/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1920 - val_acc: 0.6000\n",
      "Epoch 2576/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1919 - val_acc: 0.5500\n",
      "Epoch 2577/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1920 - val_acc: 0.5500\n",
      "Epoch 2578/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1922 - val_acc: 0.5500\n",
      "Epoch 2579/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1926 - val_acc: 0.6000\n",
      "Epoch 2580/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1924 - val_acc: 0.5500\n",
      "Epoch 2581/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1924 - val_acc: 0.5500\n",
      "Epoch 2582/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1925 - val_acc: 0.5500\n",
      "Epoch 2583/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1928 - val_acc: 0.5500\n",
      "Epoch 2584/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1931 - val_acc: 0.6000\n",
      "Epoch 2585/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1934 - val_acc: 0.6000\n",
      "Epoch 2586/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1936 - val_acc: 0.6000\n",
      "Epoch 2587/3000\n",
      "79/79 [==============================] - 0s 174us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1938 - val_acc: 0.6000\n",
      "Epoch 2588/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.6000\n",
      "Epoch 2589/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1947 - val_acc: 0.6000\n",
      "Epoch 2590/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1951 - val_acc: 0.6000\n",
      "Epoch 2591/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1953 - val_acc: 0.6000\n",
      "Epoch 2592/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.6000\n",
      "Epoch 2593/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1960 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2594/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.6000\n",
      "Epoch 2595/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.6000\n",
      "Epoch 2596/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1964 - val_acc: 0.6000\n",
      "Epoch 2597/3000\n",
      "79/79 [==============================] - 0s 191us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1964 - val_acc: 0.6000\n",
      "Epoch 2598/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.1965 - val_acc: 0.6000\n",
      "Epoch 2599/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1966 - val_acc: 0.6000\n",
      "Epoch 2600/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1966 - val_acc: 0.6000\n",
      "Epoch 2601/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1967 - val_acc: 0.6000\n",
      "Epoch 2602/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1971 - val_acc: 0.6000\n",
      "Epoch 2603/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1973 - val_acc: 0.6000\n",
      "Epoch 2604/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1974 - val_acc: 0.6000\n",
      "Epoch 2605/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1980 - val_acc: 0.6000\n",
      "Epoch 2606/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1980 - val_acc: 0.6000\n",
      "Epoch 2607/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1980 - val_acc: 0.6000\n",
      "Epoch 2608/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1977 - val_acc: 0.6000\n",
      "Epoch 2609/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1983 - val_acc: 0.6000\n",
      "Epoch 2610/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1986 - val_acc: 0.6000\n",
      "Epoch 2611/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1986 - val_acc: 0.6000\n",
      "Epoch 2612/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1984 - val_acc: 0.6000\n",
      "Epoch 2613/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1988 - val_acc: 0.6000\n",
      "Epoch 2614/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1991 - val_acc: 0.6000\n",
      "Epoch 2615/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1991 - val_acc: 0.6000\n",
      "Epoch 2616/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1992 - val_acc: 0.6000\n",
      "Epoch 2617/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1994 - val_acc: 0.6000\n",
      "Epoch 2618/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1996 - val_acc: 0.6000\n",
      "Epoch 2619/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1998 - val_acc: 0.6000\n",
      "Epoch 2620/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 2621/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1999 - val_acc: 0.6000\n",
      "Epoch 2622/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1997 - val_acc: 0.6000\n",
      "Epoch 2623/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.1998 - val_acc: 0.6000\n",
      "Epoch 2624/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 2625/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.2001 - val_acc: 0.6000\n",
      "Epoch 2626/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 2627/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 2628/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2004 - val_acc: 0.6000\n",
      "Epoch 2629/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.6000\n",
      "Epoch 2630/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2002 - val_acc: 0.6000\n",
      "Epoch 2631/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2001 - val_acc: 0.6000\n",
      "Epoch 2632/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2003 - val_acc: 0.6000\n",
      "Epoch 2633/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2002 - val_acc: 0.6000\n",
      "Epoch 2634/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2004 - val_acc: 0.6000\n",
      "Epoch 2635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2008 - val_acc: 0.6000\n",
      "Epoch 2636/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2014 - val_acc: 0.6000\n",
      "Epoch 2637/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2017 - val_acc: 0.6000\n",
      "Epoch 2638/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2017 - val_acc: 0.6000\n",
      "Epoch 2639/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2018 - val_acc: 0.6000\n",
      "Epoch 2640/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2018 - val_acc: 0.6000\n",
      "Epoch 2641/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2020 - val_acc: 0.6000\n",
      "Epoch 2642/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2021 - val_acc: 0.6000\n",
      "Epoch 2643/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2023 - val_acc: 0.6000\n",
      "Epoch 2644/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2021 - val_acc: 0.6000\n",
      "Epoch 2645/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2022 - val_acc: 0.6000\n",
      "Epoch 2646/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2024 - val_acc: 0.6000\n",
      "Epoch 2647/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2028 - val_acc: 0.6000\n",
      "Epoch 2648/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2030 - val_acc: 0.6000\n",
      "Epoch 2649/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2031 - val_acc: 0.6000\n",
      "Epoch 2650/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0062 - acc: 1.000 - 0s 171us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2031 - val_acc: 0.6000\n",
      "Epoch 2651/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2034 - val_acc: 0.6000\n",
      "Epoch 2652/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2035 - val_acc: 0.6000\n",
      "Epoch 2653/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2037 - val_acc: 0.6000\n",
      "Epoch 2654/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2038 - val_acc: 0.6000\n",
      "Epoch 2655/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2039 - val_acc: 0.6000\n",
      "Epoch 2656/3000\n",
      "79/79 [==============================] - 0s 181us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2044 - val_acc: 0.6000\n",
      "Epoch 2657/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2045 - val_acc: 0.6000\n",
      "Epoch 2658/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.6000\n",
      "Epoch 2659/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.6000\n",
      "Epoch 2660/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2051 - val_acc: 0.6000\n",
      "Epoch 2661/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2048 - val_acc: 0.6000\n",
      "Epoch 2662/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2049 - val_acc: 0.6000\n",
      "Epoch 2663/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2055 - val_acc: 0.6000\n",
      "Epoch 2664/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2056 - val_acc: 0.6000\n",
      "Epoch 2665/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2065 - val_acc: 0.6000\n",
      "Epoch 2666/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2063 - val_acc: 0.6000\n",
      "Epoch 2667/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2064 - val_acc: 0.6000\n",
      "Epoch 2668/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2065 - val_acc: 0.6000\n",
      "Epoch 2669/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.6000\n",
      "Epoch 2670/3000\n",
      "79/79 [==============================] - 0s 179us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.6000\n",
      "Epoch 2671/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.6000\n",
      "Epoch 2672/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2076 - val_acc: 0.6000\n",
      "Epoch 2673/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2077 - val_acc: 0.6000\n",
      "Epoch 2674/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2077 - val_acc: 0.6000\n",
      "Epoch 2675/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2077 - val_acc: 0.6000\n",
      "Epoch 2676/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.2077 - val_acc: 0.6000\n",
      "Epoch 2677/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2079 - val_acc: 0.6000\n",
      "Epoch 2678/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2080 - val_acc: 0.6000\n",
      "Epoch 2679/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2079 - val_acc: 0.6000\n",
      "Epoch 2680/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2083 - val_acc: 0.6000\n",
      "Epoch 2681/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2084 - val_acc: 0.6000\n",
      "Epoch 2682/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2084 - val_acc: 0.6000\n",
      "Epoch 2683/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2088 - val_acc: 0.6000\n",
      "Epoch 2684/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2092 - val_acc: 0.6000\n",
      "Epoch 2685/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2091 - val_acc: 0.6000\n",
      "Epoch 2686/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2092 - val_acc: 0.6000\n",
      "Epoch 2687/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2095 - val_acc: 0.6000\n",
      "Epoch 2688/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2097 - val_acc: 0.6000\n",
      "Epoch 2689/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2095 - val_acc: 0.6000\n",
      "Epoch 2690/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2096 - val_acc: 0.6000\n",
      "Epoch 2691/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2099 - val_acc: 0.6000\n",
      "Epoch 2692/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2099 - val_acc: 0.6000\n",
      "Epoch 2693/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2099 - val_acc: 0.6000\n",
      "Epoch 2694/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2100 - val_acc: 0.6000\n",
      "Epoch 2695/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2100 - val_acc: 0.6000\n",
      "Epoch 2696/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2100 - val_acc: 0.6000\n",
      "Epoch 2697/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2104 - val_acc: 0.6000\n",
      "Epoch 2698/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2108 - val_acc: 0.6000\n",
      "Epoch 2699/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2110 - val_acc: 0.6000\n",
      "Epoch 2700/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2110 - val_acc: 0.6000\n",
      "Epoch 2701/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2114 - val_acc: 0.6000\n",
      "Epoch 2702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2114 - val_acc: 0.6000\n",
      "Epoch 2703/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2117 - val_acc: 0.6000\n",
      "Epoch 2704/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2117 - val_acc: 0.6000\n",
      "Epoch 2705/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2120 - val_acc: 0.6000\n",
      "Epoch 2706/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2124 - val_acc: 0.6000\n",
      "Epoch 2707/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2125 - val_acc: 0.6000\n",
      "Epoch 2708/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2124 - val_acc: 0.6000\n",
      "Epoch 2709/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.2127 - val_acc: 0.6000\n",
      "Epoch 2710/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2130 - val_acc: 0.6000\n",
      "Epoch 2711/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2131 - val_acc: 0.6000\n",
      "Epoch 2712/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2131 - val_acc: 0.6000\n",
      "Epoch 2713/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2134 - val_acc: 0.6000\n",
      "Epoch 2714/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2135 - val_acc: 0.6000\n",
      "Epoch 2715/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2135 - val_acc: 0.6000\n",
      "Epoch 2716/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2133 - val_acc: 0.6000\n",
      "Epoch 2717/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2133 - val_acc: 0.6000\n",
      "Epoch 2718/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2132 - val_acc: 0.6000\n",
      "Epoch 2719/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2136 - val_acc: 0.6000\n",
      "Epoch 2720/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2141 - val_acc: 0.6000\n",
      "Epoch 2721/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2142 - val_acc: 0.6000\n",
      "Epoch 2722/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2144 - val_acc: 0.6000\n",
      "Epoch 2723/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2141 - val_acc: 0.6000\n",
      "Epoch 2724/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2146 - val_acc: 0.6000\n",
      "Epoch 2725/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2144 - val_acc: 0.6000\n",
      "Epoch 2726/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2147 - val_acc: 0.6000\n",
      "Epoch 2727/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2151 - val_acc: 0.6000\n",
      "Epoch 2728/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2152 - val_acc: 0.6000\n",
      "Epoch 2729/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2154 - val_acc: 0.6000\n",
      "Epoch 2730/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2154 - val_acc: 0.6000\n",
      "Epoch 2731/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2156 - val_acc: 0.6000\n",
      "Epoch 2732/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2159 - val_acc: 0.6000\n",
      "Epoch 2733/3000\n",
      "79/79 [==============================] - 0s 187us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2159 - val_acc: 0.6000\n",
      "Epoch 2734/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2162 - val_acc: 0.6000\n",
      "Epoch 2735/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2164 - val_acc: 0.6000\n",
      "Epoch 2736/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2165 - val_acc: 0.6000\n",
      "Epoch 2737/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2168 - val_acc: 0.6000\n",
      "Epoch 2738/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2175 - val_acc: 0.6000\n",
      "Epoch 2739/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2175 - val_acc: 0.6000\n",
      "Epoch 2740/3000\n",
      "79/79 [==============================] - 0s 184us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2176 - val_acc: 0.6000\n",
      "Epoch 2741/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2178 - val_acc: 0.6000\n",
      "Epoch 2742/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2177 - val_acc: 0.6000\n",
      "Epoch 2743/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2179 - val_acc: 0.6000\n",
      "Epoch 2744/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2180 - val_acc: 0.6000\n",
      "Epoch 2745/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2179 - val_acc: 0.6000\n",
      "Epoch 2746/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.2177 - val_acc: 0.6000\n",
      "Epoch 2747/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2177 - val_acc: 0.6000\n",
      "Epoch 2748/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2182 - val_acc: 0.6000\n",
      "Epoch 2749/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2184 - val_acc: 0.6000\n",
      "Epoch 2750/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2187 - val_acc: 0.6000\n",
      "Epoch 2751/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2188 - val_acc: 0.6000\n",
      "Epoch 2752/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2189 - val_acc: 0.6000\n",
      "Epoch 2753/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2195 - val_acc: 0.6000\n",
      "Epoch 2754/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2194 - val_acc: 0.6000\n",
      "Epoch 2755/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2195 - val_acc: 0.6000\n",
      "Epoch 2756/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2196 - val_acc: 0.6000\n",
      "Epoch 2757/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2198 - val_acc: 0.6000\n",
      "Epoch 2758/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2201 - val_acc: 0.6000\n",
      "Epoch 2759/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2760/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2198 - val_acc: 0.6000\n",
      "Epoch 2761/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2198 - val_acc: 0.6000\n",
      "Epoch 2762/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2763/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2197 - val_acc: 0.6000\n",
      "Epoch 2764/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2200 - val_acc: 0.6000\n",
      "Epoch 2765/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2766/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2767/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2768/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2199 - val_acc: 0.6000\n",
      "Epoch 2769/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2202 - val_acc: 0.6000\n",
      "Epoch 2770/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2202 - val_acc: 0.6000\n",
      "Epoch 2771/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2203 - val_acc: 0.6000\n",
      "Epoch 2772/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2204 - val_acc: 0.6000\n",
      "Epoch 2773/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2207 - val_acc: 0.6000\n",
      "Epoch 2774/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2210 - val_acc: 0.6000\n",
      "Epoch 2775/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2212 - val_acc: 0.6000\n",
      "Epoch 2776/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2214 - val_acc: 0.6000\n",
      "Epoch 2777/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2216 - val_acc: 0.6000\n",
      "Epoch 2778/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2214 - val_acc: 0.6000\n",
      "Epoch 2779/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2220 - val_acc: 0.6000\n",
      "Epoch 2780/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2223 - val_acc: 0.6000\n",
      "Epoch 2781/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2226 - val_acc: 0.6000\n",
      "Epoch 2782/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2226 - val_acc: 0.6000\n",
      "Epoch 2783/3000\n",
      "79/79 [==============================] - 0s 204us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2229 - val_acc: 0.6000\n",
      "Epoch 2784/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2232 - val_acc: 0.6000\n",
      "Epoch 2785/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2235 - val_acc: 0.6000\n",
      "Epoch 2786/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2236 - val_acc: 0.6000\n",
      "Epoch 2787/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2238 - val_acc: 0.6000\n",
      "Epoch 2788/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2239 - val_acc: 0.6000\n",
      "Epoch 2789/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2238 - val_acc: 0.6000\n",
      "Epoch 2790/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2238 - val_acc: 0.6000\n",
      "Epoch 2791/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2238 - val_acc: 0.6000\n",
      "Epoch 2792/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2239 - val_acc: 0.6000\n",
      "Epoch 2793/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2238 - val_acc: 0.6000\n",
      "Epoch 2794/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2243 - val_acc: 0.6000\n",
      "Epoch 2795/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2245 - val_acc: 0.6000\n",
      "Epoch 2796/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2247 - val_acc: 0.6000\n",
      "Epoch 2797/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.6000\n",
      "Epoch 2798/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2252 - val_acc: 0.6000\n",
      "Epoch 2799/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2251 - val_acc: 0.6000\n",
      "Epoch 2800/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2250 - val_acc: 0.6000\n",
      "Epoch 2801/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2256 - val_acc: 0.6000\n",
      "Epoch 2802/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2255 - val_acc: 0.6000\n",
      "Epoch 2803/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2256 - val_acc: 0.6000\n",
      "Epoch 2804/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2257 - val_acc: 0.6000\n",
      "Epoch 2805/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2255 - val_acc: 0.6000\n",
      "Epoch 2806/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2257 - val_acc: 0.6000\n",
      "Epoch 2807/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2259 - val_acc: 0.6000\n",
      "Epoch 2808/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2261 - val_acc: 0.6000\n",
      "Epoch 2809/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2263 - val_acc: 0.6000\n",
      "Epoch 2810/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2264 - val_acc: 0.6000\n",
      "Epoch 2811/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2267 - val_acc: 0.6000\n",
      "Epoch 2812/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2267 - val_acc: 0.6000\n",
      "Epoch 2813/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2268 - val_acc: 0.6000\n",
      "Epoch 2814/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2268 - val_acc: 0.6000\n",
      "Epoch 2815/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2270 - val_acc: 0.6000\n",
      "Epoch 2816/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2272 - val_acc: 0.6000\n",
      "Epoch 2817/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2273 - val_acc: 0.6000\n",
      "Epoch 2818/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2277 - val_acc: 0.6000\n",
      "Epoch 2819/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2280 - val_acc: 0.6000\n",
      "Epoch 2820/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2280 - val_acc: 0.6000\n",
      "Epoch 2821/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2282 - val_acc: 0.6000\n",
      "Epoch 2822/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2281 - val_acc: 0.6000\n",
      "Epoch 2823/3000\n",
      "79/79 [==============================] - 0s 183us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2282 - val_acc: 0.6000\n",
      "Epoch 2824/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2283 - val_acc: 0.6000\n",
      "Epoch 2825/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2288 - val_acc: 0.6000\n",
      "Epoch 2826/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2292 - val_acc: 0.6000\n",
      "Epoch 2827/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2294 - val_acc: 0.6000\n",
      "Epoch 2828/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2293 - val_acc: 0.6000\n",
      "Epoch 2829/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2297 - val_acc: 0.6000\n",
      "Epoch 2830/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2295 - val_acc: 0.6000\n",
      "Epoch 2831/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2296 - val_acc: 0.6000\n",
      "Epoch 2832/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2298 - val_acc: 0.6000\n",
      "Epoch 2833/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2299 - val_acc: 0.6000\n",
      "Epoch 2834/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2300 - val_acc: 0.6000\n",
      "Epoch 2835/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2305 - val_acc: 0.6000\n",
      "Epoch 2836/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2302 - val_acc: 0.6000\n",
      "Epoch 2837/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2302 - val_acc: 0.6000\n",
      "Epoch 2838/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2304 - val_acc: 0.6000\n",
      "Epoch 2839/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2305 - val_acc: 0.6000\n",
      "Epoch 2840/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2304 - val_acc: 0.6000\n",
      "Epoch 2841/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2305 - val_acc: 0.6000\n",
      "Epoch 2842/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2305 - val_acc: 0.6000\n",
      "Epoch 2843/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2310 - val_acc: 0.6000\n",
      "Epoch 2844/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2314 - val_acc: 0.6000\n",
      "Epoch 2845/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2315 - val_acc: 0.6000\n",
      "Epoch 2846/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2316 - val_acc: 0.6000\n",
      "Epoch 2847/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2318 - val_acc: 0.6000\n",
      "Epoch 2848/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2319 - val_acc: 0.6000\n",
      "Epoch 2849/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2322 - val_acc: 0.6000\n",
      "Epoch 2850/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2324 - val_acc: 0.6000\n",
      "Epoch 2851/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2325 - val_acc: 0.6000\n",
      "Epoch 2852/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2325 - val_acc: 0.6000\n",
      "Epoch 2853/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2322 - val_acc: 0.6000\n",
      "Epoch 2854/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2329 - val_acc: 0.6000\n",
      "Epoch 2855/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2331 - val_acc: 0.6000\n",
      "Epoch 2856/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2336 - val_acc: 0.6000\n",
      "Epoch 2857/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2336 - val_acc: 0.6000\n",
      "Epoch 2858/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2339 - val_acc: 0.6000\n",
      "Epoch 2859/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2339 - val_acc: 0.6000\n",
      "Epoch 2860/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2344 - val_acc: 0.6000\n",
      "Epoch 2861/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2343 - val_acc: 0.6000\n",
      "Epoch 2862/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2345 - val_acc: 0.6000\n",
      "Epoch 2863/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2347 - val_acc: 0.6000\n",
      "Epoch 2864/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2344 - val_acc: 0.6000\n",
      "Epoch 2865/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2346 - val_acc: 0.6000\n",
      "Epoch 2866/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2342 - val_acc: 0.6000\n",
      "Epoch 2867/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2343 - val_acc: 0.6000\n",
      "Epoch 2868/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2344 - val_acc: 0.6000\n",
      "Epoch 2869/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2348 - val_acc: 0.6000\n",
      "Epoch 2870/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 1.2349 - val_acc: 0.6000\n",
      "Epoch 2871/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2351 - val_acc: 0.6000\n",
      "Epoch 2872/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2351 - val_acc: 0.6000\n",
      "Epoch 2873/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2352 - val_acc: 0.6000\n",
      "Epoch 2874/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2356 - val_acc: 0.6000\n",
      "Epoch 2875/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2357 - val_acc: 0.6000\n",
      "Epoch 2876/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2361 - val_acc: 0.6000\n",
      "Epoch 2877/3000\n",
      "79/79 [==============================] - 0s 195us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2364 - val_acc: 0.6000\n",
      "Epoch 2878/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2364 - val_acc: 0.6000\n",
      "Epoch 2879/3000\n",
      "79/79 [==============================] - 0s 179us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2363 - val_acc: 0.6000\n",
      "Epoch 2880/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2366 - val_acc: 0.6000\n",
      "Epoch 2881/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2368 - val_acc: 0.6000\n",
      "Epoch 2882/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2368 - val_acc: 0.6000\n",
      "Epoch 2883/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2369 - val_acc: 0.6000\n",
      "Epoch 2884/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2369 - val_acc: 0.6000\n",
      "Epoch 2885/3000\n",
      "79/79 [==============================] - 0s 197us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2370 - val_acc: 0.6000\n",
      "Epoch 2886/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2368 - val_acc: 0.6000\n",
      "Epoch 2887/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2371 - val_acc: 0.6000\n",
      "Epoch 2888/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2368 - val_acc: 0.6000\n",
      "Epoch 2889/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2370 - val_acc: 0.6000\n",
      "Epoch 2890/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2373 - val_acc: 0.6000\n",
      "Epoch 2891/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2375 - val_acc: 0.6000\n",
      "Epoch 2892/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2380 - val_acc: 0.6000\n",
      "Epoch 2893/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2389 - val_acc: 0.6000\n",
      "Epoch 2894/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2389 - val_acc: 0.6000\n",
      "Epoch 2895/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.2392 - val_acc: 0.6000\n",
      "Epoch 2896/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2390 - val_acc: 0.6000\n",
      "Epoch 2897/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2390 - val_acc: 0.6000\n",
      "Epoch 2898/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2393 - val_acc: 0.6000\n",
      "Epoch 2899/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2393 - val_acc: 0.6000\n",
      "Epoch 2900/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.6000\n",
      "Epoch 2901/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2392 - val_acc: 0.6000\n",
      "Epoch 2902/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.6000\n",
      "Epoch 2903/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.6000\n",
      "Epoch 2904/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2395 - val_acc: 0.6000\n",
      "Epoch 2905/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2395 - val_acc: 0.6000\n",
      "Epoch 2906/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2399 - val_acc: 0.6000\n",
      "Epoch 2907/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2401 - val_acc: 0.6000\n",
      "Epoch 2908/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2399 - val_acc: 0.6000\n",
      "Epoch 2909/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2401 - val_acc: 0.6000\n",
      "Epoch 2910/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2404 - val_acc: 0.6000\n",
      "Epoch 2911/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2404 - val_acc: 0.6000\n",
      "Epoch 2912/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2405 - val_acc: 0.6000\n",
      "Epoch 2913/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2408 - val_acc: 0.6000\n",
      "Epoch 2914/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2415 - val_acc: 0.6000\n",
      "Epoch 2915/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2417 - val_acc: 0.6000\n",
      "Epoch 2916/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2422 - val_acc: 0.6000\n",
      "Epoch 2917/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2421 - val_acc: 0.6000\n",
      "Epoch 2918/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 1.2421 - val_acc: 0.6000\n",
      "Epoch 2919/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2427 - val_acc: 0.6000\n",
      "Epoch 2920/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2429 - val_acc: 0.6000\n",
      "Epoch 2921/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2430 - val_acc: 0.6000\n",
      "Epoch 2922/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2430 - val_acc: 0.6000\n",
      "Epoch 2923/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2428 - val_acc: 0.6000\n",
      "Epoch 2924/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2428 - val_acc: 0.6000\n",
      "Epoch 2925/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2424 - val_acc: 0.6000\n",
      "Epoch 2926/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2428 - val_acc: 0.6000\n",
      "Epoch 2927/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2429 - val_acc: 0.6000\n",
      "Epoch 2928/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2434 - val_acc: 0.6000\n",
      "Epoch 2929/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2433 - val_acc: 0.6000\n",
      "Epoch 2930/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2435 - val_acc: 0.6000\n",
      "Epoch 2931/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2436 - val_acc: 0.6000\n",
      "Epoch 2932/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2437 - val_acc: 0.6000\n",
      "Epoch 2933/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2436 - val_acc: 0.6000\n",
      "Epoch 2934/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2435 - val_acc: 0.6000\n",
      "Epoch 2935/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2436 - val_acc: 0.6000\n",
      "Epoch 2936/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2438 - val_acc: 0.6000\n",
      "Epoch 2937/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2439 - val_acc: 0.6000\n",
      "Epoch 2938/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2439 - val_acc: 0.6000\n",
      "Epoch 2939/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2442 - val_acc: 0.6000\n",
      "Epoch 2940/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2446 - val_acc: 0.6000\n",
      "Epoch 2941/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2447 - val_acc: 0.6000\n",
      "Epoch 2942/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.2447 - val_acc: 0.6000\n",
      "Epoch 2943/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2446 - val_acc: 0.6000\n",
      "Epoch 2944/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2449 - val_acc: 0.6000\n",
      "Epoch 2945/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2450 - val_acc: 0.6000\n",
      "Epoch 2946/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2450 - val_acc: 0.6000\n",
      "Epoch 2947/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2452 - val_acc: 0.6000\n",
      "Epoch 2948/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2455 - val_acc: 0.6000\n",
      "Epoch 2949/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2457 - val_acc: 0.6000\n",
      "Epoch 2950/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2458 - val_acc: 0.6000\n",
      "Epoch 2951/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2460 - val_acc: 0.6000\n",
      "Epoch 2952/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2462 - val_acc: 0.6000\n",
      "Epoch 2953/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2461 - val_acc: 0.6000\n",
      "Epoch 2954/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2464 - val_acc: 0.6000\n",
      "Epoch 2955/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2467 - val_acc: 0.6000\n",
      "Epoch 2956/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2470 - val_acc: 0.6000\n",
      "Epoch 2957/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2472 - val_acc: 0.6000\n",
      "Epoch 2958/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2471 - val_acc: 0.6000\n",
      "Epoch 2959/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2469 - val_acc: 0.6000\n",
      "Epoch 2960/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2471 - val_acc: 0.6000\n",
      "Epoch 2961/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2470 - val_acc: 0.6000\n",
      "Epoch 2962/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2475 - val_acc: 0.6000\n",
      "Epoch 2963/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2473 - val_acc: 0.6000\n",
      "Epoch 2964/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2475 - val_acc: 0.6000\n",
      "Epoch 2965/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2477 - val_acc: 0.6000\n",
      "Epoch 2966/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2479 - val_acc: 0.6000\n",
      "Epoch 2967/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2478 - val_acc: 0.6000\n",
      "Epoch 2968/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2476 - val_acc: 0.6000\n",
      "Epoch 2969/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 1.2479 - val_acc: 0.6000\n",
      "Epoch 2970/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2480 - val_acc: 0.6000\n",
      "Epoch 2971/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2483 - val_acc: 0.6000\n",
      "Epoch 2972/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2484 - val_acc: 0.6000\n",
      "Epoch 2973/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2484 - val_acc: 0.6000\n",
      "Epoch 2974/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2482 - val_acc: 0.6000\n",
      "Epoch 2975/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.6000\n",
      "Epoch 2976/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2489 - val_acc: 0.6000\n",
      "Epoch 2977/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.6000\n",
      "Epoch 2978/3000\n",
      "79/79 [==============================] - 0s 170us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2488 - val_acc: 0.6000\n",
      "Epoch 2979/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2491 - val_acc: 0.6000\n",
      "Epoch 2980/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2492 - val_acc: 0.6000\n",
      "Epoch 2981/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2494 - val_acc: 0.6000\n",
      "Epoch 2982/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2495 - val_acc: 0.6000\n",
      "Epoch 2983/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2497 - val_acc: 0.6000\n",
      "Epoch 2984/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2500 - val_acc: 0.6000\n",
      "Epoch 2985/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2504 - val_acc: 0.6000\n",
      "Epoch 2986/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2503 - val_acc: 0.6000\n",
      "Epoch 2987/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2506 - val_acc: 0.6000\n",
      "Epoch 2988/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2507 - val_acc: 0.6000\n",
      "Epoch 2989/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2509 - val_acc: 0.6000\n",
      "Epoch 2990/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2509 - val_acc: 0.6000\n",
      "Epoch 2991/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2508 - val_acc: 0.6000\n",
      "Epoch 2992/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2510 - val_acc: 0.6000\n",
      "Epoch 2993/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2511 - val_acc: 0.6000\n",
      "Epoch 2994/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2513 - val_acc: 0.6000\n",
      "Epoch 2995/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2517 - val_acc: 0.6000\n",
      "Epoch 2996/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2518 - val_acc: 0.6000\n",
      "Epoch 2997/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2517 - val_acc: 0.6000\n",
      "Epoch 2998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2518 - val_acc: 0.6000\n",
      "Epoch 2999/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2518 - val_acc: 0.6000\n",
      "Epoch 3000/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2519 - val_acc: 0.6000\n",
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/3000\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.9889 - acc: 0.4810 - val_loss: 0.7377 - val_acc: 0.6000\n",
      "Epoch 2/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.8573 - acc: 0.4810 - val_loss: 0.7002 - val_acc: 0.6000\n",
      "Epoch 3/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.7915 - acc: 0.4810 - val_loss: 0.6792 - val_acc: 0.6000\n",
      "Epoch 4/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.7461 - acc: 0.4810 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 5/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.7217 - acc: 0.4810 - val_loss: 0.6734 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.7085 - acc: 0.4810 - val_loss: 0.6776 - val_acc: 0.6000\n",
      "Epoch 7/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.7000 - acc: 0.4810 - val_loss: 0.6828 - val_acc: 0.6000\n",
      "Epoch 8/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6964 - acc: 0.4810 - val_loss: 0.6872 - val_acc: 0.6000\n",
      "Epoch 9/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6947 - acc: 0.4430 - val_loss: 0.6881 - val_acc: 0.6000\n",
      "Epoch 10/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6942 - acc: 0.5063 - val_loss: 0.6889 - val_acc: 0.6000\n",
      "Epoch 11/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6930 - acc: 0.4810 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 12/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6909 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 13/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6911 - acc: 0.5190 - val_loss: 0.6955 - val_acc: 0.4000\n",
      "Epoch 14/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6952 - acc: 0.5190 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 15/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6915 - acc: 0.5443 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 16/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6908 - acc: 0.5316 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 17/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6906 - acc: 0.5190 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 18/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6933 - acc: 0.5190 - val_loss: 0.6909 - val_acc: 0.6000\n",
      "Epoch 19/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6911 - acc: 0.5316 - val_loss: 0.6923 - val_acc: 0.4500\n",
      "Epoch 20/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6921 - acc: 0.5823 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 21/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6901 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 22/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6901 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 23/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6902 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 24/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 25/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6925 - acc: 0.5190 - val_loss: 0.7079 - val_acc: 0.4000\n",
      "Epoch 26/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6900 - acc: 0.5190 - val_loss: 0.7039 - val_acc: 0.4000\n",
      "Epoch 27/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 28/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 29/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6911 - acc: 0.5190 - val_loss: 0.7084 - val_acc: 0.4000\n",
      "Epoch 30/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6899 - acc: 0.5190 - val_loss: 0.7090 - val_acc: 0.4000\n",
      "Epoch 31/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6912 - acc: 0.5190 - val_loss: 0.7042 - val_acc: 0.4000\n",
      "Epoch 32/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6896 - acc: 0.5190 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 33/3000\n",
      "79/79 [==============================] - 0s 287us/sample - loss: 0.6932 - acc: 0.5190 - val_loss: 0.6930 - val_acc: 0.6500\n",
      "Epoch 34/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6898 - acc: 0.7342 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 35/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6890 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 36/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6896 - acc: 0.5190 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 37/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6899 - acc: 0.5316 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 38/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6909 - acc: 0.5316 - val_loss: 0.6908 - val_acc: 0.6000\n",
      "Epoch 39/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6896 - acc: 0.6835 - val_loss: 0.6939 - val_acc: 0.5500\n",
      "Epoch 40/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6898 - acc: 0.6582 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 41/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6927 - acc: 0.5443 - val_loss: 0.6885 - val_acc: 0.6000\n",
      "Epoch 42/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6902 - acc: 0.4810 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 43/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6894 - acc: 0.7215 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 44/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 45/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6884 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 46/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.6939 - acc: 0.4430 - val_loss: 0.7097 - val_acc: 0.4000\n",
      "Epoch 47/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6897 - acc: 0.5190 - val_loss: 0.7102 - val_acc: 0.4000\n",
      "Epoch 48/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6895 - acc: 0.5190 - val_loss: 0.7126 - val_acc: 0.4000\n",
      "Epoch 49/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6912 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 50/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6885 - acc: 0.5190 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 51/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6888 - acc: 0.5190 - val_loss: 0.7082 - val_acc: 0.4000\n",
      "Epoch 52/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6887 - acc: 0.5190 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 53/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6887 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 54/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6879 - acc: 0.5190 - val_loss: 0.7009 - val_acc: 0.4000\n",
      "Epoch 55/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6879 - acc: 0.5190 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 56/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6888 - acc: 0.5190 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 57/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6883 - acc: 0.5190 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 58/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6898 - acc: 0.5190 - val_loss: 0.7080 - val_acc: 0.4000\n",
      "Epoch 59/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6889 - acc: 0.5190 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 60/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.7059 - val_acc: 0.4000\n",
      "Epoch 61/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6889 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 62/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6893 - acc: 0.5190 - val_loss: 0.6936 - val_acc: 0.5500\n",
      "Epoch 63/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6885 - acc: 0.7595 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 64/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 65/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6884 - acc: 0.5190 - val_loss: 0.6956 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.6936 - val_acc: 0.5500\n",
      "Epoch 67/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6881 - acc: 0.6203 - val_loss: 0.6940 - val_acc: 0.5500\n",
      "Epoch 68/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6877 - acc: 0.593 - 0s 128us/sample - loss: 0.6891 - acc: 0.6076 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 69/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6880 - acc: 0.5190 - val_loss: 0.7068 - val_acc: 0.4000\n",
      "Epoch 70/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6883 - acc: 0.5190 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 71/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 72/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6904 - acc: 0.5570 - val_loss: 0.7113 - val_acc: 0.4000\n",
      "Epoch 73/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6887 - acc: 0.5190 - val_loss: 0.7133 - val_acc: 0.4000\n",
      "Epoch 74/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6885 - acc: 0.5190 - val_loss: 0.7102 - val_acc: 0.4000\n",
      "Epoch 75/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6880 - acc: 0.5190 - val_loss: 0.7034 - val_acc: 0.4000\n",
      "Epoch 76/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6915 - acc: 0.5190 - val_loss: 0.7068 - val_acc: 0.4000\n",
      "Epoch 77/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6900 - acc: 0.5190 - val_loss: 0.7152 - val_acc: 0.4000\n",
      "Epoch 78/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6884 - acc: 0.5190 - val_loss: 0.7086 - val_acc: 0.4000\n",
      "Epoch 79/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6886 - acc: 0.5190 - val_loss: 0.7072 - val_acc: 0.4000\n",
      "Epoch 80/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 81/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6885 - acc: 0.5190 - val_loss: 0.7116 - val_acc: 0.4000\n",
      "Epoch 82/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.6881 - acc: 0.5190 - val_loss: 0.7090 - val_acc: 0.4000\n",
      "Epoch 83/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6888 - acc: 0.5190 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 84/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 85/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 86/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6905 - acc: 0.5190 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 87/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 88/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6875 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 89/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 90/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6874 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 91/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6867 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 92/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6872 - acc: 0.5190 - val_loss: 0.7043 - val_acc: 0.4000\n",
      "Epoch 93/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6869 - acc: 0.5190 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 94/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6877 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 95/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6867 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 96/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7040 - val_acc: 0.4000\n",
      "Epoch 97/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6874 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 98/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 99/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 100/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6871 - acc: 0.5696 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 101/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6869 - acc: 0.5190 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 102/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6868 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 103/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 104/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 105/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.7002 - val_acc: 0.4000\n",
      "Epoch 106/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 107/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6892 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 108/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6877 - acc: 0.5190 - val_loss: 0.7114 - val_acc: 0.4000\n",
      "Epoch 109/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6906 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 110/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6881 - acc: 0.5190 - val_loss: 0.7094 - val_acc: 0.4000\n",
      "Epoch 111/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.7073 - val_acc: 0.4000\n",
      "Epoch 112/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6867 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 113/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6868 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 114/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6881 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 115/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6863 - acc: 0.5190 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 116/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6863 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 117/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6868 - acc: 0.5190 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 118/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6868 - acc: 0.6709 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 119/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6876 - acc: 0.5190 - val_loss: 0.7017 - val_acc: 0.4000\n",
      "Epoch 120/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6902 - acc: 0.5190 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 121/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6880 - acc: 0.5190 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 122/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 123/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6861 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 124/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 125/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 126/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6857 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 127/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6864 - acc: 0.5190 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 128/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 129/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5190 - val_loss: 0.7002 - val_acc: 0.4000\n",
      "Epoch 130/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6884 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 131/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 132/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6867 - acc: 0.5190 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 133/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6871 - acc: 0.5190 - val_loss: 0.7007 - val_acc: 0.4000\n",
      "Epoch 134/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6871 - acc: 0.5316 - val_loss: 0.7037 - val_acc: 0.4000\n",
      "Epoch 135/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6861 - acc: 0.5190 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 136/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6873 - acc: 0.5190 - val_loss: 0.7129 - val_acc: 0.4000\n",
      "Epoch 137/3000\n",
      "79/79 [==============================] - 0s 168us/sample - loss: 0.6867 - acc: 0.5190 - val_loss: 0.7097 - val_acc: 0.4000\n",
      "Epoch 138/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6877 - acc: 0.5190 - val_loss: 0.7101 - val_acc: 0.4000\n",
      "Epoch 139/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.6862 - acc: 0.5190 - val_loss: 0.7031 - val_acc: 0.4000\n",
      "Epoch 140/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6856 - acc: 0.5190 - val_loss: 0.7047 - val_acc: 0.4000\n",
      "Epoch 141/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6857 - acc: 0.5190 - val_loss: 0.7062 - val_acc: 0.4000\n",
      "Epoch 142/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6858 - acc: 0.5190 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 143/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6855 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 144/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.6856 - acc: 0.5190 - val_loss: 0.7066 - val_acc: 0.4000\n",
      "Epoch 145/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6863 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 146/3000\n",
      "79/79 [==============================] - 0s 190us/sample - loss: 0.6851 - acc: 0.5190 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 147/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6859 - acc: 0.5190 - val_loss: 0.7017 - val_acc: 0.4000\n",
      "Epoch 148/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4000\n",
      "Epoch 149/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6853 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 150/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6850 - acc: 0.5190 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 151/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6850 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 152/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6850 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 153/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 154/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4000\n",
      "Epoch 155/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6868 - acc: 0.5570 - val_loss: 0.7042 - val_acc: 0.4000\n",
      "Epoch 156/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6866 - acc: 0.5190 - val_loss: 0.7075 - val_acc: 0.4000\n",
      "Epoch 157/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5190 - val_loss: 0.7037 - val_acc: 0.4000\n",
      "Epoch 158/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6865 - acc: 0.5190 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 159/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.7001 - val_acc: 0.4000\n",
      "Epoch 160/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6855 - acc: 0.5190 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 161/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6877 - acc: 0.5570 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 162/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6855 - acc: 0.5443 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 163/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6850 - acc: 0.5696 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 164/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6971 - acc: 0.3924 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 165/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6847 - acc: 0.5190 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 166/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6863 - acc: 0.5190 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 167/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6844 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4000\n",
      "Epoch 168/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6848 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 169/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6845 - acc: 0.5316 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 170/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6844 - acc: 0.5190 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 171/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.6939 - val_acc: 0.5500\n",
      "Epoch 172/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6855 - acc: 0.5696 - val_loss: 0.6905 - val_acc: 0.4500\n",
      "Epoch 173/3000\n",
      "79/79 [==============================] - 0s 182us/sample - loss: 0.6862 - acc: 0.7468 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 174/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.7018 - val_acc: 0.4000\n",
      "Epoch 175/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6845 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 176/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 177/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6851 - acc: 0.5570 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 178/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6842 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 179/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 180/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6842 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 181/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 182/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6851 - acc: 0.5316 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 183/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 184/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6843 - acc: 0.5443 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 185/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6856 - acc: 0.6962 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 186/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6849 - acc: 0.8608 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 187/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.7039 - val_acc: 0.4000\n",
      "Epoch 188/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 189/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 190/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6883 - acc: 0.5190 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 191/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6840 - acc: 0.5190 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 192/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6854 - acc: 0.5316 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 193/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.6835 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 194/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6844 - acc: 0.5190 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 195/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6847 - acc: 0.5190 - val_loss: 0.7080 - val_acc: 0.4000\n",
      "Epoch 196/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6860 - acc: 0.5190 - val_loss: 0.7052 - val_acc: 0.4000\n",
      "Epoch 197/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6851 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 198/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6835 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 199/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.6845 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 200/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6840 - acc: 0.5190 - val_loss: 0.7065 - val_acc: 0.4000\n",
      "Epoch 201/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6851 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 202/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6839 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 203/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6850 - acc: 0.5190 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 204/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6850 - acc: 0.6962 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 205/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.7019 - val_acc: 0.4000\n",
      "Epoch 206/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6848 - acc: 0.5190 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 207/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6867 - acc: 0.5316 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 208/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6852 - acc: 0.5696 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 209/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6833 - acc: 0.5190 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 210/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6848 - acc: 0.5190 - val_loss: 0.6953 - val_acc: 0.4000\n",
      "Epoch 211/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6860 - acc: 0.5443 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 212/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6835 - acc: 0.5316 - val_loss: 0.7032 - val_acc: 0.4000\n",
      "Epoch 213/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6838 - acc: 0.5190 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 214/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6837 - acc: 0.5190 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 215/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6844 - acc: 0.5190 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.7068 - val_acc: 0.4000\n",
      "Epoch 217/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6838 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 218/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6837 - acc: 0.5190 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 219/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6847 - acc: 0.5570 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 220/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 221/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 222/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6825 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 223/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 224/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6842 - acc: 0.5443 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 225/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6836 - acc: 0.7089 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 226/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6824 - acc: 0.5190 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 227/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6829 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 228/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.7043 - val_acc: 0.4000\n",
      "Epoch 229/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6825 - acc: 0.5190 - val_loss: 0.7008 - val_acc: 0.4000\n",
      "Epoch 230/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6822 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 231/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6823 - acc: 0.5190 - val_loss: 0.6973 - val_acc: 0.4000\n",
      "Epoch 232/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6835 - acc: 0.5190 - val_loss: 0.6939 - val_acc: 0.5000\n",
      "Epoch 233/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6833 - acc: 0.6962 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 234/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6824 - acc: 0.5696 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 235/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6831 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 236/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6842 - acc: 0.5190 - val_loss: 0.6912 - val_acc: 0.5500\n",
      "Epoch 237/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6883 - acc: 0.5443 - val_loss: 0.6908 - val_acc: 0.6500\n",
      "Epoch 238/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6833 - acc: 0.6962 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 239/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6833 - acc: 0.7089 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 240/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6820 - acc: 0.5949 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 241/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6826 - acc: 0.5570 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 242/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6821 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 243/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6819 - acc: 0.5190 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 244/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6820 - acc: 0.5696 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 245/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6823 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 246/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.6924 - val_acc: 0.5500\n",
      "Epoch 247/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6819 - acc: 0.7342 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 248/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6819 - acc: 0.5823 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 249/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6840 - acc: 0.5316 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 250/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6819 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 251/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6814 - acc: 0.5190 - val_loss: 0.6955 - val_acc: 0.4000\n",
      "Epoch 252/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6829 - acc: 0.5316 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 253/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6818 - acc: 0.6582 - val_loss: 0.6927 - val_acc: 0.5500\n",
      "Epoch 254/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6855 - acc: 0.6329 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 255/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6816 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 256/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6814 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 257/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6826 - acc: 0.5316 - val_loss: 0.7050 - val_acc: 0.4000\n",
      "Epoch 258/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6832 - acc: 0.5190 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 259/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6851 - acc: 0.5190 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 260/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 261/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6827 - acc: 0.5316 - val_loss: 0.6905 - val_acc: 0.6500\n",
      "Epoch 262/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6823 - acc: 0.7342 - val_loss: 0.6910 - val_acc: 0.6000\n",
      "Epoch 263/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6816 - acc: 0.8608 - val_loss: 0.6918 - val_acc: 0.5500\n",
      "Epoch 264/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6821 - acc: 0.6329 - val_loss: 0.6902 - val_acc: 0.6500\n",
      "Epoch 265/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6825 - acc: 0.7848 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 266/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6818 - acc: 0.8481 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 267/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6818 - acc: 0.6076 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 268/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6817 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 269/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6815 - acc: 0.5190 - val_loss: 0.6929 - val_acc: 0.5500\n",
      "Epoch 270/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6848 - acc: 0.7342 - val_loss: 0.6899 - val_acc: 0.6500\n",
      "Epoch 271/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6884 - acc: 0.6582 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 272/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6809 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 273/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6843 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 274/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6845 - acc: 0.6329 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 275/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6808 - acc: 0.7975 - val_loss: 0.6973 - val_acc: 0.4000\n",
      "Epoch 276/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6821 - acc: 0.5190 - val_loss: 0.6997 - val_acc: 0.4000\n",
      "Epoch 277/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6810 - acc: 0.5190 - val_loss: 0.6979 - val_acc: 0.4000\n",
      "Epoch 278/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6802 - acc: 0.5190 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 279/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6738 - acc: 0.593 - 0s 126us/sample - loss: 0.6830 - acc: 0.5316 - val_loss: 0.7011 - val_acc: 0.4000\n",
      "Epoch 280/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6809 - acc: 0.5190 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 281/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6804 - acc: 0.5190 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 282/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6827 - acc: 0.5190 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 283/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6804 - acc: 0.6329 - val_loss: 0.6968 - val_acc: 0.4000\n",
      "Epoch 284/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6802 - acc: 0.5316 - val_loss: 0.6958 - val_acc: 0.4000\n",
      "Epoch 285/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6803 - acc: 0.5696 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 286/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6802 - acc: 0.5190 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 287/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6803 - acc: 0.5443 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 288/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6805 - acc: 0.6456 - val_loss: 0.6907 - val_acc: 0.6000\n",
      "Epoch 289/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6802 - acc: 0.8987 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 290/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6799 - acc: 0.7342 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 291/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6816 - acc: 0.5949 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 292/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6804 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 293/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6817 - acc: 0.6329 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 294/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6850 - acc: 0.6203 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 295/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6802 - acc: 0.5190 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 296/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6811 - acc: 0.5190 - val_loss: 0.6973 - val_acc: 0.4000\n",
      "Epoch 297/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6787 - acc: 0.531 - 0s 139us/sample - loss: 0.6794 - acc: 0.5190 - val_loss: 0.6980 - val_acc: 0.4000\n",
      "Epoch 298/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6794 - acc: 0.5190 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 299/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6797 - acc: 0.5190 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 300/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6885 - acc: 0.6203 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 301/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6804 - acc: 0.6076 - val_loss: 0.7035 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6811 - acc: 0.5190 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 303/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6795 - acc: 0.5190 - val_loss: 0.7033 - val_acc: 0.4000\n",
      "Epoch 304/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6811 - acc: 0.5190 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 305/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6813 - acc: 0.5190 - val_loss: 0.7073 - val_acc: 0.4000\n",
      "Epoch 306/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6807 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 307/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6802 - acc: 0.5190 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 308/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6882 - acc: 0.406 - 0s 124us/sample - loss: 0.6808 - acc: 0.6962 - val_loss: 0.7047 - val_acc: 0.4000\n",
      "Epoch 309/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6795 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 310/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6788 - acc: 0.5190 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 311/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6788 - acc: 0.5190 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 312/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6791 - acc: 0.5190 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 313/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6827 - acc: 0.5570 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 314/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6795 - acc: 0.5443 - val_loss: 0.6930 - val_acc: 0.5500\n",
      "Epoch 315/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6796 - acc: 0.7089 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 316/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6816 - acc: 0.6203 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 317/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6794 - acc: 0.5570 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 318/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6849 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 319/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6787 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 320/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6792 - acc: 0.5190 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 321/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6786 - acc: 0.5190 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 322/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6817 - acc: 0.7342 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 323/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6809 - acc: 0.5190 - val_loss: 0.7112 - val_acc: 0.4000\n",
      "Epoch 324/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6800 - acc: 0.5190 - val_loss: 0.7053 - val_acc: 0.4000\n",
      "Epoch 325/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6804 - acc: 0.5190 - val_loss: 0.7063 - val_acc: 0.4000\n",
      "Epoch 326/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6812 - acc: 0.5190 - val_loss: 0.7001 - val_acc: 0.4000\n",
      "Epoch 327/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6781 - acc: 0.5190 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 328/3000\n",
      "79/79 [==============================] - 0s 218us/sample - loss: 0.6792 - acc: 0.5190 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 329/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6793 - acc: 0.5190 - val_loss: 0.7059 - val_acc: 0.4000\n",
      "Epoch 330/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6800 - acc: 0.5190 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 331/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6780 - acc: 0.5823 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 332/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6796 - acc: 0.5570 - val_loss: 0.6915 - val_acc: 0.5500\n",
      "Epoch 333/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6785 - acc: 0.7595 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 334/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6782 - acc: 0.7342 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 335/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6865 - acc: 0.4430 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 336/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6784 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.4500\n",
      "Epoch 337/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6793 - acc: 0.5443 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 338/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6791 - acc: 0.6835 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 339/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6778 - acc: 0.5190 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 340/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6775 - acc: 0.5190 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 341/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6785 - acc: 0.5190 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 342/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6779 - acc: 0.7342 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 343/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6806 - acc: 0.6456 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 344/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6781 - acc: 0.7468 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 345/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6825 - acc: 0.6962 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 346/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6790 - acc: 0.6076 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 347/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6774 - acc: 0.6835 - val_loss: 0.6924 - val_acc: 0.5500\n",
      "Epoch 348/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6812 - acc: 0.5949 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "Epoch 349/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6822 - acc: 0.7089 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 350/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6781 - acc: 0.6835 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 351/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6782 - acc: 0.6076 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 352/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6772 - acc: 0.5190 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 353/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 354/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6784 - acc: 0.5190 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 355/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6776 - acc: 0.5443 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 356/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6777 - acc: 0.6456 - val_loss: 0.6911 - val_acc: 0.5500\n",
      "Epoch 357/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6785 - acc: 0.8608 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 358/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6765 - acc: 0.5696 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 359/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6768 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 360/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6781 - acc: 0.5949 - val_loss: 0.7039 - val_acc: 0.4000\n",
      "Epoch 361/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6767 - acc: 0.5190 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 362/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6771 - acc: 0.5190 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 363/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6765 - acc: 0.5190 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 364/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6789 - acc: 0.7468 - val_loss: 0.7009 - val_acc: 0.4000\n",
      "Epoch 365/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6777 - acc: 0.5443 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 366/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6785 - acc: 0.5190 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 367/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6770 - acc: 0.5190 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 368/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6776 - acc: 0.5190 - val_loss: 0.7083 - val_acc: 0.4000\n",
      "Epoch 369/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6767 - acc: 0.5190 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 370/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 371/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 372/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6775 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 373/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6762 - acc: 0.5190 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 374/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 375/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6769 - acc: 0.7215 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 376/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6812 - acc: 0.5190 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 377/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6756 - acc: 0.7215 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 378/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6759 - acc: 0.5823 - val_loss: 0.6917 - val_acc: 0.5500\n",
      "Epoch 379/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6764 - acc: 0.7468 - val_loss: 0.6899 - val_acc: 0.6500\n",
      "Epoch 380/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6766 - acc: 0.7468 - val_loss: 0.6883 - val_acc: 0.6500\n",
      "Epoch 381/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6784 - acc: 0.7215 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 382/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6769 - acc: 0.5190 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 383/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6778 - acc: 0.6329 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 384/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6757 - acc: 0.6456 - val_loss: 0.6902 - val_acc: 0.6000\n",
      "Epoch 385/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6754 - acc: 0.8734 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 386/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6760 - acc: 0.7215 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 387/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6759 - acc: 0.6962 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 388/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6778 - acc: 0.7848 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 389/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6769 - acc: 0.5443 - val_loss: 0.7039 - val_acc: 0.4000\n",
      "Epoch 390/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6767 - acc: 0.5190 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 391/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6802 - acc: 0.6456 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 392/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6764 - acc: 0.5316 - val_loss: 0.6917 - val_acc: 0.5500\n",
      "Epoch 393/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6774 - acc: 0.6329 - val_loss: 0.6875 - val_acc: 0.6500\n",
      "Epoch 394/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6784 - acc: 0.7595 - val_loss: 0.6917 - val_acc: 0.5500\n",
      "Epoch 395/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6773 - acc: 0.5949 - val_loss: 0.6874 - val_acc: 0.6500\n",
      "Epoch 396/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6757 - acc: 0.8608 - val_loss: 0.6867 - val_acc: 0.6000\n",
      "Epoch 397/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6758 - acc: 0.8861 - val_loss: 0.6861 - val_acc: 0.5500\n",
      "Epoch 398/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6761 - acc: 0.9114 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 399/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6748 - acc: 0.8354 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 400/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6750 - acc: 0.6962 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 401/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6759 - acc: 0.5443 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 402/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6762 - acc: 0.5190 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 403/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6782 - acc: 0.5190 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 404/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6740 - acc: 0.6709 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 405/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6814 - acc: 0.6076 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 406/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6738 - acc: 0.5316 - val_loss: 0.6947 - val_acc: 0.5000\n",
      "Epoch 407/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6754 - acc: 0.6582 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 408/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6737 - acc: 0.6582 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6739 - acc: 0.5696 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 410/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6738 - acc: 0.5316 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 411/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6738 - acc: 0.5823 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 412/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6735 - acc: 0.5190 - val_loss: 0.6980 - val_acc: 0.4000\n",
      "Epoch 413/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6741 - acc: 0.5190 - val_loss: 0.6954 - val_acc: 0.4500\n",
      "Epoch 414/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6736 - acc: 0.6456 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 415/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6747 - acc: 0.5190 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 416/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6736 - acc: 0.6582 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 417/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6739 - acc: 0.6709 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 418/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6739 - acc: 0.7595 - val_loss: 0.6971 - val_acc: 0.4000\n",
      "Epoch 419/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6734 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 420/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6740 - acc: 0.5949 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 421/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6747 - acc: 0.5443 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 422/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6730 - acc: 0.5190 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 423/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6734 - acc: 0.5570 - val_loss: 0.7025 - val_acc: 0.4000\n",
      "Epoch 424/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6744 - acc: 0.5190 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 425/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6730 - acc: 0.5443 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 426/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6727 - acc: 0.5190 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 427/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6729 - acc: 0.5190 - val_loss: 0.6979 - val_acc: 0.4000\n",
      "Epoch 428/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6735 - acc: 0.5949 - val_loss: 0.7025 - val_acc: 0.4000\n",
      "Epoch 429/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6736 - acc: 0.5190 - val_loss: 0.7030 - val_acc: 0.4000\n",
      "Epoch 430/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6727 - acc: 0.5190 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 431/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6725 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 432/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6734 - acc: 0.5696 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 433/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6729 - acc: 0.5190 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 434/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6738 - acc: 0.6962 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 435/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6749 - acc: 0.5190 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 436/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6738 - acc: 0.5316 - val_loss: 0.6881 - val_acc: 0.6000\n",
      "Epoch 437/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6732 - acc: 0.7975 - val_loss: 0.6868 - val_acc: 0.6500\n",
      "Epoch 438/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6728 - acc: 0.9241 - val_loss: 0.6880 - val_acc: 0.6000\n",
      "Epoch 439/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6731 - acc: 0.7848 - val_loss: 0.6866 - val_acc: 0.6500\n",
      "Epoch 440/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6732 - acc: 0.8481 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 441/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6735 - acc: 0.6329 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 442/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6719 - acc: 0.5949 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 443/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6733 - acc: 0.5443 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 444/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6721 - acc: 0.5190 - val_loss: 0.7031 - val_acc: 0.4000\n",
      "Epoch 445/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6724 - acc: 0.5190 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 446/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6717 - acc: 0.5316 - val_loss: 0.6967 - val_acc: 0.4500\n",
      "Epoch 447/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6730 - acc: 0.5443 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 448/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6730 - acc: 0.5949 - val_loss: 0.7007 - val_acc: 0.4000\n",
      "Epoch 449/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6715 - acc: 0.5190 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 450/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6753 - acc: 0.5443 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 451/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6726 - acc: 0.5190 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 452/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6715 - acc: 0.6329 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 453/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6720 - acc: 0.5190 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 454/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6714 - acc: 0.7468 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 455/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6715 - acc: 0.5443 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 456/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6707 - acc: 0.6709 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 457/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6707 - acc: 0.7089 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 458/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6711 - acc: 0.7848 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 459/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6716 - acc: 0.5316 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 460/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6715 - acc: 0.5570 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 461/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6703 - acc: 0.5443 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6705 - acc: 0.6962 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 463/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6750 - acc: 0.5570 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 464/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6708 - acc: 0.5823 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 465/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6715 - acc: 0.5316 - val_loss: 0.7060 - val_acc: 0.4000\n",
      "Epoch 466/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6714 - acc: 0.5190 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 467/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6732 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 468/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6701 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 469/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6705 - acc: 0.5570 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 470/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6705 - acc: 0.6835 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 471/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6700 - acc: 0.5696 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 472/3000\n",
      "79/79 [==============================] - 0s 316us/sample - loss: 0.6710 - acc: 0.6203 - val_loss: 0.6888 - val_acc: 0.7000\n",
      "Epoch 473/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6705 - acc: 0.7722 - val_loss: 0.6870 - val_acc: 0.6000\n",
      "Epoch 474/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6707 - acc: 0.8608 - val_loss: 0.6861 - val_acc: 0.6500\n",
      "Epoch 475/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6710 - acc: 0.8734 - val_loss: 0.6886 - val_acc: 0.7000\n",
      "Epoch 476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6724 - acc: 0.8861 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 477/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6700 - acc: 0.5443 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 478/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6701 - acc: 0.5949 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 479/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6703 - acc: 0.5190 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 480/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6697 - acc: 0.5190 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 481/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6691 - acc: 0.5949 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 482/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6703 - acc: 0.6203 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 483/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6703 - acc: 0.5190 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 484/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6700 - acc: 0.5190 - val_loss: 0.7005 - val_acc: 0.4000\n",
      "Epoch 485/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6689 - acc: 0.5316 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 486/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6698 - acc: 0.5316 - val_loss: 0.7002 - val_acc: 0.4000\n",
      "Epoch 487/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6689 - acc: 0.5190 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 488/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6686 - acc: 0.5443 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 489/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6690 - acc: 0.6962 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 490/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6682 - acc: 0.5570 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 491/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6681 - acc: 0.5570 - val_loss: 0.6971 - val_acc: 0.4500\n",
      "Epoch 492/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6689 - acc: 0.5823 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 493/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6683 - acc: 0.5316 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 494/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6682 - acc: 0.6835 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 495/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6707 - acc: 0.6709 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 496/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6695 - acc: 0.8228 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 497/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6681 - acc: 0.8608 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 498/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6703 - acc: 0.5949 - val_loss: 0.6848 - val_acc: 0.6500\n",
      "Epoch 499/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6685 - acc: 0.9114 - val_loss: 0.6858 - val_acc: 0.6500\n",
      "Epoch 500/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6682 - acc: 0.9114 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 501/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6676 - acc: 0.8481 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 502/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6768 - acc: 0.6582 - val_loss: 0.6877 - val_acc: 0.6500\n",
      "Epoch 503/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6681 - acc: 0.9114 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 504/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6678 - acc: 0.8228 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 505/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6689 - acc: 0.5570 - val_loss: 0.6873 - val_acc: 0.6500\n",
      "Epoch 506/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6730 - acc: 0.6962 - val_loss: 0.6852 - val_acc: 0.6500\n",
      "Epoch 507/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6681 - acc: 0.9367 - val_loss: 0.6904 - val_acc: 0.5500\n",
      "Epoch 508/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6669 - acc: 0.8481 - val_loss: 0.6940 - val_acc: 0.5000\n",
      "Epoch 509/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6700 - acc: 0.5696 - val_loss: 0.6844 - val_acc: 0.6500\n",
      "Epoch 510/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6685 - acc: 0.8861 - val_loss: 0.6871 - val_acc: 0.6500\n",
      "Epoch 511/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6677 - acc: 0.8608 - val_loss: 0.6860 - val_acc: 0.6000\n",
      "Epoch 512/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6671 - acc: 0.9114 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 513/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6674 - acc: 0.7468 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 514/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6663 - acc: 0.7595 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 515/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6662 - acc: 0.6203 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 516/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6660 - acc: 0.7215 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6668 - acc: 0.7848 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 518/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6661 - acc: 0.5190 - val_loss: 0.6954 - val_acc: 0.5000\n",
      "Epoch 519/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6668 - acc: 0.6709 - val_loss: 0.6958 - val_acc: 0.5000\n",
      "Epoch 520/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6663 - acc: 0.6076 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 521/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6660 - acc: 0.7595 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 522/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6655 - acc: 0.5570 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 523/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6667 - acc: 0.6203 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 524/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6688 - acc: 0.5570 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 525/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6655 - acc: 0.5570 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 526/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6657 - acc: 0.5570 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 527/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6659 - acc: 0.5823 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 528/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6664 - acc: 0.6329 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 529/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6660 - acc: 0.7975 - val_loss: 0.6997 - val_acc: 0.4000\n",
      "Epoch 530/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6652 - acc: 0.5316 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 531/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6659 - acc: 0.7848 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 532/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6653 - acc: 0.5570 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 533/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6649 - acc: 0.5190 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 534/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6689 - acc: 0.6835 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 535/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6650 - acc: 0.5190 - val_loss: 0.7025 - val_acc: 0.4000\n",
      "Epoch 536/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6645 - acc: 0.5190 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 537/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6652 - acc: 0.5190 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 538/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6655 - acc: 0.6203 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 539/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6654 - acc: 0.6329 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 540/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6637 - acc: 0.7468 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 541/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6636 - acc: 0.8481 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 542/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6641 - acc: 0.7595 - val_loss: 0.6969 - val_acc: 0.4500\n",
      "Epoch 543/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6645 - acc: 0.5823 - val_loss: 0.6959 - val_acc: 0.5000\n",
      "Epoch 544/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6637 - acc: 0.6203 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 545/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6640 - acc: 0.7468 - val_loss: 0.6878 - val_acc: 0.7000\n",
      "Epoch 546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6660 - acc: 0.7595 - val_loss: 0.6853 - val_acc: 0.6000\n",
      "Epoch 547/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6642 - acc: 0.9114 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 548/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6632 - acc: 0.8481 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 549/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6634 - acc: 0.7215 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 550/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6659 - acc: 0.5823 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 551/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6640 - acc: 0.5316 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 552/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6625 - acc: 0.7342 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 553/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6630 - acc: 0.7595 - val_loss: 0.6983 - val_acc: 0.4500\n",
      "Epoch 554/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6625 - acc: 0.5949 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 555/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6640 - acc: 0.5316 - val_loss: 0.6879 - val_acc: 0.6500\n",
      "Epoch 556/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6623 - acc: 0.8608 - val_loss: 0.6878 - val_acc: 0.7000\n",
      "Epoch 557/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6652 - acc: 0.8734 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 558/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6625 - acc: 0.8354 - val_loss: 0.6863 - val_acc: 0.6500\n",
      "Epoch 559/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6630 - acc: 0.8608 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 560/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6620 - acc: 0.8101 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 561/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6625 - acc: 0.8228 - val_loss: 0.6872 - val_acc: 0.7000\n",
      "Epoch 562/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6653 - acc: 0.8608 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 563/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6650 - acc: 0.8354 - val_loss: 0.6920 - val_acc: 0.5000\n",
      "Epoch 564/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6623 - acc: 0.7722 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 565/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6615 - acc: 0.7215 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 566/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6623 - acc: 0.7975 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 567/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6610 - acc: 0.8228 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 568/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6610 - acc: 0.7722 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 569/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6611 - acc: 0.7848 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 570/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6616 - acc: 0.7215 - val_loss: 0.6980 - val_acc: 0.4500\n",
      "Epoch 571/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6623 - acc: 0.6456 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 572/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6616 - acc: 0.7595 - val_loss: 0.6855 - val_acc: 0.6000\n",
      "Epoch 573/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6612 - acc: 0.8481 - val_loss: 0.6839 - val_acc: 0.6000\n",
      "Epoch 574/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.6608 - acc: 0.9114 - val_loss: 0.6867 - val_acc: 0.7000\n",
      "Epoch 575/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6611 - acc: 0.8354 - val_loss: 0.6866 - val_acc: 0.6500\n",
      "Epoch 576/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6611 - acc: 0.8861 - val_loss: 0.6870 - val_acc: 0.7000\n",
      "Epoch 577/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6608 - acc: 0.8987 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 578/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6598 - acc: 0.7722 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 579/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6598 - acc: 0.7722 - val_loss: 0.6947 - val_acc: 0.5000\n",
      "Epoch 580/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6600 - acc: 0.7342 - val_loss: 0.6970 - val_acc: 0.5000\n",
      "Epoch 581/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6606 - acc: 0.6962 - val_loss: 0.7009 - val_acc: 0.4000\n",
      "Epoch 582/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6621 - acc: 0.5316 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 583/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6601 - acc: 0.7089 - val_loss: 0.6954 - val_acc: 0.5000\n",
      "Epoch 584/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6609 - acc: 0.5823 - val_loss: 0.6863 - val_acc: 0.6500\n",
      "Epoch 585/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6597 - acc: 0.8608 - val_loss: 0.6845 - val_acc: 0.6000\n",
      "Epoch 586/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6617 - acc: 0.9241 - val_loss: 0.6953 - val_acc: 0.5000\n",
      "Epoch 587/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6588 - acc: 0.6962 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 588/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6594 - acc: 0.6962 - val_loss: 0.6903 - val_acc: 0.5000\n",
      "Epoch 589/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6588 - acc: 0.8354 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 590/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6602 - acc: 0.7848 - val_loss: 0.6963 - val_acc: 0.5000\n",
      "Epoch 591/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6610 - acc: 0.6329 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 592/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6589 - acc: 0.7089 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 593/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6587 - acc: 0.8481 - val_loss: 0.6952 - val_acc: 0.5000\n",
      "Epoch 594/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6583 - acc: 0.7089 - val_loss: 0.6971 - val_acc: 0.5000\n",
      "Epoch 595/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6600 - acc: 0.6835 - val_loss: 0.6964 - val_acc: 0.5000\n",
      "Epoch 596/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6589 - acc: 0.7215 - val_loss: 0.6958 - val_acc: 0.5000\n",
      "Epoch 597/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6577 - acc: 0.7089 - val_loss: 0.6952 - val_acc: 0.5000\n",
      "Epoch 598/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6578 - acc: 0.6709 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 599/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6576 - acc: 0.8101 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 600/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6574 - acc: 0.7215 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 601/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6590 - acc: 0.8354 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 602/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6598 - acc: 0.5949 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 603/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6594 - acc: 0.7975 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 604/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6573 - acc: 0.8101 - val_loss: 0.6853 - val_acc: 0.6500\n",
      "Epoch 605/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6573 - acc: 0.8987 - val_loss: 0.6837 - val_acc: 0.6000\n",
      "Epoch 606/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6578 - acc: 0.8734 - val_loss: 0.6841 - val_acc: 0.6000\n",
      "Epoch 607/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6569 - acc: 0.8861 - val_loss: 0.6845 - val_acc: 0.6000\n",
      "Epoch 608/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6589 - acc: 0.7722 - val_loss: 0.6793 - val_acc: 0.6500\n",
      "Epoch 609/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6576 - acc: 0.9114 - val_loss: 0.6851 - val_acc: 0.6500\n",
      "Epoch 610/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6573 - acc: 0.8608 - val_loss: 0.6815 - val_acc: 0.7000\n",
      "Epoch 611/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6568 - acc: 0.9620 - val_loss: 0.6867 - val_acc: 0.6500\n",
      "Epoch 612/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6561 - acc: 0.8354 - val_loss: 0.6864 - val_acc: 0.7000\n",
      "Epoch 613/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6574 - acc: 0.8608 - val_loss: 0.6920 - val_acc: 0.5000\n",
      "Epoch 614/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6575 - acc: 0.7342 - val_loss: 0.6989 - val_acc: 0.4500\n",
      "Epoch 615/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6557 - acc: 0.6329 - val_loss: 0.6967 - val_acc: 0.5000\n",
      "Epoch 616/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6575 - acc: 0.7089 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 617/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6571 - acc: 0.5190 - val_loss: 0.6939 - val_acc: 0.5000\n",
      "Epoch 618/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6568 - acc: 0.6835 - val_loss: 0.6953 - val_acc: 0.5000\n",
      "Epoch 619/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6642 - acc: 0.656 - 0s 133us/sample - loss: 0.6557 - acc: 0.7215 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 620/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6555 - acc: 0.8101 - val_loss: 0.6972 - val_acc: 0.5000\n",
      "Epoch 621/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6556 - acc: 0.5823 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 622/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6566 - acc: 0.7975 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 623/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6550 - acc: 0.9367 - val_loss: 0.6834 - val_acc: 0.6000\n",
      "Epoch 624/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6550 - acc: 0.8608 - val_loss: 0.6820 - val_acc: 0.6000\n",
      "Epoch 625/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6545 - acc: 0.9241 - val_loss: 0.6849 - val_acc: 0.6500\n",
      "Epoch 626/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6558 - acc: 0.8101 - val_loss: 0.6845 - val_acc: 0.6500\n",
      "Epoch 627/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6560 - acc: 0.8987 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 628/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6536 - acc: 0.8481 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 629/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6561 - acc: 0.8734 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 630/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6537 - acc: 0.7089 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 631/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6534 - acc: 0.8228 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 632/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6557 - acc: 0.8101 - val_loss: 0.6975 - val_acc: 0.5000\n",
      "Epoch 633/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6538 - acc: 0.6076 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 634/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6542 - acc: 0.7975 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 635/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6530 - acc: 0.8228 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 636/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6531 - acc: 0.8481 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 637/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6524 - acc: 0.7215 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 638/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6538 - acc: 0.8228 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 639/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6522 - acc: 0.8101 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 640/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6541 - acc: 0.7722 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 641/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6532 - acc: 0.8101 - val_loss: 0.6845 - val_acc: 0.6500\n",
      "Epoch 642/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6540 - acc: 0.8734 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 643/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6533 - acc: 0.8481 - val_loss: 0.6825 - val_acc: 0.6000\n",
      "Epoch 644/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6534 - acc: 0.9241 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 645/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6515 - acc: 0.7975 - val_loss: 0.6845 - val_acc: 0.6500\n",
      "Epoch 646/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6531 - acc: 0.8608 - val_loss: 0.6789 - val_acc: 0.6500\n",
      "Epoch 647/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6530 - acc: 0.9114 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 648/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6521 - acc: 0.8987 - val_loss: 0.6793 - val_acc: 0.6500\n",
      "Epoch 649/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6543 - acc: 0.9114 - val_loss: 0.6776 - val_acc: 0.6500\n",
      "Epoch 650/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6558 - acc: 0.8987 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 651/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6519 - acc: 0.7722 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 652/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6501 - acc: 0.8608 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 653/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6524 - acc: 0.7215 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 654/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6502 - acc: 0.9114 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 655/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6505 - acc: 0.8101 - val_loss: 0.6819 - val_acc: 0.6000\n",
      "Epoch 656/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6502 - acc: 0.9114 - val_loss: 0.6847 - val_acc: 0.6500\n",
      "Epoch 657/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6498 - acc: 0.8987 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 658/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6518 - acc: 0.8228 - val_loss: 0.6824 - val_acc: 0.6000\n",
      "Epoch 659/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6501 - acc: 0.9241 - val_loss: 0.6831 - val_acc: 0.6500\n",
      "Epoch 660/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6500 - acc: 0.8734 - val_loss: 0.6815 - val_acc: 0.6000\n",
      "Epoch 661/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6496 - acc: 0.8987 - val_loss: 0.6804 - val_acc: 0.6500\n",
      "Epoch 662/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6494 - acc: 0.8861 - val_loss: 0.6834 - val_acc: 0.6500\n",
      "Epoch 663/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6485 - acc: 0.8861 - val_loss: 0.6856 - val_acc: 0.6500\n",
      "Epoch 664/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6482 - acc: 0.8608 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 665/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6489 - acc: 0.8608 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 666/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6502 - acc: 0.6582 - val_loss: 0.6848 - val_acc: 0.7000\n",
      "Epoch 667/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6482 - acc: 0.8481 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 668/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6519 - acc: 0.843 - 0s 126us/sample - loss: 0.6512 - acc: 0.9114 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 669/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6494 - acc: 0.6709 - val_loss: 0.6983 - val_acc: 0.5000\n",
      "Epoch 670/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6537 - acc: 0.5949 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 671/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6477 - acc: 0.6456 - val_loss: 0.6967 - val_acc: 0.5000\n",
      "Epoch 672/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6471 - acc: 0.6962 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 673/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6468 - acc: 0.7342 - val_loss: 0.6893 - val_acc: 0.5000\n",
      "Epoch 674/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6482 - acc: 0.8228 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 675/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6468 - acc: 0.7215 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 676/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6461 - acc: 0.8354 - val_loss: 0.6861 - val_acc: 0.6000\n",
      "Epoch 677/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6467 - acc: 0.8481 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 678/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6472 - acc: 0.8481 - val_loss: 0.6961 - val_acc: 0.5000\n",
      "Epoch 679/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6459 - acc: 0.7215 - val_loss: 0.6942 - val_acc: 0.5000\n",
      "Epoch 680/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6456 - acc: 0.7215 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6456 - acc: 0.7342 - val_loss: 0.6894 - val_acc: 0.5000\n",
      "Epoch 682/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6467 - acc: 0.7468 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 683/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6475 - acc: 0.8608 - val_loss: 0.6829 - val_acc: 0.6500\n",
      "Epoch 684/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6450 - acc: 0.8861 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 685/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6454 - acc: 0.7975 - val_loss: 0.6815 - val_acc: 0.6500\n",
      "Epoch 686/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6451 - acc: 0.8987 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 687/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6458 - acc: 0.7848 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 688/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6445 - acc: 0.8101 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 689/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6441 - acc: 0.7215 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 690/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6438 - acc: 0.7468 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 691/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6442 - acc: 0.7215 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6441 - acc: 0.8481 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 693/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6449 - acc: 0.8228 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 694/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6432 - acc: 0.7215 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 695/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6430 - acc: 0.8228 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 696/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6429 - acc: 0.7975 - val_loss: 0.6935 - val_acc: 0.5000\n",
      "Epoch 697/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6426 - acc: 0.7215 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 698/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6430 - acc: 0.7468 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "Epoch 699/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6435 - acc: 0.7848 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 700/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6423 - acc: 0.8987 - val_loss: 0.6814 - val_acc: 0.6500\n",
      "Epoch 701/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6426 - acc: 0.8608 - val_loss: 0.6811 - val_acc: 0.6500\n",
      "Epoch 702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6553 - acc: 0.8354 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 703/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6451 - acc: 0.8734 - val_loss: 0.6823 - val_acc: 0.6500\n",
      "Epoch 704/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6428 - acc: 0.8861 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 705/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.6412 - acc: 0.8101 - val_loss: 0.6845 - val_acc: 0.6500\n",
      "Epoch 706/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6414 - acc: 0.8734 - val_loss: 0.6840 - val_acc: 0.7000\n",
      "Epoch 707/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6441 - acc: 0.8987 - val_loss: 0.6861 - val_acc: 0.5500\n",
      "Epoch 708/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6406 - acc: 0.8608 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 709/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6404 - acc: 0.8354 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 710/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6408 - acc: 0.8354 - val_loss: 0.6819 - val_acc: 0.6500\n",
      "Epoch 711/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6502 - acc: 0.8228 - val_loss: 0.6789 - val_acc: 0.6000\n",
      "Epoch 712/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6403 - acc: 0.8987 - val_loss: 0.6813 - val_acc: 0.6500\n",
      "Epoch 713/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6429 - acc: 0.8861 - val_loss: 0.6841 - val_acc: 0.6500\n",
      "Epoch 714/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6400 - acc: 0.8734 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 715/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6406 - acc: 0.7595 - val_loss: 0.6803 - val_acc: 0.6000\n",
      "Epoch 716/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6390 - acc: 0.9114 - val_loss: 0.6804 - val_acc: 0.6500\n",
      "Epoch 717/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6398 - acc: 0.8608 - val_loss: 0.6823 - val_acc: 0.6500\n",
      "Epoch 718/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6386 - acc: 0.8734 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 719/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6386 - acc: 0.8608 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 720/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6381 - acc: 0.7215 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 721/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6379 - acc: 0.8354 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 722/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6393 - acc: 0.7975 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 723/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6392 - acc: 0.7595 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 724/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6397 - acc: 0.8481 - val_loss: 0.6991 - val_acc: 0.5000\n",
      "Epoch 725/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6396 - acc: 0.7468 - val_loss: 0.6984 - val_acc: 0.5000\n",
      "Epoch 726/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6380 - acc: 0.7089 - val_loss: 0.6974 - val_acc: 0.5000\n",
      "Epoch 727/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6378 - acc: 0.7215 - val_loss: 0.6893 - val_acc: 0.5000\n",
      "Epoch 728/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6366 - acc: 0.8354 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 729/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6367 - acc: 0.8228 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 730/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6364 - acc: 0.7975 - val_loss: 0.6844 - val_acc: 0.6500\n",
      "Epoch 731/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6366 - acc: 0.8354 - val_loss: 0.6847 - val_acc: 0.6000\n",
      "Epoch 732/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6359 - acc: 0.8608 - val_loss: 0.6838 - val_acc: 0.6500\n",
      "Epoch 733/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6358 - acc: 0.8734 - val_loss: 0.6807 - val_acc: 0.6500\n",
      "Epoch 734/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6357 - acc: 0.8987 - val_loss: 0.6853 - val_acc: 0.6000\n",
      "Epoch 735/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6362 - acc: 0.8481 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 736/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6354 - acc: 0.8101 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 737/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6348 - acc: 0.7848 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 738/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6351 - acc: 0.7848 - val_loss: 0.6835 - val_acc: 0.6500\n",
      "Epoch 739/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6338 - acc: 0.8481 - val_loss: 0.6816 - val_acc: 0.6500\n",
      "Epoch 740/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6357 - acc: 0.8608 - val_loss: 0.6834 - val_acc: 0.6500\n",
      "Epoch 741/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6359 - acc: 0.8354 - val_loss: 0.6785 - val_acc: 0.6000\n",
      "Epoch 742/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6340 - acc: 0.9114 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 743/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6329 - acc: 0.8608 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 744/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6335 - acc: 0.7722 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 745/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6343 - acc: 0.7975 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 746/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6330 - acc: 0.9241 - val_loss: 0.6857 - val_acc: 0.5500\n",
      "Epoch 747/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6336 - acc: 0.8101 - val_loss: 0.6873 - val_acc: 0.5000\n",
      "Epoch 748/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6314 - acc: 0.8354 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 749/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6315 - acc: 0.8354 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 750/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6316 - acc: 0.8354 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 751/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6309 - acc: 0.8608 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 752/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6306 - acc: 0.8354 - val_loss: 0.6816 - val_acc: 0.6500\n",
      "Epoch 753/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6315 - acc: 0.8734 - val_loss: 0.6792 - val_acc: 0.6500\n",
      "Epoch 754/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6303 - acc: 0.9114 - val_loss: 0.6837 - val_acc: 0.6500\n",
      "Epoch 755/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6303 - acc: 0.8481 - val_loss: 0.6802 - val_acc: 0.6500\n",
      "Epoch 756/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6304 - acc: 0.8734 - val_loss: 0.6761 - val_acc: 0.6000\n",
      "Epoch 757/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6311 - acc: 0.9114 - val_loss: 0.6753 - val_acc: 0.6000\n",
      "Epoch 758/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6297 - acc: 0.9241 - val_loss: 0.6786 - val_acc: 0.6500\n",
      "Epoch 759/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6305 - acc: 0.8861 - val_loss: 0.6790 - val_acc: 0.6500\n",
      "Epoch 760/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6296 - acc: 0.9114 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 761/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6285 - acc: 0.8228 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 762/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6288 - acc: 0.8354 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 763/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6289 - acc: 0.7595 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 764/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6277 - acc: 0.7848 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 765/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6311 - acc: 0.8228 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 766/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6272 - acc: 0.8354 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 767/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6305 - acc: 0.7848 - val_loss: 0.6814 - val_acc: 0.7000\n",
      "Epoch 768/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6265 - acc: 0.9114 - val_loss: 0.6834 - val_acc: 0.6500\n",
      "Epoch 769/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6288 - acc: 0.8734 - val_loss: 0.6823 - val_acc: 0.7000\n",
      "Epoch 770/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6279 - acc: 0.8481 - val_loss: 0.6826 - val_acc: 0.6500\n",
      "Epoch 771/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6258 - acc: 0.8481 - val_loss: 0.6823 - val_acc: 0.6500\n",
      "Epoch 772/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6257 - acc: 0.8608 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 773/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6251 - acc: 0.8354 - val_loss: 0.6848 - val_acc: 0.6000\n",
      "Epoch 774/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6282 - acc: 0.7848 - val_loss: 0.6836 - val_acc: 0.6000\n",
      "Epoch 775/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6249 - acc: 0.8608 - val_loss: 0.6820 - val_acc: 0.6500\n",
      "Epoch 776/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6238 - acc: 0.8608 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 777/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6267 - acc: 0.8734 - val_loss: 0.6815 - val_acc: 0.7000\n",
      "Epoch 778/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6237 - acc: 0.8608 - val_loss: 0.6776 - val_acc: 0.6500\n",
      "Epoch 779/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6244 - acc: 0.9114 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 780/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6249 - acc: 0.8734 - val_loss: 0.6955 - val_acc: 0.5000\n",
      "Epoch 781/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6236 - acc: 0.7342 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 782/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6259 - acc: 0.7342 - val_loss: 0.6954 - val_acc: 0.5000\n",
      "Epoch 783/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6230 - acc: 0.7342 - val_loss: 0.6862 - val_acc: 0.5000\n",
      "Epoch 784/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6227 - acc: 0.8228 - val_loss: 0.6782 - val_acc: 0.6500\n",
      "Epoch 785/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6226 - acc: 0.8861 - val_loss: 0.6737 - val_acc: 0.6000\n",
      "Epoch 786/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6223 - acc: 0.9367 - val_loss: 0.6814 - val_acc: 0.7000\n",
      "Epoch 787/3000\n",
      "79/79 [==============================] - 0s 227us/sample - loss: 0.6210 - acc: 0.8608 - val_loss: 0.6777 - val_acc: 0.6500\n",
      "Epoch 788/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.6222 - acc: 0.9114 - val_loss: 0.6820 - val_acc: 0.6500\n",
      "Epoch 789/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6200 - acc: 0.8734 - val_loss: 0.6801 - val_acc: 0.6500\n",
      "Epoch 790/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6197 - acc: 0.8734 - val_loss: 0.6816 - val_acc: 0.7000\n",
      "Epoch 791/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6219 - acc: 0.8987 - val_loss: 0.6920 - val_acc: 0.5000\n",
      "Epoch 792/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6221 - acc: 0.8228 - val_loss: 0.6977 - val_acc: 0.5000\n",
      "Epoch 793/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6209 - acc: 0.7215 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 794/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6189 - acc: 0.8228 - val_loss: 0.6843 - val_acc: 0.6000\n",
      "Epoch 795/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6214 - acc: 0.8228 - val_loss: 0.6854 - val_acc: 0.5500\n",
      "Epoch 796/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6182 - acc: 0.8354 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 797/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6185 - acc: 0.8481 - val_loss: 0.6873 - val_acc: 0.5000\n",
      "Epoch 798/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6179 - acc: 0.8101 - val_loss: 0.6807 - val_acc: 0.7000\n",
      "Epoch 799/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6182 - acc: 0.8734 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 800/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6186 - acc: 0.8481 - val_loss: 0.6950 - val_acc: 0.5000\n",
      "Epoch 801/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6175 - acc: 0.7468 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 802/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6190 - acc: 0.7848 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 803/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6163 - acc: 0.8101 - val_loss: 0.6851 - val_acc: 0.5000\n",
      "Epoch 804/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6157 - acc: 0.8608 - val_loss: 0.6863 - val_acc: 0.5000\n",
      "Epoch 805/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6178 - acc: 0.8861 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 806/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6164 - acc: 0.8354 - val_loss: 0.6881 - val_acc: 0.5000\n",
      "Epoch 807/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6157 - acc: 0.7975 - val_loss: 0.6782 - val_acc: 0.6500\n",
      "Epoch 808/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6162 - acc: 0.8481 - val_loss: 0.6713 - val_acc: 0.6500\n",
      "Epoch 809/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6153 - acc: 0.8987 - val_loss: 0.6702 - val_acc: 0.6500\n",
      "Epoch 810/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6143 - acc: 0.9494 - val_loss: 0.6761 - val_acc: 0.6500\n",
      "Epoch 811/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6150 - acc: 0.8861 - val_loss: 0.6695 - val_acc: 0.6500\n",
      "Epoch 812/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6140 - acc: 0.9114 - val_loss: 0.6727 - val_acc: 0.6000\n",
      "Epoch 813/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6128 - acc: 0.9367 - val_loss: 0.6780 - val_acc: 0.6500\n",
      "Epoch 814/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6121 - acc: 0.8861 - val_loss: 0.6811 - val_acc: 0.6500\n",
      "Epoch 815/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6127 - acc: 0.8734 - val_loss: 0.6806 - val_acc: 0.6500\n",
      "Epoch 816/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6124 - acc: 0.8987 - val_loss: 0.6881 - val_acc: 0.5000\n",
      "Epoch 817/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6134 - acc: 0.8101 - val_loss: 0.6848 - val_acc: 0.5000\n",
      "Epoch 818/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6124 - acc: 0.8354 - val_loss: 0.6857 - val_acc: 0.5000\n",
      "Epoch 819/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6132 - acc: 0.8101 - val_loss: 0.6761 - val_acc: 0.6500\n",
      "Epoch 820/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6114 - acc: 0.9241 - val_loss: 0.6826 - val_acc: 0.6000\n",
      "Epoch 821/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6097 - acc: 0.8481 - val_loss: 0.6813 - val_acc: 0.6500\n",
      "Epoch 822/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6094 - acc: 0.8608 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 823/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6092 - acc: 0.8354 - val_loss: 0.6804 - val_acc: 0.6500\n",
      "Epoch 824/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6094 - acc: 0.8734 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 825/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6094 - acc: 0.8101 - val_loss: 0.6760 - val_acc: 0.6500\n",
      "Epoch 826/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6081 - acc: 0.9114 - val_loss: 0.6763 - val_acc: 0.6500\n",
      "Epoch 827/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6072 - acc: 0.8987 - val_loss: 0.6752 - val_acc: 0.6500\n",
      "Epoch 828/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6087 - acc: 0.8861 - val_loss: 0.6688 - val_acc: 0.6000\n",
      "Epoch 829/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6072 - acc: 0.9367 - val_loss: 0.6721 - val_acc: 0.6000\n",
      "Epoch 830/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6066 - acc: 0.8987 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 831/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6061 - acc: 0.9241 - val_loss: 0.6730 - val_acc: 0.6000\n",
      "Epoch 832/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6105 - acc: 0.906 - 0s 122us/sample - loss: 0.6063 - acc: 0.9114 - val_loss: 0.6794 - val_acc: 0.7000\n",
      "Epoch 833/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6078 - acc: 0.8861 - val_loss: 0.6829 - val_acc: 0.6000\n",
      "Epoch 834/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6075 - acc: 0.8481 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 835/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6055 - acc: 0.8354 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 836/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6047 - acc: 0.7848 - val_loss: 0.6820 - val_acc: 0.6500\n",
      "Epoch 837/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6041 - acc: 0.8481 - val_loss: 0.6737 - val_acc: 0.6000\n",
      "Epoch 838/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6038 - acc: 0.9114 - val_loss: 0.6779 - val_acc: 0.6500\n",
      "Epoch 839/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6029 - acc: 0.8734 - val_loss: 0.6758 - val_acc: 0.6500\n",
      "Epoch 840/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6037 - acc: 0.8861 - val_loss: 0.6757 - val_acc: 0.6500\n",
      "Epoch 841/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6041 - acc: 0.8861 - val_loss: 0.6678 - val_acc: 0.6500\n",
      "Epoch 842/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6031 - acc: 0.9114 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 843/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.6040 - acc: 0.8861 - val_loss: 0.6637 - val_acc: 0.7000\n",
      "Epoch 844/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6031 - acc: 0.9494 - val_loss: 0.6660 - val_acc: 0.6000\n",
      "Epoch 845/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6011 - acc: 0.9494 - val_loss: 0.6700 - val_acc: 0.6000\n",
      "Epoch 846/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6001 - acc: 0.9241 - val_loss: 0.6733 - val_acc: 0.6000\n",
      "Epoch 847/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6009 - acc: 0.9241 - val_loss: 0.6735 - val_acc: 0.6500\n",
      "Epoch 848/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6000 - acc: 0.8734 - val_loss: 0.6685 - val_acc: 0.6000\n",
      "Epoch 849/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6003 - acc: 0.9241 - val_loss: 0.6762 - val_acc: 0.6500\n",
      "Epoch 850/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5979 - acc: 0.8734 - val_loss: 0.6745 - val_acc: 0.6500\n",
      "Epoch 851/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.5975 - acc: 0.9241 - val_loss: 0.6782 - val_acc: 0.7000\n",
      "Epoch 852/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6001 - acc: 0.8354 - val_loss: 0.6743 - val_acc: 0.6500\n",
      "Epoch 853/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5972 - acc: 0.8861 - val_loss: 0.6745 - val_acc: 0.6500\n",
      "Epoch 854/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5996 - acc: 0.8987 - val_loss: 0.6799 - val_acc: 0.6500\n",
      "Epoch 855/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5969 - acc: 0.8608 - val_loss: 0.6724 - val_acc: 0.6000\n",
      "Epoch 856/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5959 - acc: 0.8987 - val_loss: 0.6714 - val_acc: 0.6000\n",
      "Epoch 857/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5956 - acc: 0.9114 - val_loss: 0.6783 - val_acc: 0.7000\n",
      "Epoch 858/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5957 - acc: 0.8608 - val_loss: 0.6738 - val_acc: 0.6500\n",
      "Epoch 859/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5945 - acc: 0.8987 - val_loss: 0.6726 - val_acc: 0.6500\n",
      "Epoch 860/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5944 - acc: 0.8987 - val_loss: 0.6696 - val_acc: 0.6000\n",
      "Epoch 861/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5936 - acc: 0.9367 - val_loss: 0.6747 - val_acc: 0.6500\n",
      "Epoch 862/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5938 - acc: 0.8861 - val_loss: 0.6711 - val_acc: 0.6000\n",
      "Epoch 863/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5920 - acc: 0.9114 - val_loss: 0.6707 - val_acc: 0.6000\n",
      "Epoch 864/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5926 - acc: 0.8987 - val_loss: 0.6674 - val_acc: 0.6000\n",
      "Epoch 865/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5917 - acc: 0.9367 - val_loss: 0.6683 - val_acc: 0.6000\n",
      "Epoch 866/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5916 - acc: 0.9367 - val_loss: 0.6728 - val_acc: 0.6500\n",
      "Epoch 867/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5921 - acc: 0.9367 - val_loss: 0.6826 - val_acc: 0.6000\n",
      "Epoch 868/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5910 - acc: 0.8608 - val_loss: 0.6811 - val_acc: 0.6500\n",
      "Epoch 869/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5923 - acc: 0.8734 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 870/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5903 - acc: 0.8354 - val_loss: 0.6867 - val_acc: 0.5000\n",
      "Epoch 871/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.5914 - acc: 0.8608 - val_loss: 0.6839 - val_acc: 0.5500\n",
      "Epoch 872/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5891 - acc: 0.8354 - val_loss: 0.6751 - val_acc: 0.6500\n",
      "Epoch 873/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5889 - acc: 0.8734 - val_loss: 0.6727 - val_acc: 0.6500\n",
      "Epoch 874/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5874 - acc: 0.8987 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 875/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5868 - acc: 0.9114 - val_loss: 0.6740 - val_acc: 0.6500\n",
      "Epoch 876/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5868 - acc: 0.8734 - val_loss: 0.6717 - val_acc: 0.6500\n",
      "Epoch 877/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.5859 - acc: 0.9114 - val_loss: 0.6731 - val_acc: 0.6500\n",
      "Epoch 878/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5874 - acc: 0.8861 - val_loss: 0.6729 - val_acc: 0.6500\n",
      "Epoch 879/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.5866 - acc: 0.9114 - val_loss: 0.6746 - val_acc: 0.6500\n",
      "Epoch 880/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5844 - acc: 0.8861 - val_loss: 0.6751 - val_acc: 0.6500\n",
      "Epoch 881/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5837 - acc: 0.8987 - val_loss: 0.6776 - val_acc: 0.6500\n",
      "Epoch 882/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5843 - acc: 0.8861 - val_loss: 0.6769 - val_acc: 0.6500\n",
      "Epoch 883/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5832 - acc: 0.8734 - val_loss: 0.6706 - val_acc: 0.6500\n",
      "Epoch 884/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5824 - acc: 0.8987 - val_loss: 0.6721 - val_acc: 0.6500\n",
      "Epoch 885/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5814 - acc: 0.8987 - val_loss: 0.6723 - val_acc: 0.6500\n",
      "Epoch 886/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5809 - acc: 0.8987 - val_loss: 0.6724 - val_acc: 0.6500\n",
      "Epoch 887/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5805 - acc: 0.8987 - val_loss: 0.6705 - val_acc: 0.6500\n",
      "Epoch 888/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5817 - acc: 0.9114 - val_loss: 0.6782 - val_acc: 0.6500\n",
      "Epoch 889/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5804 - acc: 0.8734 - val_loss: 0.6715 - val_acc: 0.6500\n",
      "Epoch 890/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5790 - acc: 0.8987 - val_loss: 0.6731 - val_acc: 0.6500\n",
      "Epoch 891/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5816 - acc: 0.8861 - val_loss: 0.6743 - val_acc: 0.6500\n",
      "Epoch 892/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5783 - acc: 0.8861 - val_loss: 0.6759 - val_acc: 0.7000\n",
      "Epoch 893/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.5776 - acc: 0.8734 - val_loss: 0.6748 - val_acc: 0.7000\n",
      "Epoch 894/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5787 - acc: 0.8734 - val_loss: 0.6785 - val_acc: 0.6500\n",
      "Epoch 895/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5771 - acc: 0.8734 - val_loss: 0.6784 - val_acc: 0.6500\n",
      "Epoch 896/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5781 - acc: 0.8861 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 897/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5773 - acc: 0.8481 - val_loss: 0.6820 - val_acc: 0.6000\n",
      "Epoch 898/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5757 - acc: 0.8481 - val_loss: 0.6782 - val_acc: 0.6500\n",
      "Epoch 899/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5759 - acc: 0.8608 - val_loss: 0.6739 - val_acc: 0.7000\n",
      "Epoch 900/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5743 - acc: 0.8734 - val_loss: 0.6707 - val_acc: 0.6500\n",
      "Epoch 901/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5732 - acc: 0.9114 - val_loss: 0.6710 - val_acc: 0.6500\n",
      "Epoch 902/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5745 - acc: 0.8987 - val_loss: 0.6676 - val_acc: 0.6500\n",
      "Epoch 903/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5730 - acc: 0.9114 - val_loss: 0.6647 - val_acc: 0.6000\n",
      "Epoch 904/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5722 - acc: 0.8987 - val_loss: 0.6625 - val_acc: 0.6000\n",
      "Epoch 905/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5728 - acc: 0.9367 - val_loss: 0.6593 - val_acc: 0.6000\n",
      "Epoch 906/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5748 - acc: 0.9367 - val_loss: 0.6635 - val_acc: 0.6000\n",
      "Epoch 907/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.5711 - acc: 0.9241 - val_loss: 0.6635 - val_acc: 0.6000\n",
      "Epoch 908/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5702 - acc: 0.9241 - val_loss: 0.6611 - val_acc: 0.6000\n",
      "Epoch 909/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5695 - acc: 0.9367 - val_loss: 0.6668 - val_acc: 0.6500\n",
      "Epoch 910/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5700 - acc: 0.8987 - val_loss: 0.6721 - val_acc: 0.6500\n",
      "Epoch 911/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5681 - acc: 0.8734 - val_loss: 0.6682 - val_acc: 0.6500\n",
      "Epoch 912/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5673 - acc: 0.9241 - val_loss: 0.6662 - val_acc: 0.6500\n",
      "Epoch 913/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5686 - acc: 0.8987 - val_loss: 0.6717 - val_acc: 0.6500\n",
      "Epoch 914/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.5678 - acc: 0.8861 - val_loss: 0.6792 - val_acc: 0.6000\n",
      "Epoch 915/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5670 - acc: 0.8608 - val_loss: 0.6815 - val_acc: 0.6000\n",
      "Epoch 916/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5684 - acc: 0.8734 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 917/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5664 - acc: 0.8481 - val_loss: 0.6752 - val_acc: 0.6500\n",
      "Epoch 918/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.5675 - acc: 0.8987 - val_loss: 0.6760 - val_acc: 0.6500\n",
      "Epoch 919/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5647 - acc: 0.8734 - val_loss: 0.6732 - val_acc: 0.7000\n",
      "Epoch 920/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5629 - acc: 0.8861 - val_loss: 0.6664 - val_acc: 0.6500\n",
      "Epoch 921/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5617 - acc: 0.9114 - val_loss: 0.6670 - val_acc: 0.6500\n",
      "Epoch 922/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5620 - acc: 0.8861 - val_loss: 0.6627 - val_acc: 0.6000\n",
      "Epoch 923/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5612 - acc: 0.9114 - val_loss: 0.6613 - val_acc: 0.6000\n",
      "Epoch 924/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5609 - acc: 0.9241 - val_loss: 0.6655 - val_acc: 0.6500\n",
      "Epoch 925/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5601 - acc: 0.9241 - val_loss: 0.6720 - val_acc: 0.7000\n",
      "Epoch 926/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5593 - acc: 0.8861 - val_loss: 0.6704 - val_acc: 0.6500\n",
      "Epoch 927/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5604 - acc: 0.9114 - val_loss: 0.6698 - val_acc: 0.6500\n",
      "Epoch 928/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.5586 - acc: 0.8987 - val_loss: 0.6695 - val_acc: 0.6500\n",
      "Epoch 929/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5575 - acc: 0.8734 - val_loss: 0.6633 - val_acc: 0.6000\n",
      "Epoch 930/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5580 - acc: 0.9241 - val_loss: 0.6729 - val_acc: 0.7000\n",
      "Epoch 931/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5576 - acc: 0.8861 - val_loss: 0.6784 - val_acc: 0.6000\n",
      "Epoch 932/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5569 - acc: 0.8481 - val_loss: 0.6662 - val_acc: 0.6500\n",
      "Epoch 933/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5565 - acc: 0.9114 - val_loss: 0.6699 - val_acc: 0.6500\n",
      "Epoch 934/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5543 - acc: 0.8861 - val_loss: 0.6716 - val_acc: 0.7000\n",
      "Epoch 935/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5535 - acc: 0.8861 - val_loss: 0.6698 - val_acc: 0.6500\n",
      "Epoch 936/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5532 - acc: 0.8987 - val_loss: 0.6717 - val_acc: 0.7000\n",
      "Epoch 937/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5535 - acc: 0.8608 - val_loss: 0.6639 - val_acc: 0.6500\n",
      "Epoch 938/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5518 - acc: 0.9241 - val_loss: 0.6697 - val_acc: 0.6500\n",
      "Epoch 939/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5535 - acc: 0.8861 - val_loss: 0.6745 - val_acc: 0.6500\n",
      "Epoch 940/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5513 - acc: 0.8734 - val_loss: 0.6715 - val_acc: 0.7000\n",
      "Epoch 941/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5504 - acc: 0.8861 - val_loss: 0.6687 - val_acc: 0.6500\n",
      "Epoch 942/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5503 - acc: 0.8987 - val_loss: 0.6695 - val_acc: 0.6500\n",
      "Epoch 943/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5509 - acc: 0.9241 - val_loss: 0.6769 - val_acc: 0.6500\n",
      "Epoch 944/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5487 - acc: 0.8481 - val_loss: 0.6641 - val_acc: 0.6500\n",
      "Epoch 945/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.5470 - acc: 0.8987 - val_loss: 0.6599 - val_acc: 0.6000\n",
      "Epoch 946/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5468 - acc: 0.9241 - val_loss: 0.6551 - val_acc: 0.6000\n",
      "Epoch 947/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5457 - acc: 0.9367 - val_loss: 0.6570 - val_acc: 0.6000\n",
      "Epoch 948/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5451 - acc: 0.9367 - val_loss: 0.6633 - val_acc: 0.6500\n",
      "Epoch 949/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5452 - acc: 0.9114 - val_loss: 0.6564 - val_acc: 0.6000\n",
      "Epoch 950/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5434 - acc: 0.9367 - val_loss: 0.6583 - val_acc: 0.6000\n",
      "Epoch 951/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5434 - acc: 0.9114 - val_loss: 0.6539 - val_acc: 0.6000\n",
      "Epoch 952/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5425 - acc: 0.9367 - val_loss: 0.6574 - val_acc: 0.6000\n",
      "Epoch 953/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5424 - acc: 0.9241 - val_loss: 0.6528 - val_acc: 0.6000\n",
      "Epoch 954/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5424 - acc: 0.9367 - val_loss: 0.6552 - val_acc: 0.6000\n",
      "Epoch 955/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.5407 - acc: 0.9367 - val_loss: 0.6607 - val_acc: 0.6000\n",
      "Epoch 956/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5406 - acc: 0.9114 - val_loss: 0.6551 - val_acc: 0.6000\n",
      "Epoch 957/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5408 - acc: 0.9367 - val_loss: 0.6499 - val_acc: 0.6500\n",
      "Epoch 958/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5392 - acc: 0.9620 - val_loss: 0.6517 - val_acc: 0.6000\n",
      "Epoch 959/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5386 - acc: 0.9367 - val_loss: 0.6516 - val_acc: 0.6000\n",
      "Epoch 960/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5368 - acc: 0.9367 - val_loss: 0.6532 - val_acc: 0.6000\n",
      "Epoch 961/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.5356 - acc: 0.9367 - val_loss: 0.6560 - val_acc: 0.6000\n",
      "Epoch 962/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5387 - acc: 0.9367 - val_loss: 0.6573 - val_acc: 0.6000\n",
      "Epoch 963/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5352 - acc: 0.9367 - val_loss: 0.6545 - val_acc: 0.6000\n",
      "Epoch 964/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5342 - acc: 0.9367 - val_loss: 0.6562 - val_acc: 0.6000\n",
      "Epoch 965/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5352 - acc: 0.9367 - val_loss: 0.6567 - val_acc: 0.6000\n",
      "Epoch 966/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5320 - acc: 0.9241 - val_loss: 0.6609 - val_acc: 0.6500\n",
      "Epoch 967/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5311 - acc: 0.8987 - val_loss: 0.6633 - val_acc: 0.6500\n",
      "Epoch 968/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5308 - acc: 0.8987 - val_loss: 0.6641 - val_acc: 0.6500\n",
      "Epoch 969/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5330 - acc: 0.8987 - val_loss: 0.6720 - val_acc: 0.6500\n",
      "Epoch 970/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5296 - acc: 0.8987 - val_loss: 0.6670 - val_acc: 0.6500\n",
      "Epoch 971/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5289 - acc: 0.8987 - val_loss: 0.6692 - val_acc: 0.6500\n",
      "Epoch 972/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5292 - acc: 0.8987 - val_loss: 0.6748 - val_acc: 0.6500\n",
      "Epoch 973/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5284 - acc: 0.8734 - val_loss: 0.6640 - val_acc: 0.6500\n",
      "Epoch 974/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5270 - acc: 0.8987 - val_loss: 0.6600 - val_acc: 0.6500\n",
      "Epoch 975/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5263 - acc: 0.9241 - val_loss: 0.6582 - val_acc: 0.6500\n",
      "Epoch 976/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5255 - acc: 0.9241 - val_loss: 0.6500 - val_acc: 0.6000\n",
      "Epoch 977/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5235 - acc: 0.9367 - val_loss: 0.6535 - val_acc: 0.6000\n",
      "Epoch 978/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.5227 - acc: 0.9367 - val_loss: 0.6575 - val_acc: 0.6500\n",
      "Epoch 979/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.5214 - acc: 0.9367 - val_loss: 0.6592 - val_acc: 0.6500\n",
      "Epoch 980/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5220 - acc: 0.9241 - val_loss: 0.6542 - val_acc: 0.6000\n",
      "Epoch 981/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5237 - acc: 0.9367 - val_loss: 0.6553 - val_acc: 0.6000\n",
      "Epoch 982/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5196 - acc: 0.9114 - val_loss: 0.6549 - val_acc: 0.6000\n",
      "Epoch 983/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5184 - acc: 0.9367 - val_loss: 0.6548 - val_acc: 0.6000\n",
      "Epoch 984/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5184 - acc: 0.9241 - val_loss: 0.6577 - val_acc: 0.6500\n",
      "Epoch 985/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5176 - acc: 0.9241 - val_loss: 0.6646 - val_acc: 0.6500\n",
      "Epoch 986/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5175 - acc: 0.8861 - val_loss: 0.6694 - val_acc: 0.6500\n",
      "Epoch 987/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5161 - acc: 0.8861 - val_loss: 0.6617 - val_acc: 0.6500\n",
      "Epoch 988/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5146 - acc: 0.9114 - val_loss: 0.6603 - val_acc: 0.6500\n",
      "Epoch 989/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5145 - acc: 0.8987 - val_loss: 0.6513 - val_acc: 0.6000\n",
      "Epoch 990/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5141 - acc: 0.9241 - val_loss: 0.6562 - val_acc: 0.6500\n",
      "Epoch 991/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5138 - acc: 0.9114 - val_loss: 0.6656 - val_acc: 0.6500\n",
      "Epoch 992/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5135 - acc: 0.8861 - val_loss: 0.6502 - val_acc: 0.6000\n",
      "Epoch 993/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5103 - acc: 0.9241 - val_loss: 0.6481 - val_acc: 0.6000\n",
      "Epoch 994/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5122 - acc: 0.9367 - val_loss: 0.6454 - val_acc: 0.6000\n",
      "Epoch 995/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5098 - acc: 0.9367 - val_loss: 0.6539 - val_acc: 0.6000\n",
      "Epoch 996/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.5082 - acc: 0.9114 - val_loss: 0.6518 - val_acc: 0.6000\n",
      "Epoch 997/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5073 - acc: 0.9367 - val_loss: 0.6473 - val_acc: 0.6000\n",
      "Epoch 998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5068 - acc: 0.9367 - val_loss: 0.6561 - val_acc: 0.6500\n",
      "Epoch 999/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5063 - acc: 0.9241 - val_loss: 0.6583 - val_acc: 0.6500\n",
      "Epoch 1000/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5049 - acc: 0.9114 - val_loss: 0.6597 - val_acc: 0.6500\n",
      "Epoch 1001/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5032 - acc: 0.9114 - val_loss: 0.6553 - val_acc: 0.6500\n",
      "Epoch 1002/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5026 - acc: 0.9241 - val_loss: 0.6500 - val_acc: 0.6000\n",
      "Epoch 1003/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5025 - acc: 0.9367 - val_loss: 0.6510 - val_acc: 0.6000\n",
      "Epoch 1004/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5007 - acc: 0.9367 - val_loss: 0.6481 - val_acc: 0.6000\n",
      "Epoch 1005/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5002 - acc: 0.9367 - val_loss: 0.6476 - val_acc: 0.6000\n",
      "Epoch 1006/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5005 - acc: 0.9241 - val_loss: 0.6428 - val_acc: 0.6000\n",
      "Epoch 1007/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5007 - acc: 0.9367 - val_loss: 0.6495 - val_acc: 0.6000\n",
      "Epoch 1008/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.4970 - acc: 0.9367 - val_loss: 0.6507 - val_acc: 0.6000\n",
      "Epoch 1009/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.4966 - acc: 0.9241 - val_loss: 0.6460 - val_acc: 0.6000\n",
      "Epoch 1010/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5013 - acc: 0.9620 - val_loss: 0.6536 - val_acc: 0.6500\n",
      "Epoch 1011/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4951 - acc: 0.9241 - val_loss: 0.6458 - val_acc: 0.6000\n",
      "Epoch 1012/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4962 - acc: 0.9367 - val_loss: 0.6474 - val_acc: 0.6000\n",
      "Epoch 1013/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4930 - acc: 0.9367 - val_loss: 0.6520 - val_acc: 0.6500\n",
      "Epoch 1014/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.4916 - acc: 0.9241 - val_loss: 0.6523 - val_acc: 0.6500\n",
      "Epoch 1015/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.4911 - acc: 0.9241 - val_loss: 0.6464 - val_acc: 0.6000\n",
      "Epoch 1016/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4916 - acc: 0.9367 - val_loss: 0.6454 - val_acc: 0.6000\n",
      "Epoch 1017/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4892 - acc: 0.9367 - val_loss: 0.6455 - val_acc: 0.6000\n",
      "Epoch 1018/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4909 - acc: 0.9241 - val_loss: 0.6387 - val_acc: 0.6500\n",
      "Epoch 1019/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4891 - acc: 0.9367 - val_loss: 0.6448 - val_acc: 0.6000\n",
      "Epoch 1020/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4880 - acc: 0.9367 - val_loss: 0.6406 - val_acc: 0.6000\n",
      "Epoch 1021/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4884 - acc: 0.9367 - val_loss: 0.6535 - val_acc: 0.6500\n",
      "Epoch 1022/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4859 - acc: 0.9367 - val_loss: 0.6535 - val_acc: 0.6500\n",
      "Epoch 1023/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4859 - acc: 0.9114 - val_loss: 0.6444 - val_acc: 0.6000\n",
      "Epoch 1024/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4829 - acc: 0.9367 - val_loss: 0.6459 - val_acc: 0.6000\n",
      "Epoch 1025/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.4837 - acc: 0.9241 - val_loss: 0.6394 - val_acc: 0.6000\n",
      "Epoch 1026/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4832 - acc: 0.9367 - val_loss: 0.6398 - val_acc: 0.6000\n",
      "Epoch 1027/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4819 - acc: 0.9367 - val_loss: 0.6499 - val_acc: 0.6500\n",
      "Epoch 1028/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4804 - acc: 0.9241 - val_loss: 0.6396 - val_acc: 0.6000\n",
      "Epoch 1029/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4784 - acc: 0.9367 - val_loss: 0.6442 - val_acc: 0.6000\n",
      "Epoch 1030/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4770 - acc: 0.9367 - val_loss: 0.6476 - val_acc: 0.6000\n",
      "Epoch 1031/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4761 - acc: 0.9367 - val_loss: 0.6505 - val_acc: 0.6500\n",
      "Epoch 1032/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4751 - acc: 0.9241 - val_loss: 0.6506 - val_acc: 0.6500\n",
      "Epoch 1033/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.4746 - acc: 0.9241 - val_loss: 0.6549 - val_acc: 0.6500\n",
      "Epoch 1034/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4736 - acc: 0.9114 - val_loss: 0.6471 - val_acc: 0.6000\n",
      "Epoch 1035/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4810 - acc: 0.9367 - val_loss: 0.6611 - val_acc: 0.6500\n",
      "Epoch 1036/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4739 - acc: 0.9241 - val_loss: 0.6618 - val_acc: 0.6500\n",
      "Epoch 1037/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.4713 - acc: 0.9114 - val_loss: 0.6527 - val_acc: 0.6500\n",
      "Epoch 1038/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.4697 - acc: 0.9241 - val_loss: 0.6491 - val_acc: 0.6500\n",
      "Epoch 1039/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.4691 - acc: 0.9241 - val_loss: 0.6410 - val_acc: 0.6000\n",
      "Epoch 1040/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4700 - acc: 0.9367 - val_loss: 0.6479 - val_acc: 0.6500\n",
      "Epoch 1041/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4674 - acc: 0.8987 - val_loss: 0.6411 - val_acc: 0.6000\n",
      "Epoch 1042/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4670 - acc: 0.9367 - val_loss: 0.6421 - val_acc: 0.6000\n",
      "Epoch 1043/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4653 - acc: 0.9367 - val_loss: 0.6513 - val_acc: 0.6500\n",
      "Epoch 1044/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4636 - acc: 0.9241 - val_loss: 0.6459 - val_acc: 0.6500\n",
      "Epoch 1045/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4636 - acc: 0.9367 - val_loss: 0.6449 - val_acc: 0.6500\n",
      "Epoch 1046/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.4648 - acc: 0.9367 - val_loss: 0.6562 - val_acc: 0.6500\n",
      "Epoch 1047/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4624 - acc: 0.9241 - val_loss: 0.6487 - val_acc: 0.6500\n",
      "Epoch 1048/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4603 - acc: 0.9241 - val_loss: 0.6442 - val_acc: 0.6500\n",
      "Epoch 1049/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.4604 - acc: 0.9367 - val_loss: 0.6531 - val_acc: 0.6500\n",
      "Epoch 1050/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.4585 - acc: 0.9241 - val_loss: 0.6451 - val_acc: 0.6000\n",
      "Epoch 1051/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4575 - acc: 0.9367 - val_loss: 0.6444 - val_acc: 0.6000\n",
      "Epoch 1052/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4572 - acc: 0.9494 - val_loss: 0.6449 - val_acc: 0.6000\n",
      "Epoch 1053/3000\n",
      "79/79 [==============================] - 0s 104us/sample - loss: 0.4554 - acc: 0.9367 - val_loss: 0.6518 - val_acc: 0.6500\n",
      "Epoch 1054/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4539 - acc: 0.9241 - val_loss: 0.6462 - val_acc: 0.6000\n",
      "Epoch 1055/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4527 - acc: 0.9367 - val_loss: 0.6415 - val_acc: 0.6000\n",
      "Epoch 1056/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.4517 - acc: 0.9367 - val_loss: 0.6397 - val_acc: 0.6000\n",
      "Epoch 1057/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4508 - acc: 0.9367 - val_loss: 0.6468 - val_acc: 0.6000\n",
      "Epoch 1058/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4494 - acc: 0.9367 - val_loss: 0.6414 - val_acc: 0.6000\n",
      "Epoch 1059/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4490 - acc: 0.9367 - val_loss: 0.6364 - val_acc: 0.6000\n",
      "Epoch 1060/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4484 - acc: 0.9367 - val_loss: 0.6344 - val_acc: 0.6000\n",
      "Epoch 1061/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.4468 - acc: 0.9367 - val_loss: 0.6375 - val_acc: 0.6000\n",
      "Epoch 1062/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4475 - acc: 0.9367 - val_loss: 0.6292 - val_acc: 0.6500\n",
      "Epoch 1063/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4463 - acc: 0.9494 - val_loss: 0.6283 - val_acc: 0.6500\n",
      "Epoch 1064/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.4464 - acc: 0.9494 - val_loss: 0.6255 - val_acc: 0.6500\n",
      "Epoch 1065/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4455 - acc: 0.9494 - val_loss: 0.6372 - val_acc: 0.6000\n",
      "Epoch 1066/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4421 - acc: 0.9367 - val_loss: 0.6352 - val_acc: 0.6000\n",
      "Epoch 1067/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.4436 - acc: 0.9494 - val_loss: 0.6411 - val_acc: 0.6000\n",
      "Epoch 1068/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4410 - acc: 0.9367 - val_loss: 0.6436 - val_acc: 0.6000\n",
      "Epoch 1069/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4382 - acc: 0.9367 - val_loss: 0.6478 - val_acc: 0.6500\n",
      "Epoch 1070/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4373 - acc: 0.9494 - val_loss: 0.6443 - val_acc: 0.6000\n",
      "Epoch 1071/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4358 - acc: 0.9367 - val_loss: 0.6449 - val_acc: 0.6000\n",
      "Epoch 1072/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.4347 - acc: 0.9494 - val_loss: 0.6415 - val_acc: 0.6000\n",
      "Epoch 1073/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4352 - acc: 0.9367 - val_loss: 0.6451 - val_acc: 0.6500\n",
      "Epoch 1074/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.4338 - acc: 0.9494 - val_loss: 0.6434 - val_acc: 0.6000\n",
      "Epoch 1075/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4327 - acc: 0.9367 - val_loss: 0.6415 - val_acc: 0.6000\n",
      "Epoch 1076/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.4303 - acc: 0.9367 - val_loss: 0.6421 - val_acc: 0.6000\n",
      "Epoch 1077/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.4292 - acc: 0.9367 - val_loss: 0.6359 - val_acc: 0.6000\n",
      "Epoch 1078/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4284 - acc: 0.9367 - val_loss: 0.6322 - val_acc: 0.6000\n",
      "Epoch 1079/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4277 - acc: 0.9367 - val_loss: 0.6382 - val_acc: 0.6000\n",
      "Epoch 1080/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4271 - acc: 0.9367 - val_loss: 0.6423 - val_acc: 0.6000\n",
      "Epoch 1081/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4254 - acc: 0.9367 - val_loss: 0.6376 - val_acc: 0.6000\n",
      "Epoch 1082/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4252 - acc: 0.9367 - val_loss: 0.6321 - val_acc: 0.6000\n",
      "Epoch 1083/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4242 - acc: 0.9367 - val_loss: 0.6309 - val_acc: 0.6000\n",
      "Epoch 1084/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4225 - acc: 0.9494 - val_loss: 0.6309 - val_acc: 0.6000\n",
      "Epoch 1085/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.4207 - acc: 0.9494 - val_loss: 0.6329 - val_acc: 0.6000\n",
      "Epoch 1086/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4199 - acc: 0.9494 - val_loss: 0.6394 - val_acc: 0.6000\n",
      "Epoch 1087/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4186 - acc: 0.9367 - val_loss: 0.6345 - val_acc: 0.6000\n",
      "Epoch 1088/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4173 - acc: 0.9367 - val_loss: 0.6337 - val_acc: 0.6000\n",
      "Epoch 1089/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4169 - acc: 0.9367 - val_loss: 0.6409 - val_acc: 0.6000\n",
      "Epoch 1090/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4157 - acc: 0.9367 - val_loss: 0.6375 - val_acc: 0.6000\n",
      "Epoch 1091/3000\n",
      "79/79 [==============================] - 0s 179us/sample - loss: 0.4141 - acc: 0.9367 - val_loss: 0.6376 - val_acc: 0.6000\n",
      "Epoch 1092/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4134 - acc: 0.9367 - val_loss: 0.6301 - val_acc: 0.6000\n",
      "Epoch 1093/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4127 - acc: 0.9367 - val_loss: 0.6253 - val_acc: 0.6000\n",
      "Epoch 1094/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.4124 - acc: 0.9620 - val_loss: 0.6256 - val_acc: 0.6000\n",
      "Epoch 1095/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4122 - acc: 0.9494 - val_loss: 0.6296 - val_acc: 0.6000\n",
      "Epoch 1096/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4106 - acc: 0.9494 - val_loss: 0.6390 - val_acc: 0.6000\n",
      "Epoch 1097/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4085 - acc: 0.9494 - val_loss: 0.6405 - val_acc: 0.6000\n",
      "Epoch 1098/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4069 - acc: 0.9494 - val_loss: 0.6397 - val_acc: 0.6000\n",
      "Epoch 1099/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4060 - acc: 0.9367 - val_loss: 0.6379 - val_acc: 0.6000\n",
      "Epoch 1100/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4059 - acc: 0.9367 - val_loss: 0.6474 - val_acc: 0.6500\n",
      "Epoch 1101/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4057 - acc: 0.9494 - val_loss: 0.6387 - val_acc: 0.6000\n",
      "Epoch 1102/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.4027 - acc: 0.9494 - val_loss: 0.6312 - val_acc: 0.6000\n",
      "Epoch 1103/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4015 - acc: 0.9367 - val_loss: 0.6359 - val_acc: 0.6000\n",
      "Epoch 1104/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4039 - acc: 0.9367 - val_loss: 0.6347 - val_acc: 0.6000\n",
      "Epoch 1105/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3993 - acc: 0.9367 - val_loss: 0.6361 - val_acc: 0.6000\n",
      "Epoch 1106/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3977 - acc: 0.9367 - val_loss: 0.6309 - val_acc: 0.6000\n",
      "Epoch 1107/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3965 - acc: 0.9367 - val_loss: 0.6344 - val_acc: 0.6000\n",
      "Epoch 1108/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3954 - acc: 0.9367 - val_loss: 0.6316 - val_acc: 0.6000\n",
      "Epoch 1109/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3884 - acc: 0.906 - 0s 139us/sample - loss: 0.3973 - acc: 0.9367 - val_loss: 0.6287 - val_acc: 0.6000\n",
      "Epoch 1110/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3932 - acc: 0.9494 - val_loss: 0.6322 - val_acc: 0.6000\n",
      "Epoch 1111/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3933 - acc: 0.9367 - val_loss: 0.6413 - val_acc: 0.6500\n",
      "Epoch 1112/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3923 - acc: 0.9367 - val_loss: 0.6411 - val_acc: 0.6500\n",
      "Epoch 1113/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.3917 - acc: 0.9494 - val_loss: 0.6324 - val_acc: 0.6000\n",
      "Epoch 1114/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.3900 - acc: 0.9367 - val_loss: 0.6268 - val_acc: 0.6000\n",
      "Epoch 1115/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3878 - acc: 0.9367 - val_loss: 0.6249 - val_acc: 0.6000\n",
      "Epoch 1116/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.3867 - acc: 0.9494 - val_loss: 0.6268 - val_acc: 0.6000\n",
      "Epoch 1117/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3871 - acc: 0.9367 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1118/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3845 - acc: 0.9494 - val_loss: 0.6277 - val_acc: 0.6000\n",
      "Epoch 1119/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3842 - acc: 0.9367 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 1120/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3862 - acc: 0.9494 - val_loss: 0.6207 - val_acc: 0.6000\n",
      "Epoch 1121/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3824 - acc: 0.9494 - val_loss: 0.6242 - val_acc: 0.6000\n",
      "Epoch 1122/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3810 - acc: 0.9494 - val_loss: 0.6238 - val_acc: 0.6000\n",
      "Epoch 1123/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.3799 - acc: 0.9494 - val_loss: 0.6188 - val_acc: 0.6000\n",
      "Epoch 1124/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.3803 - acc: 0.9620 - val_loss: 0.6248 - val_acc: 0.6000\n",
      "Epoch 1125/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.3774 - acc: 0.9367 - val_loss: 0.6205 - val_acc: 0.6000\n",
      "Epoch 1126/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.3759 - acc: 0.9620 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1127/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.3756 - acc: 0.9620 - val_loss: 0.6340 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1128/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3740 - acc: 0.9494 - val_loss: 0.6291 - val_acc: 0.6000\n",
      "Epoch 1129/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3726 - acc: 0.9367 - val_loss: 0.6263 - val_acc: 0.6000\n",
      "Epoch 1130/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.3727 - acc: 0.9367 - val_loss: 0.6308 - val_acc: 0.6000\n",
      "Epoch 1131/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3711 - acc: 0.9367 - val_loss: 0.6294 - val_acc: 0.6000\n",
      "Epoch 1132/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3703 - acc: 0.9620 - val_loss: 0.6283 - val_acc: 0.6000\n",
      "Epoch 1133/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3684 - acc: 0.9367 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1134/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.3685 - acc: 0.9494 - val_loss: 0.6224 - val_acc: 0.6000\n",
      "Epoch 1135/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3660 - acc: 0.9494 - val_loss: 0.6246 - val_acc: 0.6000\n",
      "Epoch 1136/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3664 - acc: 0.9367 - val_loss: 0.6219 - val_acc: 0.6000\n",
      "Epoch 1137/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3656 - acc: 0.9620 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 1138/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3637 - acc: 0.9620 - val_loss: 0.6222 - val_acc: 0.6000\n",
      "Epoch 1139/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.3620 - acc: 0.9620 - val_loss: 0.6250 - val_acc: 0.6000\n",
      "Epoch 1140/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3610 - acc: 0.9620 - val_loss: 0.6225 - val_acc: 0.6000\n",
      "Epoch 1141/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3601 - acc: 0.9620 - val_loss: 0.6249 - val_acc: 0.6000\n",
      "Epoch 1142/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3598 - acc: 0.9620 - val_loss: 0.6331 - val_acc: 0.6000\n",
      "Epoch 1143/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.3595 - acc: 0.9494 - val_loss: 0.6310 - val_acc: 0.6000\n",
      "Epoch 1144/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.3568 - acc: 0.9367 - val_loss: 0.6278 - val_acc: 0.6000\n",
      "Epoch 1145/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3565 - acc: 0.9494 - val_loss: 0.6187 - val_acc: 0.6000\n",
      "Epoch 1146/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3553 - acc: 0.9620 - val_loss: 0.6163 - val_acc: 0.6000\n",
      "Epoch 1147/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3542 - acc: 0.9620 - val_loss: 0.6182 - val_acc: 0.6000\n",
      "Epoch 1148/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3534 - acc: 0.9620 - val_loss: 0.6148 - val_acc: 0.6000\n",
      "Epoch 1149/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3519 - acc: 0.9620 - val_loss: 0.6197 - val_acc: 0.6000\n",
      "Epoch 1150/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.3501 - acc: 0.9620 - val_loss: 0.6204 - val_acc: 0.6000\n",
      "Epoch 1151/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3499 - acc: 0.9494 - val_loss: 0.6153 - val_acc: 0.6000\n",
      "Epoch 1152/3000\n",
      "79/79 [==============================] - 0s 328us/sample - loss: 0.3492 - acc: 0.9620 - val_loss: 0.6146 - val_acc: 0.6000\n",
      "Epoch 1153/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.3478 - acc: 0.9620 - val_loss: 0.6189 - val_acc: 0.6000\n",
      "Epoch 1154/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.3459 - acc: 0.9620 - val_loss: 0.6202 - val_acc: 0.6000\n",
      "Epoch 1155/3000\n",
      "79/79 [==============================] - 0s 237us/sample - loss: 0.3448 - acc: 0.9620 - val_loss: 0.6274 - val_acc: 0.6000\n",
      "Epoch 1156/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3432 - acc: 0.9494 - val_loss: 0.6265 - val_acc: 0.6000\n",
      "Epoch 1157/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.3440 - acc: 0.9494 - val_loss: 0.6284 - val_acc: 0.6000\n",
      "Epoch 1158/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3411 - acc: 0.9494 - val_loss: 0.6270 - val_acc: 0.6000\n",
      "Epoch 1159/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3401 - acc: 0.9494 - val_loss: 0.6289 - val_acc: 0.6000\n",
      "Epoch 1160/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3390 - acc: 0.9494 - val_loss: 0.6267 - val_acc: 0.6000\n",
      "Epoch 1161/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3378 - acc: 0.9620 - val_loss: 0.6275 - val_acc: 0.6000\n",
      "Epoch 1162/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3375 - acc: 0.9494 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1163/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3355 - acc: 0.9620 - val_loss: 0.6237 - val_acc: 0.6000\n",
      "Epoch 1164/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.3366 - acc: 0.9620 - val_loss: 0.6294 - val_acc: 0.6000\n",
      "Epoch 1165/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3359 - acc: 0.9494 - val_loss: 0.6320 - val_acc: 0.6000\n",
      "Epoch 1166/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3324 - acc: 0.9367 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1167/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3316 - acc: 0.9494 - val_loss: 0.6184 - val_acc: 0.6000\n",
      "Epoch 1168/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3309 - acc: 0.9620 - val_loss: 0.6245 - val_acc: 0.6000\n",
      "Epoch 1169/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.3306 - acc: 0.9620 - val_loss: 0.6197 - val_acc: 0.6000\n",
      "Epoch 1170/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3317 - acc: 0.9620 - val_loss: 0.6273 - val_acc: 0.6000\n",
      "Epoch 1171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3271 - acc: 0.9494 - val_loss: 0.6205 - val_acc: 0.6000\n",
      "Epoch 1172/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3260 - acc: 0.9620 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1173/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3247 - acc: 0.9620 - val_loss: 0.6260 - val_acc: 0.6000\n",
      "Epoch 1174/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3247 - acc: 0.9494 - val_loss: 0.6237 - val_acc: 0.6000\n",
      "Epoch 1175/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3226 - acc: 0.9620 - val_loss: 0.6241 - val_acc: 0.6000\n",
      "Epoch 1176/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3215 - acc: 0.9620 - val_loss: 0.6263 - val_acc: 0.6000\n",
      "Epoch 1177/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.3211 - acc: 0.9620 - val_loss: 0.6320 - val_acc: 0.6000\n",
      "Epoch 1178/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.3204 - acc: 0.9367 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1179/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3206 - acc: 0.9620 - val_loss: 0.6184 - val_acc: 0.6000\n",
      "Epoch 1180/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.3188 - acc: 0.9620 - val_loss: 0.6184 - val_acc: 0.6000\n",
      "Epoch 1181/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3369 - acc: 0.968 - 0s 139us/sample - loss: 0.3163 - acc: 0.9620 - val_loss: 0.6223 - val_acc: 0.6000\n",
      "Epoch 1182/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3165 - acc: 0.9620 - val_loss: 0.6190 - val_acc: 0.6000\n",
      "Epoch 1183/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.3144 - acc: 0.9620 - val_loss: 0.6156 - val_acc: 0.6000\n",
      "Epoch 1184/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3139 - acc: 0.9620 - val_loss: 0.6125 - val_acc: 0.6000\n",
      "Epoch 1185/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3130 - acc: 0.9620 - val_loss: 0.6142 - val_acc: 0.6000\n",
      "Epoch 1186/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 138us/sample - loss: 0.3125 - acc: 0.9620 - val_loss: 0.6144 - val_acc: 0.6000\n",
      "Epoch 1187/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3103 - acc: 0.9620 - val_loss: 0.6163 - val_acc: 0.6000\n",
      "Epoch 1188/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3116 - acc: 0.9620 - val_loss: 0.6191 - val_acc: 0.6000\n",
      "Epoch 1189/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3076 - acc: 0.9620 - val_loss: 0.6198 - val_acc: 0.6000\n",
      "Epoch 1190/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3079 - acc: 0.9620 - val_loss: 0.6219 - val_acc: 0.6000\n",
      "Epoch 1191/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3064 - acc: 0.9620 - val_loss: 0.6314 - val_acc: 0.6000\n",
      "Epoch 1192/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3059 - acc: 0.9620 - val_loss: 0.6245 - val_acc: 0.6000\n",
      "Epoch 1193/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3042 - acc: 0.9620 - val_loss: 0.6244 - val_acc: 0.6000\n",
      "Epoch 1194/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3028 - acc: 0.9620 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1195/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3033 - acc: 0.9620 - val_loss: 0.6332 - val_acc: 0.6000\n",
      "Epoch 1196/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3013 - acc: 0.9620 - val_loss: 0.6267 - val_acc: 0.6000\n",
      "Epoch 1197/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2996 - acc: 0.9620 - val_loss: 0.6181 - val_acc: 0.6000\n",
      "Epoch 1198/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.3010 - acc: 0.9620 - val_loss: 0.6234 - val_acc: 0.6000\n",
      "Epoch 1199/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.2979 - acc: 0.9620 - val_loss: 0.6242 - val_acc: 0.6000\n",
      "Epoch 1200/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.2973 - acc: 0.9620 - val_loss: 0.6308 - val_acc: 0.6000\n",
      "Epoch 1201/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2959 - acc: 0.9747 - val_loss: 0.6229 - val_acc: 0.6000\n",
      "Epoch 1202/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2960 - acc: 0.9620 - val_loss: 0.6242 - val_acc: 0.6000\n",
      "Epoch 1203/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2962 - acc: 0.9620 - val_loss: 0.6305 - val_acc: 0.6000\n",
      "Epoch 1204/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2929 - acc: 0.9747 - val_loss: 0.6228 - val_acc: 0.6000\n",
      "Epoch 1205/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.2916 - acc: 0.9620 - val_loss: 0.6207 - val_acc: 0.6000\n",
      "Epoch 1206/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.2912 - acc: 0.9620 - val_loss: 0.6139 - val_acc: 0.6000\n",
      "Epoch 1207/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.2907 - acc: 0.9620 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1208/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.2896 - acc: 0.9620 - val_loss: 0.6174 - val_acc: 0.6000\n",
      "Epoch 1209/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2880 - acc: 0.9620 - val_loss: 0.6172 - val_acc: 0.6000\n",
      "Epoch 1210/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2867 - acc: 0.9620 - val_loss: 0.6167 - val_acc: 0.6000\n",
      "Epoch 1211/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2880 - acc: 0.9620 - val_loss: 0.6210 - val_acc: 0.6000\n",
      "Epoch 1212/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2843 - acc: 0.9620 - val_loss: 0.6263 - val_acc: 0.6000\n",
      "Epoch 1213/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2852 - acc: 0.9620 - val_loss: 0.6283 - val_acc: 0.6000\n",
      "Epoch 1214/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.2825 - acc: 0.9620 - val_loss: 0.6291 - val_acc: 0.6000\n",
      "Epoch 1215/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.2817 - acc: 0.9620 - val_loss: 0.6276 - val_acc: 0.6000\n",
      "Epoch 1216/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.2808 - acc: 0.9620 - val_loss: 0.6203 - val_acc: 0.6000\n",
      "Epoch 1217/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2794 - acc: 0.9620 - val_loss: 0.6218 - val_acc: 0.6000\n",
      "Epoch 1218/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.2783 - acc: 0.9620 - val_loss: 0.6223 - val_acc: 0.6000\n",
      "Epoch 1219/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2784 - acc: 0.9620 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 1220/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2766 - acc: 0.9620 - val_loss: 0.6198 - val_acc: 0.6000\n",
      "Epoch 1221/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2756 - acc: 0.9620 - val_loss: 0.6160 - val_acc: 0.6000\n",
      "Epoch 1222/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2745 - acc: 0.9620 - val_loss: 0.6162 - val_acc: 0.6000\n",
      "Epoch 1223/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.2733 - acc: 0.9620 - val_loss: 0.6194 - val_acc: 0.6000\n",
      "Epoch 1224/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2741 - acc: 0.9620 - val_loss: 0.6315 - val_acc: 0.6000\n",
      "Epoch 1225/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2716 - acc: 0.9747 - val_loss: 0.6291 - val_acc: 0.6000\n",
      "Epoch 1226/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.2706 - acc: 0.9747 - val_loss: 0.6307 - val_acc: 0.6000\n",
      "Epoch 1227/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2696 - acc: 0.9747 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 1228/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2701 - acc: 0.9620 - val_loss: 0.6303 - val_acc: 0.6000\n",
      "Epoch 1229/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2687 - acc: 0.9747 - val_loss: 0.6235 - val_acc: 0.6000\n",
      "Epoch 1230/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.2675 - acc: 0.9620 - val_loss: 0.6216 - val_acc: 0.6000\n",
      "Epoch 1231/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.2660 - acc: 0.9620 - val_loss: 0.6238 - val_acc: 0.6000\n",
      "Epoch 1232/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2649 - acc: 0.9620 - val_loss: 0.6179 - val_acc: 0.6000\n",
      "Epoch 1233/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.2644 - acc: 0.9620 - val_loss: 0.6131 - val_acc: 0.6000\n",
      "Epoch 1234/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2651 - acc: 0.9620 - val_loss: 0.6115 - val_acc: 0.6000\n",
      "Epoch 1235/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2627 - acc: 0.9620 - val_loss: 0.6104 - val_acc: 0.6000\n",
      "Epoch 1236/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2619 - acc: 0.9620 - val_loss: 0.6131 - val_acc: 0.6000\n",
      "Epoch 1237/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2604 - acc: 0.9620 - val_loss: 0.6206 - val_acc: 0.6000\n",
      "Epoch 1238/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2595 - acc: 0.9747 - val_loss: 0.6131 - val_acc: 0.6000\n",
      "Epoch 1239/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2585 - acc: 0.9620 - val_loss: 0.6140 - val_acc: 0.6000\n",
      "Epoch 1240/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2586 - acc: 0.9620 - val_loss: 0.6222 - val_acc: 0.6000\n",
      "Epoch 1241/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2563 - acc: 0.9747 - val_loss: 0.6149 - val_acc: 0.6000\n",
      "Epoch 1242/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.2566 - acc: 0.9747 - val_loss: 0.6226 - val_acc: 0.6000\n",
      "Epoch 1243/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2555 - acc: 0.9620 - val_loss: 0.6316 - val_acc: 0.6000\n",
      "Epoch 1244/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2554 - acc: 0.9747 - val_loss: 0.6254 - val_acc: 0.6000\n",
      "Epoch 1245/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2525 - acc: 0.9747 - val_loss: 0.6230 - val_acc: 0.6000\n",
      "Epoch 1246/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2525 - acc: 0.9747 - val_loss: 0.6131 - val_acc: 0.6000\n",
      "Epoch 1247/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.2514 - acc: 0.9620 - val_loss: 0.6190 - val_acc: 0.6000\n",
      "Epoch 1248/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2503 - acc: 0.9747 - val_loss: 0.6234 - val_acc: 0.6000\n",
      "Epoch 1249/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2494 - acc: 0.9747 - val_loss: 0.6181 - val_acc: 0.6000\n",
      "Epoch 1250/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2488 - acc: 0.9747 - val_loss: 0.6124 - val_acc: 0.6000\n",
      "Epoch 1251/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.2476 - acc: 0.9620 - val_loss: 0.6118 - val_acc: 0.6000\n",
      "Epoch 1252/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2466 - acc: 0.9620 - val_loss: 0.6146 - val_acc: 0.6000\n",
      "Epoch 1253/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2460 - acc: 0.9620 - val_loss: 0.6173 - val_acc: 0.6000\n",
      "Epoch 1254/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2446 - acc: 0.9747 - val_loss: 0.6167 - val_acc: 0.6000\n",
      "Epoch 1255/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2451 - acc: 0.9747 - val_loss: 0.6116 - val_acc: 0.6000\n",
      "Epoch 1256/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.2439 - acc: 0.9620 - val_loss: 0.6161 - val_acc: 0.6000\n",
      "Epoch 1257/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2421 - acc: 0.9620 - val_loss: 0.6154 - val_acc: 0.6000\n",
      "Epoch 1258/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2413 - acc: 0.9620 - val_loss: 0.6204 - val_acc: 0.6000\n",
      "Epoch 1259/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2402 - acc: 0.9747 - val_loss: 0.6205 - val_acc: 0.6000\n",
      "Epoch 1260/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2395 - acc: 0.9747 - val_loss: 0.6234 - val_acc: 0.6000\n",
      "Epoch 1261/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.2387 - acc: 0.9747 - val_loss: 0.6239 - val_acc: 0.6000\n",
      "Epoch 1262/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2384 - acc: 0.9747 - val_loss: 0.6260 - val_acc: 0.6000\n",
      "Epoch 1263/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2386 - acc: 0.9747 - val_loss: 0.6322 - val_acc: 0.6000\n",
      "Epoch 1264/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2367 - acc: 0.9747 - val_loss: 0.6236 - val_acc: 0.6000\n",
      "Epoch 1265/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.2353 - acc: 0.9747 - val_loss: 0.6224 - val_acc: 0.6000\n",
      "Epoch 1266/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2345 - acc: 0.9747 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1267/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2335 - acc: 0.9747 - val_loss: 0.6189 - val_acc: 0.6000\n",
      "Epoch 1268/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2323 - acc: 0.9747 - val_loss: 0.6213 - val_acc: 0.6000\n",
      "Epoch 1269/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2316 - acc: 0.9747 - val_loss: 0.6164 - val_acc: 0.6000\n",
      "Epoch 1270/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2308 - acc: 0.9747 - val_loss: 0.6207 - val_acc: 0.6000\n",
      "Epoch 1271/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2299 - acc: 0.9747 - val_loss: 0.6140 - val_acc: 0.6000\n",
      "Epoch 1272/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.2292 - acc: 0.9620 - val_loss: 0.6173 - val_acc: 0.6000\n",
      "Epoch 1273/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.2282 - acc: 0.9747 - val_loss: 0.6190 - val_acc: 0.6000\n",
      "Epoch 1274/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.2270 - acc: 0.9747 - val_loss: 0.6175 - val_acc: 0.6000\n",
      "Epoch 1275/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.2268 - acc: 0.9620 - val_loss: 0.6241 - val_acc: 0.6000\n",
      "Epoch 1276/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2259 - acc: 0.9747 - val_loss: 0.6271 - val_acc: 0.6000\n",
      "Epoch 1277/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.2279 - acc: 0.9747 - val_loss: 0.6333 - val_acc: 0.6000\n",
      "Epoch 1278/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2251 - acc: 0.9747 - val_loss: 0.6193 - val_acc: 0.6000\n",
      "Epoch 1279/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2246 - acc: 0.9747 - val_loss: 0.6276 - val_acc: 0.6000\n",
      "Epoch 1280/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2261 - acc: 0.9747 - val_loss: 0.6354 - val_acc: 0.6000\n",
      "Epoch 1281/3000\n",
      "79/79 [==============================] - 0s 165us/sample - loss: 0.2231 - acc: 0.9747 - val_loss: 0.6209 - val_acc: 0.6000\n",
      "Epoch 1282/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.2252 - acc: 0.9620 - val_loss: 0.6026 - val_acc: 0.5500\n",
      "Epoch 1283/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.2233 - acc: 0.9747 - val_loss: 0.6216 - val_acc: 0.6000\n",
      "Epoch 1284/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2214 - acc: 0.9747 - val_loss: 0.6224 - val_acc: 0.6000\n",
      "Epoch 1285/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2206 - acc: 0.9620 - val_loss: 0.6248 - val_acc: 0.6000\n",
      "Epoch 1286/3000\n",
      "79/79 [==============================] - 0s 492us/sample - loss: 0.2197 - acc: 0.9747 - val_loss: 0.6271 - val_acc: 0.6000\n",
      "Epoch 1287/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2190 - acc: 0.9747 - val_loss: 0.6268 - val_acc: 0.6000\n",
      "Epoch 1288/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2181 - acc: 0.9747 - val_loss: 0.6267 - val_acc: 0.6000\n",
      "Epoch 1289/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2174 - acc: 0.9747 - val_loss: 0.6285 - val_acc: 0.6000\n",
      "Epoch 1290/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2167 - acc: 0.9747 - val_loss: 0.6236 - val_acc: 0.6000\n",
      "Epoch 1291/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.2161 - acc: 0.9620 - val_loss: 0.6277 - val_acc: 0.6000\n",
      "Epoch 1292/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2165 - acc: 0.9620 - val_loss: 0.6292 - val_acc: 0.6000\n",
      "Epoch 1293/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2152 - acc: 0.9620 - val_loss: 0.6251 - val_acc: 0.6000\n",
      "Epoch 1294/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2146 - acc: 0.9620 - val_loss: 0.6287 - val_acc: 0.6000\n",
      "Epoch 1295/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2149 - acc: 0.9620 - val_loss: 0.6227 - val_acc: 0.6000\n",
      "Epoch 1296/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2128 - acc: 0.9620 - val_loss: 0.6250 - val_acc: 0.6000\n",
      "Epoch 1297/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2116 - acc: 0.9620 - val_loss: 0.6278 - val_acc: 0.6000\n",
      "Epoch 1298/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2107 - acc: 0.9747 - val_loss: 0.6221 - val_acc: 0.6000\n",
      "Epoch 1299/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2093 - acc: 0.9747 - val_loss: 0.6283 - val_acc: 0.6000\n",
      "Epoch 1300/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.2084 - acc: 0.9747 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 1301/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.2081 - acc: 0.9747 - val_loss: 0.6332 - val_acc: 0.6000\n",
      "Epoch 1302/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2072 - acc: 0.9747 - val_loss: 0.6318 - val_acc: 0.6000\n",
      "Epoch 1303/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2062 - acc: 0.9747 - val_loss: 0.6273 - val_acc: 0.6000\n",
      "Epoch 1304/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 155us/sample - loss: 0.2058 - acc: 0.9747 - val_loss: 0.6254 - val_acc: 0.6000\n",
      "Epoch 1305/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.2053 - acc: 0.9747 - val_loss: 0.6200 - val_acc: 0.6000\n",
      "Epoch 1306/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2044 - acc: 0.9747 - val_loss: 0.6247 - val_acc: 0.6000\n",
      "Epoch 1307/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2030 - acc: 0.9747 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 1308/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2251 - acc: 0.937 - 0s 126us/sample - loss: 0.2032 - acc: 0.9747 - val_loss: 0.6212 - val_acc: 0.6000\n",
      "Epoch 1309/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.2014 - acc: 0.9873 - val_loss: 0.6221 - val_acc: 0.6000\n",
      "Epoch 1310/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2007 - acc: 0.9873 - val_loss: 0.6197 - val_acc: 0.6000\n",
      "Epoch 1311/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2003 - acc: 0.9747 - val_loss: 0.6225 - val_acc: 0.6000\n",
      "Epoch 1312/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1997 - acc: 0.9873 - val_loss: 0.6175 - val_acc: 0.5500\n",
      "Epoch 1313/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1984 - acc: 0.9747 - val_loss: 0.6213 - val_acc: 0.6000\n",
      "Epoch 1314/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1980 - acc: 0.9873 - val_loss: 0.6226 - val_acc: 0.6000\n",
      "Epoch 1315/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1970 - acc: 0.9873 - val_loss: 0.6247 - val_acc: 0.6000\n",
      "Epoch 1316/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1967 - acc: 0.9873 - val_loss: 0.6265 - val_acc: 0.6000\n",
      "Epoch 1317/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1961 - acc: 0.9747 - val_loss: 0.6208 - val_acc: 0.6000\n",
      "Epoch 1318/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1969 - acc: 0.9747 - val_loss: 0.6206 - val_acc: 0.6000\n",
      "Epoch 1319/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1939 - acc: 0.9873 - val_loss: 0.6182 - val_acc: 0.6000\n",
      "Epoch 1320/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1936 - acc: 0.9747 - val_loss: 0.6234 - val_acc: 0.6000\n",
      "Epoch 1321/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1927 - acc: 0.9747 - val_loss: 0.6173 - val_acc: 0.6000\n",
      "Epoch 1322/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1916 - acc: 0.9873 - val_loss: 0.6247 - val_acc: 0.6000\n",
      "Epoch 1323/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1918 - acc: 0.9873 - val_loss: 0.6347 - val_acc: 0.6000\n",
      "Epoch 1324/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1919 - acc: 0.9747 - val_loss: 0.6355 - val_acc: 0.6000\n",
      "Epoch 1325/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1922 - acc: 0.9873 - val_loss: 0.6390 - val_acc: 0.6000\n",
      "Epoch 1326/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1891 - acc: 0.9747 - val_loss: 0.6318 - val_acc: 0.6000\n",
      "Epoch 1327/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1879 - acc: 0.9747 - val_loss: 0.6286 - val_acc: 0.6000\n",
      "Epoch 1328/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1872 - acc: 0.9747 - val_loss: 0.6209 - val_acc: 0.6000\n",
      "Epoch 1329/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1863 - acc: 0.9873 - val_loss: 0.6184 - val_acc: 0.6000\n",
      "Epoch 1330/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1860 - acc: 0.9873 - val_loss: 0.6256 - val_acc: 0.6000\n",
      "Epoch 1331/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1855 - acc: 0.9747 - val_loss: 0.6227 - val_acc: 0.6000\n",
      "Epoch 1332/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1842 - acc: 0.9873 - val_loss: 0.6255 - val_acc: 0.6000\n",
      "Epoch 1333/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1838 - acc: 0.9873 - val_loss: 0.6283 - val_acc: 0.6000\n",
      "Epoch 1334/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1826 - acc: 0.9873 - val_loss: 0.6246 - val_acc: 0.6000\n",
      "Epoch 1335/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.1819 - acc: 0.9873 - val_loss: 0.6237 - val_acc: 0.6000\n",
      "Epoch 1336/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1818 - acc: 0.9873 - val_loss: 0.6183 - val_acc: 0.6000\n",
      "Epoch 1337/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.1809 - acc: 0.9873 - val_loss: 0.6189 - val_acc: 0.6000\n",
      "Epoch 1338/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1807 - acc: 0.9873 - val_loss: 0.6249 - val_acc: 0.6000\n",
      "Epoch 1339/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.1819 - acc: 0.9747 - val_loss: 0.6350 - val_acc: 0.6000\n",
      "Epoch 1340/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1794 - acc: 0.9873 - val_loss: 0.6213 - val_acc: 0.6000\n",
      "Epoch 1341/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1782 - acc: 0.9873 - val_loss: 0.6226 - val_acc: 0.6000\n",
      "Epoch 1342/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1774 - acc: 0.9873 - val_loss: 0.6168 - val_acc: 0.6000\n",
      "Epoch 1343/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.1765 - acc: 0.9873 - val_loss: 0.6181 - val_acc: 0.6000\n",
      "Epoch 1344/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1763 - acc: 0.9873 - val_loss: 0.6217 - val_acc: 0.6000\n",
      "Epoch 1345/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1750 - acc: 0.9873 - val_loss: 0.6282 - val_acc: 0.6000\n",
      "Epoch 1346/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1748 - acc: 0.9873 - val_loss: 0.6231 - val_acc: 0.6000\n",
      "Epoch 1347/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1665 - acc: 1.000 - 0s 139us/sample - loss: 0.1739 - acc: 0.9873 - val_loss: 0.6253 - val_acc: 0.6000\n",
      "Epoch 1348/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1740 - acc: 0.9873 - val_loss: 0.6167 - val_acc: 0.6000\n",
      "Epoch 1349/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1730 - acc: 0.9873 - val_loss: 0.6161 - val_acc: 0.6000\n",
      "Epoch 1350/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1724 - acc: 0.9873 - val_loss: 0.6171 - val_acc: 0.6000\n",
      "Epoch 1351/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1721 - acc: 0.9873 - val_loss: 0.6307 - val_acc: 0.6000\n",
      "Epoch 1352/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1706 - acc: 0.9873 - val_loss: 0.6315 - val_acc: 0.6000\n",
      "Epoch 1353/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1702 - acc: 0.9873 - val_loss: 0.6299 - val_acc: 0.6000\n",
      "Epoch 1354/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1703 - acc: 0.9873 - val_loss: 0.6347 - val_acc: 0.6000\n",
      "Epoch 1355/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1689 - acc: 0.9873 - val_loss: 0.6351 - val_acc: 0.6000\n",
      "Epoch 1356/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1686 - acc: 0.9873 - val_loss: 0.6247 - val_acc: 0.6000\n",
      "Epoch 1357/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1669 - acc: 0.9873 - val_loss: 0.6223 - val_acc: 0.6000\n",
      "Epoch 1358/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1669 - acc: 0.9873 - val_loss: 0.6254 - val_acc: 0.6000\n",
      "Epoch 1359/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1658 - acc: 0.9873 - val_loss: 0.6269 - val_acc: 0.6000\n",
      "Epoch 1360/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.1655 - acc: 0.9873 - val_loss: 0.6201 - val_acc: 0.6000\n",
      "Epoch 1361/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1642 - acc: 0.9873 - val_loss: 0.6224 - val_acc: 0.6000\n",
      "Epoch 1362/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1638 - acc: 0.9873 - val_loss: 0.6201 - val_acc: 0.6000\n",
      "Epoch 1363/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1642 - acc: 0.9873 - val_loss: 0.6210 - val_acc: 0.6000\n",
      "Epoch 1364/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1625 - acc: 0.9873 - val_loss: 0.6250 - val_acc: 0.6000\n",
      "Epoch 1365/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1621 - acc: 0.9873 - val_loss: 0.6206 - val_acc: 0.6000\n",
      "Epoch 1366/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1614 - acc: 0.9873 - val_loss: 0.6251 - val_acc: 0.6000\n",
      "Epoch 1367/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1610 - acc: 0.9873 - val_loss: 0.6305 - val_acc: 0.6000\n",
      "Epoch 1368/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.1599 - acc: 0.9873 - val_loss: 0.6314 - val_acc: 0.6000\n",
      "Epoch 1369/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1594 - acc: 0.9873 - val_loss: 0.6272 - val_acc: 0.6000\n",
      "Epoch 1370/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1603 - acc: 0.9873 - val_loss: 0.6251 - val_acc: 0.6000\n",
      "Epoch 1371/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1582 - acc: 0.9873 - val_loss: 0.6248 - val_acc: 0.6000\n",
      "Epoch 1372/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1577 - acc: 0.9873 - val_loss: 0.6245 - val_acc: 0.5500\n",
      "Epoch 1373/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.1573 - acc: 0.9873 - val_loss: 0.6289 - val_acc: 0.6000\n",
      "Epoch 1374/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1564 - acc: 0.9873 - val_loss: 0.6235 - val_acc: 0.6000\n",
      "Epoch 1375/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1556 - acc: 0.9873 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1376/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1560 - acc: 0.9873 - val_loss: 0.6182 - val_acc: 0.6000\n",
      "Epoch 1377/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1570 - acc: 0.9873 - val_loss: 0.6355 - val_acc: 0.6000\n",
      "Epoch 1378/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1560 - acc: 0.9873 - val_loss: 0.6366 - val_acc: 0.6000\n",
      "Epoch 1379/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1551 - acc: 0.9873 - val_loss: 0.6188 - val_acc: 0.6000\n",
      "Epoch 1380/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1565 - acc: 0.9873 - val_loss: 0.6274 - val_acc: 0.6000\n",
      "Epoch 1381/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1560 - acc: 0.9873 - val_loss: 0.6202 - val_acc: 0.6000\n",
      "Epoch 1382/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1552 - acc: 0.9873 - val_loss: 0.6227 - val_acc: 0.6000\n",
      "Epoch 1383/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1553 - acc: 0.9873 - val_loss: 0.6258 - val_acc: 0.6000\n",
      "Epoch 1384/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1548 - acc: 0.9873 - val_loss: 0.6224 - val_acc: 0.6000\n",
      "Epoch 1385/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1535 - acc: 0.9873 - val_loss: 0.6235 - val_acc: 0.6000\n",
      "Epoch 1386/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1532 - acc: 0.9873 - val_loss: 0.6264 - val_acc: 0.6000\n",
      "Epoch 1387/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1527 - acc: 0.9873 - val_loss: 0.6306 - val_acc: 0.6000\n",
      "Epoch 1388/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1524 - acc: 0.9873 - val_loss: 0.6311 - val_acc: 0.6000\n",
      "Epoch 1389/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1516 - acc: 0.9873 - val_loss: 0.6275 - val_acc: 0.6000\n",
      "Epoch 1390/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1508 - acc: 0.9873 - val_loss: 0.6274 - val_acc: 0.6000\n",
      "Epoch 1391/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1515 - acc: 0.9873 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 1392/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1498 - acc: 0.9873 - val_loss: 0.6309 - val_acc: 0.6000\n",
      "Epoch 1393/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1502 - acc: 0.9873 - val_loss: 0.6307 - val_acc: 0.6000\n",
      "Epoch 1394/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1491 - acc: 0.9873 - val_loss: 0.6305 - val_acc: 0.6000\n",
      "Epoch 1395/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1479 - acc: 0.9873 - val_loss: 0.6299 - val_acc: 0.6000\n",
      "Epoch 1396/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1486 - acc: 0.9873 - val_loss: 0.6299 - val_acc: 0.6000\n",
      "Epoch 1397/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1469 - acc: 0.9873 - val_loss: 0.6308 - val_acc: 0.6000\n",
      "Epoch 1398/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1480 - acc: 0.9873 - val_loss: 0.6262 - val_acc: 0.6000\n",
      "Epoch 1399/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1460 - acc: 0.9873 - val_loss: 0.6238 - val_acc: 0.6000\n",
      "Epoch 1400/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1465 - acc: 0.9873 - val_loss: 0.6259 - val_acc: 0.6000\n",
      "Epoch 1401/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1458 - acc: 0.9873 - val_loss: 0.6205 - val_acc: 0.6000\n",
      "Epoch 1402/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1439 - acc: 0.9873 - val_loss: 0.6221 - val_acc: 0.6000\n",
      "Epoch 1403/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1433 - acc: 0.9873 - val_loss: 0.6251 - val_acc: 0.6000\n",
      "Epoch 1404/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1424 - acc: 0.9873 - val_loss: 0.6248 - val_acc: 0.6000\n",
      "Epoch 1405/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1424 - acc: 0.9873 - val_loss: 0.6241 - val_acc: 0.6000\n",
      "Epoch 1406/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1420 - acc: 0.9873 - val_loss: 0.6310 - val_acc: 0.6000\n",
      "Epoch 1407/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1411 - acc: 0.9873 - val_loss: 0.6332 - val_acc: 0.6000\n",
      "Epoch 1408/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.1403 - acc: 0.9873 - val_loss: 0.6271 - val_acc: 0.6000\n",
      "Epoch 1409/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1405 - acc: 0.9873 - val_loss: 0.6292 - val_acc: 0.6000\n",
      "Epoch 1410/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.1391 - acc: 0.9873 - val_loss: 0.6255 - val_acc: 0.6000\n",
      "Epoch 1411/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.1390 - acc: 0.9873 - val_loss: 0.6222 - val_acc: 0.6000\n",
      "Epoch 1412/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1388 - acc: 0.9873 - val_loss: 0.6201 - val_acc: 0.6000\n",
      "Epoch 1413/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1392 - acc: 0.9873 - val_loss: 0.6222 - val_acc: 0.6000\n",
      "Epoch 1414/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1373 - acc: 0.9873 - val_loss: 0.6295 - val_acc: 0.6000\n",
      "Epoch 1415/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1365 - acc: 0.9873 - val_loss: 0.6303 - val_acc: 0.6000\n",
      "Epoch 1416/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1359 - acc: 0.9873 - val_loss: 0.6281 - val_acc: 0.6000\n",
      "Epoch 1417/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1355 - acc: 0.9873 - val_loss: 0.6275 - val_acc: 0.6000\n",
      "Epoch 1418/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.1349 - acc: 0.9873 - val_loss: 0.6289 - val_acc: 0.6000\n",
      "Epoch 1419/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1345 - acc: 0.9873 - val_loss: 0.6251 - val_acc: 0.6000\n",
      "Epoch 1420/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1342 - acc: 0.9873 - val_loss: 0.6274 - val_acc: 0.6000\n",
      "Epoch 1421/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 109us/sample - loss: 0.1334 - acc: 0.9873 - val_loss: 0.6303 - val_acc: 0.6000\n",
      "Epoch 1422/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1328 - acc: 0.9873 - val_loss: 0.6296 - val_acc: 0.6000\n",
      "Epoch 1423/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1324 - acc: 0.9873 - val_loss: 0.6288 - val_acc: 0.6000\n",
      "Epoch 1424/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1324 - acc: 0.9873 - val_loss: 0.6324 - val_acc: 0.6000\n",
      "Epoch 1425/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1314 - acc: 0.9873 - val_loss: 0.6313 - val_acc: 0.6000\n",
      "Epoch 1426/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1313 - acc: 0.9873 - val_loss: 0.6359 - val_acc: 0.6000\n",
      "Epoch 1427/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1307 - acc: 0.9873 - val_loss: 0.6373 - val_acc: 0.6000\n",
      "Epoch 1428/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.1316 - acc: 0.9873 - val_loss: 0.6385 - val_acc: 0.6000\n",
      "Epoch 1429/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1305 - acc: 0.9873 - val_loss: 0.6402 - val_acc: 0.6000\n",
      "Epoch 1430/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.1306 - acc: 0.9873 - val_loss: 0.6375 - val_acc: 0.6000\n",
      "Epoch 1431/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1290 - acc: 0.9873 - val_loss: 0.6365 - val_acc: 0.6000\n",
      "Epoch 1432/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1286 - acc: 0.9873 - val_loss: 0.6322 - val_acc: 0.6000\n",
      "Epoch 1433/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1301 - acc: 0.9873 - val_loss: 0.6194 - val_acc: 0.5500\n",
      "Epoch 1434/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1286 - acc: 0.9873 - val_loss: 0.6238 - val_acc: 0.6000\n",
      "Epoch 1435/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1279 - acc: 0.9873 - val_loss: 0.6342 - val_acc: 0.6000\n",
      "Epoch 1436/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1265 - acc: 0.9873 - val_loss: 0.6321 - val_acc: 0.6000\n",
      "Epoch 1437/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1267 - acc: 0.9873 - val_loss: 0.6265 - val_acc: 0.6000\n",
      "Epoch 1438/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1261 - acc: 0.9873 - val_loss: 0.6243 - val_acc: 0.6000\n",
      "Epoch 1439/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1254 - acc: 0.9873 - val_loss: 0.6264 - val_acc: 0.6000\n",
      "Epoch 1440/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1247 - acc: 0.9873 - val_loss: 0.6283 - val_acc: 0.6000\n",
      "Epoch 1441/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1252 - acc: 0.9873 - val_loss: 0.6314 - val_acc: 0.6000\n",
      "Epoch 1442/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1244 - acc: 0.9873 - val_loss: 0.6246 - val_acc: 0.6000\n",
      "Epoch 1443/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1239 - acc: 0.9873 - val_loss: 0.6297 - val_acc: 0.6000\n",
      "Epoch 1444/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1228 - acc: 0.9873 - val_loss: 0.6297 - val_acc: 0.6000\n",
      "Epoch 1445/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1222 - acc: 0.9873 - val_loss: 0.6330 - val_acc: 0.6000\n",
      "Epoch 1446/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1217 - acc: 0.9873 - val_loss: 0.6328 - val_acc: 0.6000\n",
      "Epoch 1447/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.1214 - acc: 0.9873 - val_loss: 0.6314 - val_acc: 0.6000\n",
      "Epoch 1448/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1213 - acc: 0.9873 - val_loss: 0.6299 - val_acc: 0.6000\n",
      "Epoch 1449/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1214 - acc: 0.9873 - val_loss: 0.6253 - val_acc: 0.6000\n",
      "Epoch 1450/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1204 - acc: 0.9873 - val_loss: 0.6295 - val_acc: 0.6000\n",
      "Epoch 1451/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1197 - acc: 0.9873 - val_loss: 0.6353 - val_acc: 0.6000\n",
      "Epoch 1452/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1191 - acc: 0.9873 - val_loss: 0.6466 - val_acc: 0.6000\n",
      "Epoch 1453/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1197 - acc: 0.9873 - val_loss: 0.6345 - val_acc: 0.6000\n",
      "Epoch 1454/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1180 - acc: 0.9873 - val_loss: 0.6361 - val_acc: 0.6000\n",
      "Epoch 1455/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1170 - acc: 0.9873 - val_loss: 0.6331 - val_acc: 0.6000\n",
      "Epoch 1456/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1163 - acc: 0.9873 - val_loss: 0.6318 - val_acc: 0.6000\n",
      "Epoch 1457/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1157 - acc: 0.9873 - val_loss: 0.6341 - val_acc: 0.6000\n",
      "Epoch 1458/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1163 - acc: 0.9873 - val_loss: 0.6402 - val_acc: 0.6000\n",
      "Epoch 1459/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1151 - acc: 0.9873 - val_loss: 0.6365 - val_acc: 0.6000\n",
      "Epoch 1460/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1149 - acc: 0.9873 - val_loss: 0.6396 - val_acc: 0.6000\n",
      "Epoch 1461/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1147 - acc: 0.9873 - val_loss: 0.6394 - val_acc: 0.6000\n",
      "Epoch 1462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1143 - acc: 0.9873 - val_loss: 0.6386 - val_acc: 0.6000\n",
      "Epoch 1463/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.1131 - acc: 0.9873 - val_loss: 0.6373 - val_acc: 0.6000\n",
      "Epoch 1464/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1129 - acc: 0.9873 - val_loss: 0.6428 - val_acc: 0.6000\n",
      "Epoch 1465/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1123 - acc: 0.9873 - val_loss: 0.6460 - val_acc: 0.6000\n",
      "Epoch 1466/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1118 - acc: 0.9873 - val_loss: 0.6492 - val_acc: 0.6000\n",
      "Epoch 1467/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1112 - acc: 0.9873 - val_loss: 0.6444 - val_acc: 0.6000\n",
      "Epoch 1468/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.1107 - acc: 0.9873 - val_loss: 0.6423 - val_acc: 0.6000\n",
      "Epoch 1469/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1111 - acc: 0.9873 - val_loss: 0.6478 - val_acc: 0.6000\n",
      "Epoch 1470/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1105 - acc: 0.9873 - val_loss: 0.6416 - val_acc: 0.6000\n",
      "Epoch 1471/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1104 - acc: 0.9873 - val_loss: 0.6335 - val_acc: 0.6000\n",
      "Epoch 1472/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1100 - acc: 0.9873 - val_loss: 0.6394 - val_acc: 0.6000\n",
      "Epoch 1473/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1088 - acc: 0.9873 - val_loss: 0.6365 - val_acc: 0.6000\n",
      "Epoch 1474/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0893 - acc: 1.000 - 0s 126us/sample - loss: 0.1086 - acc: 0.9873 - val_loss: 0.6329 - val_acc: 0.6000\n",
      "Epoch 1475/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1082 - acc: 0.9873 - val_loss: 0.6380 - val_acc: 0.6000\n",
      "Epoch 1476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1079 - acc: 0.9873 - val_loss: 0.6323 - val_acc: 0.6000\n",
      "Epoch 1477/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1073 - acc: 0.9873 - val_loss: 0.6373 - val_acc: 0.6000\n",
      "Epoch 1478/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1075 - acc: 0.9873 - val_loss: 0.6360 - val_acc: 0.6000\n",
      "Epoch 1479/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1066 - acc: 0.9873 - val_loss: 0.6409 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1480/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1053 - acc: 0.9873 - val_loss: 0.6420 - val_acc: 0.6000\n",
      "Epoch 1481/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1055 - acc: 0.9873 - val_loss: 0.6439 - val_acc: 0.6000\n",
      "Epoch 1482/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1053 - acc: 0.9873 - val_loss: 0.6426 - val_acc: 0.6000\n",
      "Epoch 1483/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1048 - acc: 0.9873 - val_loss: 0.6379 - val_acc: 0.6000\n",
      "Epoch 1484/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1043 - acc: 0.9873 - val_loss: 0.6450 - val_acc: 0.6000\n",
      "Epoch 1485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1034 - acc: 0.9873 - val_loss: 0.6381 - val_acc: 0.6000\n",
      "Epoch 1486/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1028 - acc: 0.9873 - val_loss: 0.6373 - val_acc: 0.6000\n",
      "Epoch 1487/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1030 - acc: 0.9873 - val_loss: 0.6394 - val_acc: 0.6000\n",
      "Epoch 1488/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1021 - acc: 0.9873 - val_loss: 0.6384 - val_acc: 0.6000\n",
      "Epoch 1489/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1020 - acc: 0.9873 - val_loss: 0.6401 - val_acc: 0.6000\n",
      "Epoch 1490/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1012 - acc: 0.9873 - val_loss: 0.6429 - val_acc: 0.6000\n",
      "Epoch 1491/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1011 - acc: 0.9873 - val_loss: 0.6454 - val_acc: 0.6000\n",
      "Epoch 1492/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1007 - acc: 0.9873 - val_loss: 0.6488 - val_acc: 0.6000\n",
      "Epoch 1493/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1011 - acc: 0.9873 - val_loss: 0.6461 - val_acc: 0.6000\n",
      "Epoch 1494/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1014 - acc: 0.9873 - val_loss: 0.6455 - val_acc: 0.6000\n",
      "Epoch 1495/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.1004 - acc: 0.9873 - val_loss: 0.6387 - val_acc: 0.6000\n",
      "Epoch 1496/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1010 - acc: 0.9873 - val_loss: 0.6351 - val_acc: 0.5500\n",
      "Epoch 1497/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0998 - acc: 0.9873 - val_loss: 0.6360 - val_acc: 0.6000\n",
      "Epoch 1498/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0992 - acc: 0.9873 - val_loss: 0.6386 - val_acc: 0.6000\n",
      "Epoch 1499/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0987 - acc: 0.9873 - val_loss: 0.6422 - val_acc: 0.6000\n",
      "Epoch 1500/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0984 - acc: 0.9873 - val_loss: 0.6468 - val_acc: 0.6000\n",
      "Epoch 1501/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0980 - acc: 0.9873 - val_loss: 0.6423 - val_acc: 0.6000\n",
      "Epoch 1502/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0978 - acc: 0.9873 - val_loss: 0.6434 - val_acc: 0.6000\n",
      "Epoch 1503/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0975 - acc: 0.9873 - val_loss: 0.6426 - val_acc: 0.6000\n",
      "Epoch 1504/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0968 - acc: 0.9873 - val_loss: 0.6401 - val_acc: 0.6000\n",
      "Epoch 1505/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0965 - acc: 0.9873 - val_loss: 0.6435 - val_acc: 0.6000\n",
      "Epoch 1506/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0963 - acc: 0.9873 - val_loss: 0.6437 - val_acc: 0.6000\n",
      "Epoch 1507/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0960 - acc: 0.9873 - val_loss: 0.6456 - val_acc: 0.6000\n",
      "Epoch 1508/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0955 - acc: 0.9873 - val_loss: 0.6413 - val_acc: 0.6000\n",
      "Epoch 1509/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0955 - acc: 0.9873 - val_loss: 0.6416 - val_acc: 0.6000\n",
      "Epoch 1510/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0949 - acc: 0.9873 - val_loss: 0.6387 - val_acc: 0.6000\n",
      "Epoch 1511/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0952 - acc: 0.9873 - val_loss: 0.6442 - val_acc: 0.6000\n",
      "Epoch 1512/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0939 - acc: 0.9873 - val_loss: 0.6423 - val_acc: 0.6000\n",
      "Epoch 1513/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0949 - acc: 0.9873 - val_loss: 0.6447 - val_acc: 0.6000\n",
      "Epoch 1514/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0940 - acc: 0.9873 - val_loss: 0.6511 - val_acc: 0.6000\n",
      "Epoch 1515/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0929 - acc: 0.9873 - val_loss: 0.6461 - val_acc: 0.6000\n",
      "Epoch 1516/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0925 - acc: 0.9873 - val_loss: 0.6446 - val_acc: 0.6000\n",
      "Epoch 1517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0924 - acc: 0.9873 - val_loss: 0.6387 - val_acc: 0.6000\n",
      "Epoch 1518/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0920 - acc: 0.9873 - val_loss: 0.6403 - val_acc: 0.6000\n",
      "Epoch 1519/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0922 - acc: 0.9873 - val_loss: 0.6364 - val_acc: 0.5500\n",
      "Epoch 1520/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0914 - acc: 0.9873 - val_loss: 0.6429 - val_acc: 0.6000\n",
      "Epoch 1521/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0907 - acc: 0.9873 - val_loss: 0.6446 - val_acc: 0.6000\n",
      "Epoch 1522/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0904 - acc: 0.9873 - val_loss: 0.6450 - val_acc: 0.6000\n",
      "Epoch 1523/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0901 - acc: 0.9873 - val_loss: 0.6469 - val_acc: 0.6000\n",
      "Epoch 1524/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0902 - acc: 0.9873 - val_loss: 0.6393 - val_acc: 0.6000\n",
      "Epoch 1525/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0896 - acc: 0.9873 - val_loss: 0.6462 - val_acc: 0.6000\n",
      "Epoch 1526/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0893 - acc: 0.9873 - val_loss: 0.6448 - val_acc: 0.6000\n",
      "Epoch 1527/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0894 - acc: 0.9873 - val_loss: 0.6378 - val_acc: 0.5500\n",
      "Epoch 1528/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0886 - acc: 0.9873 - val_loss: 0.6428 - val_acc: 0.6000\n",
      "Epoch 1529/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0887 - acc: 0.9873 - val_loss: 0.6468 - val_acc: 0.6000\n",
      "Epoch 1530/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0879 - acc: 0.9873 - val_loss: 0.6442 - val_acc: 0.6000\n",
      "Epoch 1531/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0883 - acc: 0.9873 - val_loss: 0.6459 - val_acc: 0.6000\n",
      "Epoch 1532/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0871 - acc: 0.9873 - val_loss: 0.6475 - val_acc: 0.6000\n",
      "Epoch 1533/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0869 - acc: 0.9873 - val_loss: 0.6508 - val_acc: 0.6000\n",
      "Epoch 1534/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0867 - acc: 0.9873 - val_loss: 0.6452 - val_acc: 0.6000\n",
      "Epoch 1535/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0864 - acc: 0.9873 - val_loss: 0.6494 - val_acc: 0.6000\n",
      "Epoch 1536/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0863 - acc: 0.9873 - val_loss: 0.6548 - val_acc: 0.6000\n",
      "Epoch 1537/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0856 - acc: 0.9873 - val_loss: 0.6510 - val_acc: 0.6000\n",
      "Epoch 1538/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0852 - acc: 0.9873 - val_loss: 0.6496 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1539/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0848 - acc: 0.9873 - val_loss: 0.6489 - val_acc: 0.6000\n",
      "Epoch 1540/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0845 - acc: 0.9873 - val_loss: 0.6545 - val_acc: 0.6000\n",
      "Epoch 1541/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0840 - acc: 0.9873 - val_loss: 0.6558 - val_acc: 0.6000\n",
      "Epoch 1542/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0843 - acc: 0.9873 - val_loss: 0.6604 - val_acc: 0.6000\n",
      "Epoch 1543/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0836 - acc: 0.9873 - val_loss: 0.6536 - val_acc: 0.6000\n",
      "Epoch 1544/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0832 - acc: 0.9873 - val_loss: 0.6542 - val_acc: 0.6000\n",
      "Epoch 1545/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0827 - acc: 0.9873 - val_loss: 0.6530 - val_acc: 0.6000\n",
      "Epoch 1546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0837 - acc: 0.9873 - val_loss: 0.6497 - val_acc: 0.6000\n",
      "Epoch 1547/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0821 - acc: 0.9873 - val_loss: 0.6502 - val_acc: 0.6000\n",
      "Epoch 1548/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0818 - acc: 0.9873 - val_loss: 0.6533 - val_acc: 0.6000\n",
      "Epoch 1549/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0820 - acc: 0.9873 - val_loss: 0.6542 - val_acc: 0.6000\n",
      "Epoch 1550/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0812 - acc: 0.9873 - val_loss: 0.6568 - val_acc: 0.6000\n",
      "Epoch 1551/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0813 - acc: 0.9873 - val_loss: 0.6614 - val_acc: 0.6000\n",
      "Epoch 1552/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0809 - acc: 0.9873 - val_loss: 0.6629 - val_acc: 0.6000\n",
      "Epoch 1553/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0807 - acc: 0.9873 - val_loss: 0.6589 - val_acc: 0.6000\n",
      "Epoch 1554/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0804 - acc: 0.9873 - val_loss: 0.6628 - val_acc: 0.6000\n",
      "Epoch 1555/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0802 - acc: 0.9873 - val_loss: 0.6525 - val_acc: 0.5500\n",
      "Epoch 1556/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0796 - acc: 0.9873 - val_loss: 0.6510 - val_acc: 0.6000\n",
      "Epoch 1557/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0791 - acc: 0.9873 - val_loss: 0.6532 - val_acc: 0.6000\n",
      "Epoch 1558/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0788 - acc: 0.9873 - val_loss: 0.6560 - val_acc: 0.6000\n",
      "Epoch 1559/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0786 - acc: 0.9873 - val_loss: 0.6608 - val_acc: 0.6000\n",
      "Epoch 1560/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0783 - acc: 0.9873 - val_loss: 0.6601 - val_acc: 0.6000\n",
      "Epoch 1561/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0781 - acc: 0.9873 - val_loss: 0.6598 - val_acc: 0.6000\n",
      "Epoch 1562/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0893 - acc: 0.968 - 0s 126us/sample - loss: 0.0781 - acc: 0.9873 - val_loss: 0.6613 - val_acc: 0.6000\n",
      "Epoch 1563/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0775 - acc: 0.9873 - val_loss: 0.6564 - val_acc: 0.6000\n",
      "Epoch 1564/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0770 - acc: 0.9873 - val_loss: 0.6598 - val_acc: 0.6000\n",
      "Epoch 1565/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0767 - acc: 0.9873 - val_loss: 0.6607 - val_acc: 0.6000\n",
      "Epoch 1566/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0773 - acc: 0.9873 - val_loss: 0.6608 - val_acc: 0.6000\n",
      "Epoch 1567/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0763 - acc: 0.9873 - val_loss: 0.6567 - val_acc: 0.6000\n",
      "Epoch 1568/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0762 - acc: 0.9873 - val_loss: 0.6537 - val_acc: 0.5500\n",
      "Epoch 1569/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0762 - acc: 0.9873 - val_loss: 0.6496 - val_acc: 0.5500\n",
      "Epoch 1570/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0762 - acc: 0.9873 - val_loss: 0.6579 - val_acc: 0.5500\n",
      "Epoch 1571/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0759 - acc: 0.9873 - val_loss: 0.6623 - val_acc: 0.6000\n",
      "Epoch 1572/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0752 - acc: 0.9873 - val_loss: 0.6551 - val_acc: 0.5500\n",
      "Epoch 1573/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0749 - acc: 0.9873 - val_loss: 0.6540 - val_acc: 0.5500\n",
      "Epoch 1574/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0747 - acc: 0.9873 - val_loss: 0.6546 - val_acc: 0.5500\n",
      "Epoch 1575/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.5500\n",
      "Epoch 1576/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0746 - acc: 0.9873 - val_loss: 0.6629 - val_acc: 0.6000\n",
      "Epoch 1577/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0738 - acc: 0.9873 - val_loss: 0.6648 - val_acc: 0.6000\n",
      "Epoch 1578/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0736 - acc: 0.9873 - val_loss: 0.6596 - val_acc: 0.5500\n",
      "Epoch 1579/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0734 - acc: 0.9873 - val_loss: 0.6553 - val_acc: 0.5500\n",
      "Epoch 1580/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0729 - acc: 1.0000 - val_loss: 0.6573 - val_acc: 0.5500\n",
      "Epoch 1581/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0729 - acc: 0.9873 - val_loss: 0.6585 - val_acc: 0.5500\n",
      "Epoch 1582/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0726 - acc: 0.9873 - val_loss: 0.6612 - val_acc: 0.5500\n",
      "Epoch 1583/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0722 - acc: 0.9873 - val_loss: 0.6587 - val_acc: 0.5500\n",
      "Epoch 1584/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0719 - acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.5500\n",
      "Epoch 1585/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.6624 - val_acc: 0.5500\n",
      "Epoch 1586/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0716 - acc: 1.0000 - val_loss: 0.6617 - val_acc: 0.5500\n",
      "Epoch 1587/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0714 - acc: 0.9873 - val_loss: 0.6607 - val_acc: 0.5500\n",
      "Epoch 1588/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0710 - acc: 1.0000 - val_loss: 0.6624 - val_acc: 0.5500\n",
      "Epoch 1589/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.6640 - val_acc: 0.5500\n",
      "Epoch 1590/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0704 - acc: 1.0000 - val_loss: 0.6626 - val_acc: 0.5500\n",
      "Epoch 1591/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0701 - acc: 1.0000 - val_loss: 0.6640 - val_acc: 0.5500\n",
      "Epoch 1592/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0699 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.5500\n",
      "Epoch 1593/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0698 - acc: 1.0000 - val_loss: 0.6672 - val_acc: 0.6000\n",
      "Epoch 1594/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.6000\n",
      "Epoch 1595/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0692 - acc: 1.0000 - val_loss: 0.6638 - val_acc: 0.5500\n",
      "Epoch 1596/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0693 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.5500\n",
      "Epoch 1597/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0692 - acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.5500\n",
      "Epoch 1598/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0684 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.5500\n",
      "Epoch 1599/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 0.5500\n",
      "Epoch 1600/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 1601/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0683 - acc: 0.9873 - val_loss: 0.6730 - val_acc: 0.6000\n",
      "Epoch 1602/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0675 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.5500\n",
      "Epoch 1603/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0674 - acc: 1.0000 - val_loss: 0.6731 - val_acc: 0.6000\n",
      "Epoch 1604/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0673 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.6000\n",
      "Epoch 1605/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0673 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.6000\n",
      "Epoch 1606/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0668 - acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.6000\n",
      "Epoch 1607/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0668 - acc: 1.0000 - val_loss: 0.6718 - val_acc: 0.5500\n",
      "Epoch 1608/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0661 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.5500\n",
      "Epoch 1609/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.5500\n",
      "Epoch 1610/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0657 - acc: 1.0000 - val_loss: 0.6830 - val_acc: 0.5500\n",
      "Epoch 1611/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 1612/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0654 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.5500\n",
      "Epoch 1613/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0652 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 0.5500\n",
      "Epoch 1614/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.5500\n",
      "Epoch 1615/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0645 - acc: 1.0000 - val_loss: 0.6675 - val_acc: 0.5500\n",
      "Epoch 1616/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0646 - acc: 1.0000 - val_loss: 0.6657 - val_acc: 0.5500\n",
      "Epoch 1617/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.5500\n",
      "Epoch 1618/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0640 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.5500\n",
      "Epoch 1619/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.6744 - val_acc: 0.5500\n",
      "Epoch 1620/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0650 - acc: 1.0000 - val_loss: 0.6747 - val_acc: 0.6000\n",
      "Epoch 1621/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.6000\n",
      "Epoch 1622/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0646 - acc: 1.0000 - val_loss: 0.7217 - val_acc: 0.6000\n",
      "Epoch 1623/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0643 - acc: 1.0000 - val_loss: 0.7175 - val_acc: 0.6000\n",
      "Epoch 1624/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0640 - acc: 1.0000 - val_loss: 0.7159 - val_acc: 0.6000\n",
      "Epoch 1625/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.7134 - val_acc: 0.6000\n",
      "Epoch 1626/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.7114 - val_acc: 0.6000\n",
      "Epoch 1627/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.6000\n",
      "Epoch 1628/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.5500\n",
      "Epoch 1629/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0630 - acc: 1.0000 - val_loss: 0.7131 - val_acc: 0.6000\n",
      "Epoch 1630/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.7084 - val_acc: 0.5500\n",
      "Epoch 1631/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0623 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.5500\n",
      "Epoch 1632/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0621 - acc: 1.0000 - val_loss: 0.7077 - val_acc: 0.5500\n",
      "Epoch 1633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.7078 - val_acc: 0.5500\n",
      "Epoch 1634/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.7103 - val_acc: 0.5500\n",
      "Epoch 1635/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.5500\n",
      "Epoch 1636/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.5500\n",
      "Epoch 1637/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0612 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.5500\n",
      "Epoch 1638/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.5500\n",
      "Epoch 1639/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.5500\n",
      "Epoch 1640/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.5500\n",
      "Epoch 1641/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.7100 - val_acc: 0.5500\n",
      "Epoch 1642/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.5500\n",
      "Epoch 1643/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0598 - acc: 1.0000 - val_loss: 0.7062 - val_acc: 0.5500\n",
      "Epoch 1644/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0599 - acc: 1.0000 - val_loss: 0.6997 - val_acc: 0.5500\n",
      "Epoch 1645/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.6993 - val_acc: 0.5500\n",
      "Epoch 1646/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.7030 - val_acc: 0.5500\n",
      "Epoch 1647/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.5500\n",
      "Epoch 1648/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.5500\n",
      "Epoch 1649/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0588 - acc: 1.0000 - val_loss: 0.7087 - val_acc: 0.5500\n",
      "Epoch 1650/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.7053 - val_acc: 0.5500\n",
      "Epoch 1651/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.5500\n",
      "Epoch 1652/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0588 - acc: 1.0000 - val_loss: 0.6956 - val_acc: 0.5500\n",
      "Epoch 1653/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0583 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.5500\n",
      "Epoch 1654/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.7072 - val_acc: 0.5500\n",
      "Epoch 1655/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0577 - acc: 1.0000 - val_loss: 0.7076 - val_acc: 0.5500\n",
      "Epoch 1656/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.7100 - val_acc: 0.5500\n",
      "Epoch 1657/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.7142 - val_acc: 0.5500\n",
      "Epoch 1658/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0570 - acc: 1.0000 - val_loss: 0.7128 - val_acc: 0.5500\n",
      "Epoch 1659/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0568 - acc: 1.0000 - val_loss: 0.7078 - val_acc: 0.5500\n",
      "Epoch 1660/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0574 - acc: 1.0000 - val_loss: 0.7096 - val_acc: 0.5500\n",
      "Epoch 1661/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.5500\n",
      "Epoch 1662/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0562 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.5500\n",
      "Epoch 1663/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0562 - acc: 1.0000 - val_loss: 0.7056 - val_acc: 0.5500\n",
      "Epoch 1664/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.7071 - val_acc: 0.5500\n",
      "Epoch 1665/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.7129 - val_acc: 0.5500\n",
      "Epoch 1666/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.7099 - val_acc: 0.5500\n",
      "Epoch 1667/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.5500\n",
      "Epoch 1668/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.7146 - val_acc: 0.5500\n",
      "Epoch 1669/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.5500\n",
      "Epoch 1670/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0550 - acc: 1.0000 - val_loss: 0.7163 - val_acc: 0.5500\n",
      "Epoch 1671/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.7139 - val_acc: 0.5500\n",
      "Epoch 1672/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.5500\n",
      "Epoch 1673/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.7167 - val_acc: 0.5500\n",
      "Epoch 1674/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0543 - acc: 1.0000 - val_loss: 0.7212 - val_acc: 0.5500\n",
      "Epoch 1675/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.7199 - val_acc: 0.5500\n",
      "Epoch 1676/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.7198 - val_acc: 0.5500\n",
      "Epoch 1677/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.5500\n",
      "Epoch 1678/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.7119 - val_acc: 0.5500\n",
      "Epoch 1679/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.5500\n",
      "Epoch 1680/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.7142 - val_acc: 0.5500\n",
      "Epoch 1681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.5500\n",
      "Epoch 1682/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.5500\n",
      "Epoch 1683/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0529 - acc: 1.0000 - val_loss: 0.7120 - val_acc: 0.5500\n",
      "Epoch 1684/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.7149 - val_acc: 0.5500\n",
      "Epoch 1685/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.7207 - val_acc: 0.5500\n",
      "Epoch 1686/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.5500\n",
      "Epoch 1687/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.5500\n",
      "Epoch 1688/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.5500\n",
      "Epoch 1689/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0517 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.5500\n",
      "Epoch 1690/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0515 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 0.5500\n",
      "Epoch 1691/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.5500\n",
      "Epoch 1692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.5500\n",
      "Epoch 1693/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0510 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 0.5500\n",
      "Epoch 1694/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0510 - acc: 1.0000 - val_loss: 0.7245 - val_acc: 0.5500\n",
      "Epoch 1695/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.7248 - val_acc: 0.5500\n",
      "Epoch 1696/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0506 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.5500\n",
      "Epoch 1697/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 0.5500\n",
      "Epoch 1698/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.7305 - val_acc: 0.5500\n",
      "Epoch 1699/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.5500\n",
      "Epoch 1700/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.5500\n",
      "Epoch 1701/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.5500\n",
      "Epoch 1702/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.7309 - val_acc: 0.5500\n",
      "Epoch 1703/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.5500\n",
      "Epoch 1704/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.5500\n",
      "Epoch 1705/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0496 - acc: 1.0000 - val_loss: 0.7209 - val_acc: 0.5500\n",
      "Epoch 1706/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.7221 - val_acc: 0.5500\n",
      "Epoch 1707/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0490 - acc: 1.0000 - val_loss: 0.7224 - val_acc: 0.5500\n",
      "Epoch 1708/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0489 - acc: 1.0000 - val_loss: 0.7240 - val_acc: 0.5500\n",
      "Epoch 1709/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.5500\n",
      "Epoch 1710/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.5500\n",
      "Epoch 1711/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 0.5500\n",
      "Epoch 1712/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.5500\n",
      "Epoch 1713/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.5500\n",
      "Epoch 1714/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.5500\n",
      "Epoch 1715/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 0.5500\n",
      "Epoch 1716/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 0.5500\n",
      "Epoch 1717/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 0.5500\n",
      "Epoch 1718/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.7307 - val_acc: 0.5500\n",
      "Epoch 1719/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.7292 - val_acc: 0.5500\n",
      "Epoch 1720/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 0.5500\n",
      "Epoch 1721/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0469 - acc: 1.0000 - val_loss: 0.7302 - val_acc: 0.5500\n",
      "Epoch 1722/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0468 - acc: 1.0000 - val_loss: 0.7312 - val_acc: 0.5500\n",
      "Epoch 1723/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0469 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.5500\n",
      "Epoch 1724/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.7369 - val_acc: 0.5500\n",
      "Epoch 1725/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.5500\n",
      "Epoch 1726/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.5500\n",
      "Epoch 1727/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.5500\n",
      "Epoch 1728/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.5500\n",
      "Epoch 1729/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.5500\n",
      "Epoch 1730/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.7375 - val_acc: 0.5500\n",
      "Epoch 1731/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.7364 - val_acc: 0.5500\n",
      "Epoch 1732/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.5500\n",
      "Epoch 1733/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.7292 - val_acc: 0.5500\n",
      "Epoch 1734/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.5500\n",
      "Epoch 1735/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.7275 - val_acc: 0.5500\n",
      "Epoch 1736/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.7273 - val_acc: 0.5500\n",
      "Epoch 1737/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.5500\n",
      "Epoch 1738/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.5500\n",
      "Epoch 1739/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.5500\n",
      "Epoch 1740/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0443 - acc: 1.0000 - val_loss: 0.7341 - val_acc: 0.5500\n",
      "Epoch 1741/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.5500\n",
      "Epoch 1742/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0441 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.5500\n",
      "Epoch 1743/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.5500\n",
      "Epoch 1744/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.5500\n",
      "Epoch 1745/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.7405 - val_acc: 0.5500\n",
      "Epoch 1746/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.5500\n",
      "Epoch 1747/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.5500\n",
      "Epoch 1748/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.7390 - val_acc: 0.5500\n",
      "Epoch 1749/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.7373 - val_acc: 0.5500\n",
      "Epoch 1750/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.5500\n",
      "Epoch 1751/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0431 - acc: 1.0000 - val_loss: 0.7403 - val_acc: 0.5500\n",
      "Epoch 1752/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 0.5500\n",
      "Epoch 1753/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.5500\n",
      "Epoch 1754/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.5500\n",
      "Epoch 1755/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.5500\n",
      "Epoch 1756/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.5500\n",
      "Epoch 1757/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.5500\n",
      "Epoch 1758/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.7477 - val_acc: 0.5500\n",
      "Epoch 1759/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5500\n",
      "Epoch 1760/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.7482 - val_acc: 0.5500\n",
      "Epoch 1761/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.7457 - val_acc: 0.5500\n",
      "Epoch 1762/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 0.5500\n",
      "Epoch 1763/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.5500\n",
      "Epoch 1764/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.7444 - val_acc: 0.5500\n",
      "Epoch 1765/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.7511 - val_acc: 0.5500\n",
      "Epoch 1766/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.7526 - val_acc: 0.5500\n",
      "Epoch 1767/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.7531 - val_acc: 0.5500\n",
      "Epoch 1768/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.5500\n",
      "Epoch 1769/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 0.7523 - val_acc: 0.5500\n",
      "Epoch 1770/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.7508 - val_acc: 0.5500\n",
      "Epoch 1771/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.7516 - val_acc: 0.5500\n",
      "Epoch 1772/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.7504 - val_acc: 0.5500\n",
      "Epoch 1773/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.5500\n",
      "Epoch 1774/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7532 - val_acc: 0.5500\n",
      "Epoch 1775/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.5500\n",
      "Epoch 1776/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.5500\n",
      "Epoch 1777/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.5500\n",
      "Epoch 1778/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.5500\n",
      "Epoch 1779/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.7510 - val_acc: 0.5500\n",
      "Epoch 1780/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.7539 - val_acc: 0.5500\n",
      "Epoch 1781/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.7553 - val_acc: 0.5500\n",
      "Epoch 1782/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0396 - acc: 1.0000 - val_loss: 0.7496 - val_acc: 0.5500\n",
      "Epoch 1783/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0392 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.5500\n",
      "Epoch 1784/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.7496 - val_acc: 0.5500\n",
      "Epoch 1785/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.7467 - val_acc: 0.5500\n",
      "Epoch 1786/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.5500\n",
      "Epoch 1787/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.5500\n",
      "Epoch 1788/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.5500\n",
      "Epoch 1789/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.7543 - val_acc: 0.5500\n",
      "Epoch 1790/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 0.5500\n",
      "Epoch 1791/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.7611 - val_acc: 0.5500\n",
      "Epoch 1792/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 0.5500\n",
      "Epoch 1793/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.5500\n",
      "Epoch 1794/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.5500\n",
      "Epoch 1795/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.5500\n",
      "Epoch 1796/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.5500\n",
      "Epoch 1797/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 0.7562 - val_acc: 0.5500\n",
      "Epoch 1798/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.5500\n",
      "Epoch 1799/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.5500\n",
      "Epoch 1800/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0374 - acc: 1.0000 - val_loss: 0.7582 - val_acc: 0.5500\n",
      "Epoch 1801/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.7590 - val_acc: 0.5500\n",
      "Epoch 1802/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.7591 - val_acc: 0.5500\n",
      "Epoch 1803/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.7573 - val_acc: 0.5500\n",
      "Epoch 1804/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.7613 - val_acc: 0.5500\n",
      "Epoch 1805/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 0.5500\n",
      "Epoch 1806/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 0.5500\n",
      "Epoch 1807/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 0.5500\n",
      "Epoch 1808/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.5500\n",
      "Epoch 1809/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.7653 - val_acc: 0.5500\n",
      "Epoch 1810/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.7616 - val_acc: 0.5500\n",
      "Epoch 1811/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.5500\n",
      "Epoch 1812/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.5500\n",
      "Epoch 1813/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5500\n",
      "Epoch 1814/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.5500\n",
      "Epoch 1815/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.7686 - val_acc: 0.5500\n",
      "Epoch 1816/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.7682 - val_acc: 0.5500\n",
      "Epoch 1817/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.5500\n",
      "Epoch 1818/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.7699 - val_acc: 0.5500\n",
      "Epoch 1819/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.5500\n",
      "Epoch 1820/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.7689 - val_acc: 0.5500\n",
      "Epoch 1821/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.7679 - val_acc: 0.5500\n",
      "Epoch 1822/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.7675 - val_acc: 0.5500\n",
      "Epoch 1823/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.7683 - val_acc: 0.5500\n",
      "Epoch 1824/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.5500\n",
      "Epoch 1825/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.5500\n",
      "Epoch 1826/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.7665 - val_acc: 0.5500\n",
      "Epoch 1827/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.5500\n",
      "Epoch 1828/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0349 - acc: 1.0000 - val_loss: 0.7689 - val_acc: 0.5500\n",
      "Epoch 1829/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.7700 - val_acc: 0.5500\n",
      "Epoch 1830/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.5500\n",
      "Epoch 1831/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.7731 - val_acc: 0.5500\n",
      "Epoch 1832/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0344 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.5500\n",
      "Epoch 1833/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.5500\n",
      "Epoch 1834/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.7710 - val_acc: 0.5500\n",
      "Epoch 1835/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.5500\n",
      "Epoch 1836/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.5500\n",
      "Epoch 1837/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.7729 - val_acc: 0.5500\n",
      "Epoch 1838/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.5500\n",
      "Epoch 1839/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.5500\n",
      "Epoch 1840/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.5500\n",
      "Epoch 1841/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.7763 - val_acc: 0.5500\n",
      "Epoch 1842/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.5500\n",
      "Epoch 1843/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 0.5500\n",
      "Epoch 1844/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 0.5500\n",
      "Epoch 1845/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.5500\n",
      "Epoch 1846/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 0.5500\n",
      "Epoch 1847/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.7746 - val_acc: 0.5500\n",
      "Epoch 1848/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.7750 - val_acc: 0.5500\n",
      "Epoch 1849/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.5500\n",
      "Epoch 1850/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.5500\n",
      "Epoch 1851/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.7751 - val_acc: 0.5500\n",
      "Epoch 1852/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.5500\n",
      "Epoch 1853/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.5500\n",
      "Epoch 1854/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.7776 - val_acc: 0.5500\n",
      "Epoch 1855/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.5500\n",
      "Epoch 1856/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.5500\n",
      "Epoch 1857/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.5500\n",
      "Epoch 1858/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.7798 - val_acc: 0.5500\n",
      "Epoch 1859/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.5500\n",
      "Epoch 1860/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.7789 - val_acc: 0.5500\n",
      "Epoch 1861/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.7818 - val_acc: 0.5500\n",
      "Epoch 1862/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.5500\n",
      "Epoch 1863/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.7825 - val_acc: 0.5500\n",
      "Epoch 1864/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.7786 - val_acc: 0.5500\n",
      "Epoch 1865/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.7802 - val_acc: 0.5500\n",
      "Epoch 1866/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.7847 - val_acc: 0.5500\n",
      "Epoch 1867/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.5500\n",
      "Epoch 1868/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.5500\n",
      "Epoch 1869/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.7796 - val_acc: 0.5500\n",
      "Epoch 1870/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.5500\n",
      "Epoch 1871/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.5500\n",
      "Epoch 1872/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.7832 - val_acc: 0.5500\n",
      "Epoch 1873/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.5500\n",
      "Epoch 1874/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.7821 - val_acc: 0.5500\n",
      "Epoch 1875/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.5500\n",
      "Epoch 1876/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7817 - val_acc: 0.5500\n",
      "Epoch 1877/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.7829 - val_acc: 0.5500\n",
      "Epoch 1878/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.5500\n",
      "Epoch 1879/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.5500\n",
      "Epoch 1880/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.7855 - val_acc: 0.5500\n",
      "Epoch 1881/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.7855 - val_acc: 0.5500\n",
      "Epoch 1882/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.7852 - val_acc: 0.5500\n",
      "Epoch 1883/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.7853 - val_acc: 0.5500\n",
      "Epoch 1884/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.7848 - val_acc: 0.5500\n",
      "Epoch 1885/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.7830 - val_acc: 0.5500\n",
      "Epoch 1886/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.7830 - val_acc: 0.5500\n",
      "Epoch 1887/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.7881 - val_acc: 0.5500\n",
      "Epoch 1888/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.5500\n",
      "Epoch 1889/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.5500\n",
      "Epoch 1890/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.7923 - val_acc: 0.5500\n",
      "Epoch 1891/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.7951 - val_acc: 0.5500\n",
      "Epoch 1892/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.7939 - val_acc: 0.5500\n",
      "Epoch 1893/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.7939 - val_acc: 0.5500\n",
      "Epoch 1894/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.5500\n",
      "Epoch 1895/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7986 - val_acc: 0.5500\n",
      "Epoch 1896/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.7989 - val_acc: 0.5500\n",
      "Epoch 1897/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.7993 - val_acc: 0.5500\n",
      "Epoch 1898/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.7982 - val_acc: 0.5500\n",
      "Epoch 1899/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.7987 - val_acc: 0.5500\n",
      "Epoch 1900/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 0.5500\n",
      "Epoch 1901/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7999 - val_acc: 0.5500\n",
      "Epoch 1902/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.8004 - val_acc: 0.5500\n",
      "Epoch 1903/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.8020 - val_acc: 0.5500\n",
      "Epoch 1904/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.5500\n",
      "Epoch 1905/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.8011 - val_acc: 0.5500\n",
      "Epoch 1906/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.7955 - val_acc: 0.5500\n",
      "Epoch 1907/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.7939 - val_acc: 0.5500\n",
      "Epoch 1908/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 0.5500\n",
      "Epoch 1909/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.8020 - val_acc: 0.5500\n",
      "Epoch 1910/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.7993 - val_acc: 0.5500\n",
      "Epoch 1911/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.5500\n",
      "Epoch 1912/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.8033 - val_acc: 0.5500\n",
      "Epoch 1913/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.8009 - val_acc: 0.5500\n",
      "Epoch 1914/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.5500\n",
      "Epoch 1915/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.8047 - val_acc: 0.5500\n",
      "Epoch 1916/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.5500\n",
      "Epoch 1917/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.8055 - val_acc: 0.5500\n",
      "Epoch 1918/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.5500\n",
      "Epoch 1919/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.8029 - val_acc: 0.5500\n",
      "Epoch 1920/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.8023 - val_acc: 0.5500\n",
      "Epoch 1921/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.8045 - val_acc: 0.5500\n",
      "Epoch 1922/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.8007 - val_acc: 0.5500\n",
      "Epoch 1923/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.7997 - val_acc: 0.5500\n",
      "Epoch 1924/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.8002 - val_acc: 0.5500\n",
      "Epoch 1925/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.8019 - val_acc: 0.5500\n",
      "Epoch 1926/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.8071 - val_acc: 0.5500\n",
      "Epoch 1927/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.8058 - val_acc: 0.5500\n",
      "Epoch 1928/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.7955 - val_acc: 0.5500\n",
      "Epoch 1929/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.8104 - val_acc: 0.5500\n",
      "Epoch 1930/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.8115 - val_acc: 0.5500\n",
      "Epoch 1931/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.8117 - val_acc: 0.5500\n",
      "Epoch 1932/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.8140 - val_acc: 0.5500\n",
      "Epoch 1933/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.8160 - val_acc: 0.5500\n",
      "Epoch 1934/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.8142 - val_acc: 0.5500\n",
      "Epoch 1935/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.8167 - val_acc: 0.5500\n",
      "Epoch 1936/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.8126 - val_acc: 0.5500\n",
      "Epoch 1937/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.8120 - val_acc: 0.5500\n",
      "Epoch 1938/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.8150 - val_acc: 0.5500\n",
      "Epoch 1939/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.8109 - val_acc: 0.5500\n",
      "Epoch 1940/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.8122 - val_acc: 0.5500\n",
      "Epoch 1941/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.5500\n",
      "Epoch 1942/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.8159 - val_acc: 0.5500\n",
      "Epoch 1943/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.8162 - val_acc: 0.5500\n",
      "Epoch 1944/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.8181 - val_acc: 0.5500\n",
      "Epoch 1945/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.8194 - val_acc: 0.5500\n",
      "Epoch 1946/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.8211 - val_acc: 0.5500\n",
      "Epoch 1947/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.8208 - val_acc: 0.5500\n",
      "Epoch 1948/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.8219 - val_acc: 0.5500\n",
      "Epoch 1949/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.8213 - val_acc: 0.5500\n",
      "Epoch 1950/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.8227 - val_acc: 0.5500\n",
      "Epoch 1951/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.8192 - val_acc: 0.5500\n",
      "Epoch 1952/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.8200 - val_acc: 0.5500\n",
      "Epoch 1953/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.8214 - val_acc: 0.5500\n",
      "Epoch 1954/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.5500\n",
      "Epoch 1955/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.8198 - val_acc: 0.5500\n",
      "Epoch 1956/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8199 - val_acc: 0.5500\n",
      "Epoch 1957/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8199 - val_acc: 0.5500\n",
      "Epoch 1958/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.8146 - val_acc: 0.5500\n",
      "Epoch 1959/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.8162 - val_acc: 0.5500\n",
      "Epoch 1960/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.5500\n",
      "Epoch 1961/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.8138 - val_acc: 0.5500\n",
      "Epoch 1962/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 0.5500\n",
      "Epoch 1963/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.8197 - val_acc: 0.5500\n",
      "Epoch 1964/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.5500\n",
      "Epoch 1965/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.5500\n",
      "Epoch 1966/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 0.5500\n",
      "Epoch 1967/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.8255 - val_acc: 0.5500\n",
      "Epoch 1968/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.8224 - val_acc: 0.5500\n",
      "Epoch 1969/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.8259 - val_acc: 0.5500\n",
      "Epoch 1970/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.8218 - val_acc: 0.5500\n",
      "Epoch 1971/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.8230 - val_acc: 0.5500\n",
      "Epoch 1972/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.8251 - val_acc: 0.5500\n",
      "Epoch 1973/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.8252 - val_acc: 0.5500\n",
      "Epoch 1974/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.8264 - val_acc: 0.5500\n",
      "Epoch 1975/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.8276 - val_acc: 0.5500\n",
      "Epoch 1976/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.5500\n",
      "Epoch 1977/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.5500\n",
      "Epoch 1978/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.5500\n",
      "Epoch 1979/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.8230 - val_acc: 0.5500\n",
      "Epoch 1980/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.8244 - val_acc: 0.5500\n",
      "Epoch 1981/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.8233 - val_acc: 0.5500\n",
      "Epoch 1982/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.8242 - val_acc: 0.5500\n",
      "Epoch 1983/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.8281 - val_acc: 0.5500\n",
      "Epoch 1984/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.8293 - val_acc: 0.5500\n",
      "Epoch 1985/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.5500\n",
      "Epoch 1986/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.8275 - val_acc: 0.5500\n",
      "Epoch 1987/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.8280 - val_acc: 0.5500\n",
      "Epoch 1988/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.8275 - val_acc: 0.5500\n",
      "Epoch 1989/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.8285 - val_acc: 0.5500\n",
      "Epoch 1990/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.5500\n",
      "Epoch 1991/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.5500\n",
      "Epoch 1992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.8288 - val_acc: 0.5500\n",
      "Epoch 1993/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.5500\n",
      "Epoch 1994/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.8307 - val_acc: 0.5500\n",
      "Epoch 1995/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.8306 - val_acc: 0.5500\n",
      "Epoch 1996/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.8301 - val_acc: 0.5500\n",
      "Epoch 1997/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.8325 - val_acc: 0.5500\n",
      "Epoch 1998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.8348 - val_acc: 0.5500\n",
      "Epoch 1999/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.8342 - val_acc: 0.5500\n",
      "Epoch 2000/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.5500\n",
      "Epoch 2001/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.8347 - val_acc: 0.5500\n",
      "Epoch 2002/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.8333 - val_acc: 0.5500\n",
      "Epoch 2003/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.8366 - val_acc: 0.5500\n",
      "Epoch 2004/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.5500\n",
      "Epoch 2005/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.5500\n",
      "Epoch 2006/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.8362 - val_acc: 0.5500\n",
      "Epoch 2007/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.8360 - val_acc: 0.5500\n",
      "Epoch 2008/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.8366 - val_acc: 0.5500\n",
      "Epoch 2009/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.5500\n",
      "Epoch 2010/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.5500\n",
      "Epoch 2011/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.8382 - val_acc: 0.5500\n",
      "Epoch 2012/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.8370 - val_acc: 0.5500\n",
      "Epoch 2013/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.8384 - val_acc: 0.5500\n",
      "Epoch 2014/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.5500\n",
      "Epoch 2015/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.8400 - val_acc: 0.5500\n",
      "Epoch 2016/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.8403 - val_acc: 0.5500\n",
      "Epoch 2017/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.8418 - val_acc: 0.5500\n",
      "Epoch 2018/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.8432 - val_acc: 0.5500\n",
      "Epoch 2019/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.5500\n",
      "Epoch 2020/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.5500\n",
      "Epoch 2021/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.8421 - val_acc: 0.5500\n",
      "Epoch 2022/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.8431 - val_acc: 0.5500\n",
      "Epoch 2023/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.8389 - val_acc: 0.5500\n",
      "Epoch 2024/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.8403 - val_acc: 0.5500\n",
      "Epoch 2025/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.5500\n",
      "Epoch 2026/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.5500\n",
      "Epoch 2027/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.8403 - val_acc: 0.5500\n",
      "Epoch 2028/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.8396 - val_acc: 0.5500\n",
      "Epoch 2029/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.5500\n",
      "Epoch 2030/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.8422 - val_acc: 0.5500\n",
      "Epoch 2031/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.5500\n",
      "Epoch 2032/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.5500\n",
      "Epoch 2033/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.5500\n",
      "Epoch 2034/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.8441 - val_acc: 0.5500\n",
      "Epoch 2035/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.8444 - val_acc: 0.5500\n",
      "Epoch 2036/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.8446 - val_acc: 0.5500\n",
      "Epoch 2037/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.8448 - val_acc: 0.5500\n",
      "Epoch 2038/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.8419 - val_acc: 0.5500\n",
      "Epoch 2039/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8414 - val_acc: 0.5500\n",
      "Epoch 2040/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.5500\n",
      "Epoch 2041/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8469 - val_acc: 0.5500\n",
      "Epoch 2042/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.8465 - val_acc: 0.5500\n",
      "Epoch 2043/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.8441 - val_acc: 0.5500\n",
      "Epoch 2044/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.8408 - val_acc: 0.5500\n",
      "Epoch 2045/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.5500\n",
      "Epoch 2046/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.8425 - val_acc: 0.5500\n",
      "Epoch 2047/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.8451 - val_acc: 0.5500\n",
      "Epoch 2048/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.5500\n",
      "Epoch 2049/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.8521 - val_acc: 0.5500\n",
      "Epoch 2050/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.5500\n",
      "Epoch 2051/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.8515 - val_acc: 0.5500\n",
      "Epoch 2052/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.5500\n",
      "Epoch 2053/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.8486 - val_acc: 0.5500\n",
      "Epoch 2054/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.8469 - val_acc: 0.5500\n",
      "Epoch 2055/3000\n",
      "79/79 [==============================] - 0s 104us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.8480 - val_acc: 0.5500\n",
      "Epoch 2056/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.8503 - val_acc: 0.5500\n",
      "Epoch 2057/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.5500\n",
      "Epoch 2058/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.8510 - val_acc: 0.5500\n",
      "Epoch 2059/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.8516 - val_acc: 0.5500\n",
      "Epoch 2060/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.8496 - val_acc: 0.5500\n",
      "Epoch 2061/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.8509 - val_acc: 0.5500\n",
      "Epoch 2062/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.8534 - val_acc: 0.5500\n",
      "Epoch 2063/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.8564 - val_acc: 0.5500\n",
      "Epoch 2064/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.5500\n",
      "Epoch 2065/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.8526 - val_acc: 0.5500\n",
      "Epoch 2066/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 0.5500\n",
      "Epoch 2067/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 0.5500\n",
      "Epoch 2068/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.8522 - val_acc: 0.5500\n",
      "Epoch 2069/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.8503 - val_acc: 0.5500\n",
      "Epoch 2070/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 0.5500\n",
      "Epoch 2071/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.8519 - val_acc: 0.5500\n",
      "Epoch 2072/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.8501 - val_acc: 0.5500\n",
      "Epoch 2073/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.8478 - val_acc: 0.5500\n",
      "Epoch 2074/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.8483 - val_acc: 0.5500\n",
      "Epoch 2075/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.8476 - val_acc: 0.5500\n",
      "Epoch 2076/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.5500\n",
      "Epoch 2077/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.5500\n",
      "Epoch 2078/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.8532 - val_acc: 0.5500\n",
      "Epoch 2079/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 0.5500\n",
      "Epoch 2080/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.8573 - val_acc: 0.5500\n",
      "Epoch 2081/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.5500\n",
      "Epoch 2082/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.8594 - val_acc: 0.5500\n",
      "Epoch 2083/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.8608 - val_acc: 0.5500\n",
      "Epoch 2084/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.5500\n",
      "Epoch 2085/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.8619 - val_acc: 0.5500\n",
      "Epoch 2086/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.8594 - val_acc: 0.5500\n",
      "Epoch 2087/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.8602 - val_acc: 0.5500\n",
      "Epoch 2088/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.5500\n",
      "Epoch 2089/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.8594 - val_acc: 0.5500\n",
      "Epoch 2090/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.8612 - val_acc: 0.5500\n",
      "Epoch 2091/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.8640 - val_acc: 0.5500\n",
      "Epoch 2092/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.8658 - val_acc: 0.5500\n",
      "Epoch 2093/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.5500\n",
      "Epoch 2094/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.5500\n",
      "Epoch 2095/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.5500\n",
      "Epoch 2096/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.5500\n",
      "Epoch 2097/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.5500\n",
      "Epoch 2098/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.8622 - val_acc: 0.5500\n",
      "Epoch 2099/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.5500\n",
      "Epoch 2100/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.8615 - val_acc: 0.5500\n",
      "Epoch 2101/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.5500\n",
      "Epoch 2102/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.8629 - val_acc: 0.5500\n",
      "Epoch 2103/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.5500\n",
      "Epoch 2104/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.8667 - val_acc: 0.5500\n",
      "Epoch 2105/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.8684 - val_acc: 0.5500\n",
      "Epoch 2106/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.5500\n",
      "Epoch 2107/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.5500\n",
      "Epoch 2108/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.5500\n",
      "Epoch 2109/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.8707 - val_acc: 0.5500\n",
      "Epoch 2110/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.8656 - val_acc: 0.5500\n",
      "Epoch 2111/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.8618 - val_acc: 0.5500\n",
      "Epoch 2112/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.8629 - val_acc: 0.5500\n",
      "Epoch 2113/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.8646 - val_acc: 0.5500\n",
      "Epoch 2114/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.8668 - val_acc: 0.5500\n",
      "Epoch 2115/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.8673 - val_acc: 0.5500\n",
      "Epoch 2116/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.5500\n",
      "Epoch 2117/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.8678 - val_acc: 0.5500\n",
      "Epoch 2118/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.5500\n",
      "Epoch 2119/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.5500\n",
      "Epoch 2120/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.5500\n",
      "Epoch 2121/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.8650 - val_acc: 0.5500\n",
      "Epoch 2122/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.5500\n",
      "Epoch 2123/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.5500\n",
      "Epoch 2124/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.8680 - val_acc: 0.5500\n",
      "Epoch 2125/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.5500\n",
      "Epoch 2126/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.8665 - val_acc: 0.5500\n",
      "Epoch 2127/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.8671 - val_acc: 0.5500\n",
      "Epoch 2128/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.5500\n",
      "Epoch 2129/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.8687 - val_acc: 0.5500\n",
      "Epoch 2130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.8697 - val_acc: 0.5500\n",
      "Epoch 2131/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.8697 - val_acc: 0.5500\n",
      "Epoch 2132/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.5500\n",
      "Epoch 2133/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.8737 - val_acc: 0.5500\n",
      "Epoch 2134/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.5500\n",
      "Epoch 2135/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.5500\n",
      "Epoch 2136/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.8734 - val_acc: 0.5500\n",
      "Epoch 2137/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.5500\n",
      "Epoch 2138/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.8694 - val_acc: 0.5500\n",
      "Epoch 2139/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.8713 - val_acc: 0.5500\n",
      "Epoch 2140/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.8712 - val_acc: 0.5500\n",
      "Epoch 2141/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.8703 - val_acc: 0.5500\n",
      "Epoch 2142/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.8706 - val_acc: 0.5500\n",
      "Epoch 2143/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.8713 - val_acc: 0.5500\n",
      "Epoch 2144/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.5500\n",
      "Epoch 2145/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 0.5500\n",
      "Epoch 2146/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.8740 - val_acc: 0.5500\n",
      "Epoch 2147/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.8755 - val_acc: 0.5500\n",
      "Epoch 2148/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.8765 - val_acc: 0.5500\n",
      "Epoch 2149/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.5500\n",
      "Epoch 2150/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8744 - val_acc: 0.5500\n",
      "Epoch 2151/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8765 - val_acc: 0.5500\n",
      "Epoch 2152/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8793 - val_acc: 0.5500\n",
      "Epoch 2153/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.5500\n",
      "Epoch 2154/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.8793 - val_acc: 0.5500\n",
      "Epoch 2155/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.8807 - val_acc: 0.5500\n",
      "Epoch 2156/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.8816 - val_acc: 0.5500\n",
      "Epoch 2157/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.8816 - val_acc: 0.5500\n",
      "Epoch 2158/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.8811 - val_acc: 0.5500\n",
      "Epoch 2159/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.8809 - val_acc: 0.5500\n",
      "Epoch 2160/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.5500\n",
      "Epoch 2161/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.8843 - val_acc: 0.5500\n",
      "Epoch 2162/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.8826 - val_acc: 0.5500\n",
      "Epoch 2163/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.8832 - val_acc: 0.5500\n",
      "Epoch 2164/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.5500\n",
      "Epoch 2165/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.5500\n",
      "Epoch 2166/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.8828 - val_acc: 0.5500\n",
      "Epoch 2167/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.8841 - val_acc: 0.5500\n",
      "Epoch 2168/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.8837 - val_acc: 0.5500\n",
      "Epoch 2169/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.8843 - val_acc: 0.5500\n",
      "Epoch 2170/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.5500\n",
      "Epoch 2171/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.8863 - val_acc: 0.5500\n",
      "Epoch 2172/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.8850 - val_acc: 0.5500\n",
      "Epoch 2173/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.5500\n",
      "Epoch 2174/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.5500\n",
      "Epoch 2175/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.8825 - val_acc: 0.5500\n",
      "Epoch 2176/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.8821 - val_acc: 0.5500\n",
      "Epoch 2177/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.8812 - val_acc: 0.5500\n",
      "Epoch 2178/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.8838 - val_acc: 0.5500\n",
      "Epoch 2179/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.8845 - val_acc: 0.5500\n",
      "Epoch 2180/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.8849 - val_acc: 0.5500\n",
      "Epoch 2181/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.5500\n",
      "Epoch 2182/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.8834 - val_acc: 0.5500\n",
      "Epoch 2183/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 0.5500\n",
      "Epoch 2184/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.8850 - val_acc: 0.5500\n",
      "Epoch 2185/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.8862 - val_acc: 0.5500\n",
      "Epoch 2186/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.8873 - val_acc: 0.5500\n",
      "Epoch 2187/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.8883 - val_acc: 0.5500\n",
      "Epoch 2188/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.8902 - val_acc: 0.5500\n",
      "Epoch 2189/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.8902 - val_acc: 0.5500\n",
      "Epoch 2190/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.5500\n",
      "Epoch 2191/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.8929 - val_acc: 0.5500\n",
      "Epoch 2192/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.8939 - val_acc: 0.5500\n",
      "Epoch 2193/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.8945 - val_acc: 0.5500\n",
      "Epoch 2194/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.8956 - val_acc: 0.5500\n",
      "Epoch 2195/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.8939 - val_acc: 0.5500\n",
      "Epoch 2196/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.8918 - val_acc: 0.5500\n",
      "Epoch 2197/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.8920 - val_acc: 0.5500\n",
      "Epoch 2198/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.8929 - val_acc: 0.5500\n",
      "Epoch 2199/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.8934 - val_acc: 0.5500\n",
      "Epoch 2200/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.8942 - val_acc: 0.5500\n",
      "Epoch 2201/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.8929 - val_acc: 0.5500\n",
      "Epoch 2202/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.8900 - val_acc: 0.5500\n",
      "Epoch 2203/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8888 - val_acc: 0.5500\n",
      "Epoch 2204/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8904 - val_acc: 0.5500\n",
      "Epoch 2205/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.5500\n",
      "Epoch 2206/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.5500\n",
      "Epoch 2207/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.5500\n",
      "Epoch 2208/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.5500\n",
      "Epoch 2209/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.8905 - val_acc: 0.5500\n",
      "Epoch 2210/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.8902 - val_acc: 0.5500\n",
      "Epoch 2211/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.8893 - val_acc: 0.5500\n",
      "Epoch 2212/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.8904 - val_acc: 0.5500\n",
      "Epoch 2213/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.8928 - val_acc: 0.5500\n",
      "Epoch 2214/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.8925 - val_acc: 0.5500\n",
      "Epoch 2215/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.5500\n",
      "Epoch 2216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.8925 - val_acc: 0.5500\n",
      "Epoch 2217/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.8943 - val_acc: 0.5500\n",
      "Epoch 2218/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.5500\n",
      "Epoch 2219/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.8967 - val_acc: 0.5500\n",
      "Epoch 2220/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.8973 - val_acc: 0.5500\n",
      "Epoch 2221/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.5500\n",
      "Epoch 2222/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8986 - val_acc: 0.5500\n",
      "Epoch 2223/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8979 - val_acc: 0.5500\n",
      "Epoch 2224/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8979 - val_acc: 0.5500\n",
      "Epoch 2225/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8990 - val_acc: 0.5500\n",
      "Epoch 2226/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8966 - val_acc: 0.5500\n",
      "Epoch 2227/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8955 - val_acc: 0.5500\n",
      "Epoch 2228/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.5500\n",
      "Epoch 2229/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.8931 - val_acc: 0.5500\n",
      "Epoch 2230/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.8935 - val_acc: 0.5500\n",
      "Epoch 2231/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.8945 - val_acc: 0.5500\n",
      "Epoch 2232/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.5500\n",
      "Epoch 2233/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.9012 - val_acc: 0.5500\n",
      "Epoch 2234/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9019 - val_acc: 0.5500\n",
      "Epoch 2235/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9020 - val_acc: 0.5500\n",
      "Epoch 2236/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5500\n",
      "Epoch 2237/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9033 - val_acc: 0.5500\n",
      "Epoch 2238/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5500\n",
      "Epoch 2239/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9010 - val_acc: 0.5500\n",
      "Epoch 2240/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9009 - val_acc: 0.5500\n",
      "Epoch 2241/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.9028 - val_acc: 0.5500\n",
      "Epoch 2242/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.9060 - val_acc: 0.5500\n",
      "Epoch 2243/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.9058 - val_acc: 0.5500\n",
      "Epoch 2244/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.9057 - val_acc: 0.5500\n",
      "Epoch 2245/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.9065 - val_acc: 0.5500\n",
      "Epoch 2246/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.9085 - val_acc: 0.5500\n",
      "Epoch 2247/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.9100 - val_acc: 0.5500\n",
      "Epoch 2248/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.9097 - val_acc: 0.5500\n",
      "Epoch 2249/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.9079 - val_acc: 0.5500\n",
      "Epoch 2250/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.9064 - val_acc: 0.5500\n",
      "Epoch 2251/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.9069 - val_acc: 0.5500\n",
      "Epoch 2252/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9068 - val_acc: 0.5500\n",
      "Epoch 2253/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9051 - val_acc: 0.5500\n",
      "Epoch 2254/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9044 - val_acc: 0.5500\n",
      "Epoch 2255/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9034 - val_acc: 0.5500\n",
      "Epoch 2256/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.9036 - val_acc: 0.5500\n",
      "Epoch 2257/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5500\n",
      "Epoch 2258/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.9028 - val_acc: 0.5500\n",
      "Epoch 2259/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.9019 - val_acc: 0.5500\n",
      "Epoch 2260/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.5500\n",
      "Epoch 2261/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.9042 - val_acc: 0.5500\n",
      "Epoch 2262/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9043 - val_acc: 0.5500\n",
      "Epoch 2263/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9062 - val_acc: 0.5500\n",
      "Epoch 2264/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9071 - val_acc: 0.5500\n",
      "Epoch 2265/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9038 - val_acc: 0.5500\n",
      "Epoch 2266/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9023 - val_acc: 0.5500\n",
      "Epoch 2267/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5500\n",
      "Epoch 2268/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.9060 - val_acc: 0.5500\n",
      "Epoch 2269/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.9042 - val_acc: 0.5500\n",
      "Epoch 2270/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.9050 - val_acc: 0.5500\n",
      "Epoch 2271/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.9071 - val_acc: 0.5500\n",
      "Epoch 2272/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.9076 - val_acc: 0.5500\n",
      "Epoch 2273/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.9102 - val_acc: 0.5500\n",
      "Epoch 2274/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.9110 - val_acc: 0.5500\n",
      "Epoch 2275/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.9102 - val_acc: 0.5500\n",
      "Epoch 2276/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.5500\n",
      "Epoch 2277/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.9099 - val_acc: 0.5500\n",
      "Epoch 2278/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.5500\n",
      "Epoch 2279/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9112 - val_acc: 0.5500\n",
      "Epoch 2280/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9108 - val_acc: 0.5500\n",
      "Epoch 2281/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.5500\n",
      "Epoch 2282/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.5500\n",
      "Epoch 2283/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9119 - val_acc: 0.5500\n",
      "Epoch 2284/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9134 - val_acc: 0.5500\n",
      "Epoch 2285/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.9139 - val_acc: 0.5500\n",
      "Epoch 2286/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.9145 - val_acc: 0.5500\n",
      "Epoch 2287/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.9142 - val_acc: 0.5500\n",
      "Epoch 2288/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.9153 - val_acc: 0.5500\n",
      "Epoch 2289/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.9164 - val_acc: 0.5500\n",
      "Epoch 2290/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9163 - val_acc: 0.5500\n",
      "Epoch 2291/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.5500\n",
      "Epoch 2292/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9189 - val_acc: 0.5500\n",
      "Epoch 2293/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.5500\n",
      "Epoch 2294/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9187 - val_acc: 0.5500\n",
      "Epoch 2295/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9184 - val_acc: 0.5500\n",
      "Epoch 2296/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.9179 - val_acc: 0.5500\n",
      "Epoch 2297/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.5500\n",
      "Epoch 2298/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.5500\n",
      "Epoch 2299/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.5500\n",
      "Epoch 2300/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9162 - val_acc: 0.5500\n",
      "Epoch 2301/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9167 - val_acc: 0.5500\n",
      "Epoch 2302/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.5500\n",
      "Epoch 2303/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9180 - val_acc: 0.5500\n",
      "Epoch 2304/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.9188 - val_acc: 0.5500\n",
      "Epoch 2305/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.9191 - val_acc: 0.5500\n",
      "Epoch 2306/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.9181 - val_acc: 0.5500\n",
      "Epoch 2307/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.9158 - val_acc: 0.5500\n",
      "Epoch 2308/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9160 - val_acc: 0.5500\n",
      "Epoch 2309/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 0.5500\n",
      "Epoch 2310/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9170 - val_acc: 0.5500\n",
      "Epoch 2311/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9189 - val_acc: 0.5500\n",
      "Epoch 2312/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9178 - val_acc: 0.5500\n",
      "Epoch 2313/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9174 - val_acc: 0.5500\n",
      "Epoch 2314/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9183 - val_acc: 0.5500\n",
      "Epoch 2315/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9174 - val_acc: 0.5500\n",
      "Epoch 2316/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.5500\n",
      "Epoch 2317/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9194 - val_acc: 0.5500\n",
      "Epoch 2318/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9188 - val_acc: 0.5500\n",
      "Epoch 2319/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9204 - val_acc: 0.5500\n",
      "Epoch 2320/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.5500\n",
      "Epoch 2321/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9220 - val_acc: 0.5500\n",
      "Epoch 2322/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9219 - val_acc: 0.5500\n",
      "Epoch 2323/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.5500\n",
      "Epoch 2324/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9207 - val_acc: 0.5500\n",
      "Epoch 2325/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9217 - val_acc: 0.5500\n",
      "Epoch 2326/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9208 - val_acc: 0.5500\n",
      "Epoch 2327/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.5500\n",
      "Epoch 2328/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9199 - val_acc: 0.5500\n",
      "Epoch 2329/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9220 - val_acc: 0.5500\n",
      "Epoch 2330/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.9212 - val_acc: 0.5500\n",
      "Epoch 2331/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9216 - val_acc: 0.5500\n",
      "Epoch 2332/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.5500\n",
      "Epoch 2333/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9208 - val_acc: 0.5500\n",
      "Epoch 2334/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9205 - val_acc: 0.5500\n",
      "Epoch 2335/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9208 - val_acc: 0.5500\n",
      "Epoch 2336/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9219 - val_acc: 0.5500\n",
      "Epoch 2337/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9222 - val_acc: 0.5500\n",
      "Epoch 2338/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9224 - val_acc: 0.5500\n",
      "Epoch 2339/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9230 - val_acc: 0.5500\n",
      "Epoch 2340/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.5500\n",
      "Epoch 2341/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9213 - val_acc: 0.5500\n",
      "Epoch 2342/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.9238 - val_acc: 0.5500\n",
      "Epoch 2343/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.9243 - val_acc: 0.5500\n",
      "Epoch 2344/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.9246 - val_acc: 0.5500\n",
      "Epoch 2345/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.9234 - val_acc: 0.5500\n",
      "Epoch 2346/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9242 - val_acc: 0.5500\n",
      "Epoch 2347/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9258 - val_acc: 0.5500\n",
      "Epoch 2348/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9276 - val_acc: 0.5500\n",
      "Epoch 2349/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9273 - val_acc: 0.5500\n",
      "Epoch 2350/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9275 - val_acc: 0.5500\n",
      "Epoch 2351/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9285 - val_acc: 0.5500\n",
      "Epoch 2352/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9305 - val_acc: 0.5500\n",
      "Epoch 2353/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.5500\n",
      "Epoch 2354/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9276 - val_acc: 0.5500\n",
      "Epoch 2355/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.5500\n",
      "Epoch 2356/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9296 - val_acc: 0.5500\n",
      "Epoch 2357/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9303 - val_acc: 0.5500\n",
      "Epoch 2358/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.5500\n",
      "Epoch 2359/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 0.5500\n",
      "Epoch 2360/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9317 - val_acc: 0.5500\n",
      "Epoch 2361/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9316 - val_acc: 0.5500\n",
      "Epoch 2362/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.9314 - val_acc: 0.5500\n",
      "Epoch 2363/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.9316 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2364/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9300 - val_acc: 0.5500\n",
      "Epoch 2365/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9313 - val_acc: 0.5500\n",
      "Epoch 2366/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.5500\n",
      "Epoch 2367/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9345 - val_acc: 0.5500\n",
      "Epoch 2368/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9353 - val_acc: 0.5500\n",
      "Epoch 2369/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.5500\n",
      "Epoch 2370/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9349 - val_acc: 0.5500\n",
      "Epoch 2371/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9346 - val_acc: 0.5500\n",
      "Epoch 2372/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9362 - val_acc: 0.5500\n",
      "Epoch 2373/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9368 - val_acc: 0.5500\n",
      "Epoch 2374/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9385 - val_acc: 0.5500\n",
      "Epoch 2375/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.9386 - val_acc: 0.5500\n",
      "Epoch 2376/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.9388 - val_acc: 0.5500\n",
      "Epoch 2377/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.5500\n",
      "Epoch 2378/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.9382 - val_acc: 0.5500\n",
      "Epoch 2379/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9391 - val_acc: 0.5500\n",
      "Epoch 2380/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.5500\n",
      "Epoch 2381/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9427 - val_acc: 0.5500\n",
      "Epoch 2382/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.5500\n",
      "Epoch 2383/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5500\n",
      "Epoch 2384/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9430 - val_acc: 0.5500\n",
      "Epoch 2385/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9433 - val_acc: 0.5500\n",
      "Epoch 2386/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9431 - val_acc: 0.5500\n",
      "Epoch 2387/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5500\n",
      "Epoch 2388/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9405 - val_acc: 0.5500\n",
      "Epoch 2389/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9410 - val_acc: 0.5500\n",
      "Epoch 2390/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9418 - val_acc: 0.5500\n",
      "Epoch 2391/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9438 - val_acc: 0.5500\n",
      "Epoch 2392/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.5500\n",
      "Epoch 2393/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9426 - val_acc: 0.5500\n",
      "Epoch 2394/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9440 - val_acc: 0.5500\n",
      "Epoch 2395/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9432 - val_acc: 0.5500\n",
      "Epoch 2396/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9450 - val_acc: 0.5500\n",
      "Epoch 2397/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9443 - val_acc: 0.5500\n",
      "Epoch 2398/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9450 - val_acc: 0.5500\n",
      "Epoch 2399/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9446 - val_acc: 0.5500\n",
      "Epoch 2400/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9447 - val_acc: 0.5500\n",
      "Epoch 2401/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9435 - val_acc: 0.5500\n",
      "Epoch 2402/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9406 - val_acc: 0.5500\n",
      "Epoch 2403/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.9412 - val_acc: 0.5500\n",
      "Epoch 2404/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9413 - val_acc: 0.5500\n",
      "Epoch 2405/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.5500\n",
      "Epoch 2406/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9403 - val_acc: 0.5500\n",
      "Epoch 2407/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.5500\n",
      "Epoch 2408/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9402 - val_acc: 0.5500\n",
      "Epoch 2409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9397 - val_acc: 0.5500\n",
      "Epoch 2410/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9411 - val_acc: 0.5500\n",
      "Epoch 2411/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5500\n",
      "Epoch 2412/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.5500\n",
      "Epoch 2413/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9431 - val_acc: 0.5500\n",
      "Epoch 2414/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9431 - val_acc: 0.5500\n",
      "Epoch 2415/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9435 - val_acc: 0.5500\n",
      "Epoch 2416/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.9446 - val_acc: 0.5500\n",
      "Epoch 2417/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9469 - val_acc: 0.5500\n",
      "Epoch 2418/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9487 - val_acc: 0.5500\n",
      "Epoch 2419/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9488 - val_acc: 0.5500\n",
      "Epoch 2420/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9513 - val_acc: 0.5500\n",
      "Epoch 2421/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9511 - val_acc: 0.5500\n",
      "Epoch 2422/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9516 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2423/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9512 - val_acc: 0.5500\n",
      "Epoch 2424/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9488 - val_acc: 0.5500\n",
      "Epoch 2425/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9505 - val_acc: 0.5500\n",
      "Epoch 2426/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9500 - val_acc: 0.5500\n",
      "Epoch 2427/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9496 - val_acc: 0.5500\n",
      "Epoch 2428/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9482 - val_acc: 0.5500\n",
      "Epoch 2429/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9479 - val_acc: 0.5500\n",
      "Epoch 2430/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9488 - val_acc: 0.5500\n",
      "Epoch 2431/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9490 - val_acc: 0.5500\n",
      "Epoch 2432/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9477 - val_acc: 0.5500\n",
      "Epoch 2433/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9478 - val_acc: 0.5500\n",
      "Epoch 2434/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9475 - val_acc: 0.5500\n",
      "Epoch 2435/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9474 - val_acc: 0.5500\n",
      "Epoch 2436/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9476 - val_acc: 0.5500\n",
      "Epoch 2437/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9486 - val_acc: 0.5500\n",
      "Epoch 2438/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9514 - val_acc: 0.5500\n",
      "Epoch 2439/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9537 - val_acc: 0.5500\n",
      "Epoch 2440/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9538 - val_acc: 0.5500\n",
      "Epoch 2441/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.5500\n",
      "Epoch 2442/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9517 - val_acc: 0.5500\n",
      "Epoch 2443/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9526 - val_acc: 0.5500\n",
      "Epoch 2444/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.5500\n",
      "Epoch 2445/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.9505 - val_acc: 0.5500\n",
      "Epoch 2446/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.5500\n",
      "Epoch 2447/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9518 - val_acc: 0.5500\n",
      "Epoch 2448/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9521 - val_acc: 0.5500\n",
      "Epoch 2449/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.5500\n",
      "Epoch 2450/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.5500\n",
      "Epoch 2451/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9547 - val_acc: 0.5500\n",
      "Epoch 2452/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9539 - val_acc: 0.5500\n",
      "Epoch 2453/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.5500\n",
      "Epoch 2454/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.5500\n",
      "Epoch 2455/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9534 - val_acc: 0.5500\n",
      "Epoch 2456/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9564 - val_acc: 0.5500\n",
      "Epoch 2457/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9541 - val_acc: 0.5500\n",
      "Epoch 2458/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9540 - val_acc: 0.5500\n",
      "Epoch 2459/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9542 - val_acc: 0.5500\n",
      "Epoch 2460/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9519 - val_acc: 0.5500\n",
      "Epoch 2461/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9537 - val_acc: 0.5500\n",
      "Epoch 2462/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9543 - val_acc: 0.5500\n",
      "Epoch 2463/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9556 - val_acc: 0.5500\n",
      "Epoch 2464/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9563 - val_acc: 0.5500\n",
      "Epoch 2465/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.9589 - val_acc: 0.5500\n",
      "Epoch 2466/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9592 - val_acc: 0.5500\n",
      "Epoch 2467/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9600 - val_acc: 0.5500\n",
      "Epoch 2468/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9599 - val_acc: 0.5500\n",
      "Epoch 2469/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9602 - val_acc: 0.5500\n",
      "Epoch 2470/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9604 - val_acc: 0.5500\n",
      "Epoch 2471/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9604 - val_acc: 0.5500\n",
      "Epoch 2472/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9613 - val_acc: 0.5500\n",
      "Epoch 2473/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9615 - val_acc: 0.5500\n",
      "Epoch 2474/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9614 - val_acc: 0.5500\n",
      "Epoch 2475/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9609 - val_acc: 0.5500\n",
      "Epoch 2476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.5500\n",
      "Epoch 2477/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9591 - val_acc: 0.5500\n",
      "Epoch 2478/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9587 - val_acc: 0.5500\n",
      "Epoch 2479/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9596 - val_acc: 0.5500\n",
      "Epoch 2480/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9590 - val_acc: 0.5500\n",
      "Epoch 2481/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.9611 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2482/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.5500\n",
      "Epoch 2483/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9604 - val_acc: 0.5500\n",
      "Epoch 2484/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9619 - val_acc: 0.5500\n",
      "Epoch 2485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9622 - val_acc: 0.5500\n",
      "Epoch 2486/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.5500\n",
      "Epoch 2487/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9632 - val_acc: 0.5500\n",
      "Epoch 2488/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.5500\n",
      "Epoch 2489/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9623 - val_acc: 0.5500\n",
      "Epoch 2490/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9634 - val_acc: 0.5500\n",
      "Epoch 2491/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.5500\n",
      "Epoch 2492/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9659 - val_acc: 0.5500\n",
      "Epoch 2493/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9654 - val_acc: 0.5500\n",
      "Epoch 2494/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9644 - val_acc: 0.5500\n",
      "Epoch 2495/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9646 - val_acc: 0.5500\n",
      "Epoch 2496/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9662 - val_acc: 0.5500\n",
      "Epoch 2497/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9665 - val_acc: 0.5500\n",
      "Epoch 2498/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9680 - val_acc: 0.5500\n",
      "Epoch 2499/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.5500\n",
      "Epoch 2500/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9678 - val_acc: 0.5500\n",
      "Epoch 2501/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.5500\n",
      "Epoch 2502/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9692 - val_acc: 0.5500\n",
      "Epoch 2503/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9703 - val_acc: 0.5500\n",
      "Epoch 2504/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.9700 - val_acc: 0.5500\n",
      "Epoch 2505/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9675 - val_acc: 0.5500\n",
      "Epoch 2506/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9670 - val_acc: 0.5500\n",
      "Epoch 2507/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9683 - val_acc: 0.5500\n",
      "Epoch 2508/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.5500\n",
      "Epoch 2509/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9679 - val_acc: 0.5500\n",
      "Epoch 2510/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9685 - val_acc: 0.5500\n",
      "Epoch 2511/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9696 - val_acc: 0.5500\n",
      "Epoch 2512/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9699 - val_acc: 0.5500\n",
      "Epoch 2513/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.5500\n",
      "Epoch 2514/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.5500\n",
      "Epoch 2515/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9706 - val_acc: 0.5500\n",
      "Epoch 2516/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9715 - val_acc: 0.5500\n",
      "Epoch 2517/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9725 - val_acc: 0.5500\n",
      "Epoch 2518/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9722 - val_acc: 0.5500\n",
      "Epoch 2519/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9720 - val_acc: 0.5500\n",
      "Epoch 2520/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.5500\n",
      "Epoch 2521/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9739 - val_acc: 0.5500\n",
      "Epoch 2522/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9748 - val_acc: 0.5500\n",
      "Epoch 2523/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.5500\n",
      "Epoch 2524/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9740 - val_acc: 0.5500\n",
      "Epoch 2525/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9761 - val_acc: 0.5500\n",
      "Epoch 2526/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9764 - val_acc: 0.5500\n",
      "Epoch 2527/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9766 - val_acc: 0.5500\n",
      "Epoch 2528/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9768 - val_acc: 0.5500\n",
      "Epoch 2529/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.5500\n",
      "Epoch 2530/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9753 - val_acc: 0.5500\n",
      "Epoch 2531/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9761 - val_acc: 0.5500\n",
      "Epoch 2532/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9759 - val_acc: 0.5500\n",
      "Epoch 2533/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9756 - val_acc: 0.5500\n",
      "Epoch 2534/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9765 - val_acc: 0.5500\n",
      "Epoch 2535/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.5500\n",
      "Epoch 2536/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9758 - val_acc: 0.5500\n",
      "Epoch 2537/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9772 - val_acc: 0.5500\n",
      "Epoch 2538/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9761 - val_acc: 0.5500\n",
      "Epoch 2539/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.9744 - val_acc: 0.5500\n",
      "Epoch 2540/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2541/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9740 - val_acc: 0.5500\n",
      "Epoch 2542/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9745 - val_acc: 0.5500\n",
      "Epoch 2543/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9737 - val_acc: 0.5500\n",
      "Epoch 2544/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.5500\n",
      "Epoch 2545/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.5500\n",
      "Epoch 2546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9737 - val_acc: 0.5500\n",
      "Epoch 2547/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.5500\n",
      "Epoch 2548/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9766 - val_acc: 0.5500\n",
      "Epoch 2549/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9760 - val_acc: 0.5500\n",
      "Epoch 2550/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9758 - val_acc: 0.5500\n",
      "Epoch 2551/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9739 - val_acc: 0.5500\n",
      "Epoch 2552/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9723 - val_acc: 0.5500\n",
      "Epoch 2553/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9704 - val_acc: 0.5500\n",
      "Epoch 2554/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9707 - val_acc: 0.5500\n",
      "Epoch 2555/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9718 - val_acc: 0.5500\n",
      "Epoch 2556/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9725 - val_acc: 0.5500\n",
      "Epoch 2557/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9715 - val_acc: 0.5500\n",
      "Epoch 2558/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9718 - val_acc: 0.5500\n",
      "Epoch 2559/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9729 - val_acc: 0.5500\n",
      "Epoch 2560/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9750 - val_acc: 0.5500\n",
      "Epoch 2561/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.5500\n",
      "Epoch 2562/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9760 - val_acc: 0.5500\n",
      "Epoch 2563/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.5500\n",
      "Epoch 2564/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9792 - val_acc: 0.5500\n",
      "Epoch 2565/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9799 - val_acc: 0.5500\n",
      "Epoch 2566/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9796 - val_acc: 0.5500\n",
      "Epoch 2567/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9802 - val_acc: 0.5500\n",
      "Epoch 2568/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9810 - val_acc: 0.5500\n",
      "Epoch 2569/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.5500\n",
      "Epoch 2570/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.5500\n",
      "Epoch 2571/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9827 - val_acc: 0.5500\n",
      "Epoch 2572/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.5500\n",
      "Epoch 2573/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9868 - val_acc: 0.5500\n",
      "Epoch 2574/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.5500\n",
      "Epoch 2575/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.5500\n",
      "Epoch 2576/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9878 - val_acc: 0.5500\n",
      "Epoch 2577/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.5500\n",
      "Epoch 2578/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9870 - val_acc: 0.5500\n",
      "Epoch 2579/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9868 - val_acc: 0.5500\n",
      "Epoch 2580/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9869 - val_acc: 0.5500\n",
      "Epoch 2581/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9862 - val_acc: 0.5500\n",
      "Epoch 2582/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.5500\n",
      "Epoch 2583/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.5500\n",
      "Epoch 2584/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9836 - val_acc: 0.5500\n",
      "Epoch 2585/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9832 - val_acc: 0.5500\n",
      "Epoch 2586/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9818 - val_acc: 0.5500\n",
      "Epoch 2587/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9813 - val_acc: 0.5500\n",
      "Epoch 2588/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9807 - val_acc: 0.5500\n",
      "Epoch 2589/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9799 - val_acc: 0.5500\n",
      "Epoch 2590/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9807 - val_acc: 0.5500\n",
      "Epoch 2591/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9801 - val_acc: 0.5500\n",
      "Epoch 2592/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9782 - val_acc: 0.5500\n",
      "Epoch 2593/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.5500\n",
      "Epoch 2594/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.5500\n",
      "Epoch 2595/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9818 - val_acc: 0.5500\n",
      "Epoch 2596/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.5500\n",
      "Epoch 2597/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.9808 - val_acc: 0.5500\n",
      "Epoch 2598/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9816 - val_acc: 0.5500\n",
      "Epoch 2599/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2600/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9826 - val_acc: 0.5500\n",
      "Epoch 2601/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9833 - val_acc: 0.5500\n",
      "Epoch 2602/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9839 - val_acc: 0.5500\n",
      "Epoch 2603/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9835 - val_acc: 0.5500\n",
      "Epoch 2604/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9819 - val_acc: 0.5500\n",
      "Epoch 2605/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.5500\n",
      "Epoch 2606/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9831 - val_acc: 0.5500\n",
      "Epoch 2607/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.5500\n",
      "Epoch 2608/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9839 - val_acc: 0.5500\n",
      "Epoch 2609/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9839 - val_acc: 0.5500\n",
      "Epoch 2610/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9844 - val_acc: 0.5500\n",
      "Epoch 2611/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.5500\n",
      "Epoch 2612/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.5500\n",
      "Epoch 2613/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9836 - val_acc: 0.5500\n",
      "Epoch 2614/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9857 - val_acc: 0.5500\n",
      "Epoch 2615/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9861 - val_acc: 0.5500\n",
      "Epoch 2616/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9864 - val_acc: 0.5500\n",
      "Epoch 2617/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9865 - val_acc: 0.5500\n",
      "Epoch 2618/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9859 - val_acc: 0.5500\n",
      "Epoch 2619/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9851 - val_acc: 0.5500\n",
      "Epoch 2620/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9836 - val_acc: 0.5500\n",
      "Epoch 2621/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9846 - val_acc: 0.5500\n",
      "Epoch 2622/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9864 - val_acc: 0.5500\n",
      "Epoch 2623/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9865 - val_acc: 0.5500\n",
      "Epoch 2624/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9887 - val_acc: 0.5500\n",
      "Epoch 2625/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.5500\n",
      "Epoch 2626/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.5500\n",
      "Epoch 2627/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.5500\n",
      "Epoch 2628/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.5500\n",
      "Epoch 2629/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.5500\n",
      "Epoch 2630/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9869 - val_acc: 0.5500\n",
      "Epoch 2631/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.5500\n",
      "Epoch 2632/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.5500\n",
      "Epoch 2633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9868 - val_acc: 0.5500\n",
      "Epoch 2634/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.5500\n",
      "Epoch 2635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.5500\n",
      "Epoch 2636/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.5500\n",
      "Epoch 2637/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9905 - val_acc: 0.5500\n",
      "Epoch 2638/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.5500\n",
      "Epoch 2639/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9928 - val_acc: 0.5500\n",
      "Epoch 2640/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.5500\n",
      "Epoch 2641/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.5500\n",
      "Epoch 2642/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.5500\n",
      "Epoch 2643/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.5500\n",
      "Epoch 2644/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.5500\n",
      "Epoch 2645/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.5500\n",
      "Epoch 2646/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9908 - val_acc: 0.5500\n",
      "Epoch 2647/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.5500\n",
      "Epoch 2648/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9916 - val_acc: 0.5500\n",
      "Epoch 2649/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.5500\n",
      "Epoch 2650/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9916 - val_acc: 0.5500\n",
      "Epoch 2651/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.5500\n",
      "Epoch 2652/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.5500\n",
      "Epoch 2653/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.5500\n",
      "Epoch 2654/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.5500\n",
      "Epoch 2655/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.5500\n",
      "Epoch 2656/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.5500\n",
      "Epoch 2657/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.5500\n",
      "Epoch 2658/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2659/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9966 - val_acc: 0.5500\n",
      "Epoch 2660/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.5500\n",
      "Epoch 2661/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.5500\n",
      "Epoch 2662/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.5500\n",
      "Epoch 2663/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.5500\n",
      "Epoch 2664/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9965 - val_acc: 0.5500\n",
      "Epoch 2665/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9970 - val_acc: 0.5500\n",
      "Epoch 2666/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9976 - val_acc: 0.5500\n",
      "Epoch 2667/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9970 - val_acc: 0.5500\n",
      "Epoch 2668/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9976 - val_acc: 0.5500\n",
      "Epoch 2669/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9968 - val_acc: 0.5500\n",
      "Epoch 2670/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9965 - val_acc: 0.5500\n",
      "Epoch 2671/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9966 - val_acc: 0.5500\n",
      "Epoch 2672/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9966 - val_acc: 0.5500\n",
      "Epoch 2673/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.5500\n",
      "Epoch 2674/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.5500\n",
      "Epoch 2675/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.5500\n",
      "Epoch 2676/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9974 - val_acc: 0.5500\n",
      "Epoch 2677/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9984 - val_acc: 0.5500\n",
      "Epoch 2678/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.9996 - val_acc: 0.5500\n",
      "Epoch 2679/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0006 - val_acc: 0.5500\n",
      "Epoch 2680/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0006 - val_acc: 0.5500\n",
      "Epoch 2681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0016 - val_acc: 0.5500\n",
      "Epoch 2682/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0024 - val_acc: 0.5500\n",
      "Epoch 2683/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0016 - val_acc: 0.5500\n",
      "Epoch 2684/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0013 - val_acc: 0.5500\n",
      "Epoch 2685/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0021 - val_acc: 0.5500\n",
      "Epoch 2686/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0012 - val_acc: 0.5500\n",
      "Epoch 2687/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0018 - val_acc: 0.5500\n",
      "Epoch 2688/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0082 - acc: 1.000 - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0009 - val_acc: 0.5500\n",
      "Epoch 2689/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0013 - val_acc: 0.5500\n",
      "Epoch 2690/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.5500\n",
      "Epoch 2691/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0024 - val_acc: 0.5500\n",
      "Epoch 2692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0023 - val_acc: 0.5500\n",
      "Epoch 2693/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 1.0024 - val_acc: 0.5500\n",
      "Epoch 2694/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0014 - val_acc: 0.5500\n",
      "Epoch 2695/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0013 - val_acc: 0.5500\n",
      "Epoch 2696/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.5500\n",
      "Epoch 2697/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.5500\n",
      "Epoch 2698/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0027 - val_acc: 0.5500\n",
      "Epoch 2699/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0038 - val_acc: 0.5500\n",
      "Epoch 2700/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0036 - val_acc: 0.5500\n",
      "Epoch 2701/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.000 - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0037 - val_acc: 0.5500\n",
      "Epoch 2702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0030 - val_acc: 0.5500\n",
      "Epoch 2703/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0040 - val_acc: 0.5500\n",
      "Epoch 2704/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0050 - val_acc: 0.5500\n",
      "Epoch 2705/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0041 - val_acc: 0.5500\n",
      "Epoch 2706/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.0038 - val_acc: 0.5500\n",
      "Epoch 2707/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0032 - val_acc: 0.5500\n",
      "Epoch 2708/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0046 - val_acc: 0.5500\n",
      "Epoch 2709/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0046 - val_acc: 0.5500\n",
      "Epoch 2710/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0055 - val_acc: 0.5500\n",
      "Epoch 2711/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0054 - val_acc: 0.5500\n",
      "Epoch 2712/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0050 - val_acc: 0.5500\n",
      "Epoch 2713/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0055 - val_acc: 0.5500\n",
      "Epoch 2714/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0071 - val_acc: 0.5500\n",
      "Epoch 2715/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0070 - val_acc: 0.5500\n",
      "Epoch 2716/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0050 - val_acc: 0.5500\n",
      "Epoch 2717/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0051 - val_acc: 0.5500\n",
      "Epoch 2718/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0053 - val_acc: 0.5500\n",
      "Epoch 2719/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0047 - val_acc: 0.5500\n",
      "Epoch 2720/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0040 - val_acc: 0.5500\n",
      "Epoch 2721/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0043 - val_acc: 0.5500\n",
      "Epoch 2722/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0048 - val_acc: 0.5500\n",
      "Epoch 2723/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0060 - val_acc: 0.5500\n",
      "Epoch 2724/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0073 - val_acc: 0.5500\n",
      "Epoch 2725/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0071 - val_acc: 0.5500\n",
      "Epoch 2726/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0087 - val_acc: 0.5500\n",
      "Epoch 2727/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0084 - val_acc: 0.5500\n",
      "Epoch 2728/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0093 - val_acc: 0.5500\n",
      "Epoch 2729/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0079 - val_acc: 0.5500\n",
      "Epoch 2730/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0086 - val_acc: 0.5500\n",
      "Epoch 2731/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0096 - val_acc: 0.5500\n",
      "Epoch 2732/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0093 - val_acc: 0.5500\n",
      "Epoch 2733/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0102 - val_acc: 0.5500\n",
      "Epoch 2734/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0117 - val_acc: 0.5500\n",
      "Epoch 2735/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0114 - val_acc: 0.5500\n",
      "Epoch 2736/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.5500\n",
      "Epoch 2737/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0116 - val_acc: 0.5500\n",
      "Epoch 2738/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0118 - val_acc: 0.5500\n",
      "Epoch 2739/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0119 - val_acc: 0.5500\n",
      "Epoch 2740/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0121 - val_acc: 0.5500\n",
      "Epoch 2741/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.5500\n",
      "Epoch 2742/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0105 - val_acc: 0.5500\n",
      "Epoch 2743/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0102 - val_acc: 0.5500\n",
      "Epoch 2744/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0103 - val_acc: 0.5500\n",
      "Epoch 2745/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0114 - val_acc: 0.5500\n",
      "Epoch 2746/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0103 - val_acc: 0.5500\n",
      "Epoch 2747/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0113 - val_acc: 0.5500\n",
      "Epoch 2748/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.5500\n",
      "Epoch 2749/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0094 - val_acc: 0.5500\n",
      "Epoch 2750/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0093 - val_acc: 0.5500\n",
      "Epoch 2751/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0087 - val_acc: 0.5500\n",
      "Epoch 2752/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0084 - val_acc: 0.5500\n",
      "Epoch 2753/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0097 - val_acc: 0.5500\n",
      "Epoch 2754/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0105 - val_acc: 0.5500\n",
      "Epoch 2755/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0107 - val_acc: 0.5500\n",
      "Epoch 2756/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0100 - val_acc: 0.5500\n",
      "Epoch 2757/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0107 - val_acc: 0.5500\n",
      "Epoch 2758/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0114 - val_acc: 0.5500\n",
      "Epoch 2759/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0122 - val_acc: 0.5500\n",
      "Epoch 2760/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0106 - val_acc: 0.5500\n",
      "Epoch 2761/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.5500\n",
      "Epoch 2762/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0115 - val_acc: 0.5500\n",
      "Epoch 2763/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0132 - val_acc: 0.5500\n",
      "Epoch 2764/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0134 - val_acc: 0.5500\n",
      "Epoch 2765/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0122 - val_acc: 0.5500\n",
      "Epoch 2766/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0126 - val_acc: 0.5500\n",
      "Epoch 2767/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0126 - val_acc: 0.5500\n",
      "Epoch 2768/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0128 - val_acc: 0.5500\n",
      "Epoch 2769/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0145 - val_acc: 0.5500\n",
      "Epoch 2770/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0139 - val_acc: 0.5500\n",
      "Epoch 2771/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0136 - val_acc: 0.5500\n",
      "Epoch 2772/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0142 - val_acc: 0.5500\n",
      "Epoch 2773/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0148 - val_acc: 0.5500\n",
      "Epoch 2774/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0168 - val_acc: 0.5500\n",
      "Epoch 2775/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2776/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2777/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.5500\n",
      "Epoch 2778/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0176 - val_acc: 0.5500\n",
      "Epoch 2779/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0182 - val_acc: 0.5500\n",
      "Epoch 2780/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.5500\n",
      "Epoch 2781/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0163 - val_acc: 0.5500\n",
      "Epoch 2782/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0167 - val_acc: 0.5500\n",
      "Epoch 2783/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.5500\n",
      "Epoch 2784/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0175 - val_acc: 0.5500\n",
      "Epoch 2785/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.5500\n",
      "Epoch 2786/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0183 - val_acc: 0.5500\n",
      "Epoch 2787/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0189 - val_acc: 0.5500\n",
      "Epoch 2788/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0171 - val_acc: 0.5500\n",
      "Epoch 2789/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0164 - val_acc: 0.5500\n",
      "Epoch 2790/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.5500\n",
      "Epoch 2791/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.5500\n",
      "Epoch 2792/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.5500\n",
      "Epoch 2793/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.000 - 0s 105us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2794/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0179 - val_acc: 0.5500\n",
      "Epoch 2795/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0182 - val_acc: 0.5500\n",
      "Epoch 2796/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0196 - val_acc: 0.5500\n",
      "Epoch 2797/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0195 - val_acc: 0.5500\n",
      "Epoch 2798/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.5500\n",
      "Epoch 2799/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0186 - val_acc: 0.5500\n",
      "Epoch 2800/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0183 - val_acc: 0.5500\n",
      "Epoch 2801/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0179 - val_acc: 0.5500\n",
      "Epoch 2802/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0167 - val_acc: 0.5500\n",
      "Epoch 2803/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0171 - val_acc: 0.5500\n",
      "Epoch 2804/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.5500\n",
      "Epoch 2805/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0171 - val_acc: 0.5500\n",
      "Epoch 2806/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0160 - val_acc: 0.5500\n",
      "Epoch 2807/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2808/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2809/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.5500\n",
      "Epoch 2810/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0181 - val_acc: 0.5500\n",
      "Epoch 2811/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.5500\n",
      "Epoch 2812/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0154 - val_acc: 0.5500\n",
      "Epoch 2813/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.5500\n",
      "Epoch 2814/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0179 - val_acc: 0.5500\n",
      "Epoch 2815/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0181 - val_acc: 0.5500\n",
      "Epoch 2816/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0191 - val_acc: 0.5500\n",
      "Epoch 2817/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0200 - val_acc: 0.5500\n",
      "Epoch 2818/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0212 - val_acc: 0.5500\n",
      "Epoch 2819/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0203 - val_acc: 0.5500\n",
      "Epoch 2820/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0203 - val_acc: 0.5500\n",
      "Epoch 2821/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0212 - val_acc: 0.5500\n",
      "Epoch 2822/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0228 - val_acc: 0.5500\n",
      "Epoch 2823/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0222 - val_acc: 0.5500\n",
      "Epoch 2824/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0231 - val_acc: 0.5500\n",
      "Epoch 2825/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0232 - val_acc: 0.5500\n",
      "Epoch 2826/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0234 - val_acc: 0.5500\n",
      "Epoch 2827/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0241 - val_acc: 0.5500\n",
      "Epoch 2828/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0248 - val_acc: 0.5500\n",
      "Epoch 2829/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0248 - val_acc: 0.5500\n",
      "Epoch 2830/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0257 - val_acc: 0.5500\n",
      "Epoch 2831/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0257 - val_acc: 0.5500\n",
      "Epoch 2832/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0259 - val_acc: 0.5500\n",
      "Epoch 2833/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0253 - val_acc: 0.5500\n",
      "Epoch 2834/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0256 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2835/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0267 - val_acc: 0.5500\n",
      "Epoch 2836/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0270 - val_acc: 0.5500\n",
      "Epoch 2837/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0262 - val_acc: 0.5500\n",
      "Epoch 2838/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0265 - val_acc: 0.5500\n",
      "Epoch 2839/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.5500\n",
      "Epoch 2840/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.5500\n",
      "Epoch 2841/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0277 - val_acc: 0.5500\n",
      "Epoch 2842/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0286 - val_acc: 0.5500\n",
      "Epoch 2843/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.5500\n",
      "Epoch 2844/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0295 - val_acc: 0.5500\n",
      "Epoch 2845/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0312 - val_acc: 0.5500\n",
      "Epoch 2846/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0321 - val_acc: 0.5500\n",
      "Epoch 2847/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0309 - val_acc: 0.5500\n",
      "Epoch 2848/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.5500\n",
      "Epoch 2849/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.5500\n",
      "Epoch 2850/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0302 - val_acc: 0.5500\n",
      "Epoch 2851/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0316 - val_acc: 0.5500\n",
      "Epoch 2852/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0324 - val_acc: 0.5500\n",
      "Epoch 2853/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0321 - val_acc: 0.5500\n",
      "Epoch 2854/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0316 - val_acc: 0.5500\n",
      "Epoch 2855/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0313 - val_acc: 0.5500\n",
      "Epoch 2856/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 2857/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0297 - val_acc: 0.5500\n",
      "Epoch 2858/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 2859/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0308 - val_acc: 0.5500\n",
      "Epoch 2860/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0297 - val_acc: 0.5500\n",
      "Epoch 2861/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0295 - val_acc: 0.5500\n",
      "Epoch 2862/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.5500\n",
      "Epoch 2863/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0303 - val_acc: 0.5500\n",
      "Epoch 2864/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0302 - val_acc: 0.5500\n",
      "Epoch 2865/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.5500\n",
      "Epoch 2866/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0288 - val_acc: 0.5500\n",
      "Epoch 2867/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0303 - val_acc: 0.5500\n",
      "Epoch 2868/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0304 - val_acc: 0.5500\n",
      "Epoch 2869/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 2870/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0303 - val_acc: 0.5500\n",
      "Epoch 2871/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0291 - val_acc: 0.5500\n",
      "Epoch 2872/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0300 - val_acc: 0.5500\n",
      "Epoch 2873/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0307 - val_acc: 0.5500\n",
      "Epoch 2874/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0297 - val_acc: 0.5500\n",
      "Epoch 2875/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.5500\n",
      "Epoch 2876/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0283 - val_acc: 0.5500\n",
      "Epoch 2877/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0292 - val_acc: 0.5500\n",
      "Epoch 2878/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.5500\n",
      "Epoch 2879/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0313 - val_acc: 0.5500\n",
      "Epoch 2880/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0331 - val_acc: 0.5500\n",
      "Epoch 2881/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0342 - val_acc: 0.5500\n",
      "Epoch 2882/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0353 - val_acc: 0.5500\n",
      "Epoch 2883/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.5500\n",
      "Epoch 2884/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0339 - val_acc: 0.5500\n",
      "Epoch 2885/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0335 - val_acc: 0.5500\n",
      "Epoch 2886/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0341 - val_acc: 0.5500\n",
      "Epoch 2887/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0347 - val_acc: 0.5500\n",
      "Epoch 2888/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.5500\n",
      "Epoch 2889/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.5500\n",
      "Epoch 2890/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0341 - val_acc: 0.5500\n",
      "Epoch 2891/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0335 - val_acc: 0.5500\n",
      "Epoch 2892/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.5500\n",
      "Epoch 2893/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2894/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0347 - val_acc: 0.5500\n",
      "Epoch 2895/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0360 - val_acc: 0.5500\n",
      "Epoch 2896/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0354 - val_acc: 0.5500\n",
      "Epoch 2897/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0365 - val_acc: 0.5500\n",
      "Epoch 2898/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0376 - val_acc: 0.5500\n",
      "Epoch 2899/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0380 - val_acc: 0.5500\n",
      "Epoch 2900/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0384 - val_acc: 0.5500\n",
      "Epoch 2901/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0393 - val_acc: 0.5500\n",
      "Epoch 2902/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5500\n",
      "Epoch 2903/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0384 - val_acc: 0.5500\n",
      "Epoch 2904/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0386 - val_acc: 0.5500\n",
      "Epoch 2905/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5500\n",
      "Epoch 2906/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.5500\n",
      "Epoch 2907/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0388 - val_acc: 0.5500\n",
      "Epoch 2908/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0377 - val_acc: 0.5500\n",
      "Epoch 2909/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - 0s 124us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0377 - val_acc: 0.5500\n",
      "Epoch 2910/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0383 - val_acc: 0.5500\n",
      "Epoch 2911/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0396 - val_acc: 0.5500\n",
      "Epoch 2912/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0401 - val_acc: 0.5500\n",
      "Epoch 2913/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0392 - val_acc: 0.5500\n",
      "Epoch 2914/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5500\n",
      "Epoch 2915/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5500\n",
      "Epoch 2916/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0398 - val_acc: 0.5500\n",
      "Epoch 2917/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0393 - val_acc: 0.5500\n",
      "Epoch 2918/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0396 - val_acc: 0.5500\n",
      "Epoch 2919/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0409 - val_acc: 0.5500\n",
      "Epoch 2920/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.5500\n",
      "Epoch 2921/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0412 - val_acc: 0.5500\n",
      "Epoch 2922/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0424 - val_acc: 0.5500\n",
      "Epoch 2923/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.5500\n",
      "Epoch 2924/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0416 - val_acc: 0.5500\n",
      "Epoch 2925/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0419 - val_acc: 0.5500\n",
      "Epoch 2926/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.5500\n",
      "Epoch 2927/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0408 - val_acc: 0.5500\n",
      "Epoch 2928/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.5500\n",
      "Epoch 2929/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.000 - 0s 128us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.5500\n",
      "Epoch 2930/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.5500\n",
      "Epoch 2931/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5500\n",
      "Epoch 2932/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.5500\n",
      "Epoch 2933/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0410 - val_acc: 0.5500\n",
      "Epoch 2934/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0413 - val_acc: 0.5500\n",
      "Epoch 2935/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.5500\n",
      "Epoch 2936/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0401 - val_acc: 0.5500\n",
      "Epoch 2937/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.5500\n",
      "Epoch 2938/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.5500\n",
      "Epoch 2939/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.5500\n",
      "Epoch 2940/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.5500\n",
      "Epoch 2941/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0407 - val_acc: 0.5500\n",
      "Epoch 2942/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.5500\n",
      "Epoch 2943/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0407 - val_acc: 0.5500\n",
      "Epoch 2944/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0392 - val_acc: 0.5500\n",
      "Epoch 2945/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0400 - val_acc: 0.5500\n",
      "Epoch 2946/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0409 - val_acc: 0.5500\n",
      "Epoch 2947/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.5500\n",
      "Epoch 2948/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0428 - val_acc: 0.5500\n",
      "Epoch 2949/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0428 - val_acc: 0.5500\n",
      "Epoch 2950/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0416 - val_acc: 0.5500\n",
      "Epoch 2951/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.5500\n",
      "Epoch 2952/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0417 - val_acc: 0.5500\n",
      "Epoch 2953/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0419 - val_acc: 0.5500\n",
      "Epoch 2954/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0435 - val_acc: 0.5500\n",
      "Epoch 2955/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0442 - val_acc: 0.5500\n",
      "Epoch 2956/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.5500\n",
      "Epoch 2957/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0462 - val_acc: 0.5500\n",
      "Epoch 2958/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0465 - val_acc: 0.5500\n",
      "Epoch 2959/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0466 - val_acc: 0.5500\n",
      "Epoch 2960/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0476 - val_acc: 0.5500\n",
      "Epoch 2961/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0478 - val_acc: 0.5500\n",
      "Epoch 2962/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0480 - val_acc: 0.5500\n",
      "Epoch 2963/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.5500\n",
      "Epoch 2964/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0488 - val_acc: 0.5500\n",
      "Epoch 2965/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0488 - val_acc: 0.5500\n",
      "Epoch 2966/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0477 - val_acc: 0.5500\n",
      "Epoch 2967/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0475 - val_acc: 0.5500\n",
      "Epoch 2968/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0473 - val_acc: 0.5500\n",
      "Epoch 2969/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0482 - val_acc: 0.5500\n",
      "Epoch 2970/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.5500\n",
      "Epoch 2971/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0491 - val_acc: 0.5500\n",
      "Epoch 2972/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0492 - val_acc: 0.5500\n",
      "Epoch 2973/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.5500\n",
      "Epoch 2974/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0518 - val_acc: 0.5500\n",
      "Epoch 2975/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.5500\n",
      "Epoch 2976/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.5500\n",
      "Epoch 2977/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5500\n",
      "Epoch 2978/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.5500\n",
      "Epoch 2979/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5500\n",
      "Epoch 2980/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0519 - val_acc: 0.5500\n",
      "Epoch 2981/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0506 - val_acc: 0.5500\n",
      "Epoch 2982/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0514 - val_acc: 0.5500\n",
      "Epoch 2983/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0512 - val_acc: 0.5500\n",
      "Epoch 2984/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0519 - val_acc: 0.5500\n",
      "Epoch 2985/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0504 - val_acc: 0.5500\n",
      "Epoch 2986/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.5500\n",
      "Epoch 2987/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5500\n",
      "Epoch 2988/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0515 - val_acc: 0.5500\n",
      "Epoch 2989/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.5500\n",
      "Epoch 2990/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0516 - val_acc: 0.5500\n",
      "Epoch 2991/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5500\n",
      "Epoch 2992/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.5500\n",
      "Epoch 2993/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0506 - val_acc: 0.5500\n",
      "Epoch 2994/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5500\n",
      "Epoch 2995/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0512 - val_acc: 0.5500\n",
      "Epoch 2996/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0507 - val_acc: 0.5500\n",
      "Epoch 2997/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0517 - val_acc: 0.5500\n",
      "Epoch 2998/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0523 - val_acc: 0.5500\n",
      "Epoch 2999/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0521 - val_acc: 0.5500\n",
      "Epoch 3000/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0526 - val_acc: 0.5500\n",
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/3000\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.6918 - acc: 0.5316 - val_loss: 0.7101 - val_acc: 0.4000\n",
      "Epoch 2/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6907 - acc: 0.5316 - val_loss: 0.7093 - val_acc: 0.4000\n",
      "Epoch 3/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6923 - acc: 0.5316 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 4/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6920 - acc: 0.5316 - val_loss: 0.7032 - val_acc: 0.4000\n",
      "Epoch 5/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6933 - acc: 0.5316 - val_loss: 0.7078 - val_acc: 0.4000\n",
      "Epoch 6/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6894 - acc: 0.5316 - val_loss: 0.7101 - val_acc: 0.4000\n",
      "Epoch 7/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6891 - acc: 0.5316 - val_loss: 0.7072 - val_acc: 0.4000\n",
      "Epoch 8/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6902 - acc: 0.5316 - val_loss: 0.7119 - val_acc: 0.4000\n",
      "Epoch 9/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6908 - acc: 0.5316 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 10/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6888 - acc: 0.5316 - val_loss: 0.7043 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6887 - acc: 0.5316 - val_loss: 0.7076 - val_acc: 0.4000\n",
      "Epoch 12/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6896 - acc: 0.5316 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 13/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6890 - acc: 0.5316 - val_loss: 0.7106 - val_acc: 0.4000\n",
      "Epoch 14/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6890 - acc: 0.5316 - val_loss: 0.7151 - val_acc: 0.4000\n",
      "Epoch 15/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6908 - acc: 0.5316 - val_loss: 0.7149 - val_acc: 0.4000\n",
      "Epoch 16/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6885 - acc: 0.5316 - val_loss: 0.7155 - val_acc: 0.4000\n",
      "Epoch 17/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6890 - acc: 0.5316 - val_loss: 0.7186 - val_acc: 0.4000\n",
      "Epoch 18/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6887 - acc: 0.5316 - val_loss: 0.7179 - val_acc: 0.4000\n",
      "Epoch 19/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6884 - acc: 0.5316 - val_loss: 0.7124 - val_acc: 0.4000\n",
      "Epoch 20/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6883 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 21/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6913 - acc: 0.5316 - val_loss: 0.6979 - val_acc: 0.4000\n",
      "Epoch 22/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6894 - acc: 0.5696 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 23/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6906 - acc: 0.5316 - val_loss: 0.7055 - val_acc: 0.4000\n",
      "Epoch 24/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6881 - acc: 0.5316 - val_loss: 0.7083 - val_acc: 0.4000\n",
      "Epoch 25/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6888 - acc: 0.5316 - val_loss: 0.7102 - val_acc: 0.4000\n",
      "Epoch 26/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6910 - acc: 0.5316 - val_loss: 0.7163 - val_acc: 0.4000\n",
      "Epoch 27/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6890 - acc: 0.5316 - val_loss: 0.7119 - val_acc: 0.4000\n",
      "Epoch 28/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6880 - acc: 0.5316 - val_loss: 0.7059 - val_acc: 0.4000\n",
      "Epoch 29/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6886 - acc: 0.5316 - val_loss: 0.7084 - val_acc: 0.4000\n",
      "Epoch 30/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6878 - acc: 0.5316 - val_loss: 0.7104 - val_acc: 0.4000\n",
      "Epoch 31/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7096 - val_acc: 0.4000\n",
      "Epoch 32/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6879 - acc: 0.5316 - val_loss: 0.7095 - val_acc: 0.4000\n",
      "Epoch 33/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6878 - acc: 0.5316 - val_loss: 0.7141 - val_acc: 0.4000\n",
      "Epoch 34/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6889 - acc: 0.5316 - val_loss: 0.7116 - val_acc: 0.4000\n",
      "Epoch 35/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6845 - acc: 0.562 - 0s 139us/sample - loss: 0.6873 - acc: 0.5316 - val_loss: 0.7103 - val_acc: 0.4000\n",
      "Epoch 36/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7094 - val_acc: 0.4000\n",
      "Epoch 37/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.7063 - val_acc: 0.4000\n",
      "Epoch 38/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6882 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 39/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6909 - acc: 0.5316 - val_loss: 0.6968 - val_acc: 0.4000\n",
      "Epoch 40/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6885 - acc: 0.5316 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 41/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6873 - acc: 0.5316 - val_loss: 0.7019 - val_acc: 0.4000\n",
      "Epoch 42/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 43/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7039 - val_acc: 0.4000\n",
      "Epoch 44/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6881 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 45/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6894 - acc: 0.5316 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 46/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7032 - val_acc: 0.4000\n",
      "Epoch 47/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7091 - val_acc: 0.4000\n",
      "Epoch 48/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6868 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 49/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6871 - acc: 0.5316 - val_loss: 0.7088 - val_acc: 0.4000\n",
      "Epoch 50/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6867 - acc: 0.5316 - val_loss: 0.7083 - val_acc: 0.4000\n",
      "Epoch 51/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6886 - acc: 0.5316 - val_loss: 0.7135 - val_acc: 0.4000\n",
      "Epoch 52/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6867 - acc: 0.5316 - val_loss: 0.7118 - val_acc: 0.4000\n",
      "Epoch 53/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6871 - acc: 0.5316 - val_loss: 0.7084 - val_acc: 0.4000\n",
      "Epoch 54/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6864 - acc: 0.5316 - val_loss: 0.7082 - val_acc: 0.4000\n",
      "Epoch 55/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7107 - val_acc: 0.4000\n",
      "Epoch 56/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 57/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6900 - acc: 0.5316 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 58/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.7055 - val_acc: 0.4000\n",
      "Epoch 59/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 60/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7108 - val_acc: 0.4000\n",
      "Epoch 61/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7101 - val_acc: 0.4000\n",
      "Epoch 62/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6873 - acc: 0.5316 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 63/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6873 - acc: 0.5316 - val_loss: 0.7111 - val_acc: 0.4000\n",
      "Epoch 64/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6866 - acc: 0.5316 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 65/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6868 - acc: 0.5316 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 66/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 67/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.7073 - val_acc: 0.4000\n",
      "Epoch 68/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.7094 - val_acc: 0.4000\n",
      "Epoch 69/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6898 - acc: 0.5316 - val_loss: 0.7073 - val_acc: 0.4000\n",
      "Epoch 70/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.7078 - val_acc: 0.4000\n",
      "Epoch 71/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6871 - acc: 0.5316 - val_loss: 0.7105 - val_acc: 0.4000\n",
      "Epoch 72/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6860 - acc: 0.5316 - val_loss: 0.7071 - val_acc: 0.4000\n",
      "Epoch 73/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6905 - acc: 0.5316 - val_loss: 0.7179 - val_acc: 0.4000\n",
      "Epoch 74/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6881 - acc: 0.5316 - val_loss: 0.7223 - val_acc: 0.4000\n",
      "Epoch 75/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7151 - val_acc: 0.4000\n",
      "Epoch 76/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.7129 - val_acc: 0.4000\n",
      "Epoch 77/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6864 - acc: 0.5316 - val_loss: 0.7163 - val_acc: 0.4000\n",
      "Epoch 78/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.7214 - val_acc: 0.4000\n",
      "Epoch 79/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6932 - acc: 0.5316 - val_loss: 0.7108 - val_acc: 0.4000\n",
      "Epoch 80/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 81/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6861 - acc: 0.5316 - val_loss: 0.7097 - val_acc: 0.4000\n",
      "Epoch 82/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6894 - acc: 0.5316 - val_loss: 0.7185 - val_acc: 0.4000\n",
      "Epoch 83/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.6878 - acc: 0.5316 - val_loss: 0.7145 - val_acc: 0.4000\n",
      "Epoch 84/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6868 - acc: 0.5316 - val_loss: 0.7071 - val_acc: 0.4000\n",
      "Epoch 85/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6856 - acc: 0.5316 - val_loss: 0.7096 - val_acc: 0.4000\n",
      "Epoch 86/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6879 - acc: 0.5316 - val_loss: 0.7159 - val_acc: 0.4000\n",
      "Epoch 87/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7103 - val_acc: 0.4000\n",
      "Epoch 88/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.7142 - val_acc: 0.4000\n",
      "Epoch 89/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6863 - acc: 0.5316 - val_loss: 0.7117 - val_acc: 0.4000\n",
      "Epoch 90/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6884 - acc: 0.5316 - val_loss: 0.7097 - val_acc: 0.4000\n",
      "Epoch 91/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6859 - acc: 0.5316 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 92/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6858 - acc: 0.5316 - val_loss: 0.7049 - val_acc: 0.4000\n",
      "Epoch 93/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6858 - acc: 0.5316 - val_loss: 0.7011 - val_acc: 0.4000\n",
      "Epoch 94/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6868 - acc: 0.5316 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 95/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6856 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 96/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6854 - acc: 0.5316 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 97/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6854 - acc: 0.5316 - val_loss: 0.7020 - val_acc: 0.4000\n",
      "Epoch 98/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6903 - acc: 0.5316 - val_loss: 0.6978 - val_acc: 0.4000\n",
      "Epoch 99/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6874 - acc: 0.5316 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 100/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6884 - acc: 0.6203 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 101/3000\n",
      "79/79 [==============================] - 0s 278us/sample - loss: 0.6879 - acc: 0.5696 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 102/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6869 - acc: 0.7089 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 103/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6861 - acc: 0.5443 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 104/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6860 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 105/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6866 - acc: 0.5316 - val_loss: 0.7031 - val_acc: 0.4000\n",
      "Epoch 106/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6852 - acc: 0.5316 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 107/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7119 - val_acc: 0.4000\n",
      "Epoch 108/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6872 - acc: 0.5316 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 109/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6851 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 110/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6861 - acc: 0.5316 - val_loss: 0.7071 - val_acc: 0.4000\n",
      "Epoch 111/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6860 - acc: 0.5316 - val_loss: 0.7115 - val_acc: 0.4000\n",
      "Epoch 112/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 113/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6903 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 114/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 115/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6872 - acc: 0.5443 - val_loss: 0.7053 - val_acc: 0.4000\n",
      "Epoch 116/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6848 - acc: 0.5316 - val_loss: 0.7036 - val_acc: 0.4000\n",
      "Epoch 117/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7062 - val_acc: 0.4000\n",
      "Epoch 118/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7132 - val_acc: 0.4000\n",
      "Epoch 119/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6849 - acc: 0.5316 - val_loss: 0.7114 - val_acc: 0.4000\n",
      "Epoch 120/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6859 - acc: 0.5316 - val_loss: 0.7121 - val_acc: 0.4000\n",
      "Epoch 121/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.7105 - val_acc: 0.4000\n",
      "Epoch 122/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6858 - acc: 0.5316 - val_loss: 0.7124 - val_acc: 0.4000\n",
      "Epoch 123/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6859 - acc: 0.5316 - val_loss: 0.7136 - val_acc: 0.4000\n",
      "Epoch 124/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6854 - acc: 0.5316 - val_loss: 0.7112 - val_acc: 0.4000\n",
      "Epoch 125/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6866 - acc: 0.5316 - val_loss: 0.7155 - val_acc: 0.4000\n",
      "Epoch 126/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7186 - val_acc: 0.4000\n",
      "Epoch 127/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.7257 - val_acc: 0.4000\n",
      "Epoch 128/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6869 - acc: 0.5316 - val_loss: 0.7121 - val_acc: 0.4000\n",
      "Epoch 129/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6851 - acc: 0.5316 - val_loss: 0.7108 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6849 - acc: 0.5316 - val_loss: 0.7146 - val_acc: 0.4000\n",
      "Epoch 131/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6855 - acc: 0.5316 - val_loss: 0.7049 - val_acc: 0.4000\n",
      "Epoch 132/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6854 - acc: 0.5316 - val_loss: 0.7073 - val_acc: 0.4000\n",
      "Epoch 133/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 134/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6852 - acc: 0.5316 - val_loss: 0.7109 - val_acc: 0.4000\n",
      "Epoch 135/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6842 - acc: 0.5316 - val_loss: 0.7096 - val_acc: 0.4000\n",
      "Epoch 136/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6864 - acc: 0.5316 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 137/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6863 - acc: 0.5316 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 138/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6855 - acc: 0.5316 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 139/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6851 - acc: 0.5823 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 140/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6851 - acc: 0.5316 - val_loss: 0.7099 - val_acc: 0.4000\n",
      "Epoch 141/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.7109 - val_acc: 0.4000\n",
      "Epoch 142/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6862 - acc: 0.5316 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 143/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.7060 - val_acc: 0.4000\n",
      "Epoch 144/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6877 - acc: 0.5316 - val_loss: 0.7047 - val_acc: 0.4000\n",
      "Epoch 145/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6840 - acc: 0.5316 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 146/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6839 - acc: 0.5316 - val_loss: 0.7055 - val_acc: 0.4000\n",
      "Epoch 147/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6839 - acc: 0.5316 - val_loss: 0.7080 - val_acc: 0.4000\n",
      "Epoch 148/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6844 - acc: 0.5316 - val_loss: 0.7126 - val_acc: 0.4000\n",
      "Epoch 149/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6845 - acc: 0.5316 - val_loss: 0.7130 - val_acc: 0.4000\n",
      "Epoch 150/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6845 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 151/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6843 - acc: 0.5316 - val_loss: 0.7060 - val_acc: 0.4000\n",
      "Epoch 152/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6843 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 153/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6858 - acc: 0.5316 - val_loss: 0.7107 - val_acc: 0.4000\n",
      "Epoch 154/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6844 - acc: 0.5316 - val_loss: 0.7090 - val_acc: 0.4000\n",
      "Epoch 155/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6841 - acc: 0.5316 - val_loss: 0.7109 - val_acc: 0.4000\n",
      "Epoch 156/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6870 - acc: 0.5316 - val_loss: 0.7154 - val_acc: 0.4000\n",
      "Epoch 157/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.7122 - val_acc: 0.4000\n",
      "Epoch 158/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6842 - acc: 0.5316 - val_loss: 0.7154 - val_acc: 0.4000\n",
      "Epoch 159/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6844 - acc: 0.5316 - val_loss: 0.7075 - val_acc: 0.4000\n",
      "Epoch 160/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6839 - acc: 0.5316 - val_loss: 0.7093 - val_acc: 0.4000\n",
      "Epoch 161/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6841 - acc: 0.5316 - val_loss: 0.7088 - val_acc: 0.4000\n",
      "Epoch 162/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6845 - acc: 0.5316 - val_loss: 0.7053 - val_acc: 0.4000\n",
      "Epoch 163/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6834 - acc: 0.5316 - val_loss: 0.7078 - val_acc: 0.4000\n",
      "Epoch 164/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6832 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 165/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6856 - acc: 0.5316 - val_loss: 0.7088 - val_acc: 0.4000\n",
      "Epoch 166/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6843 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 167/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6835 - acc: 0.5316 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 168/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 169/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 170/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6846 - acc: 0.5316 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6847 - acc: 0.6582 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 172/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6838 - acc: 0.5316 - val_loss: 0.7036 - val_acc: 0.4000\n",
      "Epoch 173/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6835 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 174/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.5316 - val_loss: 0.7071 - val_acc: 0.4000\n",
      "Epoch 175/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6836 - acc: 0.5316 - val_loss: 0.7119 - val_acc: 0.4000\n",
      "Epoch 176/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6844 - acc: 0.5316 - val_loss: 0.7148 - val_acc: 0.4000\n",
      "Epoch 177/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.7079 - val_acc: 0.4000\n",
      "Epoch 178/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6840 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 179/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6827 - acc: 0.5316 - val_loss: 0.7050 - val_acc: 0.4000\n",
      "Epoch 180/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6834 - acc: 0.5316 - val_loss: 0.7050 - val_acc: 0.4000\n",
      "Epoch 181/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6832 - acc: 0.5316 - val_loss: 0.7034 - val_acc: 0.4000\n",
      "Epoch 182/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6832 - acc: 0.5316 - val_loss: 0.7017 - val_acc: 0.4000\n",
      "Epoch 183/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6839 - acc: 0.5316 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 184/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6849 - acc: 0.5316 - val_loss: 0.7126 - val_acc: 0.4000\n",
      "Epoch 185/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6841 - acc: 0.5316 - val_loss: 0.7184 - val_acc: 0.4000\n",
      "Epoch 186/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6850 - acc: 0.5316 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 187/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6824 - acc: 0.5316 - val_loss: 0.7052 - val_acc: 0.4000\n",
      "Epoch 188/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 189/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6831 - acc: 0.5316 - val_loss: 0.7097 - val_acc: 0.4000\n",
      "Epoch 190/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6830 - acc: 0.5316 - val_loss: 0.7108 - val_acc: 0.4000\n",
      "Epoch 191/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6830 - acc: 0.5316 - val_loss: 0.7072 - val_acc: 0.4000\n",
      "Epoch 192/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6845 - acc: 0.5316 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 193/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6828 - acc: 0.5316 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 194/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6847 - acc: 0.5316 - val_loss: 0.7052 - val_acc: 0.4000\n",
      "Epoch 195/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6834 - acc: 0.5316 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 196/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6825 - acc: 0.5316 - val_loss: 0.7020 - val_acc: 0.4000\n",
      "Epoch 197/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6824 - acc: 0.5316 - val_loss: 0.7030 - val_acc: 0.4000\n",
      "Epoch 198/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6856 - acc: 0.5316 - val_loss: 0.6980 - val_acc: 0.4000\n",
      "Epoch 199/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6833 - acc: 0.5316 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 200/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6840 - acc: 0.5443 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 201/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6838 - acc: 0.7342 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 202/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6827 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 203/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6832 - acc: 0.5316 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 204/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6821 - acc: 0.5316 - val_loss: 0.7068 - val_acc: 0.4000\n",
      "Epoch 205/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6820 - acc: 0.5316 - val_loss: 0.7063 - val_acc: 0.4000\n",
      "Epoch 206/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6853 - acc: 0.5316 - val_loss: 0.7129 - val_acc: 0.4000\n",
      "Epoch 207/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6885 - acc: 0.5316 - val_loss: 0.7096 - val_acc: 0.4000\n",
      "Epoch 208/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6824 - acc: 0.5316 - val_loss: 0.7135 - val_acc: 0.4000\n",
      "Epoch 209/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6821 - acc: 0.5316 - val_loss: 0.7111 - val_acc: 0.4000\n",
      "Epoch 210/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6820 - acc: 0.5316 - val_loss: 0.7070 - val_acc: 0.4000\n",
      "Epoch 211/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6822 - acc: 0.5316 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 212/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6819 - acc: 0.5316 - val_loss: 0.7055 - val_acc: 0.4000\n",
      "Epoch 213/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6818 - acc: 0.5316 - val_loss: 0.7033 - val_acc: 0.4000\n",
      "Epoch 214/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6817 - acc: 0.5316 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 215/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6822 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 216/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6818 - acc: 0.5316 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 217/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6829 - acc: 0.5316 - val_loss: 0.7030 - val_acc: 0.4000\n",
      "Epoch 218/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6847 - acc: 0.5570 - val_loss: 0.7091 - val_acc: 0.4000\n",
      "Epoch 219/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6814 - acc: 0.5316 - val_loss: 0.7080 - val_acc: 0.4000\n",
      "Epoch 220/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6815 - acc: 0.5316 - val_loss: 0.7050 - val_acc: 0.4000\n",
      "Epoch 221/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6815 - acc: 0.5316 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 222/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6832 - acc: 0.5316 - val_loss: 0.7133 - val_acc: 0.4000\n",
      "Epoch 223/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6823 - acc: 0.5316 - val_loss: 0.7113 - val_acc: 0.4000\n",
      "Epoch 224/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6831 - acc: 0.5316 - val_loss: 0.7100 - val_acc: 0.4000\n",
      "Epoch 225/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6823 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 226/3000\n",
      "79/79 [==============================] - 0s 252us/sample - loss: 0.6848 - acc: 0.5316 - val_loss: 0.6922 - val_acc: 0.5500\n",
      "Epoch 227/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6824 - acc: 0.7975 - val_loss: 0.6979 - val_acc: 0.4000\n",
      "Epoch 228/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6849 - acc: 0.5316 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 229/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6881 - acc: 0.4304 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 230/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6814 - acc: 0.5316 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 231/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6818 - acc: 0.5316 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 232/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6817 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 233/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6809 - acc: 0.5316 - val_loss: 0.7047 - val_acc: 0.4000\n",
      "Epoch 234/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6821 - acc: 0.5316 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 235/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6810 - acc: 0.5316 - val_loss: 0.7047 - val_acc: 0.4000\n",
      "Epoch 236/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6812 - acc: 0.5316 - val_loss: 0.7023 - val_acc: 0.4000\n",
      "Epoch 237/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6823 - acc: 0.5316 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 238/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6836 - acc: 0.5443 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 239/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6818 - acc: 0.6709 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 240/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6812 - acc: 0.5570 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 241/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6818 - acc: 0.5316 - val_loss: 0.7094 - val_acc: 0.4000\n",
      "Epoch 242/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6821 - acc: 0.5316 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 243/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6807 - acc: 0.5316 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 244/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6812 - acc: 0.5316 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 245/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6811 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 246/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6827 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 247/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6813 - acc: 0.5696 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 248/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 249/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6810 - acc: 0.5316 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 250/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 251/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6840 - acc: 0.5949 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 252/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6807 - acc: 0.5316 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 253/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6806 - acc: 0.5316 - val_loss: 0.7059 - val_acc: 0.4000\n",
      "Epoch 254/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6813 - acc: 0.5316 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 255/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.7027 - val_acc: 0.4000\n",
      "Epoch 256/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6805 - acc: 0.5316 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 257/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 258/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6826 - acc: 0.5316 - val_loss: 0.7017 - val_acc: 0.4000\n",
      "Epoch 259/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6801 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 260/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6801 - acc: 0.5316 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 261/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6807 - acc: 0.5316 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 262/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 263/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 264/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6800 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 265/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 266/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6797 - acc: 0.5316 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 267/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6841 - acc: 0.5316 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 268/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6816 - acc: 0.5316 - val_loss: 0.6956 - val_acc: 0.4000\n",
      "Epoch 269/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6800 - acc: 0.5443 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 270/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6804 - acc: 0.5316 - val_loss: 0.7001 - val_acc: 0.4000\n",
      "Epoch 271/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6797 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 272/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6799 - acc: 0.5316 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 273/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6793 - acc: 0.5316 - val_loss: 0.7049 - val_acc: 0.4000\n",
      "Epoch 274/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6805 - acc: 0.5316 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 275/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6794 - acc: 0.5316 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 276/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6797 - acc: 0.5316 - val_loss: 0.7033 - val_acc: 0.4000\n",
      "Epoch 277/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6793 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 278/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6797 - acc: 0.5316 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 279/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6797 - acc: 0.5316 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 280/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6802 - acc: 0.5316 - val_loss: 0.7079 - val_acc: 0.4000\n",
      "Epoch 281/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.7122 - val_acc: 0.4000\n",
      "Epoch 282/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6804 - acc: 0.5316 - val_loss: 0.7068 - val_acc: 0.4000\n",
      "Epoch 283/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6796 - acc: 0.5316 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 284/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6800 - acc: 0.5316 - val_loss: 0.7096 - val_acc: 0.4000\n",
      "Epoch 285/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.6796 - acc: 0.5316 - val_loss: 0.7102 - val_acc: 0.4000\n",
      "Epoch 286/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6800 - acc: 0.5316 - val_loss: 0.7013 - val_acc: 0.4000\n",
      "Epoch 287/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6789 - acc: 0.5316 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 288/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6788 - acc: 0.5316 - val_loss: 0.7042 - val_acc: 0.4000\n",
      "Epoch 289/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6799 - acc: 0.5316 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 290/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6806 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 291/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6786 - acc: 0.5316 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 292/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6787 - acc: 0.5316 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 293/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6798 - acc: 0.5316 - val_loss: 0.7062 - val_acc: 0.4000\n",
      "Epoch 294/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6790 - acc: 0.5316 - val_loss: 0.7084 - val_acc: 0.4000\n",
      "Epoch 295/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6805 - acc: 0.5316 - val_loss: 0.7018 - val_acc: 0.4000\n",
      "Epoch 296/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6800 - acc: 0.5316 - val_loss: 0.7030 - val_acc: 0.4000\n",
      "Epoch 297/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6795 - acc: 0.5316 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 298/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6790 - acc: 0.5316 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 299/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6808 - acc: 0.5316 - val_loss: 0.6929 - val_acc: 0.4000\n",
      "Epoch 300/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6793 - acc: 0.6076 - val_loss: 0.6938 - val_acc: 0.4000\n",
      "Epoch 301/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6794 - acc: 0.7089 - val_loss: 0.7011 - val_acc: 0.4000\n",
      "Epoch 302/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6789 - acc: 0.5316 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 303/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.7064 - val_acc: 0.4000\n",
      "Epoch 304/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6783 - acc: 0.5316 - val_loss: 0.7080 - val_acc: 0.4000\n",
      "Epoch 305/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6786 - acc: 0.5316 - val_loss: 0.7089 - val_acc: 0.4000\n",
      "Epoch 306/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6816 - acc: 0.5316 - val_loss: 0.7115 - val_acc: 0.4000\n",
      "Epoch 307/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6807 - acc: 0.5316 - val_loss: 0.7110 - val_acc: 0.4000\n",
      "Epoch 308/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6787 - acc: 0.5316 - val_loss: 0.7037 - val_acc: 0.4000\n",
      "Epoch 309/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6780 - acc: 0.5316 - val_loss: 0.7060 - val_acc: 0.4000\n",
      "Epoch 310/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6824 - acc: 0.5316 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 311/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6794 - acc: 0.5316 - val_loss: 0.7114 - val_acc: 0.4000\n",
      "Epoch 312/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6783 - acc: 0.5316 - val_loss: 0.7115 - val_acc: 0.4000\n",
      "Epoch 313/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6831 - acc: 0.5316 - val_loss: 0.7153 - val_acc: 0.4000\n",
      "Epoch 314/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6785 - acc: 0.5316 - val_loss: 0.7092 - val_acc: 0.4000\n",
      "Epoch 315/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6791 - acc: 0.5316 - val_loss: 0.7121 - val_acc: 0.4000\n",
      "Epoch 316/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6784 - acc: 0.5316 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 317/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6788 - acc: 0.5316 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 318/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6792 - acc: 0.5316 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 319/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6812 - acc: 0.5570 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 320/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6786 - acc: 0.5316 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 321/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6788 - acc: 0.5316 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 322/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6780 - acc: 0.5316 - val_loss: 0.7090 - val_acc: 0.4000\n",
      "Epoch 323/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6776 - acc: 0.5316 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 324/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6811 - acc: 0.5443 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 325/3000\n",
      "79/79 [==============================] - 0s 104us/sample - loss: 0.6784 - acc: 0.5316 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 326/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6794 - acc: 0.5316 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 327/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6781 - acc: 0.5443 - val_loss: 0.6937 - val_acc: 0.4000\n",
      "Epoch 328/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6785 - acc: 0.5949 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 329/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6780 - acc: 0.5443 - val_loss: 0.7025 - val_acc: 0.4000\n",
      "Epoch 330/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6771 - acc: 0.5316 - val_loss: 0.7004 - val_acc: 0.4000\n",
      "Epoch 331/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6771 - acc: 0.5316 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 332/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6771 - acc: 0.5316 - val_loss: 0.7042 - val_acc: 0.4000\n",
      "Epoch 333/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6794 - acc: 0.5316 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 334/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.6778 - acc: 0.5316 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 335/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6776 - acc: 0.5949 - val_loss: 0.7018 - val_acc: 0.4000\n",
      "Epoch 336/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6780 - acc: 0.5316 - val_loss: 0.7066 - val_acc: 0.4000\n",
      "Epoch 337/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6817 - acc: 0.5316 - val_loss: 0.6971 - val_acc: 0.4000\n",
      "Epoch 338/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6783 - acc: 0.5443 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 339/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6767 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 340/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6767 - acc: 0.5316 - val_loss: 0.7067 - val_acc: 0.4000\n",
      "Epoch 341/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6771 - acc: 0.5316 - val_loss: 0.7007 - val_acc: 0.4000\n",
      "Epoch 342/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6769 - acc: 0.5316 - val_loss: 0.7061 - val_acc: 0.4000\n",
      "Epoch 343/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6776 - acc: 0.5316 - val_loss: 0.7129 - val_acc: 0.4000\n",
      "Epoch 344/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6769 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 345/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6769 - acc: 0.5316 - val_loss: 0.7088 - val_acc: 0.4000\n",
      "Epoch 346/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6771 - acc: 0.5316 - val_loss: 0.7067 - val_acc: 0.4000\n",
      "Epoch 347/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6768 - acc: 0.5316 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 348/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6764 - acc: 0.5316 - val_loss: 0.7037 - val_acc: 0.4000\n",
      "Epoch 349/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6792 - acc: 0.5316 - val_loss: 0.6925 - val_acc: 0.4000\n",
      "Epoch 350/3000\n",
      "79/79 [==============================] - 0s 254us/sample - loss: 0.6792 - acc: 0.5570 - val_loss: 0.6875 - val_acc: 0.7000\n",
      "Epoch 351/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6781 - acc: 0.8481 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 352/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6809 - acc: 0.6709 - val_loss: 0.6889 - val_acc: 0.6000\n",
      "Epoch 353/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6810 - acc: 0.8228 - val_loss: 0.6875 - val_acc: 0.6500\n",
      "Epoch 354/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6794 - acc: 0.7595 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 355/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6763 - acc: 0.5316 - val_loss: 0.6979 - val_acc: 0.4000\n",
      "Epoch 356/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6764 - acc: 0.5316 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 357/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6766 - acc: 0.5316 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 358/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6766 - acc: 0.6582 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 359/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6769 - acc: 0.5316 - val_loss: 0.6977 - val_acc: 0.4000\n",
      "Epoch 360/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6770 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 361/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6757 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 362/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6760 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 363/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6765 - acc: 0.5316 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 364/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6761 - acc: 0.5316 - val_loss: 0.7005 - val_acc: 0.4000\n",
      "Epoch 365/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6766 - acc: 0.5316 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 366/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6755 - acc: 0.5316 - val_loss: 0.7070 - val_acc: 0.4000\n",
      "Epoch 367/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6761 - acc: 0.5316 - val_loss: 0.7105 - val_acc: 0.4000\n",
      "Epoch 368/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6756 - acc: 0.5316 - val_loss: 0.7056 - val_acc: 0.4000\n",
      "Epoch 369/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6821 - acc: 0.5316 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 370/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6772 - acc: 0.5570 - val_loss: 0.7098 - val_acc: 0.4000\n",
      "Epoch 371/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6755 - acc: 0.5316 - val_loss: 0.7077 - val_acc: 0.4000\n",
      "Epoch 372/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6767 - acc: 0.5316 - val_loss: 0.7142 - val_acc: 0.4000\n",
      "Epoch 373/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6768 - acc: 0.5316 - val_loss: 0.7058 - val_acc: 0.4000\n",
      "Epoch 374/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6749 - acc: 0.5316 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 375/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6750 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 376/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.6760 - acc: 0.5316 - val_loss: 0.6970 - val_acc: 0.4000\n",
      "Epoch 377/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6751 - acc: 0.5316 - val_loss: 0.7007 - val_acc: 0.4000\n",
      "Epoch 378/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6748 - acc: 0.5316 - val_loss: 0.7036 - val_acc: 0.4000\n",
      "Epoch 379/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6758 - acc: 0.5316 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 380/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6759 - acc: 0.5316 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 381/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6771 - acc: 0.5696 - val_loss: 0.6922 - val_acc: 0.4500\n",
      "Epoch 382/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6754 - acc: 0.6076 - val_loss: 0.6928 - val_acc: 0.4000\n",
      "Epoch 383/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6764 - acc: 0.5823 - val_loss: 0.6931 - val_acc: 0.4000\n",
      "Epoch 384/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6762 - acc: 0.5696 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 385/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6746 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 386/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6756 - acc: 0.5316 - val_loss: 0.6973 - val_acc: 0.4000\n",
      "Epoch 387/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6746 - acc: 0.5316 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 388/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6782 - acc: 0.6076 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 389/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6750 - acc: 0.5570 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 390/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6762 - acc: 0.5696 - val_loss: 0.7094 - val_acc: 0.4000\n",
      "Epoch 391/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6751 - acc: 0.5316 - val_loss: 0.7124 - val_acc: 0.4000\n",
      "Epoch 392/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6748 - acc: 0.5316 - val_loss: 0.7118 - val_acc: 0.4000\n",
      "Epoch 393/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6777 - acc: 0.5316 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 394/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6747 - acc: 0.5316 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 395/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6752 - acc: 0.5316 - val_loss: 0.7019 - val_acc: 0.4000\n",
      "Epoch 396/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6744 - acc: 0.5316 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 397/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6740 - acc: 0.5316 - val_loss: 0.7029 - val_acc: 0.4000\n",
      "Epoch 398/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6748 - acc: 0.5316 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 399/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6758 - acc: 0.6456 - val_loss: 0.7026 - val_acc: 0.4000\n",
      "Epoch 400/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6774 - acc: 0.5570 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 401/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6736 - acc: 0.5316 - val_loss: 0.7045 - val_acc: 0.4000\n",
      "Epoch 402/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6790 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 403/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6763 - acc: 0.5316 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 404/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6735 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 405/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6733 - acc: 0.5316 - val_loss: 0.7008 - val_acc: 0.4000\n",
      "Epoch 406/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6734 - acc: 0.5316 - val_loss: 0.7033 - val_acc: 0.4000\n",
      "Epoch 407/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6744 - acc: 0.5316 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 408/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6745 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 409/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6738 - acc: 0.5316 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 410/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6737 - acc: 0.5316 - val_loss: 0.7005 - val_acc: 0.4000\n",
      "Epoch 411/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.6763 - acc: 0.5316 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 412/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6743 - acc: 0.5443 - val_loss: 0.7017 - val_acc: 0.4000\n",
      "Epoch 413/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6734 - acc: 0.5316 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 414/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6752 - acc: 0.5316 - val_loss: 0.7063 - val_acc: 0.4000\n",
      "Epoch 415/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6742 - acc: 0.5316 - val_loss: 0.7069 - val_acc: 0.4000\n",
      "Epoch 416/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6739 - acc: 0.5316 - val_loss: 0.6982 - val_acc: 0.4000\n",
      "Epoch 417/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6743 - acc: 0.5570 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 418/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6738 - acc: 0.5443 - val_loss: 0.7055 - val_acc: 0.4000\n",
      "Epoch 419/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6732 - acc: 0.5316 - val_loss: 0.7066 - val_acc: 0.4000\n",
      "Epoch 420/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6739 - acc: 0.5316 - val_loss: 0.7129 - val_acc: 0.4000\n",
      "Epoch 421/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6746 - acc: 0.5316 - val_loss: 0.7175 - val_acc: 0.4000\n",
      "Epoch 422/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6748 - acc: 0.5316 - val_loss: 0.7043 - val_acc: 0.4000\n",
      "Epoch 423/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6731 - acc: 0.5316 - val_loss: 0.7086 - val_acc: 0.4000\n",
      "Epoch 424/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6726 - acc: 0.5316 - val_loss: 0.7063 - val_acc: 0.4000\n",
      "Epoch 425/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6725 - acc: 0.5316 - val_loss: 0.7046 - val_acc: 0.4000\n",
      "Epoch 426/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6724 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 427/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6728 - acc: 0.5316 - val_loss: 0.7059 - val_acc: 0.4000\n",
      "Epoch 428/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6723 - acc: 0.5316 - val_loss: 0.7020 - val_acc: 0.4000\n",
      "Epoch 429/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6732 - acc: 0.5316 - val_loss: 0.7070 - val_acc: 0.4000\n",
      "Epoch 430/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6723 - acc: 0.5316 - val_loss: 0.7079 - val_acc: 0.4000\n",
      "Epoch 431/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6734 - acc: 0.5316 - val_loss: 0.7079 - val_acc: 0.4000\n",
      "Epoch 432/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6722 - acc: 0.5316 - val_loss: 0.7034 - val_acc: 0.4000\n",
      "Epoch 433/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6770 - acc: 0.500 - 0s 139us/sample - loss: 0.6720 - acc: 0.5316 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 434/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6722 - acc: 0.5316 - val_loss: 0.6997 - val_acc: 0.4000\n",
      "Epoch 435/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6724 - acc: 0.5316 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 436/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6719 - acc: 0.5696 - val_loss: 0.6996 - val_acc: 0.4000\n",
      "Epoch 437/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6717 - acc: 0.5316 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 438/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6717 - acc: 0.5316 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 439/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6726 - acc: 0.5316 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 440/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6720 - acc: 0.5316 - val_loss: 0.6943 - val_acc: 0.4000\n",
      "Epoch 441/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6715 - acc: 0.5823 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 442/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6715 - acc: 0.5570 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 443/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6717 - acc: 0.5316 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 444/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6711 - acc: 0.5316 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 445/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6716 - acc: 0.5570 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 446/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6712 - acc: 0.5316 - val_loss: 0.7018 - val_acc: 0.4000\n",
      "Epoch 447/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6748 - acc: 0.5696 - val_loss: 0.7048 - val_acc: 0.4000\n",
      "Epoch 448/3000\n",
      "79/79 [==============================] - 0s 103us/sample - loss: 0.6717 - acc: 0.5316 - val_loss: 0.7089 - val_acc: 0.4000\n",
      "Epoch 449/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6714 - acc: 0.5316 - val_loss: 0.7091 - val_acc: 0.4000\n",
      "Epoch 450/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6724 - acc: 0.5316 - val_loss: 0.7095 - val_acc: 0.4000\n",
      "Epoch 451/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6722 - acc: 0.5316 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 452/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6713 - acc: 0.5316 - val_loss: 0.7057 - val_acc: 0.4000\n",
      "Epoch 453/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6718 - acc: 0.5316 - val_loss: 0.6989 - val_acc: 0.4000\n",
      "Epoch 454/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6706 - acc: 0.5316 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 455/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6728 - acc: 0.5443 - val_loss: 0.6965 - val_acc: 0.4000\n",
      "Epoch 456/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6725 - acc: 0.6076 - val_loss: 0.7054 - val_acc: 0.4000\n",
      "Epoch 457/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6712 - acc: 0.5316 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 458/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6719 - acc: 0.5316 - val_loss: 0.7119 - val_acc: 0.4000\n",
      "Epoch 459/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6715 - acc: 0.5316 - val_loss: 0.7111 - val_acc: 0.4000\n",
      "Epoch 460/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6708 - acc: 0.5316 - val_loss: 0.7051 - val_acc: 0.4000\n",
      "Epoch 461/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6709 - acc: 0.5316 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6715 - acc: 0.5316 - val_loss: 0.7031 - val_acc: 0.4000\n",
      "Epoch 463/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6705 - acc: 0.5316 - val_loss: 0.7044 - val_acc: 0.4000\n",
      "Epoch 464/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6705 - acc: 0.5316 - val_loss: 0.7060 - val_acc: 0.4000\n",
      "Epoch 465/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6706 - acc: 0.5316 - val_loss: 0.7038 - val_acc: 0.4000\n",
      "Epoch 466/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6697 - acc: 0.5316 - val_loss: 0.7027 - val_acc: 0.4000\n",
      "Epoch 467/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6719 - acc: 0.5316 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 468/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6709 - acc: 0.5570 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 469/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6714 - acc: 0.8608 - val_loss: 0.6999 - val_acc: 0.4000\n",
      "Epoch 470/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6696 - acc: 0.5316 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 471/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6699 - acc: 0.5316 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 472/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6694 - acc: 0.5316 - val_loss: 0.7019 - val_acc: 0.4000\n",
      "Epoch 473/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6694 - acc: 0.5316 - val_loss: 0.7015 - val_acc: 0.4000\n",
      "Epoch 474/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6692 - acc: 0.5316 - val_loss: 0.6986 - val_acc: 0.4000\n",
      "Epoch 475/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6695 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6695 - acc: 0.5316 - val_loss: 0.7028 - val_acc: 0.4000\n",
      "Epoch 477/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6701 - acc: 0.5316 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 478/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6690 - acc: 0.5316 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 479/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6712 - acc: 0.5570 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 480/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6708 - acc: 0.5949 - val_loss: 0.7070 - val_acc: 0.4000\n",
      "Epoch 481/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6711 - acc: 0.5316 - val_loss: 0.7157 - val_acc: 0.4000\n",
      "Epoch 482/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6713 - acc: 0.5316 - val_loss: 0.7190 - val_acc: 0.4000\n",
      "Epoch 483/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6709 - acc: 0.5316 - val_loss: 0.7151 - val_acc: 0.4000\n",
      "Epoch 484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6696 - acc: 0.5316 - val_loss: 0.7100 - val_acc: 0.4000\n",
      "Epoch 485/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6690 - acc: 0.5316 - val_loss: 0.7041 - val_acc: 0.4000\n",
      "Epoch 486/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6696 - acc: 0.5316 - val_loss: 0.7106 - val_acc: 0.4000\n",
      "Epoch 487/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6706 - acc: 0.5316 - val_loss: 0.7014 - val_acc: 0.4000\n",
      "Epoch 488/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6682 - acc: 0.5316 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 489/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6681 - acc: 0.5316 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 490/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6681 - acc: 0.5316 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 491/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6685 - acc: 0.5570 - val_loss: 0.6919 - val_acc: 0.4000\n",
      "Epoch 492/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6689 - acc: 0.5696 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 493/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6683 - acc: 0.7468 - val_loss: 0.6924 - val_acc: 0.4000\n",
      "Epoch 494/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6681 - acc: 0.6709 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 495/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6678 - acc: 0.5443 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 496/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6677 - acc: 0.5570 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 497/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6697 - acc: 0.5443 - val_loss: 0.7002 - val_acc: 0.4000\n",
      "Epoch 498/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6675 - acc: 0.5316 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 499/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6685 - acc: 0.5316 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 500/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6679 - acc: 0.5443 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 501/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6688 - acc: 0.5949 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 502/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6675 - acc: 0.5316 - val_loss: 0.6953 - val_acc: 0.4000\n",
      "Epoch 503/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6683 - acc: 0.5443 - val_loss: 0.7009 - val_acc: 0.4000\n",
      "Epoch 504/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6718 - acc: 0.5316 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 505/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6676 - acc: 0.6203 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 506/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6669 - acc: 0.5570 - val_loss: 0.6995 - val_acc: 0.4000\n",
      "Epoch 507/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6668 - acc: 0.5316 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 508/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6678 - acc: 0.5316 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 509/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6687 - acc: 0.5316 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 510/3000\n",
      "79/79 [==============================] - 0s 248us/sample - loss: 0.6712 - acc: 0.6329 - val_loss: 0.6810 - val_acc: 0.7500\n",
      "Epoch 511/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6689 - acc: 0.9114 - val_loss: 0.6857 - val_acc: 0.6000\n",
      "Epoch 512/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6705 - acc: 0.7468 - val_loss: 0.6888 - val_acc: 0.5000\n",
      "Epoch 513/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6693 - acc: 0.6582 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 514/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6669 - acc: 0.6835 - val_loss: 0.6897 - val_acc: 0.4500\n",
      "Epoch 515/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6665 - acc: 0.7342 - val_loss: 0.6922 - val_acc: 0.4000\n",
      "Epoch 516/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6664 - acc: 0.6329 - val_loss: 0.6920 - val_acc: 0.4000\n",
      "Epoch 517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6667 - acc: 0.6076 - val_loss: 0.6895 - val_acc: 0.4500\n",
      "Epoch 518/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6698 - acc: 0.7215 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "Epoch 519/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6689 - acc: 0.9241 - val_loss: 0.6927 - val_acc: 0.4000\n",
      "Epoch 520/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6658 - acc: 0.5949 - val_loss: 0.6944 - val_acc: 0.4000\n",
      "Epoch 521/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6662 - acc: 0.6203 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 522/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6661 - acc: 0.5316 - val_loss: 0.6953 - val_acc: 0.4000\n",
      "Epoch 523/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6656 - acc: 0.5443 - val_loss: 0.6938 - val_acc: 0.4000\n",
      "Epoch 524/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6659 - acc: 0.6203 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 525/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6657 - acc: 0.5316 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 526/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6656 - acc: 0.5316 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 527/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6656 - acc: 0.5570 - val_loss: 0.6911 - val_acc: 0.4000\n",
      "Epoch 528/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6660 - acc: 0.7215 - val_loss: 0.6935 - val_acc: 0.4000\n",
      "Epoch 529/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6651 - acc: 0.6329 - val_loss: 0.6972 - val_acc: 0.4000\n",
      "Epoch 530/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6654 - acc: 0.5316 - val_loss: 0.6927 - val_acc: 0.4000\n",
      "Epoch 531/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6654 - acc: 0.6582 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 532/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6659 - acc: 0.5443 - val_loss: 0.6991 - val_acc: 0.4000\n",
      "Epoch 533/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6684 - acc: 0.5949 - val_loss: 0.7021 - val_acc: 0.4000\n",
      "Epoch 534/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6659 - acc: 0.5316 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 535/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6686 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 536/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6656 - acc: 0.5316 - val_loss: 0.6984 - val_acc: 0.4000\n",
      "Epoch 537/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6649 - acc: 0.5316 - val_loss: 0.6938 - val_acc: 0.4000\n",
      "Epoch 538/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6678 - acc: 0.5823 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 539/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6642 - acc: 0.5316 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 540/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6641 - acc: 0.5316 - val_loss: 0.6983 - val_acc: 0.4000\n",
      "Epoch 541/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6695 - acc: 0.5823 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 542/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6639 - acc: 0.5316 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 543/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6639 - acc: 0.5570 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 544/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6649 - acc: 0.5570 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 545/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6648 - acc: 0.7595 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6660 - acc: 0.6709 - val_loss: 0.6833 - val_acc: 0.7000\n",
      "Epoch 547/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6670 - acc: 0.8734 - val_loss: 0.6898 - val_acc: 0.4500\n",
      "Epoch 548/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6648 - acc: 0.6203 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 549/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6652 - acc: 0.7468 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 550/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6654 - acc: 0.7089 - val_loss: 0.6901 - val_acc: 0.4500\n",
      "Epoch 551/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6644 - acc: 0.7595 - val_loss: 0.6993 - val_acc: 0.4000\n",
      "Epoch 552/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6642 - acc: 0.5316 - val_loss: 0.7006 - val_acc: 0.4000\n",
      "Epoch 553/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6665 - acc: 0.5316 - val_loss: 0.7065 - val_acc: 0.4000\n",
      "Epoch 554/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6632 - acc: 0.5316 - val_loss: 0.7034 - val_acc: 0.4000\n",
      "Epoch 555/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6643 - acc: 0.5316 - val_loss: 0.6936 - val_acc: 0.4000\n",
      "Epoch 556/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6647 - acc: 0.5443 - val_loss: 0.6896 - val_acc: 0.4500\n",
      "Epoch 557/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6638 - acc: 0.7975 - val_loss: 0.6988 - val_acc: 0.4000\n",
      "Epoch 558/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6625 - acc: 0.5316 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 559/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6622 - acc: 0.5570 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 560/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6623 - acc: 0.5570 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 561/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6626 - acc: 0.5316 - val_loss: 0.6990 - val_acc: 0.4000\n",
      "Epoch 562/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6642 - acc: 0.5316 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 563/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6620 - acc: 0.5570 - val_loss: 0.6933 - val_acc: 0.4000\n",
      "Epoch 564/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6631 - acc: 0.5696 - val_loss: 0.6895 - val_acc: 0.4500\n",
      "Epoch 565/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6626 - acc: 0.7975 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 566/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6618 - acc: 0.5443 - val_loss: 0.6963 - val_acc: 0.4000\n",
      "Epoch 567/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6622 - acc: 0.5696 - val_loss: 0.7012 - val_acc: 0.4000\n",
      "Epoch 568/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6617 - acc: 0.5316 - val_loss: 0.7022 - val_acc: 0.4000\n",
      "Epoch 569/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6621 - acc: 0.5316 - val_loss: 0.7024 - val_acc: 0.4000\n",
      "Epoch 570/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6616 - acc: 0.5316 - val_loss: 0.7007 - val_acc: 0.4000\n",
      "Epoch 571/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6629 - acc: 0.5443 - val_loss: 0.7000 - val_acc: 0.4000\n",
      "Epoch 572/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6617 - acc: 0.5316 - val_loss: 0.6938 - val_acc: 0.4000\n",
      "Epoch 573/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6623 - acc: 0.5570 - val_loss: 0.6966 - val_acc: 0.4000\n",
      "Epoch 574/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6610 - acc: 0.5316 - val_loss: 0.6941 - val_acc: 0.4000\n",
      "Epoch 575/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6609 - acc: 0.5570 - val_loss: 0.6924 - val_acc: 0.4000\n",
      "Epoch 576/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6643 - acc: 0.5949 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 577/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6607 - acc: 0.5443 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 578/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6617 - acc: 0.5316 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 579/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6611 - acc: 0.5696 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 580/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6648 - acc: 0.6582 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 581/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6609 - acc: 0.5443 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 582/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6640 - acc: 0.5570 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 583/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6601 - acc: 0.5316 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 584/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6600 - acc: 0.5570 - val_loss: 0.6925 - val_acc: 0.4000\n",
      "Epoch 585/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6600 - acc: 0.5949 - val_loss: 0.6911 - val_acc: 0.4000\n",
      "Epoch 586/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6599 - acc: 0.6962 - val_loss: 0.6949 - val_acc: 0.4000\n",
      "Epoch 587/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6625 - acc: 0.5443 - val_loss: 0.6944 - val_acc: 0.4000\n",
      "Epoch 588/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6687 - acc: 0.5570 - val_loss: 0.6934 - val_acc: 0.4000\n",
      "Epoch 589/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6599 - acc: 0.6329 - val_loss: 0.6969 - val_acc: 0.4000\n",
      "Epoch 590/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6599 - acc: 0.5443 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 591/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6604 - acc: 0.5570 - val_loss: 0.6916 - val_acc: 0.4000\n",
      "Epoch 592/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6611 - acc: 0.7215 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 593/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6619 - acc: 0.5316 - val_loss: 0.7074 - val_acc: 0.4000\n",
      "Epoch 594/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6601 - acc: 0.5316 - val_loss: 0.7010 - val_acc: 0.4000\n",
      "Epoch 595/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6602 - acc: 0.5316 - val_loss: 0.6917 - val_acc: 0.4000\n",
      "Epoch 596/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6588 - acc: 0.6582 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 597/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6590 - acc: 0.5823 - val_loss: 0.6891 - val_acc: 0.4500\n",
      "Epoch 598/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6599 - acc: 0.6329 - val_loss: 0.6862 - val_acc: 0.5000\n",
      "Epoch 599/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6601 - acc: 0.7848 - val_loss: 0.6908 - val_acc: 0.4000\n",
      "Epoch 600/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6595 - acc: 0.6456 - val_loss: 0.6941 - val_acc: 0.4000\n",
      "Epoch 601/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6587 - acc: 0.5823 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 602/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6602 - acc: 0.5443 - val_loss: 0.6935 - val_acc: 0.4000\n",
      "Epoch 603/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6590 - acc: 0.5570 - val_loss: 0.6890 - val_acc: 0.4500\n",
      "Epoch 604/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6580 - acc: 0.7595 - val_loss: 0.6932 - val_acc: 0.4000\n",
      "Epoch 605/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6583 - acc: 0.5949 - val_loss: 0.6893 - val_acc: 0.4500\n",
      "Epoch 606/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6578 - acc: 0.7215 - val_loss: 0.6931 - val_acc: 0.4000\n",
      "Epoch 607/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6579 - acc: 0.5823 - val_loss: 0.6907 - val_acc: 0.4000\n",
      "Epoch 608/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6575 - acc: 0.6456 - val_loss: 0.6894 - val_acc: 0.4500\n",
      "Epoch 609/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6587 - acc: 0.8101 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 610/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6578 - acc: 0.5316 - val_loss: 0.6924 - val_acc: 0.4000\n",
      "Epoch 611/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6581 - acc: 0.5949 - val_loss: 0.6881 - val_acc: 0.4500\n",
      "Epoch 612/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6577 - acc: 0.7595 - val_loss: 0.6904 - val_acc: 0.4000\n",
      "Epoch 613/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6570 - acc: 0.6456 - val_loss: 0.6894 - val_acc: 0.4500\n",
      "Epoch 614/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6574 - acc: 0.7215 - val_loss: 0.6913 - val_acc: 0.4000\n",
      "Epoch 615/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6570 - acc: 0.6962 - val_loss: 0.6948 - val_acc: 0.4000\n",
      "Epoch 616/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6563 - acc: 0.5823 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 617/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6564 - acc: 0.5696 - val_loss: 0.6919 - val_acc: 0.4000\n",
      "Epoch 618/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6563 - acc: 0.6582 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 619/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6561 - acc: 0.5696 - val_loss: 0.6922 - val_acc: 0.4000\n",
      "Epoch 620/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6561 - acc: 0.6076 - val_loss: 0.6926 - val_acc: 0.4000\n",
      "Epoch 621/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6559 - acc: 0.6076 - val_loss: 0.6909 - val_acc: 0.4000\n",
      "Epoch 622/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6564 - acc: 0.5823 - val_loss: 0.6915 - val_acc: 0.4000\n",
      "Epoch 623/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6562 - acc: 0.6582 - val_loss: 0.6927 - val_acc: 0.4000\n",
      "Epoch 624/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6555 - acc: 0.5949 - val_loss: 0.6907 - val_acc: 0.4000\n",
      "Epoch 625/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6560 - acc: 0.6076 - val_loss: 0.6871 - val_acc: 0.5000\n",
      "Epoch 626/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6578 - acc: 0.6582 - val_loss: 0.6864 - val_acc: 0.5000\n",
      "Epoch 627/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6564 - acc: 0.8861 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 628/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6570 - acc: 0.6456 - val_loss: 0.7009 - val_acc: 0.4000\n",
      "Epoch 629/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6574 - acc: 0.5696 - val_loss: 0.7075 - val_acc: 0.4000\n",
      "Epoch 630/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6564 - acc: 0.5316 - val_loss: 0.7087 - val_acc: 0.4000\n",
      "Epoch 631/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6566 - acc: 0.5316 - val_loss: 0.7003 - val_acc: 0.4000\n",
      "Epoch 632/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6550 - acc: 0.5316 - val_loss: 0.6960 - val_acc: 0.4000\n",
      "Epoch 633/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6556 - acc: 0.5443 - val_loss: 0.6973 - val_acc: 0.4000\n",
      "Epoch 634/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6547 - acc: 0.5696 - val_loss: 0.6992 - val_acc: 0.4000\n",
      "Epoch 635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6553 - acc: 0.5316 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 636/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6538 - acc: 0.5696 - val_loss: 0.6946 - val_acc: 0.4000\n",
      "Epoch 637/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6553 - acc: 0.6582 - val_loss: 0.7025 - val_acc: 0.4000\n",
      "Epoch 638/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6546 - acc: 0.5316 - val_loss: 0.7018 - val_acc: 0.4000\n",
      "Epoch 639/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6540 - acc: 0.5316 - val_loss: 0.7016 - val_acc: 0.4000\n",
      "Epoch 640/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6552 - acc: 0.5316 - val_loss: 0.6981 - val_acc: 0.4000\n",
      "Epoch 641/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6545 - acc: 0.5570 - val_loss: 0.6944 - val_acc: 0.4000\n",
      "Epoch 642/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6542 - acc: 0.5443 - val_loss: 0.6911 - val_acc: 0.4000\n",
      "Epoch 643/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6545 - acc: 0.7089 - val_loss: 0.6921 - val_acc: 0.4000\n",
      "Epoch 644/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6564 - acc: 0.5949 - val_loss: 0.6891 - val_acc: 0.4500\n",
      "Epoch 645/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6531 - acc: 0.6582 - val_loss: 0.6875 - val_acc: 0.4500\n",
      "Epoch 646/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6550 - acc: 0.6962 - val_loss: 0.6911 - val_acc: 0.4000\n",
      "Epoch 647/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6525 - acc: 0.6582 - val_loss: 0.6920 - val_acc: 0.4000\n",
      "Epoch 648/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6523 - acc: 0.6329 - val_loss: 0.6920 - val_acc: 0.4000\n",
      "Epoch 649/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6524 - acc: 0.5823 - val_loss: 0.6876 - val_acc: 0.4500\n",
      "Epoch 650/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6532 - acc: 0.8228 - val_loss: 0.6921 - val_acc: 0.4000\n",
      "Epoch 651/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6522 - acc: 0.6329 - val_loss: 0.6903 - val_acc: 0.4000\n",
      "Epoch 652/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6527 - acc: 0.7342 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 653/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6533 - acc: 0.5443 - val_loss: 0.6961 - val_acc: 0.4000\n",
      "Epoch 654/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6535 - acc: 0.5443 - val_loss: 0.6917 - val_acc: 0.4000\n",
      "Epoch 655/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6532 - acc: 0.6835 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 656/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6514 - acc: 0.5570 - val_loss: 0.6959 - val_acc: 0.4000\n",
      "Epoch 657/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6515 - acc: 0.5570 - val_loss: 0.6968 - val_acc: 0.4000\n",
      "Epoch 658/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6508 - acc: 0.5570 - val_loss: 0.6951 - val_acc: 0.4000\n",
      "Epoch 659/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6514 - acc: 0.6203 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 660/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6517 - acc: 0.5316 - val_loss: 0.6895 - val_acc: 0.4000\n",
      "Epoch 661/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6517 - acc: 0.6709 - val_loss: 0.6920 - val_acc: 0.4000\n",
      "Epoch 662/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6507 - acc: 0.5949 - val_loss: 0.6891 - val_acc: 0.4500\n",
      "Epoch 663/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6514 - acc: 0.6962 - val_loss: 0.6855 - val_acc: 0.5000\n",
      "Epoch 664/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6521 - acc: 0.8734 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 665/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6512 - acc: 0.5316 - val_loss: 0.6974 - val_acc: 0.4000\n",
      "Epoch 666/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6504 - acc: 0.5443 - val_loss: 0.6933 - val_acc: 0.4000\n",
      "Epoch 667/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6501 - acc: 0.6456 - val_loss: 0.6955 - val_acc: 0.4000\n",
      "Epoch 668/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.6500 - acc: 0.5696 - val_loss: 0.6918 - val_acc: 0.4000\n",
      "Epoch 669/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6516 - acc: 0.6709 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 670/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6493 - acc: 0.5823 - val_loss: 0.6939 - val_acc: 0.4000\n",
      "Epoch 671/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6526 - acc: 0.5823 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 672/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6492 - acc: 0.5696 - val_loss: 0.6980 - val_acc: 0.4000\n",
      "Epoch 673/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6508 - acc: 0.5316 - val_loss: 0.6900 - val_acc: 0.4000\n",
      "Epoch 674/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6486 - acc: 0.6582 - val_loss: 0.6876 - val_acc: 0.4500\n",
      "Epoch 675/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6485 - acc: 0.7595 - val_loss: 0.6908 - val_acc: 0.4000\n",
      "Epoch 676/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6487 - acc: 0.7342 - val_loss: 0.6936 - val_acc: 0.4000\n",
      "Epoch 677/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6486 - acc: 0.6329 - val_loss: 0.6957 - val_acc: 0.4000\n",
      "Epoch 678/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6501 - acc: 0.5443 - val_loss: 0.6909 - val_acc: 0.4000\n",
      "Epoch 679/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6483 - acc: 0.6456 - val_loss: 0.6886 - val_acc: 0.4500\n",
      "Epoch 680/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6498 - acc: 0.5949 - val_loss: 0.6819 - val_acc: 0.5500\n",
      "Epoch 681/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6504 - acc: 0.7595 - val_loss: 0.6816 - val_acc: 0.5500\n",
      "Epoch 682/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6484 - acc: 0.7975 - val_loss: 0.6816 - val_acc: 0.5500\n",
      "Epoch 683/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6480 - acc: 0.9367 - val_loss: 0.6889 - val_acc: 0.4500\n",
      "Epoch 684/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6491 - acc: 0.6076 - val_loss: 0.6841 - val_acc: 0.5000\n",
      "Epoch 685/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6478 - acc: 0.7342 - val_loss: 0.6813 - val_acc: 0.5500\n",
      "Epoch 686/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6489 - acc: 0.8734 - val_loss: 0.6780 - val_acc: 0.6000\n",
      "Epoch 687/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6476 - acc: 0.9494 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 688/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6467 - acc: 0.8354 - val_loss: 0.6858 - val_acc: 0.4500\n",
      "Epoch 689/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6477 - acc: 0.7215 - val_loss: 0.6808 - val_acc: 0.5500\n",
      "Epoch 690/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6469 - acc: 0.9367 - val_loss: 0.6882 - val_acc: 0.4500\n",
      "Epoch 691/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6458 - acc: 0.6835 - val_loss: 0.6885 - val_acc: 0.4500\n",
      "Epoch 692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6468 - acc: 0.6329 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 693/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6462 - acc: 0.7975 - val_loss: 0.6833 - val_acc: 0.5000\n",
      "Epoch 694/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6470 - acc: 0.8354 - val_loss: 0.6925 - val_acc: 0.4000\n",
      "Epoch 695/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6464 - acc: 0.6709 - val_loss: 0.6998 - val_acc: 0.4000\n",
      "Epoch 696/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6461 - acc: 0.5316 - val_loss: 0.6958 - val_acc: 0.4000\n",
      "Epoch 697/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6473 - acc: 0.5823 - val_loss: 0.6892 - val_acc: 0.4000\n",
      "Epoch 698/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6480 - acc: 0.5823 - val_loss: 0.6795 - val_acc: 0.6000\n",
      "Epoch 699/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6464 - acc: 0.8987 - val_loss: 0.6785 - val_acc: 0.5500\n",
      "Epoch 700/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6466 - acc: 0.9747 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 701/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6467 - acc: 0.8861 - val_loss: 0.6826 - val_acc: 0.5000\n",
      "Epoch 702/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6454 - acc: 0.7468 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 703/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6457 - acc: 0.8481 - val_loss: 0.6796 - val_acc: 0.6000\n",
      "Epoch 704/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6449 - acc: 0.8861 - val_loss: 0.6783 - val_acc: 0.5500\n",
      "Epoch 705/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6446 - acc: 0.9367 - val_loss: 0.6835 - val_acc: 0.5000\n",
      "Epoch 706/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6439 - acc: 0.7722 - val_loss: 0.6805 - val_acc: 0.5500\n",
      "Epoch 707/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6456 - acc: 0.9114 - val_loss: 0.6847 - val_acc: 0.4500\n",
      "Epoch 708/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6435 - acc: 0.8101 - val_loss: 0.6906 - val_acc: 0.4000\n",
      "Epoch 709/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6428 - acc: 0.6329 - val_loss: 0.6874 - val_acc: 0.4500\n",
      "Epoch 710/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6426 - acc: 0.7722 - val_loss: 0.6905 - val_acc: 0.4000\n",
      "Epoch 711/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6437 - acc: 0.6835 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 712/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6427 - acc: 0.6456 - val_loss: 0.6937 - val_acc: 0.4000\n",
      "Epoch 713/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6426 - acc: 0.6456 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 714/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6428 - acc: 0.6203 - val_loss: 0.6976 - val_acc: 0.4000\n",
      "Epoch 715/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6433 - acc: 0.5316 - val_loss: 0.6964 - val_acc: 0.4000\n",
      "Epoch 716/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6431 - acc: 0.5570 - val_loss: 0.6985 - val_acc: 0.4000\n",
      "Epoch 717/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6420 - acc: 0.5570 - val_loss: 0.6975 - val_acc: 0.4000\n",
      "Epoch 718/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6414 - acc: 0.5696 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 719/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6415 - acc: 0.5949 - val_loss: 0.6945 - val_acc: 0.4000\n",
      "Epoch 720/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6408 - acc: 0.6203 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 721/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6407 - acc: 0.6203 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 722/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6415 - acc: 0.6203 - val_loss: 0.6902 - val_acc: 0.4000\n",
      "Epoch 723/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6406 - acc: 0.6329 - val_loss: 0.6888 - val_acc: 0.4000\n",
      "Epoch 724/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6400 - acc: 0.6709 - val_loss: 0.6834 - val_acc: 0.5000\n",
      "Epoch 725/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6406 - acc: 0.7215 - val_loss: 0.6779 - val_acc: 0.6000\n",
      "Epoch 726/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6403 - acc: 0.8481 - val_loss: 0.6781 - val_acc: 0.6000\n",
      "Epoch 727/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6405 - acc: 0.9620 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 728/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6389 - acc: 0.7975 - val_loss: 0.6847 - val_acc: 0.4500\n",
      "Epoch 729/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6385 - acc: 0.7975 - val_loss: 0.6854 - val_acc: 0.4500\n",
      "Epoch 730/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6390 - acc: 0.7848 - val_loss: 0.6910 - val_acc: 0.4000\n",
      "Epoch 731/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6402 - acc: 0.6076 - val_loss: 0.6837 - val_acc: 0.4500\n",
      "Epoch 732/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6385 - acc: 0.8861 - val_loss: 0.6879 - val_acc: 0.4500\n",
      "Epoch 733/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6400 - acc: 0.7722 - val_loss: 0.6909 - val_acc: 0.4000\n",
      "Epoch 734/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6379 - acc: 0.6582 - val_loss: 0.6922 - val_acc: 0.4000\n",
      "Epoch 735/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6376 - acc: 0.6203 - val_loss: 0.6876 - val_acc: 0.4500\n",
      "Epoch 736/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6387 - acc: 0.7089 - val_loss: 0.6801 - val_acc: 0.5000\n",
      "Epoch 737/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6417 - acc: 0.8861 - val_loss: 0.6831 - val_acc: 0.5000\n",
      "Epoch 738/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6369 - acc: 0.8101 - val_loss: 0.6863 - val_acc: 0.4500\n",
      "Epoch 739/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6390 - acc: 0.7089 - val_loss: 0.6936 - val_acc: 0.4000\n",
      "Epoch 740/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6412 - acc: 0.6835 - val_loss: 0.6923 - val_acc: 0.4000\n",
      "Epoch 741/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6363 - acc: 0.6329 - val_loss: 0.6903 - val_acc: 0.4000\n",
      "Epoch 742/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6362 - acc: 0.6835 - val_loss: 0.6916 - val_acc: 0.4000\n",
      "Epoch 743/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6374 - acc: 0.6203 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 744/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6361 - acc: 0.7722 - val_loss: 0.6804 - val_acc: 0.5000\n",
      "Epoch 745/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6376 - acc: 0.7342 - val_loss: 0.6765 - val_acc: 0.6000\n",
      "Epoch 746/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6361 - acc: 0.9620 - val_loss: 0.6837 - val_acc: 0.4500\n",
      "Epoch 747/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6353 - acc: 0.8101 - val_loss: 0.6892 - val_acc: 0.4000\n",
      "Epoch 748/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6353 - acc: 0.6456 - val_loss: 0.6871 - val_acc: 0.4500\n",
      "Epoch 749/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6345 - acc: 0.6962 - val_loss: 0.6840 - val_acc: 0.4500\n",
      "Epoch 750/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6358 - acc: 0.8101 - val_loss: 0.6919 - val_acc: 0.4000\n",
      "Epoch 751/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6344 - acc: 0.6456 - val_loss: 0.6921 - val_acc: 0.4000\n",
      "Epoch 752/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6362 - acc: 0.6329 - val_loss: 0.6944 - val_acc: 0.4000\n",
      "Epoch 753/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6350 - acc: 0.6203 - val_loss: 0.6855 - val_acc: 0.4500\n",
      "Epoch 754/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6346 - acc: 0.7722 - val_loss: 0.6831 - val_acc: 0.4500\n",
      "Epoch 755/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6352 - acc: 0.8354 - val_loss: 0.6891 - val_acc: 0.4000\n",
      "Epoch 756/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6337 - acc: 0.7468 - val_loss: 0.6931 - val_acc: 0.4000\n",
      "Epoch 757/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6348 - acc: 0.6709 - val_loss: 0.6994 - val_acc: 0.4000\n",
      "Epoch 758/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6342 - acc: 0.5696 - val_loss: 0.6967 - val_acc: 0.4000\n",
      "Epoch 759/3000\n",
      "79/79 [==============================] - 0s 103us/sample - loss: 0.6336 - acc: 0.6076 - val_loss: 0.6954 - val_acc: 0.4000\n",
      "Epoch 760/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6345 - acc: 0.5696 - val_loss: 0.6852 - val_acc: 0.4500\n",
      "Epoch 761/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6346 - acc: 0.6962 - val_loss: 0.6838 - val_acc: 0.4500\n",
      "Epoch 762/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6345 - acc: 0.7342 - val_loss: 0.6833 - val_acc: 0.4500\n",
      "Epoch 763/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6326 - acc: 0.7215 - val_loss: 0.6854 - val_acc: 0.4500\n",
      "Epoch 764/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6319 - acc: 0.7215 - val_loss: 0.6846 - val_acc: 0.4500\n",
      "Epoch 765/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6317 - acc: 0.8101 - val_loss: 0.6878 - val_acc: 0.4000\n",
      "Epoch 766/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6337 - acc: 0.7595 - val_loss: 0.6867 - val_acc: 0.4500\n",
      "Epoch 767/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6317 - acc: 0.6709 - val_loss: 0.6879 - val_acc: 0.4000\n",
      "Epoch 768/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6308 - acc: 0.7215 - val_loss: 0.6883 - val_acc: 0.4000\n",
      "Epoch 769/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6302 - acc: 0.6709 - val_loss: 0.6843 - val_acc: 0.4500\n",
      "Epoch 770/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6296 - acc: 0.7848 - val_loss: 0.6837 - val_acc: 0.4500\n",
      "Epoch 771/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6308 - acc: 0.8354 - val_loss: 0.6814 - val_acc: 0.5000\n",
      "Epoch 772/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6293 - acc: 0.8354 - val_loss: 0.6821 - val_acc: 0.4500\n",
      "Epoch 773/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6291 - acc: 0.7975 - val_loss: 0.6825 - val_acc: 0.4500\n",
      "Epoch 774/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6300 - acc: 0.7215 - val_loss: 0.6751 - val_acc: 0.5500\n",
      "Epoch 775/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6288 - acc: 0.9620 - val_loss: 0.6777 - val_acc: 0.5000\n",
      "Epoch 776/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6290 - acc: 0.9241 - val_loss: 0.6797 - val_acc: 0.5000\n",
      "Epoch 777/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6286 - acc: 0.8101 - val_loss: 0.6756 - val_acc: 0.6000\n",
      "Epoch 778/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6297 - acc: 0.8608 - val_loss: 0.6766 - val_acc: 0.5000\n",
      "Epoch 779/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6277 - acc: 0.9114 - val_loss: 0.6786 - val_acc: 0.5000\n",
      "Epoch 780/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6279 - acc: 0.8861 - val_loss: 0.6774 - val_acc: 0.5000\n",
      "Epoch 781/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6285 - acc: 0.8734 - val_loss: 0.6745 - val_acc: 0.6000\n",
      "Epoch 782/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6306 - acc: 0.9494 - val_loss: 0.6880 - val_acc: 0.4000\n",
      "Epoch 783/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6274 - acc: 0.6835 - val_loss: 0.6851 - val_acc: 0.4500\n",
      "Epoch 784/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6270 - acc: 0.7848 - val_loss: 0.6872 - val_acc: 0.4000\n",
      "Epoch 785/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6298 - acc: 0.6582 - val_loss: 0.6817 - val_acc: 0.4500\n",
      "Epoch 786/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6264 - acc: 0.7722 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 787/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6297 - acc: 0.8228 - val_loss: 0.6798 - val_acc: 0.5000\n",
      "Epoch 788/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6265 - acc: 0.8228 - val_loss: 0.6849 - val_acc: 0.4500\n",
      "Epoch 789/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6264 - acc: 0.7848 - val_loss: 0.6867 - val_acc: 0.4500\n",
      "Epoch 790/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6251 - acc: 0.7089 - val_loss: 0.6844 - val_acc: 0.4500\n",
      "Epoch 791/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.6250 - acc: 0.7595 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 792/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6296 - acc: 0.8734 - val_loss: 0.6823 - val_acc: 0.4500\n",
      "Epoch 793/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6245 - acc: 0.7848 - val_loss: 0.6769 - val_acc: 0.5000\n",
      "Epoch 794/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6248 - acc: 0.8481 - val_loss: 0.6729 - val_acc: 0.6000\n",
      "Epoch 795/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6242 - acc: 0.9241 - val_loss: 0.6704 - val_acc: 0.5500\n",
      "Epoch 796/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6236 - acc: 0.9494 - val_loss: 0.6754 - val_acc: 0.5000\n",
      "Epoch 797/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6234 - acc: 0.9367 - val_loss: 0.6819 - val_acc: 0.4500\n",
      "Epoch 798/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6225 - acc: 0.7975 - val_loss: 0.6840 - val_acc: 0.4500\n",
      "Epoch 799/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6243 - acc: 0.7722 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 800/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6232 - acc: 0.7975 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 801/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6225 - acc: 0.9494 - val_loss: 0.6728 - val_acc: 0.6000\n",
      "Epoch 802/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6221 - acc: 0.9367 - val_loss: 0.6703 - val_acc: 0.5500\n",
      "Epoch 803/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6216 - acc: 0.9494 - val_loss: 0.6756 - val_acc: 0.5000\n",
      "Epoch 804/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6213 - acc: 0.9620 - val_loss: 0.6819 - val_acc: 0.4500\n",
      "Epoch 805/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6206 - acc: 0.7848 - val_loss: 0.6806 - val_acc: 0.4500\n",
      "Epoch 806/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6215 - acc: 0.8228 - val_loss: 0.6845 - val_acc: 0.4500\n",
      "Epoch 807/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6206 - acc: 0.7848 - val_loss: 0.6881 - val_acc: 0.4000\n",
      "Epoch 808/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6209 - acc: 0.7089 - val_loss: 0.6901 - val_acc: 0.4000\n",
      "Epoch 809/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6204 - acc: 0.6582 - val_loss: 0.6892 - val_acc: 0.4000\n",
      "Epoch 810/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6202 - acc: 0.6962 - val_loss: 0.6828 - val_acc: 0.4500\n",
      "Epoch 811/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6215 - acc: 0.6835 - val_loss: 0.6730 - val_acc: 0.5500\n",
      "Epoch 812/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6202 - acc: 0.9114 - val_loss: 0.6700 - val_acc: 0.5500\n",
      "Epoch 813/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6209 - acc: 0.9367 - val_loss: 0.6783 - val_acc: 0.5000\n",
      "Epoch 814/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6183 - acc: 0.8101 - val_loss: 0.6754 - val_acc: 0.5000\n",
      "Epoch 815/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6178 - acc: 0.9241 - val_loss: 0.6780 - val_acc: 0.5000\n",
      "Epoch 816/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6205 - acc: 0.8734 - val_loss: 0.6842 - val_acc: 0.4500\n",
      "Epoch 817/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6173 - acc: 0.7468 - val_loss: 0.6763 - val_acc: 0.5000\n",
      "Epoch 818/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6184 - acc: 0.8987 - val_loss: 0.6883 - val_acc: 0.4000\n",
      "Epoch 819/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6181 - acc: 0.7595 - val_loss: 0.6846 - val_acc: 0.4500\n",
      "Epoch 820/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6163 - acc: 0.7595 - val_loss: 0.6797 - val_acc: 0.4500\n",
      "Epoch 821/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6177 - acc: 0.7722 - val_loss: 0.6803 - val_acc: 0.4500\n",
      "Epoch 822/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6150 - acc: 0.7975 - val_loss: 0.6792 - val_acc: 0.5000\n",
      "Epoch 823/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6184 - acc: 0.8608 - val_loss: 0.6822 - val_acc: 0.4500\n",
      "Epoch 824/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6175 - acc: 0.8734 - val_loss: 0.6926 - val_acc: 0.4000\n",
      "Epoch 825/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6171 - acc: 0.6962 - val_loss: 0.6874 - val_acc: 0.4000\n",
      "Epoch 826/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6159 - acc: 0.7595 - val_loss: 0.6927 - val_acc: 0.4000\n",
      "Epoch 827/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6150 - acc: 0.6709 - val_loss: 0.6899 - val_acc: 0.4000\n",
      "Epoch 828/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.6152 - acc: 0.6582 - val_loss: 0.6816 - val_acc: 0.4500\n",
      "Epoch 829/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6143 - acc: 0.8481 - val_loss: 0.6857 - val_acc: 0.4500\n",
      "Epoch 830/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6145 - acc: 0.7215 - val_loss: 0.6880 - val_acc: 0.4000\n",
      "Epoch 831/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6130 - acc: 0.7342 - val_loss: 0.6836 - val_acc: 0.4500\n",
      "Epoch 832/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6129 - acc: 0.7975 - val_loss: 0.6841 - val_acc: 0.4500\n",
      "Epoch 833/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6121 - acc: 0.7848 - val_loss: 0.6838 - val_acc: 0.4500\n",
      "Epoch 834/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6129 - acc: 0.7848 - val_loss: 0.6845 - val_acc: 0.4500\n",
      "Epoch 835/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6116 - acc: 0.7848 - val_loss: 0.6815 - val_acc: 0.4500\n",
      "Epoch 836/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6114 - acc: 0.8228 - val_loss: 0.6824 - val_acc: 0.4500\n",
      "Epoch 837/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6132 - acc: 0.7848 - val_loss: 0.6818 - val_acc: 0.4500\n",
      "Epoch 838/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6106 - acc: 0.7848 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 839/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6103 - acc: 0.8734 - val_loss: 0.6737 - val_acc: 0.5000\n",
      "Epoch 840/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6094 - acc: 0.8608 - val_loss: 0.6711 - val_acc: 0.5500\n",
      "Epoch 841/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6102 - acc: 0.9114 - val_loss: 0.6648 - val_acc: 0.5500\n",
      "Epoch 842/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6091 - acc: 0.9494 - val_loss: 0.6679 - val_acc: 0.5500\n",
      "Epoch 843/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6089 - acc: 0.9494 - val_loss: 0.6726 - val_acc: 0.5000\n",
      "Epoch 844/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6084 - acc: 0.8734 - val_loss: 0.6701 - val_acc: 0.6000\n",
      "Epoch 845/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6111 - acc: 0.9620 - val_loss: 0.6830 - val_acc: 0.4500\n",
      "Epoch 846/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6082 - acc: 0.7342 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 847/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6082 - acc: 0.8987 - val_loss: 0.6784 - val_acc: 0.4500\n",
      "Epoch 848/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6069 - acc: 0.8101 - val_loss: 0.6762 - val_acc: 0.5000\n",
      "Epoch 849/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6069 - acc: 0.8861 - val_loss: 0.6757 - val_acc: 0.5000\n",
      "Epoch 850/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6097 - acc: 0.8101 - val_loss: 0.6648 - val_acc: 0.5500\n",
      "Epoch 851/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6064 - acc: 0.9494 - val_loss: 0.6694 - val_acc: 0.6000\n",
      "Epoch 852/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6054 - acc: 0.9494 - val_loss: 0.6702 - val_acc: 0.5000\n",
      "Epoch 853/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6054 - acc: 0.9494 - val_loss: 0.6758 - val_acc: 0.5000\n",
      "Epoch 854/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6057 - acc: 0.8608 - val_loss: 0.6826 - val_acc: 0.4500\n",
      "Epoch 855/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6050 - acc: 0.7468 - val_loss: 0.6756 - val_acc: 0.5000\n",
      "Epoch 856/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6042 - acc: 0.8861 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 857/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6042 - acc: 0.8101 - val_loss: 0.6747 - val_acc: 0.5000\n",
      "Epoch 858/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6065 - acc: 0.8228 - val_loss: 0.6811 - val_acc: 0.4500\n",
      "Epoch 859/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6056 - acc: 0.8101 - val_loss: 0.6752 - val_acc: 0.5000\n",
      "Epoch 860/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6054 - acc: 0.7848 - val_loss: 0.6680 - val_acc: 0.6000\n",
      "Epoch 861/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6032 - acc: 0.9494 - val_loss: 0.6641 - val_acc: 0.5500\n",
      "Epoch 862/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6018 - acc: 0.9494 - val_loss: 0.6688 - val_acc: 0.5500\n",
      "Epoch 863/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6034 - acc: 0.9494 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 864/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6052 - acc: 0.8861 - val_loss: 0.6628 - val_acc: 0.5500\n",
      "Epoch 865/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6008 - acc: 0.9494 - val_loss: 0.6674 - val_acc: 0.6000\n",
      "Epoch 866/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6005 - acc: 0.9620 - val_loss: 0.6690 - val_acc: 0.5000\n",
      "Epoch 867/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.5996 - acc: 0.9494 - val_loss: 0.6718 - val_acc: 0.5000\n",
      "Epoch 868/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5998 - acc: 0.8861 - val_loss: 0.6659 - val_acc: 0.6000\n",
      "Epoch 869/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6040 - acc: 0.8861 - val_loss: 0.6607 - val_acc: 0.5000\n",
      "Epoch 870/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5997 - acc: 0.9620 - val_loss: 0.6587 - val_acc: 0.6500\n",
      "Epoch 871/3000\n",
      "79/79 [==============================] - 0s 266us/sample - loss: 0.5997 - acc: 0.9494 - val_loss: 0.6570 - val_acc: 0.8000\n",
      "Epoch 872/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5998 - acc: 0.9367 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 873/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5974 - acc: 0.9494 - val_loss: 0.6723 - val_acc: 0.5000\n",
      "Epoch 874/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5970 - acc: 0.8734 - val_loss: 0.6706 - val_acc: 0.5000\n",
      "Epoch 875/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5982 - acc: 0.9241 - val_loss: 0.6783 - val_acc: 0.4500\n",
      "Epoch 876/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.5975 - acc: 0.7722 - val_loss: 0.6714 - val_acc: 0.5000\n",
      "Epoch 877/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5962 - acc: 0.9241 - val_loss: 0.6706 - val_acc: 0.5000\n",
      "Epoch 878/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5977 - acc: 0.9114 - val_loss: 0.6679 - val_acc: 0.5000\n",
      "Epoch 879/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5950 - acc: 0.9241 - val_loss: 0.6703 - val_acc: 0.5000\n",
      "Epoch 880/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5945 - acc: 0.9367 - val_loss: 0.6726 - val_acc: 0.5000\n",
      "Epoch 881/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5942 - acc: 0.8987 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 882/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5961 - acc: 0.8228 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 883/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5936 - acc: 0.8481 - val_loss: 0.6683 - val_acc: 0.5000\n",
      "Epoch 884/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5935 - acc: 0.8861 - val_loss: 0.6674 - val_acc: 0.5000\n",
      "Epoch 885/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5935 - acc: 0.9241 - val_loss: 0.6686 - val_acc: 0.5000\n",
      "Epoch 886/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5942 - acc: 0.9494 - val_loss: 0.6717 - val_acc: 0.5000\n",
      "Epoch 887/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5921 - acc: 0.8987 - val_loss: 0.6675 - val_acc: 0.5000\n",
      "Epoch 888/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5934 - acc: 0.8987 - val_loss: 0.6694 - val_acc: 0.5000\n",
      "Epoch 889/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5911 - acc: 0.8987 - val_loss: 0.6624 - val_acc: 0.5500\n",
      "Epoch 890/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.5908 - acc: 0.9620 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 891/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5898 - acc: 0.9620 - val_loss: 0.6676 - val_acc: 0.5000\n",
      "Epoch 892/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.5894 - acc: 0.9241 - val_loss: 0.6639 - val_acc: 0.6000\n",
      "Epoch 893/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5903 - acc: 0.9494 - val_loss: 0.6725 - val_acc: 0.5000\n",
      "Epoch 894/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5887 - acc: 0.8228 - val_loss: 0.6668 - val_acc: 0.5000\n",
      "Epoch 895/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5885 - acc: 0.9367 - val_loss: 0.6641 - val_acc: 0.6000\n",
      "Epoch 896/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5877 - acc: 0.9494 - val_loss: 0.6669 - val_acc: 0.5000\n",
      "Epoch 897/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5881 - acc: 0.9620 - val_loss: 0.6742 - val_acc: 0.5000\n",
      "Epoch 898/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5892 - acc: 0.8101 - val_loss: 0.6613 - val_acc: 0.5500\n",
      "Epoch 899/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5899 - acc: 0.9620 - val_loss: 0.6659 - val_acc: 0.5000\n",
      "Epoch 900/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5874 - acc: 0.9241 - val_loss: 0.6659 - val_acc: 0.5000\n",
      "Epoch 901/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.5866 - acc: 0.9367 - val_loss: 0.6683 - val_acc: 0.5000\n",
      "Epoch 902/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5851 - acc: 0.9114 - val_loss: 0.6674 - val_acc: 0.5000\n",
      "Epoch 903/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5848 - acc: 0.9114 - val_loss: 0.6603 - val_acc: 0.5500\n",
      "Epoch 904/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5844 - acc: 0.9494 - val_loss: 0.6669 - val_acc: 0.5000\n",
      "Epoch 905/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.5839 - acc: 0.9114 - val_loss: 0.6615 - val_acc: 0.6000\n",
      "Epoch 906/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5830 - acc: 0.9620 - val_loss: 0.6644 - val_acc: 0.5000\n",
      "Epoch 907/3000\n",
      "79/79 [==============================] - 0s 163us/sample - loss: 0.5830 - acc: 0.9367 - val_loss: 0.6604 - val_acc: 0.5500\n",
      "Epoch 908/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5832 - acc: 0.9494 - val_loss: 0.6643 - val_acc: 0.5000\n",
      "Epoch 909/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5816 - acc: 0.9367 - val_loss: 0.6625 - val_acc: 0.5500\n",
      "Epoch 910/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.5817 - acc: 0.9494 - val_loss: 0.6601 - val_acc: 0.5500\n",
      "Epoch 911/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5806 - acc: 0.9620 - val_loss: 0.6607 - val_acc: 0.6000\n",
      "Epoch 912/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5824 - acc: 0.9620 - val_loss: 0.6561 - val_acc: 0.5500\n",
      "Epoch 913/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5798 - acc: 0.9494 - val_loss: 0.6579 - val_acc: 0.5500\n",
      "Epoch 914/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5802 - acc: 0.9494 - val_loss: 0.6675 - val_acc: 0.5000\n",
      "Epoch 915/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5810 - acc: 0.8734 - val_loss: 0.6609 - val_acc: 0.6000\n",
      "Epoch 916/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5788 - acc: 0.9620 - val_loss: 0.6608 - val_acc: 0.6000\n",
      "Epoch 917/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5779 - acc: 0.9620 - val_loss: 0.6582 - val_acc: 0.5500\n",
      "Epoch 918/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5776 - acc: 0.9494 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 919/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5782 - acc: 0.9367 - val_loss: 0.6709 - val_acc: 0.5000\n",
      "Epoch 920/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5768 - acc: 0.8481 - val_loss: 0.6633 - val_acc: 0.5000\n",
      "Epoch 921/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5765 - acc: 0.9620 - val_loss: 0.6628 - val_acc: 0.5000\n",
      "Epoch 922/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5755 - acc: 0.9367 - val_loss: 0.6613 - val_acc: 0.5500\n",
      "Epoch 923/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5746 - acc: 0.9494 - val_loss: 0.6611 - val_acc: 0.5500\n",
      "Epoch 924/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5743 - acc: 0.9494 - val_loss: 0.6576 - val_acc: 0.5500\n",
      "Epoch 925/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5737 - acc: 0.9620 - val_loss: 0.6572 - val_acc: 0.5500\n",
      "Epoch 926/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5748 - acc: 0.9620 - val_loss: 0.6658 - val_acc: 0.5000\n",
      "Epoch 927/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5734 - acc: 0.9241 - val_loss: 0.6690 - val_acc: 0.5000\n",
      "Epoch 928/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5733 - acc: 0.9241 - val_loss: 0.6709 - val_acc: 0.5000\n",
      "Epoch 929/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5728 - acc: 0.8734 - val_loss: 0.6699 - val_acc: 0.5000\n",
      "Epoch 930/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5717 - acc: 0.8734 - val_loss: 0.6625 - val_acc: 0.5000\n",
      "Epoch 931/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5743 - acc: 0.8608 - val_loss: 0.6502 - val_acc: 0.5000\n",
      "Epoch 932/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5727 - acc: 0.9494 - val_loss: 0.6533 - val_acc: 0.5500\n",
      "Epoch 933/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5713 - acc: 0.9747 - val_loss: 0.6514 - val_acc: 0.5500\n",
      "Epoch 934/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5691 - acc: 0.9494 - val_loss: 0.6535 - val_acc: 0.5500\n",
      "Epoch 935/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5684 - acc: 0.9620 - val_loss: 0.6515 - val_acc: 0.5500\n",
      "Epoch 936/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5689 - acc: 0.9620 - val_loss: 0.6501 - val_acc: 0.5000\n",
      "Epoch 937/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5685 - acc: 0.9620 - val_loss: 0.6501 - val_acc: 0.5000\n",
      "Epoch 938/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5675 - acc: 0.9494 - val_loss: 0.6504 - val_acc: 0.5500\n",
      "Epoch 939/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5661 - acc: 0.9494 - val_loss: 0.6524 - val_acc: 0.5500\n",
      "Epoch 940/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.5661 - acc: 0.9620 - val_loss: 0.6541 - val_acc: 0.5500\n",
      "Epoch 941/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5656 - acc: 0.9494 - val_loss: 0.6516 - val_acc: 0.5500\n",
      "Epoch 942/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5651 - acc: 0.9620 - val_loss: 0.6474 - val_acc: 0.5500\n",
      "Epoch 943/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5641 - acc: 0.9494 - val_loss: 0.6499 - val_acc: 0.5500\n",
      "Epoch 944/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.5656 - acc: 0.9494 - val_loss: 0.6453 - val_acc: 0.6500\n",
      "Epoch 945/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.5638 - acc: 0.9494 - val_loss: 0.6450 - val_acc: 0.6500\n",
      "Epoch 946/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5634 - acc: 0.9494 - val_loss: 0.6480 - val_acc: 0.5000\n",
      "Epoch 947/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.5622 - acc: 0.9494 - val_loss: 0.6532 - val_acc: 0.5500\n",
      "Epoch 948/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5610 - acc: 0.9620 - val_loss: 0.6525 - val_acc: 0.5500\n",
      "Epoch 949/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.5608 - acc: 0.9620 - val_loss: 0.6473 - val_acc: 0.5000\n",
      "Epoch 950/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5664 - acc: 0.9494 - val_loss: 0.6549 - val_acc: 0.5500\n",
      "Epoch 951/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.5629 - acc: 0.9620 - val_loss: 0.6605 - val_acc: 0.5000\n",
      "Epoch 952/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5595 - acc: 0.9241 - val_loss: 0.6574 - val_acc: 0.5500\n",
      "Epoch 953/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5583 - acc: 0.9620 - val_loss: 0.6518 - val_acc: 0.5500\n",
      "Epoch 954/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5580 - acc: 0.9620 - val_loss: 0.6493 - val_acc: 0.5500\n",
      "Epoch 955/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5571 - acc: 0.9494 - val_loss: 0.6501 - val_acc: 0.5500\n",
      "Epoch 956/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5575 - acc: 0.9620 - val_loss: 0.6587 - val_acc: 0.5000\n",
      "Epoch 957/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5568 - acc: 0.9747 - val_loss: 0.6558 - val_acc: 0.5500\n",
      "Epoch 958/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5559 - acc: 0.9494 - val_loss: 0.6557 - val_acc: 0.5500\n",
      "Epoch 959/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5547 - acc: 0.9494 - val_loss: 0.6504 - val_acc: 0.5500\n",
      "Epoch 960/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5544 - acc: 0.9494 - val_loss: 0.6471 - val_acc: 0.5500\n",
      "Epoch 961/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5546 - acc: 0.9494 - val_loss: 0.6535 - val_acc: 0.6000\n",
      "Epoch 962/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5534 - acc: 0.9620 - val_loss: 0.6584 - val_acc: 0.5000\n",
      "Epoch 963/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5531 - acc: 0.9367 - val_loss: 0.6537 - val_acc: 0.6000\n",
      "Epoch 964/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.5537 - acc: 0.9620 - val_loss: 0.6471 - val_acc: 0.5500\n",
      "Epoch 965/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.5512 - acc: 0.9494 - val_loss: 0.6516 - val_acc: 0.5500\n",
      "Epoch 966/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5526 - acc: 0.9494 - val_loss: 0.6480 - val_acc: 0.5500\n",
      "Epoch 967/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5513 - acc: 0.9494 - val_loss: 0.6485 - val_acc: 0.5500\n",
      "Epoch 968/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.5507 - acc: 0.9620 - val_loss: 0.6381 - val_acc: 0.7500\n",
      "Epoch 969/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5492 - acc: 0.9494 - val_loss: 0.6379 - val_acc: 0.7500\n",
      "Epoch 970/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.5484 - acc: 0.9494 - val_loss: 0.6400 - val_acc: 0.6500\n",
      "Epoch 971/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5509 - acc: 0.9620 - val_loss: 0.6389 - val_acc: 0.6500\n",
      "Epoch 972/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.5468 - acc: 0.9494 - val_loss: 0.6435 - val_acc: 0.5500\n",
      "Epoch 973/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5466 - acc: 0.9494 - val_loss: 0.6448 - val_acc: 0.5500\n",
      "Epoch 974/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5476 - acc: 0.9494 - val_loss: 0.6471 - val_acc: 0.5500\n",
      "Epoch 975/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5448 - acc: 0.9620 - val_loss: 0.6468 - val_acc: 0.5500\n",
      "Epoch 976/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5455 - acc: 0.9620 - val_loss: 0.6389 - val_acc: 0.6500\n",
      "Epoch 977/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5438 - acc: 0.9494 - val_loss: 0.6432 - val_acc: 0.5500\n",
      "Epoch 978/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5432 - acc: 0.9494 - val_loss: 0.6491 - val_acc: 0.5500\n",
      "Epoch 979/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5425 - acc: 0.9620 - val_loss: 0.6443 - val_acc: 0.5500\n",
      "Epoch 980/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5432 - acc: 0.9494 - val_loss: 0.6362 - val_acc: 0.7000\n",
      "Epoch 981/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5417 - acc: 0.9494 - val_loss: 0.6338 - val_acc: 0.7500\n",
      "Epoch 982/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5405 - acc: 0.9494 - val_loss: 0.6370 - val_acc: 0.6500\n",
      "Epoch 983/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5398 - acc: 0.9494 - val_loss: 0.6412 - val_acc: 0.5500\n",
      "Epoch 984/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5388 - acc: 0.9494 - val_loss: 0.6438 - val_acc: 0.5500\n",
      "Epoch 985/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5377 - acc: 0.9620 - val_loss: 0.6460 - val_acc: 0.5500\n",
      "Epoch 986/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.5371 - acc: 0.9620 - val_loss: 0.6444 - val_acc: 0.5500\n",
      "Epoch 987/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.5368 - acc: 0.9494 - val_loss: 0.6472 - val_acc: 0.5500\n",
      "Epoch 988/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5394 - acc: 0.9620 - val_loss: 0.6461 - val_acc: 0.5500\n",
      "Epoch 989/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5354 - acc: 0.9620 - val_loss: 0.6433 - val_acc: 0.5500\n",
      "Epoch 990/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5346 - acc: 0.9620 - val_loss: 0.6398 - val_acc: 0.5500\n",
      "Epoch 991/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5373 - acc: 0.9367 - val_loss: 0.6267 - val_acc: 0.7500\n",
      "Epoch 992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5340 - acc: 0.9494 - val_loss: 0.6345 - val_acc: 0.6500\n",
      "Epoch 993/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.5321 - acc: 0.9494 - val_loss: 0.6390 - val_acc: 0.5500\n",
      "Epoch 994/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.5314 - acc: 0.9494 - val_loss: 0.6421 - val_acc: 0.5500\n",
      "Epoch 995/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5309 - acc: 0.9620 - val_loss: 0.6467 - val_acc: 0.5500\n",
      "Epoch 996/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.5302 - acc: 0.9620 - val_loss: 0.6411 - val_acc: 0.5500\n",
      "Epoch 997/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5318 - acc: 0.9620 - val_loss: 0.6331 - val_acc: 0.6500\n",
      "Epoch 998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5291 - acc: 0.9494 - val_loss: 0.6430 - val_acc: 0.5500\n",
      "Epoch 999/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5281 - acc: 0.9620 - val_loss: 0.6399 - val_acc: 0.5500\n",
      "Epoch 1000/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5270 - acc: 0.9620 - val_loss: 0.6362 - val_acc: 0.5000\n",
      "Epoch 1001/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5278 - acc: 0.9494 - val_loss: 0.6287 - val_acc: 0.7500\n",
      "Epoch 1002/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5256 - acc: 0.9494 - val_loss: 0.6354 - val_acc: 0.5000\n",
      "Epoch 1003/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5253 - acc: 0.9494 - val_loss: 0.6349 - val_acc: 0.5000\n",
      "Epoch 1004/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5272 - acc: 0.9494 - val_loss: 0.6308 - val_acc: 0.6500\n",
      "Epoch 1005/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5242 - acc: 0.9494 - val_loss: 0.6429 - val_acc: 0.5500\n",
      "Epoch 1006/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5233 - acc: 0.9620 - val_loss: 0.6308 - val_acc: 0.6500\n",
      "Epoch 1007/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5218 - acc: 0.9494 - val_loss: 0.6388 - val_acc: 0.5500\n",
      "Epoch 1008/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5214 - acc: 0.9620 - val_loss: 0.6313 - val_acc: 0.6000\n",
      "Epoch 1009/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5208 - acc: 0.9494 - val_loss: 0.6315 - val_acc: 0.6000\n",
      "Epoch 1010/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5192 - acc: 0.9494 - val_loss: 0.6324 - val_acc: 0.5000\n",
      "Epoch 1011/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5187 - acc: 0.9494 - val_loss: 0.6336 - val_acc: 0.5000\n",
      "Epoch 1012/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5174 - acc: 0.9494 - val_loss: 0.6355 - val_acc: 0.5500\n",
      "Epoch 1013/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5194 - acc: 0.9494 - val_loss: 0.6333 - val_acc: 0.5000\n",
      "Epoch 1014/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5164 - acc: 0.9494 - val_loss: 0.6418 - val_acc: 0.5500\n",
      "Epoch 1015/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5163 - acc: 0.9494 - val_loss: 0.6421 - val_acc: 0.5500\n",
      "Epoch 1016/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5147 - acc: 0.9620 - val_loss: 0.6401 - val_acc: 0.5500\n",
      "Epoch 1017/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5152 - acc: 0.9494 - val_loss: 0.6336 - val_acc: 0.5000\n",
      "Epoch 1018/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.5139 - acc: 0.9494 - val_loss: 0.6447 - val_acc: 0.5000\n",
      "Epoch 1019/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5127 - acc: 0.9620 - val_loss: 0.6359 - val_acc: 0.5500\n",
      "Epoch 1020/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5119 - acc: 0.9494 - val_loss: 0.6435 - val_acc: 0.5000\n",
      "Epoch 1021/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5109 - acc: 0.9620 - val_loss: 0.6424 - val_acc: 0.5000\n",
      "Epoch 1022/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5146 - acc: 0.9367 - val_loss: 0.6431 - val_acc: 0.5000\n",
      "Epoch 1023/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5092 - acc: 0.9620 - val_loss: 0.6368 - val_acc: 0.5500\n",
      "Epoch 1024/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.5079 - acc: 0.9494 - val_loss: 0.6310 - val_acc: 0.5000\n",
      "Epoch 1025/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5073 - acc: 0.9494 - val_loss: 0.6307 - val_acc: 0.5000\n",
      "Epoch 1026/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5060 - acc: 0.9494 - val_loss: 0.6315 - val_acc: 0.5000\n",
      "Epoch 1027/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5073 - acc: 0.9494 - val_loss: 0.6330 - val_acc: 0.5500\n",
      "Epoch 1028/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5067 - acc: 0.9494 - val_loss: 0.6416 - val_acc: 0.5000\n",
      "Epoch 1029/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5045 - acc: 0.9620 - val_loss: 0.6395 - val_acc: 0.5000\n",
      "Epoch 1030/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5032 - acc: 0.9620 - val_loss: 0.6290 - val_acc: 0.5000\n",
      "Epoch 1031/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5051 - acc: 0.9620 - val_loss: 0.6282 - val_acc: 0.6000\n",
      "Epoch 1032/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5013 - acc: 0.9494 - val_loss: 0.6236 - val_acc: 0.7000\n",
      "Epoch 1033/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4998 - acc: 0.9494 - val_loss: 0.6259 - val_acc: 0.6000\n",
      "Epoch 1034/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.4998 - acc: 0.9494 - val_loss: 0.6316 - val_acc: 0.5500\n",
      "Epoch 1035/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5009 - acc: 0.9494 - val_loss: 0.6202 - val_acc: 0.7500\n",
      "Epoch 1036/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4974 - acc: 0.9494 - val_loss: 0.6244 - val_acc: 0.6500\n",
      "Epoch 1037/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.4985 - acc: 0.9620 - val_loss: 0.6267 - val_acc: 0.5500\n",
      "Epoch 1038/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4956 - acc: 0.9494 - val_loss: 0.6240 - val_acc: 0.6000\n",
      "Epoch 1039/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4949 - acc: 0.9494 - val_loss: 0.6216 - val_acc: 0.7000\n",
      "Epoch 1040/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4941 - acc: 0.9494 - val_loss: 0.6197 - val_acc: 0.7000\n",
      "Epoch 1041/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4944 - acc: 0.9494 - val_loss: 0.6181 - val_acc: 0.7500\n",
      "Epoch 1042/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4941 - acc: 0.9620 - val_loss: 0.6165 - val_acc: 0.7500\n",
      "Epoch 1043/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4917 - acc: 0.9494 - val_loss: 0.6267 - val_acc: 0.5000\n",
      "Epoch 1044/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.4903 - acc: 0.9494 - val_loss: 0.6313 - val_acc: 0.5500\n",
      "Epoch 1045/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4893 - acc: 0.9620 - val_loss: 0.6276 - val_acc: 0.5000\n",
      "Epoch 1046/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4881 - acc: 0.9620 - val_loss: 0.6254 - val_acc: 0.5000\n",
      "Epoch 1047/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4876 - acc: 0.9494 - val_loss: 0.6210 - val_acc: 0.6500\n",
      "Epoch 1048/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4888 - acc: 0.9494 - val_loss: 0.6184 - val_acc: 0.7000\n",
      "Epoch 1049/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4859 - acc: 0.9494 - val_loss: 0.6232 - val_acc: 0.6000\n",
      "Epoch 1050/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4856 - acc: 0.9494 - val_loss: 0.6178 - val_acc: 0.6000\n",
      "Epoch 1051/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4854 - acc: 0.9494 - val_loss: 0.6171 - val_acc: 0.6000\n",
      "Epoch 1052/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4832 - acc: 0.9494 - val_loss: 0.6165 - val_acc: 0.6000\n",
      "Epoch 1053/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4829 - acc: 0.9620 - val_loss: 0.6116 - val_acc: 0.7500\n",
      "Epoch 1054/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4832 - acc: 0.9494 - val_loss: 0.6116 - val_acc: 0.7500\n",
      "Epoch 1055/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4830 - acc: 0.9494 - val_loss: 0.6222 - val_acc: 0.5500\n",
      "Epoch 1056/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4841 - acc: 0.9494 - val_loss: 0.6187 - val_acc: 0.6000\n",
      "Epoch 1057/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4788 - acc: 0.9620 - val_loss: 0.6145 - val_acc: 0.6500\n",
      "Epoch 1058/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4781 - acc: 0.9494 - val_loss: 0.6194 - val_acc: 0.5500\n",
      "Epoch 1059/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.4785 - acc: 0.9620 - val_loss: 0.6130 - val_acc: 0.7000\n",
      "Epoch 1060/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.4756 - acc: 0.9620 - val_loss: 0.6148 - val_acc: 0.6500\n",
      "Epoch 1061/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4746 - acc: 0.9620 - val_loss: 0.6259 - val_acc: 0.5500\n",
      "Epoch 1062/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4734 - acc: 0.9620 - val_loss: 0.6153 - val_acc: 0.6500\n",
      "Epoch 1063/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4736 - acc: 0.9494 - val_loss: 0.6170 - val_acc: 0.6000\n",
      "Epoch 1064/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4707 - acc: 0.9494 - val_loss: 0.6204 - val_acc: 0.5500\n",
      "Epoch 1065/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.4701 - acc: 0.9620 - val_loss: 0.6079 - val_acc: 0.7500\n",
      "Epoch 1066/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4701 - acc: 0.9494 - val_loss: 0.6045 - val_acc: 0.7500\n",
      "Epoch 1067/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4756 - acc: 0.9494 - val_loss: 0.6146 - val_acc: 0.5500\n",
      "Epoch 1068/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4668 - acc: 0.9620 - val_loss: 0.6107 - val_acc: 0.7500\n",
      "Epoch 1069/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.4661 - acc: 0.9620 - val_loss: 0.6130 - val_acc: 0.6500\n",
      "Epoch 1070/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4659 - acc: 0.9620 - val_loss: 0.6256 - val_acc: 0.5500\n",
      "Epoch 1071/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.4641 - acc: 0.9620 - val_loss: 0.6142 - val_acc: 0.5500\n",
      "Epoch 1072/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4634 - acc: 0.9620 - val_loss: 0.6097 - val_acc: 0.7500\n",
      "Epoch 1073/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4620 - acc: 0.9620 - val_loss: 0.6042 - val_acc: 0.7500\n",
      "Epoch 1074/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4619 - acc: 0.9494 - val_loss: 0.6117 - val_acc: 0.7000\n",
      "Epoch 1075/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.4609 - acc: 0.9620 - val_loss: 0.5990 - val_acc: 0.7000\n",
      "Epoch 1076/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4594 - acc: 0.9494 - val_loss: 0.6061 - val_acc: 0.7500\n",
      "Epoch 1077/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4570 - acc: 0.9494 - val_loss: 0.6057 - val_acc: 0.7500\n",
      "Epoch 1078/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4574 - acc: 0.9620 - val_loss: 0.6119 - val_acc: 0.6500\n",
      "Epoch 1079/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4571 - acc: 0.9494 - val_loss: 0.6202 - val_acc: 0.6000\n",
      "Epoch 1080/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4546 - acc: 0.9620 - val_loss: 0.6139 - val_acc: 0.5500\n",
      "Epoch 1081/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4536 - acc: 0.9620 - val_loss: 0.6143 - val_acc: 0.5500\n",
      "Epoch 1082/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4530 - acc: 0.9620 - val_loss: 0.6024 - val_acc: 0.7500\n",
      "Epoch 1083/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4534 - acc: 0.9620 - val_loss: 0.6201 - val_acc: 0.6000\n",
      "Epoch 1084/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.4505 - acc: 0.9620 - val_loss: 0.6144 - val_acc: 0.5500\n",
      "Epoch 1085/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4494 - acc: 0.9620 - val_loss: 0.6131 - val_acc: 0.5500\n",
      "Epoch 1086/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4486 - acc: 0.9620 - val_loss: 0.6015 - val_acc: 0.7500\n",
      "Epoch 1087/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.4490 - acc: 0.9620 - val_loss: 0.5929 - val_acc: 0.7500\n",
      "Epoch 1088/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.4473 - acc: 0.9494 - val_loss: 0.5970 - val_acc: 0.7000\n",
      "Epoch 1089/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.4453 - acc: 0.9494 - val_loss: 0.5957 - val_acc: 0.7000\n",
      "Epoch 1090/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.4442 - acc: 0.9494 - val_loss: 0.6043 - val_acc: 0.7500\n",
      "Epoch 1091/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4449 - acc: 0.9620 - val_loss: 0.6038 - val_acc: 0.7500\n",
      "Epoch 1092/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.4416 - acc: 0.9620 - val_loss: 0.6085 - val_acc: 0.6000\n",
      "Epoch 1093/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4428 - acc: 0.9620 - val_loss: 0.5988 - val_acc: 0.7500\n",
      "Epoch 1094/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.4395 - acc: 0.9620 - val_loss: 0.5955 - val_acc: 0.7000\n",
      "Epoch 1095/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4390 - acc: 0.9494 - val_loss: 0.6032 - val_acc: 0.7000\n",
      "Epoch 1096/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4377 - acc: 0.9620 - val_loss: 0.6021 - val_acc: 0.7000\n",
      "Epoch 1097/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.4362 - acc: 0.9620 - val_loss: 0.6057 - val_acc: 0.6000\n",
      "Epoch 1098/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.4357 - acc: 0.9620 - val_loss: 0.5999 - val_acc: 0.7500\n",
      "Epoch 1099/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.4351 - acc: 0.9620 - val_loss: 0.6086 - val_acc: 0.5500\n",
      "Epoch 1100/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4340 - acc: 0.9620 - val_loss: 0.5975 - val_acc: 0.7500\n",
      "Epoch 1101/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4334 - acc: 0.9620 - val_loss: 0.5911 - val_acc: 0.7000\n",
      "Epoch 1102/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4309 - acc: 0.9494 - val_loss: 0.5954 - val_acc: 0.7500\n",
      "Epoch 1103/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4307 - acc: 0.9494 - val_loss: 0.5991 - val_acc: 0.7500\n",
      "Epoch 1104/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.4285 - acc: 0.9620 - val_loss: 0.5940 - val_acc: 0.7500\n",
      "Epoch 1105/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4288 - acc: 0.9494 - val_loss: 0.5998 - val_acc: 0.7000\n",
      "Epoch 1106/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4276 - acc: 0.9494 - val_loss: 0.6105 - val_acc: 0.5500\n",
      "Epoch 1107/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4256 - acc: 0.9620 - val_loss: 0.5999 - val_acc: 0.7000\n",
      "Epoch 1108/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4253 - acc: 0.9620 - val_loss: 0.5887 - val_acc: 0.7000\n",
      "Epoch 1109/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4244 - acc: 0.9494 - val_loss: 0.5864 - val_acc: 0.7000\n",
      "Epoch 1110/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.4224 - acc: 0.9494 - val_loss: 0.5889 - val_acc: 0.7000\n",
      "Epoch 1111/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4219 - acc: 0.9494 - val_loss: 0.5960 - val_acc: 0.7500\n",
      "Epoch 1112/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4221 - acc: 0.9620 - val_loss: 0.5883 - val_acc: 0.7000\n",
      "Epoch 1113/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4189 - acc: 0.9494 - val_loss: 0.5929 - val_acc: 0.7500\n",
      "Epoch 1114/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4188 - acc: 0.9620 - val_loss: 0.5867 - val_acc: 0.7000\n",
      "Epoch 1115/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.4168 - acc: 0.9494 - val_loss: 0.5890 - val_acc: 0.7500\n",
      "Epoch 1116/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4164 - acc: 0.9620 - val_loss: 0.5856 - val_acc: 0.7000\n",
      "Epoch 1117/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4149 - acc: 0.9494 - val_loss: 0.5841 - val_acc: 0.7000\n",
      "Epoch 1118/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4145 - acc: 0.9494 - val_loss: 0.5802 - val_acc: 0.7500\n",
      "Epoch 1119/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4134 - acc: 0.9367 - val_loss: 0.5912 - val_acc: 0.7500\n",
      "Epoch 1120/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4108 - acc: 0.9620 - val_loss: 0.5927 - val_acc: 0.7500\n",
      "Epoch 1121/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4107 - acc: 0.9494 - val_loss: 0.5963 - val_acc: 0.6500\n",
      "Epoch 1122/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4108 - acc: 0.9620 - val_loss: 0.5969 - val_acc: 0.6000\n",
      "Epoch 1123/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4082 - acc: 0.9620 - val_loss: 0.5904 - val_acc: 0.7500\n",
      "Epoch 1124/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4085 - acc: 0.9620 - val_loss: 0.5920 - val_acc: 0.7500\n",
      "Epoch 1125/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4101 - acc: 0.9494 - val_loss: 0.6065 - val_acc: 0.5500\n",
      "Epoch 1126/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4075 - acc: 0.9620 - val_loss: 0.6120 - val_acc: 0.5500\n",
      "Epoch 1127/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.4057 - acc: 0.9620 - val_loss: 0.5979 - val_acc: 0.6000\n",
      "Epoch 1128/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.4030 - acc: 0.9620 - val_loss: 0.5905 - val_acc: 0.7500\n",
      "Epoch 1129/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4022 - acc: 0.9620 - val_loss: 0.5887 - val_acc: 0.7500\n",
      "Epoch 1130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4000 - acc: 0.9620 - val_loss: 0.5842 - val_acc: 0.7500\n",
      "Epoch 1131/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3994 - acc: 0.9494 - val_loss: 0.5947 - val_acc: 0.6000\n",
      "Epoch 1132/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3978 - acc: 0.9620 - val_loss: 0.5922 - val_acc: 0.6500\n",
      "Epoch 1133/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 113us/sample - loss: 0.3965 - acc: 0.9620 - val_loss: 0.5891 - val_acc: 0.7500\n",
      "Epoch 1134/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3955 - acc: 0.9620 - val_loss: 0.5789 - val_acc: 0.7000\n",
      "Epoch 1135/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.3944 - acc: 0.9620 - val_loss: 0.5740 - val_acc: 0.7000\n",
      "Epoch 1136/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.3942 - acc: 0.9494 - val_loss: 0.5857 - val_acc: 0.7500\n",
      "Epoch 1137/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.3949 - acc: 0.9620 - val_loss: 0.5914 - val_acc: 0.6000\n",
      "Epoch 1138/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3910 - acc: 0.9620 - val_loss: 0.5908 - val_acc: 0.6000\n",
      "Epoch 1139/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3907 - acc: 0.9620 - val_loss: 0.5749 - val_acc: 0.7000\n",
      "Epoch 1140/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.3883 - acc: 0.9494 - val_loss: 0.5767 - val_acc: 0.7000\n",
      "Epoch 1141/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3877 - acc: 0.9494 - val_loss: 0.5745 - val_acc: 0.7000\n",
      "Epoch 1142/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3870 - acc: 0.9620 - val_loss: 0.5749 - val_acc: 0.7000\n",
      "Epoch 1143/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3853 - acc: 0.9494 - val_loss: 0.5821 - val_acc: 0.7500\n",
      "Epoch 1144/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.3840 - acc: 0.9620 - val_loss: 0.5774 - val_acc: 0.7500\n",
      "Epoch 1145/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.3832 - acc: 0.9494 - val_loss: 0.5852 - val_acc: 0.7500\n",
      "Epoch 1146/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3823 - acc: 0.9620 - val_loss: 0.5825 - val_acc: 0.7500\n",
      "Epoch 1147/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.3818 - acc: 0.9620 - val_loss: 0.5810 - val_acc: 0.7500\n",
      "Epoch 1148/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.3797 - acc: 0.9494 - val_loss: 0.5859 - val_acc: 0.6500\n",
      "Epoch 1149/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.3781 - acc: 0.9620 - val_loss: 0.5784 - val_acc: 0.7500\n",
      "Epoch 1150/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.3766 - acc: 0.9620 - val_loss: 0.5785 - val_acc: 0.7500\n",
      "Epoch 1151/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3781 - acc: 0.9620 - val_loss: 0.5745 - val_acc: 0.7500\n",
      "Epoch 1152/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.3753 - acc: 0.9494 - val_loss: 0.5669 - val_acc: 0.7500\n",
      "Epoch 1153/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3742 - acc: 0.9620 - val_loss: 0.5646 - val_acc: 0.7500\n",
      "Epoch 1154/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3738 - acc: 0.9620 - val_loss: 0.5613 - val_acc: 0.7500\n",
      "Epoch 1155/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3739 - acc: 0.9494 - val_loss: 0.5736 - val_acc: 0.8000\n",
      "Epoch 1156/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.3710 - acc: 0.9494 - val_loss: 0.5690 - val_acc: 0.7500\n",
      "Epoch 1157/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3706 - acc: 0.9494 - val_loss: 0.5792 - val_acc: 0.7500\n",
      "Epoch 1158/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3692 - acc: 0.9620 - val_loss: 0.5700 - val_acc: 0.8000\n",
      "Epoch 1159/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.3701 - acc: 0.9494 - val_loss: 0.5755 - val_acc: 0.7500\n",
      "Epoch 1160/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3672 - acc: 0.9620 - val_loss: 0.5656 - val_acc: 0.8000\n",
      "Epoch 1161/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.3655 - acc: 0.9620 - val_loss: 0.5675 - val_acc: 0.8000\n",
      "Epoch 1162/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3656 - acc: 0.9620 - val_loss: 0.5700 - val_acc: 0.8000\n",
      "Epoch 1163/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3647 - acc: 0.9494 - val_loss: 0.5794 - val_acc: 0.6500\n",
      "Epoch 1164/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3630 - acc: 0.9620 - val_loss: 0.5753 - val_acc: 0.7500\n",
      "Epoch 1165/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3608 - acc: 0.9620 - val_loss: 0.5642 - val_acc: 0.7500\n",
      "Epoch 1166/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.3602 - acc: 0.9620 - val_loss: 0.5670 - val_acc: 0.8000\n",
      "Epoch 1167/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.3574 - acc: 0.9620 - val_loss: 0.5708 - val_acc: 0.7500\n",
      "Epoch 1168/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.3560 - acc: 0.9494 - val_loss: 0.5740 - val_acc: 0.7000\n",
      "Epoch 1169/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3574 - acc: 0.9494 - val_loss: 0.5809 - val_acc: 0.6500\n",
      "Epoch 1170/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3559 - acc: 0.9620 - val_loss: 0.5687 - val_acc: 0.8000\n",
      "Epoch 1171/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3535 - acc: 0.9747 - val_loss: 0.5697 - val_acc: 0.8000\n",
      "Epoch 1172/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.3516 - acc: 0.9620 - val_loss: 0.5701 - val_acc: 0.8000\n",
      "Epoch 1173/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.3506 - acc: 0.9620 - val_loss: 0.5690 - val_acc: 0.8000\n",
      "Epoch 1174/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3495 - acc: 0.9620 - val_loss: 0.5680 - val_acc: 0.8000\n",
      "Epoch 1175/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3482 - acc: 0.9620 - val_loss: 0.5700 - val_acc: 0.8000\n",
      "Epoch 1176/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3482 - acc: 0.9747 - val_loss: 0.5747 - val_acc: 0.7000\n",
      "Epoch 1177/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3464 - acc: 0.9620 - val_loss: 0.5743 - val_acc: 0.7000\n",
      "Epoch 1178/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.3452 - acc: 0.9620 - val_loss: 0.5721 - val_acc: 0.7000\n",
      "Epoch 1179/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3446 - acc: 0.9620 - val_loss: 0.5796 - val_acc: 0.6500\n",
      "Epoch 1180/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3447 - acc: 0.9620 - val_loss: 0.5720 - val_acc: 0.7000\n",
      "Epoch 1181/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3431 - acc: 0.9620 - val_loss: 0.5674 - val_acc: 0.8000\n",
      "Epoch 1182/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.3402 - acc: 0.9620 - val_loss: 0.5669 - val_acc: 0.8000\n",
      "Epoch 1183/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.3391 - acc: 0.9620 - val_loss: 0.5691 - val_acc: 0.7500\n",
      "Epoch 1184/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3382 - acc: 0.9620 - val_loss: 0.5726 - val_acc: 0.7000\n",
      "Epoch 1185/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3378 - acc: 0.9620 - val_loss: 0.5727 - val_acc: 0.7000\n",
      "Epoch 1186/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.3377 - acc: 0.9620 - val_loss: 0.5689 - val_acc: 0.7000\n",
      "Epoch 1187/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.3383 - acc: 0.9620 - val_loss: 0.5548 - val_acc: 0.8000\n",
      "Epoch 1188/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3341 - acc: 0.9620 - val_loss: 0.5532 - val_acc: 0.8000\n",
      "Epoch 1189/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3326 - acc: 0.9620 - val_loss: 0.5565 - val_acc: 0.8000\n",
      "Epoch 1190/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.3312 - acc: 0.9620 - val_loss: 0.5575 - val_acc: 0.8000\n",
      "Epoch 1191/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3306 - acc: 0.9620 - val_loss: 0.5568 - val_acc: 0.8000\n",
      "Epoch 1192/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3320 - acc: 0.9620 - val_loss: 0.5657 - val_acc: 0.7000\n",
      "Epoch 1193/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.3278 - acc: 0.9620 - val_loss: 0.5669 - val_acc: 0.7000\n",
      "Epoch 1194/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3276 - acc: 0.9620 - val_loss: 0.5728 - val_acc: 0.7000\n",
      "Epoch 1195/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.3285 - acc: 0.9620 - val_loss: 0.5706 - val_acc: 0.7000\n",
      "Epoch 1196/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.3252 - acc: 0.9620 - val_loss: 0.5623 - val_acc: 0.7500\n",
      "Epoch 1197/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3250 - acc: 0.9747 - val_loss: 0.5629 - val_acc: 0.7000\n",
      "Epoch 1198/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3239 - acc: 0.9620 - val_loss: 0.5664 - val_acc: 0.7000\n",
      "Epoch 1199/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.3236 - acc: 0.9747 - val_loss: 0.5626 - val_acc: 0.7500\n",
      "Epoch 1200/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.3206 - acc: 0.9747 - val_loss: 0.5623 - val_acc: 0.7500\n",
      "Epoch 1201/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3193 - acc: 0.9620 - val_loss: 0.5593 - val_acc: 0.8000\n",
      "Epoch 1202/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3192 - acc: 0.9747 - val_loss: 0.5655 - val_acc: 0.7000\n",
      "Epoch 1203/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3183 - acc: 0.9620 - val_loss: 0.5662 - val_acc: 0.7000\n",
      "Epoch 1204/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3167 - acc: 0.9620 - val_loss: 0.5632 - val_acc: 0.7000\n",
      "Epoch 1205/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3159 - acc: 0.9620 - val_loss: 0.5689 - val_acc: 0.7000\n",
      "Epoch 1206/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3148 - acc: 0.9620 - val_loss: 0.5671 - val_acc: 0.7000\n",
      "Epoch 1207/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.3140 - acc: 0.9620 - val_loss: 0.5650 - val_acc: 0.7000\n",
      "Epoch 1208/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.3124 - acc: 0.9620 - val_loss: 0.5640 - val_acc: 0.7000\n",
      "Epoch 1209/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.3111 - acc: 0.9620 - val_loss: 0.5636 - val_acc: 0.7000\n",
      "Epoch 1210/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3098 - acc: 0.9620 - val_loss: 0.5582 - val_acc: 0.8000\n",
      "Epoch 1211/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.3090 - acc: 0.9620 - val_loss: 0.5469 - val_acc: 0.8000\n",
      "Epoch 1212/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.3078 - acc: 0.9747 - val_loss: 0.5552 - val_acc: 0.8000\n",
      "Epoch 1213/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.3068 - acc: 0.9620 - val_loss: 0.5516 - val_acc: 0.8000\n",
      "Epoch 1214/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.3056 - acc: 0.9747 - val_loss: 0.5580 - val_acc: 0.8000\n",
      "Epoch 1215/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3046 - acc: 0.9620 - val_loss: 0.5483 - val_acc: 0.8000\n",
      "Epoch 1216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3031 - acc: 0.9747 - val_loss: 0.5472 - val_acc: 0.8000\n",
      "Epoch 1217/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.3021 - acc: 0.9620 - val_loss: 0.5460 - val_acc: 0.8000\n",
      "Epoch 1218/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3015 - acc: 0.9620 - val_loss: 0.5443 - val_acc: 0.8000\n",
      "Epoch 1219/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3006 - acc: 0.9620 - val_loss: 0.5495 - val_acc: 0.8000\n",
      "Epoch 1220/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2980 - acc: 0.9747 - val_loss: 0.5483 - val_acc: 0.8000\n",
      "Epoch 1221/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2975 - acc: 0.9747 - val_loss: 0.5455 - val_acc: 0.8000\n",
      "Epoch 1222/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.2958 - acc: 0.9747 - val_loss: 0.5470 - val_acc: 0.8000\n",
      "Epoch 1223/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2958 - acc: 0.9747 - val_loss: 0.5437 - val_acc: 0.8000\n",
      "Epoch 1224/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2937 - acc: 0.9747 - val_loss: 0.5455 - val_acc: 0.8000\n",
      "Epoch 1225/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2926 - acc: 0.9747 - val_loss: 0.5493 - val_acc: 0.8000\n",
      "Epoch 1226/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2918 - acc: 0.9747 - val_loss: 0.5529 - val_acc: 0.7500\n",
      "Epoch 1227/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.2912 - acc: 0.9620 - val_loss: 0.5412 - val_acc: 0.8000\n",
      "Epoch 1228/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2904 - acc: 0.9747 - val_loss: 0.5459 - val_acc: 0.8000\n",
      "Epoch 1229/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2883 - acc: 0.9747 - val_loss: 0.5444 - val_acc: 0.8000\n",
      "Epoch 1230/3000\n",
      "79/79 [==============================] - 0s 240us/sample - loss: 0.2873 - acc: 0.9747 - val_loss: 0.5455 - val_acc: 0.8000\n",
      "Epoch 1231/3000\n",
      "79/79 [==============================] - 0s 202us/sample - loss: 0.2875 - acc: 0.9747 - val_loss: 0.5334 - val_acc: 0.8000\n",
      "Epoch 1232/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.2874 - acc: 0.9747 - val_loss: 0.5364 - val_acc: 0.8000\n",
      "Epoch 1233/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2864 - acc: 0.9747 - val_loss: 0.5392 - val_acc: 0.8000\n",
      "Epoch 1234/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2835 - acc: 0.9747 - val_loss: 0.5454 - val_acc: 0.8000\n",
      "Epoch 1235/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.2831 - acc: 0.9747 - val_loss: 0.5348 - val_acc: 0.8000\n",
      "Epoch 1236/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2817 - acc: 0.9747 - val_loss: 0.5307 - val_acc: 0.8000\n",
      "Epoch 1237/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2802 - acc: 0.9620 - val_loss: 0.5370 - val_acc: 0.8000\n",
      "Epoch 1238/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2797 - acc: 0.9747 - val_loss: 0.5445 - val_acc: 0.8000\n",
      "Epoch 1239/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.2779 - acc: 0.9747 - val_loss: 0.5453 - val_acc: 0.8000\n",
      "Epoch 1240/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2782 - acc: 0.9620 - val_loss: 0.5413 - val_acc: 0.8000\n",
      "Epoch 1241/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.2744 - acc: 0.9747 - val_loss: 0.5461 - val_acc: 0.7000\n",
      "Epoch 1242/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2739 - acc: 0.9747 - val_loss: 0.5476 - val_acc: 0.7000\n",
      "Epoch 1243/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.2722 - acc: 0.9747 - val_loss: 0.5398 - val_acc: 0.8000\n",
      "Epoch 1244/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2728 - acc: 0.9747 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 1245/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2727 - acc: 0.9747 - val_loss: 0.5318 - val_acc: 0.8000\n",
      "Epoch 1246/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2702 - acc: 0.9747 - val_loss: 0.5350 - val_acc: 0.7500\n",
      "Epoch 1247/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2697 - acc: 0.9747 - val_loss: 0.5415 - val_acc: 0.7500\n",
      "Epoch 1248/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2682 - acc: 0.9747 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 1249/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2676 - acc: 0.9620 - val_loss: 0.5420 - val_acc: 0.7500\n",
      "Epoch 1250/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2660 - acc: 0.9747 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 1251/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 129us/sample - loss: 0.2649 - acc: 0.9747 - val_loss: 0.5289 - val_acc: 0.8000\n",
      "Epoch 1252/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.2640 - acc: 0.9747 - val_loss: 0.5302 - val_acc: 0.8000\n",
      "Epoch 1253/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2636 - acc: 0.9747 - val_loss: 0.5274 - val_acc: 0.8000\n",
      "Epoch 1254/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2619 - acc: 0.9747 - val_loss: 0.5292 - val_acc: 0.8000\n",
      "Epoch 1255/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2617 - acc: 0.9747 - val_loss: 0.5306 - val_acc: 0.8000\n",
      "Epoch 1256/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2601 - acc: 0.9747 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 1257/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.2591 - acc: 0.9747 - val_loss: 0.5359 - val_acc: 0.7500\n",
      "Epoch 1258/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.2579 - acc: 0.9747 - val_loss: 0.5349 - val_acc: 0.7500\n",
      "Epoch 1259/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2571 - acc: 0.9747 - val_loss: 0.5391 - val_acc: 0.7500\n",
      "Epoch 1260/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2571 - acc: 0.9747 - val_loss: 0.5258 - val_acc: 0.8000\n",
      "Epoch 1261/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2543 - acc: 0.9747 - val_loss: 0.5276 - val_acc: 0.7500\n",
      "Epoch 1262/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2556 - acc: 0.9620 - val_loss: 0.5367 - val_acc: 0.7500\n",
      "Epoch 1263/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2537 - acc: 0.9747 - val_loss: 0.5214 - val_acc: 0.8000\n",
      "Epoch 1264/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2515 - acc: 0.9747 - val_loss: 0.5205 - val_acc: 0.8000\n",
      "Epoch 1265/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.2508 - acc: 0.9747 - val_loss: 0.5236 - val_acc: 0.8000\n",
      "Epoch 1266/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2499 - acc: 0.9747 - val_loss: 0.5242 - val_acc: 0.8000\n",
      "Epoch 1267/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2485 - acc: 0.9747 - val_loss: 0.5249 - val_acc: 0.8000\n",
      "Epoch 1268/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2485 - acc: 0.9747 - val_loss: 0.5334 - val_acc: 0.7500\n",
      "Epoch 1269/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2493 - acc: 0.9747 - val_loss: 0.5395 - val_acc: 0.7000\n",
      "Epoch 1270/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2467 - acc: 0.9747 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 1271/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2454 - acc: 0.9747 - val_loss: 0.5305 - val_acc: 0.7500\n",
      "Epoch 1272/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2438 - acc: 0.9747 - val_loss: 0.5295 - val_acc: 0.7500\n",
      "Epoch 1273/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.2432 - acc: 0.9747 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 1274/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.2443 - acc: 0.9747 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 1275/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2414 - acc: 0.9747 - val_loss: 0.5305 - val_acc: 0.7500\n",
      "Epoch 1276/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.2400 - acc: 0.9747 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 1277/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.2391 - acc: 0.9747 - val_loss: 0.5162 - val_acc: 0.8000\n",
      "Epoch 1278/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2380 - acc: 0.9747 - val_loss: 0.5155 - val_acc: 0.8000\n",
      "Epoch 1279/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2390 - acc: 0.9747 - val_loss: 0.5172 - val_acc: 0.8000\n",
      "Epoch 1280/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2362 - acc: 0.9747 - val_loss: 0.5236 - val_acc: 0.7500\n",
      "Epoch 1281/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2349 - acc: 0.9747 - val_loss: 0.5185 - val_acc: 0.8000\n",
      "Epoch 1282/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2355 - acc: 0.9747 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 1283/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2334 - acc: 0.9747 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 1284/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.2319 - acc: 0.9747 - val_loss: 0.5159 - val_acc: 0.8000\n",
      "Epoch 1285/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.2317 - acc: 0.9747 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 1286/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2300 - acc: 0.9747 - val_loss: 0.5254 - val_acc: 0.7500\n",
      "Epoch 1287/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.2288 - acc: 0.9747 - val_loss: 0.5251 - val_acc: 0.7500\n",
      "Epoch 1288/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2294 - acc: 0.9747 - val_loss: 0.5104 - val_acc: 0.8000\n",
      "Epoch 1289/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2275 - acc: 0.9747 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 1290/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2271 - acc: 0.9747 - val_loss: 0.5198 - val_acc: 0.7500\n",
      "Epoch 1291/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2249 - acc: 0.9747 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 1292/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2235 - acc: 0.9747 - val_loss: 0.5183 - val_acc: 0.7500\n",
      "Epoch 1293/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2233 - acc: 0.9747 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 1294/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2223 - acc: 0.9747 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 1295/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.2214 - acc: 0.9747 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 1296/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2205 - acc: 0.9747 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 1297/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.2209 - acc: 0.9747 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 1298/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2192 - acc: 0.9747 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 1299/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.2170 - acc: 0.9747 - val_loss: 0.5169 - val_acc: 0.7500\n",
      "Epoch 1300/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2167 - acc: 0.9747 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 1301/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2091 - acc: 0.968 - 0s 110us/sample - loss: 0.2162 - acc: 0.9747 - val_loss: 0.5199 - val_acc: 0.7500\n",
      "Epoch 1302/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.2152 - acc: 0.9747 - val_loss: 0.5230 - val_acc: 0.7500\n",
      "Epoch 1303/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2148 - acc: 0.9747 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 1304/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.2127 - acc: 0.9747 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 1305/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2115 - acc: 0.9747 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 1306/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2123 - acc: 0.9747 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 1307/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2112 - acc: 0.9873 - val_loss: 0.5040 - val_acc: 0.8000\n",
      "Epoch 1308/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2094 - acc: 0.9873 - val_loss: 0.5099 - val_acc: 0.8000\n",
      "Epoch 1309/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.2097 - acc: 0.9747 - val_loss: 0.5184 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1310/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2094 - acc: 0.9747 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 1311/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2076 - acc: 0.9747 - val_loss: 0.5095 - val_acc: 0.8000\n",
      "Epoch 1312/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2069 - acc: 0.9747 - val_loss: 0.5229 - val_acc: 0.7500\n",
      "Epoch 1313/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2053 - acc: 0.9747 - val_loss: 0.5210 - val_acc: 0.7500\n",
      "Epoch 1314/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.2043 - acc: 0.9747 - val_loss: 0.5131 - val_acc: 0.7500\n",
      "Epoch 1315/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2040 - acc: 0.9747 - val_loss: 0.5088 - val_acc: 0.8000\n",
      "Epoch 1316/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2023 - acc: 0.9747 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 1317/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2016 - acc: 0.9873 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 1318/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.2009 - acc: 0.9747 - val_loss: 0.5078 - val_acc: 0.8000\n",
      "Epoch 1319/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2016 - acc: 0.9747 - val_loss: 0.4968 - val_acc: 0.8000\n",
      "Epoch 1320/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2012 - acc: 0.9873 - val_loss: 0.4925 - val_acc: 0.8000\n",
      "Epoch 1321/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2002 - acc: 0.9873 - val_loss: 0.4931 - val_acc: 0.8000\n",
      "Epoch 1322/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.2003 - acc: 0.9873 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 1323/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1990 - acc: 0.9747 - val_loss: 0.4952 - val_acc: 0.8000\n",
      "Epoch 1324/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1991 - acc: 0.9873 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 1325/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2381 - acc: 0.968 - 0s 177us/sample - loss: 0.1958 - acc: 0.9747 - val_loss: 0.5092 - val_acc: 0.8000\n",
      "Epoch 1326/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1955 - acc: 0.9873 - val_loss: 0.5140 - val_acc: 0.8000\n",
      "Epoch 1327/3000\n",
      "79/79 [==============================] - 0s 210us/sample - loss: 0.1941 - acc: 0.9747 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 1328/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1938 - acc: 0.9747 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 1329/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1931 - acc: 0.9747 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 1330/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1927 - acc: 0.9747 - val_loss: 0.5216 - val_acc: 0.7500\n",
      "Epoch 1331/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1934 - acc: 0.9747 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 1332/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1901 - acc: 0.9747 - val_loss: 0.5107 - val_acc: 0.8000\n",
      "Epoch 1333/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1893 - acc: 0.9747 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 1334/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1898 - acc: 0.9747 - val_loss: 0.5053 - val_acc: 0.8000\n",
      "Epoch 1335/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1879 - acc: 0.9873 - val_loss: 0.5053 - val_acc: 0.8000\n",
      "Epoch 1336/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1874 - acc: 0.9873 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 1337/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.1864 - acc: 0.9747 - val_loss: 0.5057 - val_acc: 0.8000\n",
      "Epoch 1338/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1860 - acc: 0.9747 - val_loss: 0.4986 - val_acc: 0.7500\n",
      "Epoch 1339/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1845 - acc: 0.9873 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Epoch 1340/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1838 - acc: 0.9873 - val_loss: 0.5031 - val_acc: 0.7500\n",
      "Epoch 1341/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1833 - acc: 0.9873 - val_loss: 0.5185 - val_acc: 0.7000\n",
      "Epoch 1342/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1835 - acc: 0.9747 - val_loss: 0.5223 - val_acc: 0.7000\n",
      "Epoch 1343/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.1827 - acc: 0.9747 - val_loss: 0.5190 - val_acc: 0.7000\n",
      "Epoch 1344/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1805 - acc: 0.9747 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 1345/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.1804 - acc: 0.9873 - val_loss: 0.5071 - val_acc: 0.7500\n",
      "Epoch 1346/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1795 - acc: 0.9747 - val_loss: 0.5039 - val_acc: 0.7500\n",
      "Epoch 1347/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1776 - acc: 0.9873 - val_loss: 0.4988 - val_acc: 0.7500\n",
      "Epoch 1348/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1769 - acc: 0.9873 - val_loss: 0.4959 - val_acc: 0.7500\n",
      "Epoch 1349/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1771 - acc: 0.9873 - val_loss: 0.4919 - val_acc: 0.8000\n",
      "Epoch 1350/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1765 - acc: 0.9873 - val_loss: 0.4932 - val_acc: 0.8000\n",
      "Epoch 1351/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1757 - acc: 0.9873 - val_loss: 0.4904 - val_acc: 0.8000\n",
      "Epoch 1352/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1761 - acc: 0.9873 - val_loss: 0.4989 - val_acc: 0.7500\n",
      "Epoch 1353/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1734 - acc: 0.9873 - val_loss: 0.4945 - val_acc: 0.8000\n",
      "Epoch 1354/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1725 - acc: 0.9873 - val_loss: 0.4891 - val_acc: 0.8000\n",
      "Epoch 1355/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1712 - acc: 0.9873 - val_loss: 0.4931 - val_acc: 0.8000\n",
      "Epoch 1356/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1708 - acc: 0.9873 - val_loss: 0.4960 - val_acc: 0.8000\n",
      "Epoch 1357/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1692 - acc: 0.9873 - val_loss: 0.5042 - val_acc: 0.7500\n",
      "Epoch 1358/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1694 - acc: 0.9873 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 1359/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1679 - acc: 0.9873 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 1360/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1678 - acc: 0.9873 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 1361/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1666 - acc: 0.9873 - val_loss: 0.5064 - val_acc: 0.7500\n",
      "Epoch 1362/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1659 - acc: 0.9873 - val_loss: 0.4949 - val_acc: 0.7500\n",
      "Epoch 1363/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1656 - acc: 0.9873 - val_loss: 0.4951 - val_acc: 0.7500\n",
      "Epoch 1364/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1643 - acc: 0.9873 - val_loss: 0.5013 - val_acc: 0.7500\n",
      "Epoch 1365/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1636 - acc: 0.9873 - val_loss: 0.4965 - val_acc: 0.7500\n",
      "Epoch 1366/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1630 - acc: 0.9873 - val_loss: 0.4983 - val_acc: 0.7500\n",
      "Epoch 1367/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1629 - acc: 0.9873 - val_loss: 0.4926 - val_acc: 0.8000\n",
      "Epoch 1368/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1624 - acc: 0.9873 - val_loss: 0.5024 - val_acc: 0.7500\n",
      "Epoch 1369/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1617 - acc: 0.9873 - val_loss: 0.4907 - val_acc: 0.8000\n",
      "Epoch 1370/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1608 - acc: 0.9873 - val_loss: 0.4955 - val_acc: 0.7500\n",
      "Epoch 1371/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1615 - acc: 0.9873 - val_loss: 0.4932 - val_acc: 0.7500\n",
      "Epoch 1372/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.1590 - acc: 0.9873 - val_loss: 0.4909 - val_acc: 0.8000\n",
      "Epoch 1373/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1584 - acc: 0.9873 - val_loss: 0.4946 - val_acc: 0.7500\n",
      "Epoch 1374/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.1579 - acc: 0.9873 - val_loss: 0.4881 - val_acc: 0.8000\n",
      "Epoch 1375/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1578 - acc: 0.9873 - val_loss: 0.4935 - val_acc: 0.7500\n",
      "Epoch 1376/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1591 - acc: 0.9873 - val_loss: 0.4867 - val_acc: 0.8000\n",
      "Epoch 1377/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1564 - acc: 0.9873 - val_loss: 0.4904 - val_acc: 0.8000\n",
      "Epoch 1378/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.1551 - acc: 0.9873 - val_loss: 0.4913 - val_acc: 0.8000\n",
      "Epoch 1379/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1555 - acc: 0.9873 - val_loss: 0.4866 - val_acc: 0.8000\n",
      "Epoch 1380/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1542 - acc: 0.9873 - val_loss: 0.4894 - val_acc: 0.8000\n",
      "Epoch 1381/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.1544 - acc: 0.9873 - val_loss: 0.4923 - val_acc: 0.8000\n",
      "Epoch 1382/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1555 - acc: 0.9873 - val_loss: 0.4970 - val_acc: 0.8000\n",
      "Epoch 1383/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1548 - acc: 0.9873 - val_loss: 0.4970 - val_acc: 0.8000\n",
      "Epoch 1384/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1550 - acc: 0.9873 - val_loss: 0.5009 - val_acc: 0.7500\n",
      "Epoch 1385/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1540 - acc: 0.9873 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 1386/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1537 - acc: 0.9873 - val_loss: 0.4951 - val_acc: 0.8000\n",
      "Epoch 1387/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1529 - acc: 0.9873 - val_loss: 0.4919 - val_acc: 0.8000\n",
      "Epoch 1388/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1519 - acc: 0.9873 - val_loss: 0.4916 - val_acc: 0.8000\n",
      "Epoch 1389/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1507 - acc: 0.9873 - val_loss: 0.4981 - val_acc: 0.8000\n",
      "Epoch 1390/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1507 - acc: 0.9873 - val_loss: 0.4929 - val_acc: 0.8000\n",
      "Epoch 1391/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1517 - acc: 0.9873 - val_loss: 0.5003 - val_acc: 0.7500\n",
      "Epoch 1392/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1492 - acc: 0.9873 - val_loss: 0.4976 - val_acc: 0.7500\n",
      "Epoch 1393/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1485 - acc: 0.9873 - val_loss: 0.4972 - val_acc: 0.7500\n",
      "Epoch 1394/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1479 - acc: 0.9873 - val_loss: 0.5002 - val_acc: 0.7500\n",
      "Epoch 1395/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1476 - acc: 0.9873 - val_loss: 0.4910 - val_acc: 0.7500\n",
      "Epoch 1396/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1480 - acc: 0.9873 - val_loss: 0.4990 - val_acc: 0.7500\n",
      "Epoch 1397/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1461 - acc: 0.9873 - val_loss: 0.5001 - val_acc: 0.7500\n",
      "Epoch 1398/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1458 - acc: 0.9873 - val_loss: 0.5012 - val_acc: 0.7500\n",
      "Epoch 1399/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1450 - acc: 0.9873 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 1400/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1445 - acc: 0.9873 - val_loss: 0.4979 - val_acc: 0.7500\n",
      "Epoch 1401/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1442 - acc: 0.9873 - val_loss: 0.5067 - val_acc: 0.7500\n",
      "Epoch 1402/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1442 - acc: 0.9873 - val_loss: 0.5005 - val_acc: 0.7500\n",
      "Epoch 1403/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1426 - acc: 0.9873 - val_loss: 0.4970 - val_acc: 0.7500\n",
      "Epoch 1404/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1429 - acc: 0.9873 - val_loss: 0.4956 - val_acc: 0.7500\n",
      "Epoch 1405/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.1415 - acc: 0.9873 - val_loss: 0.4970 - val_acc: 0.7500\n",
      "Epoch 1406/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1408 - acc: 0.9873 - val_loss: 0.4989 - val_acc: 0.7500\n",
      "Epoch 1407/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.1409 - acc: 0.9873 - val_loss: 0.4986 - val_acc: 0.7500\n",
      "Epoch 1408/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1417 - acc: 0.9873 - val_loss: 0.4882 - val_acc: 0.7500\n",
      "Epoch 1409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1415 - acc: 0.9873 - val_loss: 0.4947 - val_acc: 0.7500\n",
      "Epoch 1410/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1385 - acc: 0.9873 - val_loss: 0.4934 - val_acc: 0.7500\n",
      "Epoch 1411/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1378 - acc: 0.9873 - val_loss: 0.4913 - val_acc: 0.7500\n",
      "Epoch 1412/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1374 - acc: 0.9873 - val_loss: 0.4891 - val_acc: 0.7500\n",
      "Epoch 1413/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1370 - acc: 0.9873 - val_loss: 0.4844 - val_acc: 0.8000\n",
      "Epoch 1414/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1368 - acc: 0.9873 - val_loss: 0.4888 - val_acc: 0.7500\n",
      "Epoch 1415/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1363 - acc: 0.9873 - val_loss: 0.4913 - val_acc: 0.7500\n",
      "Epoch 1416/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1353 - acc: 0.9873 - val_loss: 0.4918 - val_acc: 0.7500\n",
      "Epoch 1417/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1350 - acc: 0.9873 - val_loss: 0.4880 - val_acc: 0.7500\n",
      "Epoch 1418/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1342 - acc: 0.9873 - val_loss: 0.4888 - val_acc: 0.7500\n",
      "Epoch 1419/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1334 - acc: 0.9873 - val_loss: 0.4887 - val_acc: 0.7500\n",
      "Epoch 1420/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1329 - acc: 0.9873 - val_loss: 0.4925 - val_acc: 0.7500\n",
      "Epoch 1421/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1325 - acc: 0.9873 - val_loss: 0.4900 - val_acc: 0.7500\n",
      "Epoch 1422/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1320 - acc: 0.9873 - val_loss: 0.4888 - val_acc: 0.7500\n",
      "Epoch 1423/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1319 - acc: 0.9873 - val_loss: 0.4865 - val_acc: 0.7500\n",
      "Epoch 1424/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1310 - acc: 0.9873 - val_loss: 0.4905 - val_acc: 0.7500\n",
      "Epoch 1425/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1309 - acc: 0.9873 - val_loss: 0.4960 - val_acc: 0.7500\n",
      "Epoch 1426/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1301 - acc: 0.9873 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 1427/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1298 - acc: 0.9873 - val_loss: 0.5063 - val_acc: 0.7500\n",
      "Epoch 1428/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1290 - acc: 0.9873 - val_loss: 0.4995 - val_acc: 0.7500\n",
      "Epoch 1429/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1284 - acc: 0.9873 - val_loss: 0.4914 - val_acc: 0.7500\n",
      "Epoch 1430/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1284 - acc: 0.9873 - val_loss: 0.4830 - val_acc: 0.8000\n",
      "Epoch 1431/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1277 - acc: 0.9873 - val_loss: 0.4816 - val_acc: 0.8000\n",
      "Epoch 1432/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1273 - acc: 0.9873 - val_loss: 0.4917 - val_acc: 0.7500\n",
      "Epoch 1433/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1264 - acc: 0.9873 - val_loss: 0.4979 - val_acc: 0.7500\n",
      "Epoch 1434/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1252 - acc: 0.9873 - val_loss: 0.4938 - val_acc: 0.7500\n",
      "Epoch 1435/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1246 - acc: 0.9873 - val_loss: 0.4936 - val_acc: 0.7500\n",
      "Epoch 1436/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1245 - acc: 0.9873 - val_loss: 0.5004 - val_acc: 0.7500\n",
      "Epoch 1437/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1242 - acc: 0.9873 - val_loss: 0.4972 - val_acc: 0.7500\n",
      "Epoch 1438/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1238 - acc: 0.9873 - val_loss: 0.5022 - val_acc: 0.7500\n",
      "Epoch 1439/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1233 - acc: 0.9873 - val_loss: 0.4937 - val_acc: 0.7500\n",
      "Epoch 1440/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1223 - acc: 0.9873 - val_loss: 0.4907 - val_acc: 0.7500\n",
      "Epoch 1441/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1217 - acc: 0.9873 - val_loss: 0.4926 - val_acc: 0.7500\n",
      "Epoch 1442/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1210 - acc: 0.9873 - val_loss: 0.4951 - val_acc: 0.7500\n",
      "Epoch 1443/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1209 - acc: 0.9873 - val_loss: 0.4945 - val_acc: 0.7500\n",
      "Epoch 1444/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1199 - acc: 0.9873 - val_loss: 0.4934 - val_acc: 0.7500\n",
      "Epoch 1445/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1191 - acc: 0.9873 - val_loss: 0.4940 - val_acc: 0.7500\n",
      "Epoch 1446/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1188 - acc: 1.0000 - val_loss: 0.4931 - val_acc: 0.7500\n",
      "Epoch 1447/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1181 - acc: 0.9873 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 1448/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1176 - acc: 0.9873 - val_loss: 0.4843 - val_acc: 0.7500\n",
      "Epoch 1449/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1180 - acc: 0.9873 - val_loss: 0.4981 - val_acc: 0.7500\n",
      "Epoch 1450/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1168 - acc: 1.0000 - val_loss: 0.5005 - val_acc: 0.7500\n",
      "Epoch 1451/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1162 - acc: 1.0000 - val_loss: 0.4937 - val_acc: 0.7500\n",
      "Epoch 1452/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1164 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.7500\n",
      "Epoch 1453/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1162 - acc: 0.9873 - val_loss: 0.4908 - val_acc: 0.7500\n",
      "Epoch 1454/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1158 - acc: 0.9873 - val_loss: 0.4837 - val_acc: 0.7500\n",
      "Epoch 1455/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1148 - acc: 0.9873 - val_loss: 0.4817 - val_acc: 0.7500\n",
      "Epoch 1456/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1141 - acc: 0.9873 - val_loss: 0.4854 - val_acc: 0.7500\n",
      "Epoch 1457/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1132 - acc: 0.9873 - val_loss: 0.4923 - val_acc: 0.7500\n",
      "Epoch 1458/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1135 - acc: 0.9873 - val_loss: 0.4978 - val_acc: 0.7500\n",
      "Epoch 1459/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1124 - acc: 1.0000 - val_loss: 0.4922 - val_acc: 0.7500\n",
      "Epoch 1460/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1135 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.7500\n",
      "Epoch 1461/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.1127 - acc: 0.9873 - val_loss: 0.4957 - val_acc: 0.7500\n",
      "Epoch 1462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1117 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.7500\n",
      "Epoch 1463/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1114 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.7500\n",
      "Epoch 1464/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.7500\n",
      "Epoch 1465/3000\n",
      "79/79 [==============================] - 0s 272us/sample - loss: 0.1113 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.8500\n",
      "Epoch 1466/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.1102 - acc: 0.9873 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1467/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.1092 - acc: 0.9873 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1468/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.1089 - acc: 0.9873 - val_loss: 0.4839 - val_acc: 0.7500\n",
      "Epoch 1469/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1094 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.7500\n",
      "Epoch 1470/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.1077 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.7500\n",
      "Epoch 1471/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1076 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.7500\n",
      "Epoch 1472/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1069 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.7500\n",
      "Epoch 1473/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1066 - acc: 1.0000 - val_loss: 0.4910 - val_acc: 0.7500\n",
      "Epoch 1474/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1062 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.7500\n",
      "Epoch 1475/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1060 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1476/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1058 - acc: 0.9873 - val_loss: 0.4801 - val_acc: 0.8000\n",
      "Epoch 1477/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1049 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8000\n",
      "Epoch 1478/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1045 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8000\n",
      "Epoch 1479/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1040 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8000\n",
      "Epoch 1480/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1036 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.7500\n",
      "Epoch 1481/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1033 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.7500\n",
      "Epoch 1482/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1028 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.7500\n",
      "Epoch 1483/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.1024 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.7500\n",
      "Epoch 1484/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1021 - acc: 1.0000 - val_loss: 0.4932 - val_acc: 0.7500\n",
      "Epoch 1485/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1018 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.7500\n",
      "Epoch 1486/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1018 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1487/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.1011 - acc: 1.0000 - val_loss: 0.4755 - val_acc: 0.8500\n",
      "Epoch 1488/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1007 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1489/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1009 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.7500\n",
      "Epoch 1490/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 0.4991 - val_acc: 0.7500\n",
      "Epoch 1491/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0995 - acc: 1.0000 - val_loss: 0.4945 - val_acc: 0.7500\n",
      "Epoch 1492/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0991 - acc: 1.0000 - val_loss: 0.4921 - val_acc: 0.7500\n",
      "Epoch 1493/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0990 - acc: 1.0000 - val_loss: 0.4986 - val_acc: 0.7500\n",
      "Epoch 1494/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0984 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.7500\n",
      "Epoch 1495/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0979 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.7500\n",
      "Epoch 1496/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0976 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.7500\n",
      "Epoch 1497/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0970 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.7500\n",
      "Epoch 1498/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 0.4934 - val_acc: 0.7500\n",
      "Epoch 1499/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0964 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.7500\n",
      "Epoch 1500/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0960 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.7500\n",
      "Epoch 1501/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0959 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.7500\n",
      "Epoch 1502/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0953 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.7500\n",
      "Epoch 1503/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0950 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8000\n",
      "Epoch 1504/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0945 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8000\n",
      "Epoch 1505/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0945 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.7500\n",
      "Epoch 1506/3000\n",
      "79/79 [==============================] - 0s 253us/sample - loss: 0.0941 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.7500\n",
      "Epoch 1507/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0934 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.7500\n",
      "Epoch 1508/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0934 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.7500\n",
      "Epoch 1509/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.0927 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 1510/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.7500\n",
      "Epoch 1511/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0927 - acc: 1.0000 - val_loss: 0.4942 - val_acc: 0.7500\n",
      "Epoch 1512/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0918 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.7500\n",
      "Epoch 1513/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0912 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.7500\n",
      "Epoch 1514/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0912 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1515/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0906 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8000\n",
      "Epoch 1516/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0904 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8500\n",
      "Epoch 1517/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0899 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.7500\n",
      "Epoch 1518/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0896 - acc: 1.0000 - val_loss: 0.4825 - val_acc: 0.7500\n",
      "Epoch 1519/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0895 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.7500\n",
      "Epoch 1520/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.7500\n",
      "Epoch 1521/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.7500\n",
      "Epoch 1522/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0884 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.7500\n",
      "Epoch 1523/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0880 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.7500\n",
      "Epoch 1524/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0876 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8500\n",
      "Epoch 1525/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0879 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.7500\n",
      "Epoch 1526/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0869 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.7500\n",
      "Epoch 1527/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0867 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.7500\n",
      "Epoch 1528/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0863 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.7500\n",
      "Epoch 1529/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0859 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.7500\n",
      "Epoch 1530/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0863 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.7500\n",
      "Epoch 1531/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0853 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.7500\n",
      "Epoch 1532/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.7500\n",
      "Epoch 1533/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0846 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.7500\n",
      "Epoch 1534/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0843 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 1535/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0842 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.7500\n",
      "Epoch 1536/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0838 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.7500\n",
      "Epoch 1537/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0834 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 1538/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0831 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.7500\n",
      "Epoch 1539/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0827 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.7500\n",
      "Epoch 1540/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0834 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.7500\n",
      "Epoch 1541/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0826 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8500\n",
      "Epoch 1542/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0819 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 1543/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0815 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8000\n",
      "Epoch 1544/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0812 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.7500\n",
      "Epoch 1545/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0809 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.7500\n",
      "Epoch 1546/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0806 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.7500\n",
      "Epoch 1547/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0804 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.7500\n",
      "Epoch 1548/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0800 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.7500\n",
      "Epoch 1549/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0798 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.7500\n",
      "Epoch 1550/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0796 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8500\n",
      "Epoch 1551/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0792 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8500\n",
      "Epoch 1552/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0791 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.7500\n",
      "Epoch 1553/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0788 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.7500\n",
      "Epoch 1554/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0784 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.7500\n",
      "Epoch 1555/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0780 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.7500\n",
      "Epoch 1556/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0781 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1557/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0777 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.7500\n",
      "Epoch 1558/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.7500\n",
      "Epoch 1559/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0771 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.7500\n",
      "Epoch 1560/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0768 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.7500\n",
      "Epoch 1561/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0763 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8000\n",
      "Epoch 1562/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0761 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.8000\n",
      "Epoch 1563/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0758 - acc: 1.0000 - val_loss: 0.4828 - val_acc: 0.8000\n",
      "Epoch 1564/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1565/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0753 - acc: 1.0000 - val_loss: 0.4828 - val_acc: 0.8000\n",
      "Epoch 1566/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8500\n",
      "Epoch 1567/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.4771 - val_acc: 0.8500\n",
      "Epoch 1568/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0744 - acc: 1.0000 - val_loss: 0.4787 - val_acc: 0.8000\n",
      "Epoch 1569/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8000\n",
      "Epoch 1570/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0738 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1571/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8000\n",
      "Epoch 1572/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0733 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8000\n",
      "Epoch 1573/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0732 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1574/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0727 - acc: 1.0000 - val_loss: 0.4759 - val_acc: 0.8000\n",
      "Epoch 1575/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0726 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1576/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0725 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 1577/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0720 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1578/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0721 - acc: 1.0000 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 1579/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0717 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1580/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0711 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1581/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0710 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.8000\n",
      "Epoch 1582/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8000\n",
      "Epoch 1583/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0704 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1584/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0702 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 1585/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0700 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8000\n",
      "Epoch 1586/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0698 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.8500\n",
      "Epoch 1587/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0695 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8500\n",
      "Epoch 1588/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0693 - acc: 1.0000 - val_loss: 0.4771 - val_acc: 0.8000\n",
      "Epoch 1589/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.8500\n",
      "Epoch 1590/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.4707 - val_acc: 0.8500\n",
      "Epoch 1591/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.4729 - val_acc: 0.8500\n",
      "Epoch 1592/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.8000\n",
      "Epoch 1593/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1594/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1595/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0675 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1596/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0669 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 1597/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0669 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8000\n",
      "Epoch 1598/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0667 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.8500\n",
      "Epoch 1599/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0662 - acc: 1.0000 - val_loss: 0.4762 - val_acc: 0.8000\n",
      "Epoch 1600/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8000\n",
      "Epoch 1601/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8000\n",
      "Epoch 1602/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.4802 - val_acc: 0.8000\n",
      "Epoch 1603/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0654 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 1604/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.7500\n",
      "Epoch 1605/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.7500\n",
      "Epoch 1606/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0647 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.7500\n",
      "Epoch 1607/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0645 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8000\n",
      "Epoch 1608/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8000\n",
      "Epoch 1609/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0642 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.7500\n",
      "Epoch 1610/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0638 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8000\n",
      "Epoch 1611/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8000\n",
      "Epoch 1612/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8000\n",
      "Epoch 1613/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1614/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0629 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.8000\n",
      "Epoch 1615/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.8500\n",
      "Epoch 1616/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.8500\n",
      "Epoch 1617/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.8000\n",
      "Epoch 1618/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0621 - acc: 1.0000 - val_loss: 0.4723 - val_acc: 0.8500\n",
      "Epoch 1619/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.8000\n",
      "Epoch 1620/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0616 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1621/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0613 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1622/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0610 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1623/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8000\n",
      "Epoch 1624/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8000\n",
      "Epoch 1625/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0611 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1626/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0603 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8000\n",
      "Epoch 1627/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.4774 - val_acc: 0.8000\n",
      "Epoch 1628/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 0.4829 - val_acc: 0.8000\n",
      "Epoch 1629/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0599 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8000\n",
      "Epoch 1630/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8000\n",
      "Epoch 1631/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8000\n",
      "Epoch 1632/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 1633/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.4787 - val_acc: 0.8000\n",
      "Epoch 1634/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8000\n",
      "Epoch 1635/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1636/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0584 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8000\n",
      "Epoch 1637/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8000\n",
      "Epoch 1638/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1639/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0577 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8000\n",
      "Epoch 1640/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0576 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1641/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0574 - acc: 1.0000 - val_loss: 0.4747 - val_acc: 0.8000\n",
      "Epoch 1642/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.8000\n",
      "Epoch 1643/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0569 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.8000\n",
      "Epoch 1644/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0567 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.8000\n",
      "Epoch 1645/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.8000\n",
      "Epoch 1646/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8000\n",
      "Epoch 1647/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1648/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8000\n",
      "Epoch 1649/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1650/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 1651/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1652/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0552 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8000\n",
      "Epoch 1653/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0552 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1654/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.8000\n",
      "Epoch 1655/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8000\n",
      "Epoch 1656/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0545 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8000\n",
      "Epoch 1657/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0543 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1658/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8000\n",
      "Epoch 1659/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8000\n",
      "Epoch 1660/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1661/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1662/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8000\n",
      "Epoch 1663/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8000\n",
      "Epoch 1664/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0531 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8000\n",
      "Epoch 1665/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8000\n",
      "Epoch 1666/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0528 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8000\n",
      "Epoch 1667/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8000\n",
      "Epoch 1668/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0527 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8000\n",
      "Epoch 1669/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8000\n",
      "Epoch 1670/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1671/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1672/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.4746 - val_acc: 0.8000\n",
      "Epoch 1673/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.8000\n",
      "Epoch 1674/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1675/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0515 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 1676/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8000\n",
      "Epoch 1677/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8000\n",
      "Epoch 1678/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8000\n",
      "Epoch 1679/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.8000\n",
      "Epoch 1680/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0505 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0503 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1682/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8000\n",
      "Epoch 1683/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1684/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8000\n",
      "Epoch 1685/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8000\n",
      "Epoch 1686/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0498 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1687/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.8000\n",
      "Epoch 1688/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8000\n",
      "Epoch 1689/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.8000\n",
      "Epoch 1690/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0490 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8000\n",
      "Epoch 1691/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0489 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 1692/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0629 - acc: 1.000 - 0s 128us/sample - loss: 0.0486 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 1693/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8000\n",
      "Epoch 1694/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8000\n",
      "Epoch 1695/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1696/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8000\n",
      "Epoch 1697/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1698/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.4731 - val_acc: 0.8000\n",
      "Epoch 1699/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 0.4728 - val_acc: 0.8000\n",
      "Epoch 1700/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.4751 - val_acc: 0.8000\n",
      "Epoch 1701/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.8000\n",
      "Epoch 1702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8000\n",
      "Epoch 1703/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.4759 - val_acc: 0.8000\n",
      "Epoch 1704/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0469 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.8000\n",
      "Epoch 1705/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0467 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1706/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1707/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.8000\n",
      "Epoch 1708/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.8000\n",
      "Epoch 1709/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.4707 - val_acc: 0.8500\n",
      "Epoch 1710/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.4695 - val_acc: 0.8500\n",
      "Epoch 1711/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0467 - acc: 1.0000 - val_loss: 0.4712 - val_acc: 0.8500\n",
      "Epoch 1712/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.8500\n",
      "Epoch 1713/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.4717 - val_acc: 0.8500\n",
      "Epoch 1714/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.4708 - val_acc: 0.8500\n",
      "Epoch 1715/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.4688 - val_acc: 0.8500\n",
      "Epoch 1716/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.8500\n",
      "Epoch 1717/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.8500\n",
      "Epoch 1718/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.4729 - val_acc: 0.8000\n",
      "Epoch 1719/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.4742 - val_acc: 0.8000\n",
      "Epoch 1720/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.8000\n",
      "Epoch 1721/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.4737 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1722/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.4703 - val_acc: 0.8500\n",
      "Epoch 1723/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 1724/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.4751 - val_acc: 0.8000\n",
      "Epoch 1725/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0441 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8000\n",
      "Epoch 1726/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8000\n",
      "Epoch 1727/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8000\n",
      "Epoch 1728/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8000\n",
      "Epoch 1729/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8000\n",
      "Epoch 1730/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.8000\n",
      "Epoch 1731/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8000\n",
      "Epoch 1732/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8000\n",
      "Epoch 1733/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8000\n",
      "Epoch 1734/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 1735/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8000\n",
      "Epoch 1736/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.8000\n",
      "Epoch 1737/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1738/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1739/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 1740/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8000\n",
      "Epoch 1741/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8000\n",
      "Epoch 1742/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 1743/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 1744/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1745/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1746/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 1747/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.8000\n",
      "Epoch 1748/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0411 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.8500\n",
      "Epoch 1749/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.4729 - val_acc: 0.8000\n",
      "Epoch 1750/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.4726 - val_acc: 0.8000\n",
      "Epoch 1751/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0409 - acc: 1.0000 - val_loss: 0.4700 - val_acc: 0.8500\n",
      "Epoch 1752/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0408 - acc: 1.0000 - val_loss: 0.4728 - val_acc: 0.8000\n",
      "Epoch 1753/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.8500\n",
      "Epoch 1754/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.8000\n",
      "Epoch 1755/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.4714 - val_acc: 0.8500\n",
      "Epoch 1756/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.4701 - val_acc: 0.8500\n",
      "Epoch 1757/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.4694 - val_acc: 0.8500\n",
      "Epoch 1758/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.8500\n",
      "Epoch 1759/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.4718 - val_acc: 0.8000\n",
      "Epoch 1760/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.4705 - val_acc: 0.8500\n",
      "Epoch 1761/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 1762/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.4743 - val_acc: 0.8000\n",
      "Epoch 1763/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1764/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8000\n",
      "Epoch 1765/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.8000\n",
      "Epoch 1766/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.4734 - val_acc: 0.8000\n",
      "Epoch 1767/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1768/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.8500\n",
      "Epoch 1769/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.8000\n",
      "Epoch 1770/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 0.4740 - val_acc: 0.8000\n",
      "Epoch 1771/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.8000\n",
      "Epoch 1772/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.4740 - val_acc: 0.8000\n",
      "Epoch 1773/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1774/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.4770 - val_acc: 0.8000\n",
      "Epoch 1775/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.4729 - val_acc: 0.8000\n",
      "Epoch 1776/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.8000\n",
      "Epoch 1777/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.4740 - val_acc: 0.8000\n",
      "Epoch 1778/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.4775 - val_acc: 0.8000\n",
      "Epoch 1779/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.8000\n",
      "Epoch 1780/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1781/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 1782/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.8000\n",
      "Epoch 1783/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.8000\n",
      "Epoch 1784/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1785/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.8000\n",
      "Epoch 1786/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.4747 - val_acc: 0.8000\n",
      "Epoch 1787/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8000\n",
      "Epoch 1788/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1789/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8000\n",
      "Epoch 1790/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.4802 - val_acc: 0.8000\n",
      "Epoch 1791/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.4825 - val_acc: 0.8000\n",
      "Epoch 1792/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.8000\n",
      "Epoch 1793/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8000\n",
      "Epoch 1794/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1795/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1796/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.4778 - val_acc: 0.8000\n",
      "Epoch 1797/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0357 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8000\n",
      "Epoch 1798/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0357 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1799/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1800/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.8000\n",
      "Epoch 1801/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8000\n",
      "Epoch 1802/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.8000\n",
      "Epoch 1803/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 0.8000\n",
      "Epoch 1804/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.4743 - val_acc: 0.8000\n",
      "Epoch 1805/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 1806/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0349 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8000\n",
      "Epoch 1807/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0349 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8000\n",
      "Epoch 1808/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8000\n",
      "Epoch 1809/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8000\n",
      "Epoch 1810/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8000\n",
      "Epoch 1811/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8000\n",
      "Epoch 1812/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8000\n",
      "Epoch 1813/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1814/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1815/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1816/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.4764 - val_acc: 0.8000\n",
      "Epoch 1817/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.8000\n",
      "Epoch 1818/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 1819/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 1820/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 1821/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.4781 - val_acc: 0.8000\n",
      "Epoch 1822/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1823/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1824/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1825/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 1826/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.8000\n",
      "Epoch 1827/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.4821 - val_acc: 0.8000\n",
      "Epoch 1828/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.4829 - val_acc: 0.8000\n",
      "Epoch 1829/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8000\n",
      "Epoch 1830/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.4818 - val_acc: 0.8000\n",
      "Epoch 1831/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8000\n",
      "Epoch 1832/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8000\n",
      "Epoch 1833/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8000\n",
      "Epoch 1834/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1835/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 1836/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1837/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1838/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1839/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1840/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 1841/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1842/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8000\n",
      "Epoch 1843/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.8000\n",
      "Epoch 1844/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.8000\n",
      "Epoch 1845/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.8000\n",
      "Epoch 1846/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8000\n",
      "Epoch 1847/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1848/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.8000\n",
      "Epoch 1849/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.4771 - val_acc: 0.8000\n",
      "Epoch 1850/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.8000\n",
      "Epoch 1851/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.4753 - val_acc: 0.8000\n",
      "Epoch 1852/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.8000\n",
      "Epoch 1853/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1854/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.8000\n",
      "Epoch 1855/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.4774 - val_acc: 0.8000\n",
      "Epoch 1856/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.4787 - val_acc: 0.8000\n",
      "Epoch 1857/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8000\n",
      "Epoch 1858/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8000\n",
      "Epoch 1859/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8000\n",
      "Epoch 1860/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8000\n",
      "Epoch 1861/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8000\n",
      "Epoch 1862/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1863/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1864/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1865/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8000\n",
      "Epoch 1866/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1867/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8000\n",
      "Epoch 1868/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1869/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1870/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 1871/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8000\n",
      "Epoch 1872/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8000\n",
      "Epoch 1873/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1874/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 1875/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.8000\n",
      "Epoch 1876/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.4762 - val_acc: 0.8000\n",
      "Epoch 1877/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.8000\n",
      "Epoch 1878/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1879/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1880/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.8000\n",
      "Epoch 1881/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 1882/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.8000\n",
      "Epoch 1883/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8000\n",
      "Epoch 1884/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.4762 - val_acc: 0.8000\n",
      "Epoch 1885/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8000\n",
      "Epoch 1886/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 1887/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.8000\n",
      "Epoch 1888/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.4770 - val_acc: 0.8000\n",
      "Epoch 1889/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8000\n",
      "Epoch 1890/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1891/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.8000\n",
      "Epoch 1892/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.8000\n",
      "Epoch 1893/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.4718 - val_acc: 0.8000\n",
      "Epoch 1894/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.4737 - val_acc: 0.8000\n",
      "Epoch 1895/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.8000\n",
      "Epoch 1896/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1897/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.8000\n",
      "Epoch 1898/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.4737 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.8000\n",
      "Epoch 1900/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.4735 - val_acc: 0.8000\n",
      "Epoch 1901/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.4713 - val_acc: 0.8000\n",
      "Epoch 1902/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.4735 - val_acc: 0.8000\n",
      "Epoch 1903/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.8000\n",
      "Epoch 1904/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.8000\n",
      "Epoch 1905/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.8000\n",
      "Epoch 1906/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8000\n",
      "Epoch 1907/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.4735 - val_acc: 0.8000\n",
      "Epoch 1908/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.4753 - val_acc: 0.8000\n",
      "Epoch 1909/3000\n",
      "79/79 [==============================] - 0s 154us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.8000\n",
      "Epoch 1910/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.8000\n",
      "Epoch 1911/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.4770 - val_acc: 0.8000\n",
      "Epoch 1912/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.4775 - val_acc: 0.8000\n",
      "Epoch 1913/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1914/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1915/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8000\n",
      "Epoch 1916/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8000\n",
      "Epoch 1917/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.8000\n",
      "Epoch 1918/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8000\n",
      "Epoch 1919/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.4775 - val_acc: 0.8000\n",
      "Epoch 1920/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 1921/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 1922/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8000\n",
      "Epoch 1923/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 1924/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0203 - acc: 1.000 - 0s 137us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8000\n",
      "Epoch 1925/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.8000\n",
      "Epoch 1926/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.8000\n",
      "Epoch 1927/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.8000\n",
      "Epoch 1928/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8000\n",
      "Epoch 1929/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8000\n",
      "Epoch 1930/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.4785 - val_acc: 0.8000\n",
      "Epoch 1931/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8000\n",
      "Epoch 1932/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8000\n",
      "Epoch 1933/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.8000\n",
      "Epoch 1934/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8000\n",
      "Epoch 1935/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8000\n",
      "Epoch 1936/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8000\n",
      "Epoch 1937/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 1938/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 1939/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 1940/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 1941/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 1942/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 1943/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8500\n",
      "Epoch 1944/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8500\n",
      "Epoch 1945/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.8500\n",
      "Epoch 1946/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 1947/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 1948/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8500\n",
      "Epoch 1949/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8500\n",
      "Epoch 1950/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.4818 - val_acc: 0.8500\n",
      "Epoch 1951/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 1952/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 1953/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.8500\n",
      "Epoch 1954/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8500\n",
      "Epoch 1955/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.8500\n",
      "Epoch 1956/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 1957/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8500\n",
      "Epoch 1958/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8500\n",
      "Epoch 1959/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.4821 - val_acc: 0.8500\n",
      "Epoch 1960/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 1961/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8500\n",
      "Epoch 1962/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 1963/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 1964/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 1965/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 1966/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 1967/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 1968/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 1969/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.4828 - val_acc: 0.8500\n",
      "Epoch 1970/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.4829 - val_acc: 0.8500\n",
      "Epoch 1971/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.8500\n",
      "Epoch 1972/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8500\n",
      "Epoch 1973/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 1974/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 1975/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 1976/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8500\n",
      "Epoch 1977/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 1978/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8500\n",
      "Epoch 1979/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 1980/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 1981/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8500\n",
      "Epoch 1982/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8500\n",
      "Epoch 1983/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.8500\n",
      "Epoch 1984/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 1985/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 1986/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 1987/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.8500\n",
      "Epoch 1988/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 1989/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 1990/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 1991/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.8500\n",
      "Epoch 1992/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 1993/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 1994/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 1995/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8500\n",
      "Epoch 1996/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8500\n",
      "Epoch 1997/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 1998/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8500\n",
      "Epoch 1999/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8500\n",
      "Epoch 2000/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.8500\n",
      "Epoch 2001/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 2002/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8500\n",
      "Epoch 2003/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8500\n",
      "Epoch 2004/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2005/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8500\n",
      "Epoch 2006/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8500\n",
      "Epoch 2007/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 2008/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.8500\n",
      "Epoch 2009/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8500\n",
      "Epoch 2010/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.4785 - val_acc: 0.8500\n",
      "Epoch 2011/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8500\n",
      "Epoch 2012/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.4785 - val_acc: 0.8500\n",
      "Epoch 2013/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8500\n",
      "Epoch 2014/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.4802 - val_acc: 0.8500\n",
      "Epoch 2015/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8500\n",
      "Epoch 2016/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2017/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.8500\n",
      "Epoch 2018/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2019/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2020/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2021/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8500\n",
      "Epoch 2022/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.4827 - val_acc: 0.8500\n",
      "Epoch 2023/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2024/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2025/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8500\n",
      "Epoch 2026/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 2027/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2028/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8500\n",
      "Epoch 2029/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8500\n",
      "Epoch 2030/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2031/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8500\n",
      "Epoch 2032/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8500\n",
      "Epoch 2033/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2034/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.8500\n",
      "Epoch 2035/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2036/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.8500\n",
      "Epoch 2037/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2038/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2039/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8500\n",
      "Epoch 2040/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8500\n",
      "Epoch 2041/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8500\n",
      "Epoch 2042/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 2043/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2044/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8500\n",
      "Epoch 2045/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 2046/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8500\n",
      "Epoch 2047/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.4802 - val_acc: 0.8500\n",
      "Epoch 2048/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8500\n",
      "Epoch 2049/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2050/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8500\n",
      "Epoch 2051/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2052/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 2053/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8500\n",
      "Epoch 2054/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8500\n",
      "Epoch 2055/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.8500\n",
      "Epoch 2056/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8500\n",
      "Epoch 2057/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8500\n",
      "Epoch 2058/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2059/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.4825 - val_acc: 0.8500\n",
      "Epoch 2060/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2061/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 2062/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2063/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2064/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 2065/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 2066/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.4811 - val_acc: 0.8500\n",
      "Epoch 2067/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2068/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 2069/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8500\n",
      "Epoch 2070/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8500\n",
      "Epoch 2071/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2072/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8500\n",
      "Epoch 2073/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8500\n",
      "Epoch 2074/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2075/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.8500\n",
      "Epoch 2076/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8500\n",
      "Epoch 2077/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8500\n",
      "Epoch 2078/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8500\n",
      "Epoch 2079/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.8500\n",
      "Epoch 2080/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 2081/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.4828 - val_acc: 0.8500\n",
      "Epoch 2082/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2083/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2084/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4818 - val_acc: 0.8500\n",
      "Epoch 2085/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4821 - val_acc: 0.8500\n",
      "Epoch 2086/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2087/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 2088/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2089/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.8500\n",
      "Epoch 2090/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8500\n",
      "Epoch 2091/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 2092/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.8500\n",
      "Epoch 2093/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8500\n",
      "Epoch 2094/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 2095/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.4830 - val_acc: 0.8500\n",
      "Epoch 2096/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8500\n",
      "Epoch 2097/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.4829 - val_acc: 0.8500\n",
      "Epoch 2098/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.4818 - val_acc: 0.8500\n",
      "Epoch 2099/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.4819 - val_acc: 0.8500\n",
      "Epoch 2100/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.4828 - val_acc: 0.8500\n",
      "Epoch 2101/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.8500\n",
      "Epoch 2102/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8500\n",
      "Epoch 2103/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8500\n",
      "Epoch 2104/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2105/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8500\n",
      "Epoch 2106/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 2107/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2108/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.8500\n",
      "Epoch 2109/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2110/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2111/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.8500\n",
      "Epoch 2112/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8500\n",
      "Epoch 2113/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8500\n",
      "Epoch 2114/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8500\n",
      "Epoch 2115/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 2116/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2117/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 2118/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 2119/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 2120/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.8500\n",
      "Epoch 2121/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 2122/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8500\n",
      "Epoch 2123/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2124/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.4802 - val_acc: 0.8500\n",
      "Epoch 2125/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2126/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.8500\n",
      "Epoch 2127/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 2128/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2129/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.8500\n",
      "Epoch 2130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2131/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2132/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.8500\n",
      "Epoch 2133/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8500\n",
      "Epoch 2134/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8500\n",
      "Epoch 2135/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8500\n",
      "Epoch 2136/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2137/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2138/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 2139/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 2140/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 2141/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8500\n",
      "Epoch 2142/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8500\n",
      "Epoch 2143/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.4781 - val_acc: 0.8500\n",
      "Epoch 2144/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2145/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8500\n",
      "Epoch 2146/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2147/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.8500\n",
      "Epoch 2148/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2149/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.8500\n",
      "Epoch 2150/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.8500\n",
      "Epoch 2151/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.8500\n",
      "Epoch 2152/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.8500\n",
      "Epoch 2153/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 2154/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.8500\n",
      "Epoch 2155/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 2156/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8500\n",
      "Epoch 2157/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.8500\n",
      "Epoch 2158/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8500\n",
      "Epoch 2159/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4789 - val_acc: 0.8500\n",
      "Epoch 2160/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8500\n",
      "Epoch 2161/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8500\n",
      "Epoch 2162/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8500\n",
      "Epoch 2163/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8500\n",
      "Epoch 2164/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.8500\n",
      "Epoch 2165/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.8500\n",
      "Epoch 2166/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.4918 - val_acc: 0.8500\n",
      "Epoch 2167/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2168/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2169/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2170/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8500\n",
      "Epoch 2172/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2173/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 2174/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 2175/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2176/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2177/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2178/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2179/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2180/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2181/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2182/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2183/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2184/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2185/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2186/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2187/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2188/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2189/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2190/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2191/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2192/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2193/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2194/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2195/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2196/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2197/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2198/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2199/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8500\n",
      "Epoch 2200/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2201/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2202/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2203/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2204/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2205/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2206/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2207/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2208/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.8500\n",
      "Epoch 2209/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2210/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2211/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2212/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2213/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2214/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2215/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2217/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2218/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2219/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2220/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2221/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2222/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2223/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2224/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2225/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2226/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2227/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2228/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2229/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2230/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2231/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2232/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2233/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2234/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2235/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2236/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2237/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2238/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2239/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2240/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2241/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2242/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2243/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2244/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2245/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2246/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2247/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2248/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2249/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2250/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2251/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2252/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2253/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2254/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2255/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2256/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2257/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 2258/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2259/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2260/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2261/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.8500\n",
      "Epoch 2262/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 2263/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2264/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2265/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2266/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2267/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2268/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2269/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2270/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2271/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2272/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2273/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2274/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2275/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2276/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2277/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2278/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2279/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0126 - acc: 1.000 - 0s 122us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2280/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2281/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2282/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8500\n",
      "Epoch 2283/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2284/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2285/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2286/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2287/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2288/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2289/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8500\n",
      "Epoch 2290/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2291/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.4911 - val_acc: 0.8500\n",
      "Epoch 2292/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2293/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2294/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2295/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2296/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2297/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2298/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2299/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8500\n",
      "Epoch 2300/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2301/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2302/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2303/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2304/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2305/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2306/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2307/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2308/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2309/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2310/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2311/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2312/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2313/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2314/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2315/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2316/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2317/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2318/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2319/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2320/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2321/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2322/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2323/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2324/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2325/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2326/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2327/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2328/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2329/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2330/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2331/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2332/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2333/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2334/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2335/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4921 - val_acc: 0.8500\n",
      "Epoch 2336/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2337/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2338/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.8500\n",
      "Epoch 2339/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2340/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2341/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4910 - val_acc: 0.8500\n",
      "Epoch 2342/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8500\n",
      "Epoch 2343/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8500\n",
      "Epoch 2344/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2345/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2346/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2347/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2348/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2349/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2350/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2351/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2352/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2353/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8500\n",
      "Epoch 2354/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2355/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 2356/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2357/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.8500\n",
      "Epoch 2358/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2359/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 2360/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0124 - acc: 1.000 - 0s 114us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2361/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2362/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2363/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2364/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2365/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2366/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2367/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2368/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2369/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2370/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2371/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2372/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2373/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2374/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2375/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2376/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2377/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2378/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2379/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2380/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2381/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2382/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2383/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2384/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2385/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2386/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2387/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2388/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2389/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2390/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2391/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2392/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2393/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2394/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2395/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2396/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2397/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2398/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2399/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2400/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2401/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2402/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2403/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2404/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2405/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2406/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2407/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2408/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2409/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2410/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2411/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2412/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2413/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2414/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2415/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2416/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8500\n",
      "Epoch 2417/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2418/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2419/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2420/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2421/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2422/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2423/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2424/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2425/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2426/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2427/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2428/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2429/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2430/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2431/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2432/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2433/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2434/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2435/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2436/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2437/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2438/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2439/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2440/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2441/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2442/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2443/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2444/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2445/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8500\n",
      "Epoch 2446/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 2447/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.8500\n",
      "Epoch 2448/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2449/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2450/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2451/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2452/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2453/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2454/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2455/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2456/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2457/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2458/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2459/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2460/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2461/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2462/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2463/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2464/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2465/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2466/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2467/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2468/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2469/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2470/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2471/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2472/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2473/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2474/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2475/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4910 - val_acc: 0.8500\n",
      "Epoch 2476/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2477/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.8500\n",
      "Epoch 2478/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2479/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2480/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2481/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2482/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2483/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2484/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2485/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2486/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2487/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2488/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2489/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2490/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2491/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2492/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2493/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2494/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2495/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2496/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2497/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2498/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2499/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2500/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2501/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2502/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2503/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2504/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2505/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2506/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2507/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2508/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2509/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2510/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2511/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2512/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2513/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2514/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2515/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2516/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2518/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2519/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2520/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2521/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2522/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2523/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2524/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2525/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4911 - val_acc: 0.8500\n",
      "Epoch 2526/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4924 - val_acc: 0.8500\n",
      "Epoch 2527/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8500\n",
      "Epoch 2528/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8500\n",
      "Epoch 2529/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2530/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2531/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2532/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2533/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2534/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2535/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2536/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2537/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2538/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2539/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2540/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2541/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2542/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2543/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2544/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2545/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2546/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2547/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2548/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2549/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2550/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2551/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2552/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2553/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2554/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2555/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2556/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.8500\n",
      "Epoch 2557/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2558/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2559/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2560/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2561/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2562/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8500\n",
      "Epoch 2563/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2564/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2565/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2566/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2567/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2568/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2569/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2570/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2571/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2572/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2573/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2574/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2575/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2576/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2577/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2578/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2579/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2580/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2581/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2582/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2583/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2584/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2585/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2586/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2587/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2588/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2589/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2590/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2591/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2592/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2593/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2594/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2595/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2596/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2597/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2598/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2599/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2600/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2601/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2602/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2603/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2604/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2605/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2606/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2607/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2608/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2609/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2610/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2611/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2612/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2613/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2614/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2615/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2616/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2617/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2618/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2619/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2620/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2621/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2622/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2623/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2624/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2625/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2626/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2627/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2628/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2629/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2630/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2631/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2632/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2634/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2635/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8500\n",
      "Epoch 2636/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2637/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2638/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2639/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2640/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2641/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2642/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2643/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2644/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2645/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2646/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2647/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2648/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2649/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2650/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2651/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.8500\n",
      "Epoch 2652/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2653/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2654/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2655/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2656/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2657/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2658/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2659/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2660/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2661/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2662/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2663/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2664/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2665/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2666/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2667/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2668/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2669/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2670/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2671/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2672/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8500\n",
      "Epoch 2673/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2674/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2675/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2676/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2677/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2678/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.8500\n",
      "Epoch 2679/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2680/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8500\n",
      "Epoch 2681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8500\n",
      "Epoch 2682/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.8500\n",
      "Epoch 2683/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2684/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.8500\n",
      "Epoch 2685/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2686/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8500\n",
      "Epoch 2687/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8500\n",
      "Epoch 2688/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8500\n",
      "Epoch 2689/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4911 - val_acc: 0.8500\n",
      "Epoch 2690/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2691/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.8500\n",
      "Epoch 2692/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.8500\n",
      "Epoch 2693/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.8500\n",
      "Epoch 2694/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2695/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.8500\n",
      "Epoch 2696/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 2697/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8500\n",
      "Epoch 2698/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2699/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2700/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2701/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8500\n",
      "Epoch 2702/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8500\n",
      "Epoch 2703/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2704/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2705/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8500\n",
      "Epoch 2706/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2707/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2708/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2709/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2710/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2711/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2712/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2713/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2714/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2715/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2716/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2717/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8500\n",
      "Epoch 2718/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2719/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2720/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2721/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2722/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2723/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2724/3000\n",
      "79/79 [==============================] - 0s 171us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2725/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2726/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2727/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2728/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2729/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2730/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2731/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2732/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2733/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8500\n",
      "Epoch 2734/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2735/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4902 - val_acc: 0.8500\n",
      "Epoch 2736/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.8500\n",
      "Epoch 2737/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2738/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2739/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2740/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2741/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2742/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2743/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2744/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2745/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2746/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2747/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2748/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2749/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2750/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2751/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2752/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2753/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2754/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2755/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2756/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2757/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2758/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2759/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2760/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2761/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2762/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2763/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2764/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2765/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2766/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2767/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2768/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2769/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2770/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2771/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2772/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2773/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2774/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2775/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2776/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2777/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2778/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2779/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2780/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2781/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2782/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2783/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2784/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2785/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2786/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2787/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2788/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2789/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2790/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2791/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2792/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2793/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2794/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2795/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2796/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2797/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2798/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2799/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8500\n",
      "Epoch 2800/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8500\n",
      "Epoch 2801/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2802/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2803/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8500\n",
      "Epoch 2804/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2805/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2806/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.8500\n",
      "Epoch 2807/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2808/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8500\n",
      "Epoch 2809/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.8500\n",
      "Epoch 2810/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2811/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2812/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4844 - val_acc: 0.8500\n",
      "Epoch 2813/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4849 - val_acc: 0.8500\n",
      "Epoch 2814/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8500\n",
      "Epoch 2815/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2816/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8500\n",
      "Epoch 2817/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.8500\n",
      "Epoch 2818/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2819/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8500\n",
      "Epoch 2820/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8500\n",
      "Epoch 2821/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2822/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8500\n",
      "Epoch 2823/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2824/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.8500\n",
      "Epoch 2825/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.8500\n",
      "Epoch 2826/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2827/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4839 - val_acc: 0.8500\n",
      "Epoch 2828/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2829/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2830/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4837 - val_acc: 0.8500\n",
      "Epoch 2831/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 2832/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.8500\n",
      "Epoch 2833/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2834/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2835/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8500\n",
      "Epoch 2836/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8500\n",
      "Epoch 2837/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2838/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 2839/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.8500\n",
      "Epoch 2840/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2841/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2842/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.8500\n",
      "Epoch 2843/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2844/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2845/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2846/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2847/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2848/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2849/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2850/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2851/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8500\n",
      "Epoch 2852/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2853/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8500\n",
      "Epoch 2854/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2855/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2856/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2857/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2858/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2859/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2860/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2861/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2862/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2863/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2864/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2865/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2866/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2867/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2868/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2869/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2870/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2871/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2872/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2873/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2874/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2875/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2876/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2877/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2878/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2879/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2880/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2881/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2882/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2883/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2884/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2885/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2886/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2887/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2888/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8500\n",
      "Epoch 2889/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2890/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8500\n",
      "Epoch 2891/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4890 - val_acc: 0.8500\n",
      "Epoch 2892/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2893/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8500\n",
      "Epoch 2894/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8500\n",
      "Epoch 2895/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2896/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2897/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2898/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2899/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2900/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2901/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2902/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2903/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2904/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2905/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2906/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2907/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2908/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2909/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2910/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2911/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2912/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8500\n",
      "Epoch 2913/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2914/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2915/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2916/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2917/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2918/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2919/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2920/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2921/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2922/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2923/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2924/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2925/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2926/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2927/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2928/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2929/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2930/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2931/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2932/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2933/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2934/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2935/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2936/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.8500\n",
      "Epoch 2937/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2938/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2939/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4868 - val_acc: 0.8500\n",
      "Epoch 2940/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2941/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2942/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2943/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2944/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 2945/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2946/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2947/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2948/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2949/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2950/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.8500\n",
      "Epoch 2951/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2952/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8500\n",
      "Epoch 2953/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2954/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Epoch 2955/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2956/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2957/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2958/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2959/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2960/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2961/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2962/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.8500\n",
      "Epoch 2963/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.8500\n",
      "Epoch 2964/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8500\n",
      "Epoch 2965/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2966/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2967/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4881 - val_acc: 0.8500\n",
      "Epoch 2968/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2969/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2970/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2971/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2972/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.8500\n",
      "Epoch 2973/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2974/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2975/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4886 - val_acc: 0.8500\n",
      "Epoch 2976/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8500\n",
      "Epoch 2977/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4883 - val_acc: 0.8500\n",
      "Epoch 2978/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8500\n",
      "Epoch 2979/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8500\n",
      "Epoch 2980/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4876 - val_acc: 0.8500\n",
      "Epoch 2981/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2982/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8500\n",
      "Epoch 2983/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.8500\n",
      "Epoch 2984/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2985/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8500\n",
      "Epoch 2986/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2987/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8500\n",
      "Epoch 2988/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.8500\n",
      "Epoch 2989/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.8500\n",
      "Epoch 2990/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2991/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.8500\n",
      "Epoch 2993/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8500\n",
      "Epoch 2994/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8500\n",
      "Epoch 2995/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8500\n",
      "Epoch 2996/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8500\n",
      "Epoch 2997/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8500\n",
      "Epoch 2998/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8500\n",
      "Epoch 2999/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8500\n",
      "Epoch 3000/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8500\n",
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/3000\n",
      "79/79 [==============================] - 0s 2ms/sample - loss: 0.7340 - acc: 0.5063 - val_loss: 0.7451 - val_acc: 0.4500\n",
      "Epoch 2/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.7157 - acc: 0.5063 - val_loss: 0.7319 - val_acc: 0.4500\n",
      "Epoch 3/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.7067 - acc: 0.5063 - val_loss: 0.7211 - val_acc: 0.4500\n",
      "Epoch 4/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.7003 - acc: 0.5063 - val_loss: 0.7103 - val_acc: 0.4500\n",
      "Epoch 5/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6958 - acc: 0.5063 - val_loss: 0.7024 - val_acc: 0.4500\n",
      "Epoch 6/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6945 - acc: 0.5063 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 7/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 8/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6924 - acc: 0.4937 - val_loss: 0.6972 - val_acc: 0.4500\n",
      "Epoch 9/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6934 - acc: 0.4810 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 10/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6919 - acc: 0.5063 - val_loss: 0.6982 - val_acc: 0.4500\n",
      "Epoch 11/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6954 - acc: 0.5063 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 12/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6928 - acc: 0.5443 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 13/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6930 - acc: 0.5443 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 14/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6992 - val_acc: 0.4500\n",
      "Epoch 15/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6937 - acc: 0.5063 - val_loss: 0.7024 - val_acc: 0.4500\n",
      "Epoch 16/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 17/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6928 - acc: 0.5443 - val_loss: 0.7004 - val_acc: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6916 - acc: 0.5063 - val_loss: 0.6992 - val_acc: 0.4500\n",
      "Epoch 19/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6920 - acc: 0.5063 - val_loss: 0.6999 - val_acc: 0.4500\n",
      "Epoch 20/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6918 - acc: 0.5063 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 21/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6914 - acc: 0.5063 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 22/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6958 - acc: 0.3797 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 23/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6912 - acc: 0.5443 - val_loss: 0.6942 - val_acc: 0.3500\n",
      "Epoch 24/3000\n",
      "79/79 [==============================] - 0s 278us/sample - loss: 0.6918 - acc: 0.6709 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 25/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.625 - 0s 139us/sample - loss: 0.6910 - acc: 0.5443 - val_loss: 0.6952 - val_acc: 0.4000\n",
      "Epoch 26/3000\n",
      "79/79 [==============================] - 0s 284us/sample - loss: 0.6922 - acc: 0.5190 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 27/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6915 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 28/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6915 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 29/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.6911 - acc: 0.6076 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 30/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6908 - acc: 0.5443 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 31/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6918 - acc: 0.5570 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 32/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6955 - acc: 0.5316 - val_loss: 0.6918 - val_acc: 0.5500\n",
      "Epoch 33/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6921 - acc: 0.4937 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 34/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6912 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 35/3000\n",
      "79/79 [==============================] - 0s 258us/sample - loss: 0.6905 - acc: 0.5949 - val_loss: 0.6933 - val_acc: 0.6000\n",
      "Epoch 36/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6908 - acc: 0.5949 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 37/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6908 - acc: 0.5570 - val_loss: 0.6933 - val_acc: 0.6000\n",
      "Epoch 38/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6915 - acc: 0.5823 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 39/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6922 - acc: 0.4810 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 40/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6945 - acc: 0.5316 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 41/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6931 - acc: 0.5316 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 42/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6919 - acc: 0.4937 - val_loss: 0.6911 - val_acc: 0.5500\n",
      "Epoch 43/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6925 - acc: 0.4937 - val_loss: 0.6950 - val_acc: 0.4000\n",
      "Epoch 44/3000\n",
      "79/79 [==============================] - 0s 167us/sample - loss: 0.6911 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4000\n",
      "Epoch 45/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6905 - acc: 0.5316 - val_loss: 0.6929 - val_acc: 0.5500\n",
      "Epoch 46/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6918 - acc: 0.4937 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 47/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6908 - acc: 0.6203 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 48/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6903 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 49/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6911 - acc: 0.4937 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 50/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 51/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6920 - acc: 0.5316 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 52/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6916 - acc: 0.4937 - val_loss: 0.6923 - val_acc: 0.5500\n",
      "Epoch 53/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6920 - acc: 0.4430 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 54/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6909 - acc: 0.4937 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 55/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6910 - acc: 0.4937 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 56/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6901 - acc: 0.5949 - val_loss: 0.6927 - val_acc: 0.5500\n",
      "Epoch 57/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6907 - acc: 0.5823 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 58/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6906 - acc: 0.4937 - val_loss: 0.6935 - val_acc: 0.4000\n",
      "Epoch 59/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6907 - acc: 0.5949 - val_loss: 0.6927 - val_acc: 0.5500\n",
      "Epoch 60/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6903 - acc: 0.5190 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 61/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6919 - acc: 0.4557 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 62/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6899 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 63/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6932 - acc: 0.4810 - val_loss: 0.6974 - val_acc: 0.4500\n",
      "Epoch 64/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6904 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4000\n",
      "Epoch 65/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6902 - acc: 0.5190 - val_loss: 0.6923 - val_acc: 0.5500\n",
      "Epoch 66/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6897 - acc: 0.5443 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 67/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6931 - acc: 0.5190 - val_loss: 0.6963 - val_acc: 0.4500\n",
      "Epoch 68/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6897 - acc: 0.5063 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 69/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6908 - acc: 0.4684 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 70/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6893 - acc: 0.5063 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 71/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6911 - acc: 0.5443 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 72/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6891 - acc: 0.6835 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 73/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6897 - acc: 0.6203 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 74/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6915 - acc: 0.4810 - val_loss: 0.6976 - val_acc: 0.4500\n",
      "Epoch 75/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6988 - val_acc: 0.4500\n",
      "Epoch 76/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6897 - acc: 0.5063 - val_loss: 0.6993 - val_acc: 0.4500\n",
      "Epoch 77/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6911 - acc: 0.5063 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 78/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6907 - acc: 0.5063 - val_loss: 0.6988 - val_acc: 0.4500\n",
      "Epoch 79/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6895 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 80/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6891 - acc: 0.5190 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 81/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6893 - acc: 0.5063 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 82/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6890 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4500\n",
      "Epoch 83/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6892 - acc: 0.5443 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 84/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6890 - acc: 0.6709 - val_loss: 0.6961 - val_acc: 0.4500\n",
      "Epoch 85/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6888 - acc: 0.5063 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 86/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6888 - acc: 0.5949 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 87/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6898 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.5500\n",
      "Epoch 88/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6912 - acc: 0.5443 - val_loss: 0.6978 - val_acc: 0.4500\n",
      "Epoch 89/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6927 - acc: 0.5570 - val_loss: 0.6964 - val_acc: 0.4500\n",
      "Epoch 90/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6891 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 91/3000\n",
      "79/79 [==============================] - 0s 265us/sample - loss: 0.6894 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.7000\n",
      "Epoch 92/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6887 - acc: 0.7215 - val_loss: 0.6925 - val_acc: 0.6500\n",
      "Epoch 93/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6885 - acc: 0.6835 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 94/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6888 - acc: 0.6076 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 95/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6888 - acc: 0.7468 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 96/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6893 - acc: 0.5316 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 97/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6888 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 98/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6907 - acc: 0.5823 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 99/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6894 - acc: 0.5063 - val_loss: 0.6912 - val_acc: 0.5500\n",
      "Epoch 100/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6888 - acc: 0.4937 - val_loss: 0.6924 - val_acc: 0.7000\n",
      "Epoch 101/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6888 - acc: 0.7215 - val_loss: 0.6923 - val_acc: 0.6000\n",
      "Epoch 102/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6889 - acc: 0.6329 - val_loss: 0.6916 - val_acc: 0.5500\n",
      "Epoch 103/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6898 - acc: 0.4684 - val_loss: 0.6904 - val_acc: 0.5500\n",
      "Epoch 104/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6894 - acc: 0.4937 - val_loss: 0.6925 - val_acc: 0.6500\n",
      "Epoch 105/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6893 - acc: 0.6076 - val_loss: 0.6917 - val_acc: 0.5500\n",
      "Epoch 106/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6906 - acc: 0.6076 - val_loss: 0.6921 - val_acc: 0.5500\n",
      "Epoch 107/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6905 - acc: 0.5949 - val_loss: 0.6925 - val_acc: 0.6500\n",
      "Epoch 108/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6895 - acc: 0.6076 - val_loss: 0.6941 - val_acc: 0.4000\n",
      "Epoch 109/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6886 - acc: 0.6456 - val_loss: 0.6958 - val_acc: 0.4500\n",
      "Epoch 110/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6888 - acc: 0.5063 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 111/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6882 - acc: 0.6962 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 112/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6892 - acc: 0.5570 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 113/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6880 - acc: 0.6582 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 114/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6916 - acc: 0.5190 - val_loss: 0.6967 - val_acc: 0.4500\n",
      "Epoch 115/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6887 - acc: 0.5063 - val_loss: 0.6974 - val_acc: 0.4500\n",
      "Epoch 116/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6897 - acc: 0.5063 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 117/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6889 - acc: 0.6203 - val_loss: 0.6916 - val_acc: 0.5500\n",
      "Epoch 118/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6881 - acc: 0.6582 - val_loss: 0.6918 - val_acc: 0.5500\n",
      "Epoch 119/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6893 - acc: 0.5570 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 120/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6884 - acc: 0.4937 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 121/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.6879 - acc: 0.7152 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 122/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6877 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 123/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6876 - acc: 0.6456 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 124/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6881 - acc: 0.7089 - val_loss: 0.6921 - val_acc: 0.6500\n",
      "Epoch 125/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6880 - acc: 0.7722 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 126/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6886 - acc: 0.6329 - val_loss: 0.6923 - val_acc: 0.6500\n",
      "Epoch 127/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6881 - acc: 0.6456 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 128/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6911 - acc: 0.5190 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 129/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6911 - acc: 0.4937 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6880 - acc: 0.6582 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 131/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6902 - acc: 0.5823 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 132/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6890 - acc: 0.5823 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 133/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6875 - acc: 0.5696 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 134/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6877 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 135/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6879 - acc: 0.7342 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 136/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 137/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6875 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 138/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6877 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4500\n",
      "Epoch 139/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6874 - acc: 0.7595 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 140/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6905 - acc: 0.4177 - val_loss: 0.6999 - val_acc: 0.4500\n",
      "Epoch 141/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6910 - acc: 0.5063 - val_loss: 0.6989 - val_acc: 0.4500\n",
      "Epoch 142/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6877 - acc: 0.5063 - val_loss: 0.6965 - val_acc: 0.4500\n",
      "Epoch 143/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6876 - acc: 0.5063 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 144/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6932 - acc: 0.4937 - val_loss: 0.6986 - val_acc: 0.4500\n",
      "Epoch 145/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6878 - acc: 0.5063 - val_loss: 0.6976 - val_acc: 0.4500\n",
      "Epoch 146/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6874 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 147/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6891 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.5500\n",
      "Epoch 148/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6872 - acc: 0.7975 - val_loss: 0.6944 - val_acc: 0.4500\n",
      "Epoch 149/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6893 - acc: 0.5190 - val_loss: 0.6973 - val_acc: 0.4500\n",
      "Epoch 150/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6872 - acc: 0.5063 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 151/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6886 - acc: 0.6456 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 152/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6872 - acc: 0.5063 - val_loss: 0.6968 - val_acc: 0.4500\n",
      "Epoch 153/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6882 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 154/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6876 - acc: 0.6962 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 155/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6912 - acc: 0.5063 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 156/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6873 - acc: 0.7468 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 157/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6881 - acc: 0.5823 - val_loss: 0.6917 - val_acc: 0.6000\n",
      "Epoch 158/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6876 - acc: 0.6962 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 159/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6880 - acc: 0.5949 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 160/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6872 - acc: 0.5063 - val_loss: 0.6918 - val_acc: 0.6500\n",
      "Epoch 161/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6869 - acc: 0.7848 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 162/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6871 - acc: 0.7722 - val_loss: 0.6916 - val_acc: 0.6000\n",
      "Epoch 163/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6878 - acc: 0.6203 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 164/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6873 - acc: 0.6076 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 165/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6882 - acc: 0.6329 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 166/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6870 - acc: 0.5190 - val_loss: 0.6918 - val_acc: 0.6500\n",
      "Epoch 167/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6868 - acc: 0.6329 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 168/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6871 - acc: 0.5949 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 169/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6865 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 170/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.6864 - acc: 0.5443 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 171/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6864 - acc: 0.7089 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 172/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6877 - acc: 0.6203 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 173/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6865 - acc: 0.5316 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 174/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6882 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 175/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6862 - acc: 0.7848 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 176/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6887 - acc: 0.6203 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 177/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6871 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 178/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6866 - acc: 0.6709 - val_loss: 0.6921 - val_acc: 0.6500\n",
      "Epoch 179/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6870 - acc: 0.7595 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 180/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6869 - acc: 0.5063 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 181/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6867 - acc: 0.7848 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 182/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6867 - acc: 0.5949 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 183/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6860 - acc: 0.5316 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 184/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6864 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 185/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6872 - acc: 0.6329 - val_loss: 0.6904 - val_acc: 0.5500\n",
      "Epoch 186/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6865 - acc: 0.5190 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 187/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6866 - acc: 0.7595 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 188/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6866 - acc: 0.7215 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 189/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6875 - acc: 0.5443 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 190/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6875 - acc: 0.5063 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 191/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6859 - acc: 0.5063 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 192/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6868 - acc: 0.5696 - val_loss: 0.6979 - val_acc: 0.4500\n",
      "Epoch 193/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6878 - acc: 0.5063 - val_loss: 0.6998 - val_acc: 0.4500\n",
      "Epoch 194/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6906 - acc: 0.5063 - val_loss: 0.6990 - val_acc: 0.4500\n",
      "Epoch 195/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6881 - acc: 0.5063 - val_loss: 0.7020 - val_acc: 0.4500\n",
      "Epoch 196/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6902 - acc: 0.5063 - val_loss: 0.6959 - val_acc: 0.4500\n",
      "Epoch 197/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6860 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4500\n",
      "Epoch 198/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6885 - acc: 0.5696 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 199/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6859 - acc: 0.6709 - val_loss: 0.6916 - val_acc: 0.6000\n",
      "Epoch 200/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6856 - acc: 0.8228 - val_loss: 0.6916 - val_acc: 0.6000\n",
      "Epoch 201/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6869 - acc: 0.7342 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 202/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6864 - acc: 0.5316 - val_loss: 0.6915 - val_acc: 0.6500\n",
      "Epoch 203/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6871 - acc: 0.6203 - val_loss: 0.6925 - val_acc: 0.5500\n",
      "Epoch 204/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6866 - acc: 0.6962 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 205/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6854 - acc: 0.8354 - val_loss: 0.6917 - val_acc: 0.5500\n",
      "Epoch 206/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6867 - acc: 0.6203 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 207/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6892 - acc: 0.4810 - val_loss: 0.6981 - val_acc: 0.4500\n",
      "Epoch 208/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6926 - acc: 0.5949 - val_loss: 0.6975 - val_acc: 0.4500\n",
      "Epoch 209/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6861 - acc: 0.5063 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 210/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6865 - acc: 0.5063 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 211/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6854 - acc: 0.8608 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 212/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6858 - acc: 0.5570 - val_loss: 0.6950 - val_acc: 0.4500\n",
      "Epoch 213/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6854 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 214/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6853 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 215/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6867 - acc: 0.6076 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6855 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 217/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6859 - acc: 0.6709 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 218/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6859 - acc: 0.5570 - val_loss: 0.6914 - val_acc: 0.6000\n",
      "Epoch 219/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6866 - acc: 0.6835 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 220/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6852 - acc: 0.6456 - val_loss: 0.6910 - val_acc: 0.6500\n",
      "Epoch 221/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6854 - acc: 0.7215 - val_loss: 0.6911 - val_acc: 0.6500\n",
      "Epoch 222/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6860 - acc: 0.6962 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 223/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6862 - acc: 0.7089 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 224/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6855 - acc: 0.5696 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 225/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6872 - acc: 0.6709 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 226/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6853 - acc: 0.5570 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 227/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6852 - acc: 0.5190 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 228/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6848 - acc: 0.5190 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 229/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6854 - acc: 0.5063 - val_loss: 0.6909 - val_acc: 0.6500\n",
      "Epoch 230/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6851 - acc: 0.7975 - val_loss: 0.6908 - val_acc: 0.6500\n",
      "Epoch 231/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6851 - acc: 0.7089 - val_loss: 0.6909 - val_acc: 0.6500\n",
      "Epoch 232/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6862 - acc: 0.6709 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 233/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6858 - acc: 0.6456 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 234/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6856 - acc: 0.5063 - val_loss: 0.6915 - val_acc: 0.6000\n",
      "Epoch 235/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6858 - acc: 0.7975 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 236/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6846 - acc: 0.5570 - val_loss: 0.6942 - val_acc: 0.4500\n",
      "Epoch 237/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6844 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 238/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6845 - acc: 0.6962 - val_loss: 0.6945 - val_acc: 0.4500\n",
      "Epoch 239/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6847 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 240/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6843 - acc: 0.6456 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 241/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6843 - acc: 0.5949 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 242/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6846 - acc: 0.5190 - val_loss: 0.6919 - val_acc: 0.5500\n",
      "Epoch 243/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6926 - acc: 0.6076 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 244/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6846 - acc: 0.5823 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 245/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6849 - acc: 0.7468 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 246/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6851 - acc: 0.5823 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 247/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6856 - acc: 0.5949 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 248/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6851 - acc: 0.4937 - val_loss: 0.6904 - val_acc: 0.6000\n",
      "Epoch 249/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6850 - acc: 0.7342 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 250/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6882 - acc: 0.5190 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 251/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6875 - acc: 0.5316 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 252/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6845 - acc: 0.5063 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 253/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6859 - acc: 0.5570 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 254/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6842 - acc: 0.6203 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 255/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6853 - acc: 0.5570 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 256/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6871 - acc: 0.5823 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 257/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6854 - acc: 0.4937 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 258/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6847 - acc: 0.4937 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 259/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6849 - acc: 0.6962 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 260/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6848 - acc: 0.5823 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 261/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6851 - acc: 0.5823 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 262/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6846 - acc: 0.4937 - val_loss: 0.6902 - val_acc: 0.6000\n",
      "Epoch 263/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6842 - acc: 0.6203 - val_loss: 0.6922 - val_acc: 0.4500\n",
      "Epoch 264/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6836 - acc: 0.7089 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 265/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6838 - acc: 0.6076 - val_loss: 0.6909 - val_acc: 0.6500\n",
      "Epoch 266/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6847 - acc: 0.6835 - val_loss: 0.6929 - val_acc: 0.4500\n",
      "Epoch 267/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6840 - acc: 0.5696 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 268/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6853 - acc: 0.6203 - val_loss: 0.6905 - val_acc: 0.6500\n",
      "Epoch 269/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6840 - acc: 0.7089 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 270/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6855 - acc: 0.6329 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 271/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6840 - acc: 0.5443 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 272/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6870 - acc: 0.5949 - val_loss: 0.6928 - val_acc: 0.4500\n",
      "Epoch 273/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6837 - acc: 0.7848 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 274/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6844 - acc: 0.6076 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 275/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6837 - acc: 0.7342 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 276/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6840 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 277/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6831 - acc: 0.8354 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 278/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6836 - acc: 0.6329 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 279/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6838 - acc: 0.5063 - val_loss: 0.6908 - val_acc: 0.6500\n",
      "Epoch 280/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6838 - acc: 0.7342 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 281/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6834 - acc: 0.6329 - val_loss: 0.6901 - val_acc: 0.6000\n",
      "Epoch 282/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6835 - acc: 0.7595 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 283/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6844 - acc: 0.7089 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 284/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6836 - acc: 0.5190 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 285/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6837 - acc: 0.6329 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 286/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6837 - acc: 0.5443 - val_loss: 0.6903 - val_acc: 0.6500\n",
      "Epoch 287/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6828 - acc: 0.8228 - val_loss: 0.6902 - val_acc: 0.6500\n",
      "Epoch 288/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6833 - acc: 0.6709 - val_loss: 0.6912 - val_acc: 0.6000\n",
      "Epoch 289/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6834 - acc: 0.8608 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 290/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6833 - acc: 0.6076 - val_loss: 0.6940 - val_acc: 0.4500\n",
      "Epoch 291/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6856 - acc: 0.5063 - val_loss: 0.6914 - val_acc: 0.6000\n",
      "Epoch 292/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6824 - acc: 0.8101 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 293/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6849 - acc: 0.7975 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 294/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6834 - acc: 0.5190 - val_loss: 0.6906 - val_acc: 0.6500\n",
      "Epoch 295/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6830 - acc: 0.7848 - val_loss: 0.6915 - val_acc: 0.6000\n",
      "Epoch 296/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6838 - acc: 0.7215 - val_loss: 0.6923 - val_acc: 0.4500\n",
      "Epoch 297/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6838 - acc: 0.5949 - val_loss: 0.6923 - val_acc: 0.4500\n",
      "Epoch 298/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6822 - acc: 0.6076 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 299/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6827 - acc: 0.7722 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 300/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6823 - acc: 0.5570 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 301/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6831 - acc: 0.5696 - val_loss: 0.6913 - val_acc: 0.6000\n",
      "Epoch 302/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6820 - acc: 0.8481 - val_loss: 0.6909 - val_acc: 0.6000\n",
      "Epoch 303/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6821 - acc: 0.8861 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 304/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6829 - acc: 0.6203 - val_loss: 0.6899 - val_acc: 0.6500\n",
      "Epoch 305/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6839 - acc: 0.7975 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 306/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6850 - acc: 0.6329 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 307/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6826 - acc: 0.5570 - val_loss: 0.6893 - val_acc: 0.6000\n",
      "Epoch 308/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6821 - acc: 0.7848 - val_loss: 0.6902 - val_acc: 0.6500\n",
      "Epoch 309/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6832 - acc: 0.8101 - val_loss: 0.6929 - val_acc: 0.4500\n",
      "Epoch 310/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6824 - acc: 0.6709 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 311/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6817 - acc: 0.5570 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 312/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6842 - acc: 0.5570 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 313/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6834 - acc: 0.6203 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 314/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6820 - acc: 0.5696 - val_loss: 0.6948 - val_acc: 0.4500\n",
      "Epoch 315/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6822 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 316/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6819 - acc: 0.5063 - val_loss: 0.6918 - val_acc: 0.4500\n",
      "Epoch 317/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6815 - acc: 0.6835 - val_loss: 0.6911 - val_acc: 0.6000\n",
      "Epoch 318/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6816 - acc: 0.8734 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 319/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6815 - acc: 0.6456 - val_loss: 0.6928 - val_acc: 0.4500\n",
      "Epoch 320/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.6816 - acc: 0.5949 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 321/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6822 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 322/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6821 - acc: 0.5190 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 323/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6819 - acc: 0.5696 - val_loss: 0.6941 - val_acc: 0.4500\n",
      "Epoch 324/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6821 - acc: 0.5696 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 325/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6817 - acc: 0.5063 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 326/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6831 - acc: 0.6709 - val_loss: 0.6900 - val_acc: 0.6500\n",
      "Epoch 327/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6823 - acc: 0.7848 - val_loss: 0.6897 - val_acc: 0.6500\n",
      "Epoch 328/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6811 - acc: 0.8608 - val_loss: 0.6905 - val_acc: 0.6500\n",
      "Epoch 329/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6809 - acc: 0.8987 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 330/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6809 - acc: 0.8354 - val_loss: 0.6916 - val_acc: 0.4500\n",
      "Epoch 331/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6817 - acc: 0.6709 - val_loss: 0.6891 - val_acc: 0.6000\n",
      "Epoch 332/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6812 - acc: 0.7975 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 333/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6814 - acc: 0.8228 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 334/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6812 - acc: 0.6456 - val_loss: 0.6915 - val_acc: 0.4500\n",
      "Epoch 335/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6814 - acc: 0.7975 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 336/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6809 - acc: 0.5949 - val_loss: 0.6901 - val_acc: 0.6000\n",
      "Epoch 337/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6818 - acc: 0.7595 - val_loss: 0.6897 - val_acc: 0.6500\n",
      "Epoch 338/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6817 - acc: 0.8354 - val_loss: 0.6889 - val_acc: 0.6000\n",
      "Epoch 339/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6810 - acc: 0.7215 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 340/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6820 - acc: 0.7468 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 341/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6808 - acc: 0.5063 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 342/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6811 - acc: 0.8734 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 343/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6828 - acc: 0.5063 - val_loss: 0.6919 - val_acc: 0.4500\n",
      "Epoch 344/3000\n",
      "79/79 [==============================] - 0s 271us/sample - loss: 0.6808 - acc: 0.5570 - val_loss: 0.6899 - val_acc: 0.7500\n",
      "Epoch 345/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6806 - acc: 0.9114 - val_loss: 0.6916 - val_acc: 0.4500\n",
      "Epoch 346/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6884 - acc: 0.5949 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 347/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6818 - acc: 0.7342 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 348/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6825 - acc: 0.5190 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 349/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6830 - acc: 0.6203 - val_loss: 0.6974 - val_acc: 0.4500\n",
      "Epoch 350/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6812 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 351/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6714 - acc: 0.593 - 0s 119us/sample - loss: 0.6814 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 352/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6814 - acc: 0.7468 - val_loss: 0.6947 - val_acc: 0.4500\n",
      "Epoch 353/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6805 - acc: 0.5190 - val_loss: 0.6940 - val_acc: 0.4500\n",
      "Epoch 354/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6803 - acc: 0.5316 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 355/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6807 - acc: 0.5443 - val_loss: 0.6943 - val_acc: 0.4500\n",
      "Epoch 356/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6801 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.4500\n",
      "Epoch 357/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6824 - acc: 0.5316 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 358/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6803 - acc: 0.6329 - val_loss: 0.6889 - val_acc: 0.6500\n",
      "Epoch 359/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6818 - acc: 0.7215 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 360/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6802 - acc: 0.6456 - val_loss: 0.6900 - val_acc: 0.6500\n",
      "Epoch 361/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6798 - acc: 0.9114 - val_loss: 0.6915 - val_acc: 0.4500\n",
      "Epoch 362/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6814 - acc: 0.5949 - val_loss: 0.6887 - val_acc: 0.6000\n",
      "Epoch 363/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6765 - acc: 0.906 - 0s 145us/sample - loss: 0.6807 - acc: 0.7215 - val_loss: 0.6881 - val_acc: 0.6000\n",
      "Epoch 364/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6808 - acc: 0.6582 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 365/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6803 - acc: 0.5570 - val_loss: 0.6899 - val_acc: 0.6500\n",
      "Epoch 366/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6800 - acc: 0.8987 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 367/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6801 - acc: 0.6582 - val_loss: 0.6926 - val_acc: 0.4500\n",
      "Epoch 368/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6807 - acc: 0.6835 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 369/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6802 - acc: 0.6076 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 370/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6801 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4500\n",
      "Epoch 371/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6802 - acc: 0.6076 - val_loss: 0.6905 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6813 - acc: 0.6835 - val_loss: 0.6897 - val_acc: 0.6500\n",
      "Epoch 373/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6797 - acc: 0.8608 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 374/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6803 - acc: 0.8608 - val_loss: 0.6933 - val_acc: 0.4500\n",
      "Epoch 375/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6795 - acc: 0.5063 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 376/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6789 - acc: 0.7975 - val_loss: 0.6901 - val_acc: 0.6000\n",
      "Epoch 377/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6807 - acc: 0.6582 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 378/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6812 - acc: 0.6203 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 379/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6807 - acc: 0.5316 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 380/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.6789 - acc: 0.7468 - val_loss: 0.6891 - val_acc: 0.6500\n",
      "Epoch 381/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6797 - acc: 0.8354 - val_loss: 0.6880 - val_acc: 0.6000\n",
      "Epoch 382/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6789 - acc: 0.8608 - val_loss: 0.6882 - val_acc: 0.6000\n",
      "Epoch 383/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6795 - acc: 0.6709 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 384/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6787 - acc: 0.7215 - val_loss: 0.6925 - val_acc: 0.4500\n",
      "Epoch 385/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6801 - acc: 0.5823 - val_loss: 0.6946 - val_acc: 0.4500\n",
      "Epoch 386/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6790 - acc: 0.5063 - val_loss: 0.6914 - val_acc: 0.4500\n",
      "Epoch 387/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6819 - acc: 0.6329 - val_loss: 0.6955 - val_acc: 0.4500\n",
      "Epoch 388/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6792 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4500\n",
      "Epoch 389/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6798 - acc: 0.5063 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 390/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6786 - acc: 0.7342 - val_loss: 0.6891 - val_acc: 0.6500\n",
      "Epoch 391/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6799 - acc: 0.8354 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 392/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6786 - acc: 0.5063 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 393/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6796 - acc: 0.6835 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 394/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6815 - acc: 0.6582 - val_loss: 0.6895 - val_acc: 0.7000\n",
      "Epoch 395/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6792 - acc: 0.8228 - val_loss: 0.6876 - val_acc: 0.6000\n",
      "Epoch 396/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6787 - acc: 0.7595 - val_loss: 0.6894 - val_acc: 0.7000\n",
      "Epoch 397/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6791 - acc: 0.8481 - val_loss: 0.6924 - val_acc: 0.4500\n",
      "Epoch 398/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6781 - acc: 0.5570 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 399/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6804 - acc: 0.5696 - val_loss: 0.6949 - val_acc: 0.4500\n",
      "Epoch 400/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6820 - acc: 0.5443 - val_loss: 0.6962 - val_acc: 0.4500\n",
      "Epoch 401/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6784 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 402/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6781 - acc: 0.5063 - val_loss: 0.6915 - val_acc: 0.4500\n",
      "Epoch 403/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6783 - acc: 0.6329 - val_loss: 0.6913 - val_acc: 0.4500\n",
      "Epoch 404/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6782 - acc: 0.7342 - val_loss: 0.6915 - val_acc: 0.4500\n",
      "Epoch 405/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6775 - acc: 0.6456 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 406/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6777 - acc: 0.6962 - val_loss: 0.6896 - val_acc: 0.6000\n",
      "Epoch 407/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6774 - acc: 0.8608 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 408/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6773 - acc: 0.8354 - val_loss: 0.6895 - val_acc: 0.6500\n",
      "Epoch 409/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6779 - acc: 0.8987 - val_loss: 0.6922 - val_acc: 0.4500\n",
      "Epoch 410/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6773 - acc: 0.5443 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 411/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6775 - acc: 0.7595 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 412/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6774 - acc: 0.7468 - val_loss: 0.6893 - val_acc: 0.6500\n",
      "Epoch 413/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6777 - acc: 0.7975 - val_loss: 0.6897 - val_acc: 0.6000\n",
      "Epoch 414/3000\n",
      "79/79 [==============================] - 0s 269us/sample - loss: 0.6780 - acc: 0.7215 - val_loss: 0.6890 - val_acc: 0.8000\n",
      "Epoch 415/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6778 - acc: 0.8354 - val_loss: 0.6870 - val_acc: 0.6000\n",
      "Epoch 416/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6783 - acc: 0.6709 - val_loss: 0.6867 - val_acc: 0.5500\n",
      "Epoch 417/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6778 - acc: 0.6582 - val_loss: 0.6886 - val_acc: 0.6500\n",
      "Epoch 418/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6783 - acc: 0.7848 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 419/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6766 - acc: 0.8608 - val_loss: 0.6890 - val_acc: 0.7000\n",
      "Epoch 420/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6773 - acc: 0.8354 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 421/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6780 - acc: 0.8101 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 422/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6769 - acc: 0.6582 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 423/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6767 - acc: 0.5190 - val_loss: 0.6913 - val_acc: 0.4500\n",
      "Epoch 424/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6766 - acc: 0.6203 - val_loss: 0.6911 - val_acc: 0.4500\n",
      "Epoch 425/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6793 - acc: 0.6329 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 426/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6771 - acc: 0.5823 - val_loss: 0.6879 - val_acc: 0.7000\n",
      "Epoch 427/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6764 - acc: 0.8987 - val_loss: 0.6879 - val_acc: 0.6500\n",
      "Epoch 428/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6763 - acc: 0.8987 - val_loss: 0.6879 - val_acc: 0.6500\n",
      "Epoch 429/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6765 - acc: 0.8861 - val_loss: 0.6870 - val_acc: 0.6000\n",
      "Epoch 430/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6765 - acc: 0.7848 - val_loss: 0.6889 - val_acc: 0.6500\n",
      "Epoch 431/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6765 - acc: 0.7975 - val_loss: 0.6876 - val_acc: 0.6500\n",
      "Epoch 432/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6761 - acc: 0.8861 - val_loss: 0.6876 - val_acc: 0.7000\n",
      "Epoch 433/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6774 - acc: 0.7975 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 434/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6772 - acc: 0.8354 - val_loss: 0.6919 - val_acc: 0.4500\n",
      "Epoch 435/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6781 - acc: 0.6582 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 436/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6760 - acc: 0.6456 - val_loss: 0.6887 - val_acc: 0.7500\n",
      "Epoch 437/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6761 - acc: 0.8101 - val_loss: 0.6874 - val_acc: 0.6500\n",
      "Epoch 438/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6759 - acc: 0.8354 - val_loss: 0.6884 - val_acc: 0.7000\n",
      "Epoch 439/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6757 - acc: 0.9241 - val_loss: 0.6890 - val_acc: 0.6500\n",
      "Epoch 440/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6762 - acc: 0.9114 - val_loss: 0.6917 - val_acc: 0.4500\n",
      "Epoch 441/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6778 - acc: 0.5696 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 442/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6794 - acc: 0.6709 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 443/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6758 - acc: 0.5823 - val_loss: 0.6887 - val_acc: 0.6500\n",
      "Epoch 444/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6769 - acc: 0.7848 - val_loss: 0.6890 - val_acc: 0.6000\n",
      "Epoch 445/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6776 - acc: 0.7468 - val_loss: 0.6914 - val_acc: 0.4500\n",
      "Epoch 446/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6761 - acc: 0.5316 - val_loss: 0.6881 - val_acc: 0.6500\n",
      "Epoch 447/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6766 - acc: 0.8608 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 448/3000\n",
      "79/79 [==============================] - 0s 102us/sample - loss: 0.6763 - acc: 0.7468 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 449/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6768 - acc: 0.6076 - val_loss: 0.6870 - val_acc: 0.6500\n",
      "Epoch 450/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6770 - acc: 0.7975 - val_loss: 0.6849 - val_acc: 0.5500\n",
      "Epoch 451/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.6774 - acc: 0.5190 - val_loss: 0.6864 - val_acc: 0.6000\n",
      "Epoch 452/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6768 - acc: 0.8734 - val_loss: 0.6873 - val_acc: 0.7000\n",
      "Epoch 453/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6757 - acc: 0.8734 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 454/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6759 - acc: 0.8228 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 455/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6747 - acc: 0.8354 - val_loss: 0.6886 - val_acc: 0.6500\n",
      "Epoch 456/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6748 - acc: 0.8481 - val_loss: 0.6873 - val_acc: 0.6500\n",
      "Epoch 457/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6763 - acc: 0.8734 - val_loss: 0.6879 - val_acc: 0.7000\n",
      "Epoch 458/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6747 - acc: 0.8987 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 459/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6747 - acc: 0.7342 - val_loss: 0.6879 - val_acc: 0.7000\n",
      "Epoch 460/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6748 - acc: 0.9114 - val_loss: 0.6877 - val_acc: 0.6500\n",
      "Epoch 461/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6768 - acc: 0.8354 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6747 - acc: 0.7468 - val_loss: 0.6883 - val_acc: 0.7000\n",
      "Epoch 463/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6756 - acc: 0.8228 - val_loss: 0.6909 - val_acc: 0.5000\n",
      "Epoch 464/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6744 - acc: 0.6329 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 465/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6780 - acc: 0.7468 - val_loss: 0.6920 - val_acc: 0.4500\n",
      "Epoch 466/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6742 - acc: 0.5696 - val_loss: 0.6914 - val_acc: 0.4500\n",
      "Epoch 467/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6761 - acc: 0.6203 - val_loss: 0.6891 - val_acc: 0.5000\n",
      "Epoch 468/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6758 - acc: 0.6329 - val_loss: 0.6864 - val_acc: 0.6000\n",
      "Epoch 469/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.6742 - acc: 0.8228 - val_loss: 0.6883 - val_acc: 0.6500\n",
      "Epoch 470/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6758 - acc: 0.8228 - val_loss: 0.6863 - val_acc: 0.6000\n",
      "Epoch 471/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6751 - acc: 0.8354 - val_loss: 0.6862 - val_acc: 0.6000\n",
      "Epoch 472/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6759 - acc: 0.8354 - val_loss: 0.6848 - val_acc: 0.5500\n",
      "Epoch 473/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6767 - acc: 0.6329 - val_loss: 0.6867 - val_acc: 0.7000\n",
      "Epoch 474/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6742 - acc: 0.8734 - val_loss: 0.6884 - val_acc: 0.6500\n",
      "Epoch 475/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6734 - acc: 0.8734 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 476/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6742 - acc: 0.7342 - val_loss: 0.6863 - val_acc: 0.6000\n",
      "Epoch 477/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6756 - acc: 0.6835 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 478/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6735 - acc: 0.8228 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 479/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6760 - acc: 0.7595 - val_loss: 0.6960 - val_acc: 0.4500\n",
      "Epoch 480/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6747 - acc: 0.5063 - val_loss: 0.6914 - val_acc: 0.4500\n",
      "Epoch 481/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6758 - acc: 0.5696 - val_loss: 0.6917 - val_acc: 0.4500\n",
      "Epoch 482/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6761 - acc: 0.5190 - val_loss: 0.6907 - val_acc: 0.5000\n",
      "Epoch 483/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6732 - acc: 0.6456 - val_loss: 0.6902 - val_acc: 0.5000\n",
      "Epoch 484/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6744 - acc: 0.6709 - val_loss: 0.6923 - val_acc: 0.4500\n",
      "Epoch 485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6732 - acc: 0.5570 - val_loss: 0.6914 - val_acc: 0.4500\n",
      "Epoch 486/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6731 - acc: 0.5823 - val_loss: 0.6908 - val_acc: 0.5000\n",
      "Epoch 487/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6735 - acc: 0.6076 - val_loss: 0.6903 - val_acc: 0.5000\n",
      "Epoch 488/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6735 - acc: 0.6329 - val_loss: 0.6870 - val_acc: 0.6500\n",
      "Epoch 489/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6737 - acc: 0.8734 - val_loss: 0.6866 - val_acc: 0.6500\n",
      "Epoch 490/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6762 - acc: 0.8101 - val_loss: 0.6862 - val_acc: 0.7000\n",
      "Epoch 491/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6747 - acc: 0.8354 - val_loss: 0.6861 - val_acc: 0.6000\n",
      "Epoch 492/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6731 - acc: 0.8608 - val_loss: 0.6878 - val_acc: 0.6500\n",
      "Epoch 493/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6724 - acc: 0.8734 - val_loss: 0.6883 - val_acc: 0.6500\n",
      "Epoch 494/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6724 - acc: 0.9241 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 495/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6746 - acc: 0.6709 - val_loss: 0.6918 - val_acc: 0.4500\n",
      "Epoch 496/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6727 - acc: 0.5823 - val_loss: 0.6922 - val_acc: 0.4500\n",
      "Epoch 497/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6724 - acc: 0.5443 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 498/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6722 - acc: 0.7848 - val_loss: 0.6911 - val_acc: 0.4500\n",
      "Epoch 499/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6722 - acc: 0.6582 - val_loss: 0.6906 - val_acc: 0.5000\n",
      "Epoch 500/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6730 - acc: 0.5443 - val_loss: 0.6869 - val_acc: 0.7000\n",
      "Epoch 501/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6718 - acc: 0.9494 - val_loss: 0.6876 - val_acc: 0.6500\n",
      "Epoch 502/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6715 - acc: 0.8861 - val_loss: 0.6880 - val_acc: 0.6500\n",
      "Epoch 503/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6716 - acc: 0.8481 - val_loss: 0.6874 - val_acc: 0.7000\n",
      "Epoch 504/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6715 - acc: 0.8481 - val_loss: 0.6869 - val_acc: 0.7000\n",
      "Epoch 505/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6715 - acc: 0.9367 - val_loss: 0.6866 - val_acc: 0.6500\n",
      "Epoch 506/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6716 - acc: 0.9241 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 507/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6725 - acc: 0.7848 - val_loss: 0.6858 - val_acc: 0.7000\n",
      "Epoch 508/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6718 - acc: 0.9241 - val_loss: 0.6857 - val_acc: 0.7000\n",
      "Epoch 509/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6718 - acc: 0.8608 - val_loss: 0.6877 - val_acc: 0.6500\n",
      "Epoch 510/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6722 - acc: 0.8734 - val_loss: 0.6872 - val_acc: 0.7000\n",
      "Epoch 511/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6724 - acc: 0.8354 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 512/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6713 - acc: 0.6962 - val_loss: 0.6875 - val_acc: 0.7000\n",
      "Epoch 513/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6727 - acc: 0.8228 - val_loss: 0.6913 - val_acc: 0.4500\n",
      "Epoch 514/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6719 - acc: 0.6962 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 515/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6717 - acc: 0.5063 - val_loss: 0.6903 - val_acc: 0.5000\n",
      "Epoch 516/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6712 - acc: 0.6076 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 517/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6729 - acc: 0.7848 - val_loss: 0.6872 - val_acc: 0.7000\n",
      "Epoch 518/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6716 - acc: 0.7848 - val_loss: 0.6848 - val_acc: 0.6000\n",
      "Epoch 519/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6706 - acc: 0.8608 - val_loss: 0.6858 - val_acc: 0.6500\n",
      "Epoch 520/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6708 - acc: 0.8734 - val_loss: 0.6856 - val_acc: 0.6500\n",
      "Epoch 521/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6708 - acc: 0.8987 - val_loss: 0.6848 - val_acc: 0.6000\n",
      "Epoch 522/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6724 - acc: 0.8481 - val_loss: 0.6841 - val_acc: 0.6000\n",
      "Epoch 523/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6721 - acc: 0.6203 - val_loss: 0.6882 - val_acc: 0.5000\n",
      "Epoch 524/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6704 - acc: 0.8228 - val_loss: 0.6873 - val_acc: 0.6500\n",
      "Epoch 525/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6702 - acc: 0.8861 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 526/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6702 - acc: 0.7595 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 527/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6703 - acc: 0.7595 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 528/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6716 - acc: 0.7595 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 529/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6708 - acc: 0.5190 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 530/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6723 - acc: 0.5823 - val_loss: 0.6903 - val_acc: 0.5000\n",
      "Epoch 531/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6701 - acc: 0.6835 - val_loss: 0.6910 - val_acc: 0.4500\n",
      "Epoch 532/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.6702 - acc: 0.5316 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 533/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6725 - acc: 0.6835 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 534/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6717 - acc: 0.7848 - val_loss: 0.6837 - val_acc: 0.6000\n",
      "Epoch 535/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6710 - acc: 0.7848 - val_loss: 0.6865 - val_acc: 0.7000\n",
      "Epoch 536/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6698 - acc: 0.8734 - val_loss: 0.6869 - val_acc: 0.7000\n",
      "Epoch 537/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6707 - acc: 0.7722 - val_loss: 0.6870 - val_acc: 0.7000\n",
      "Epoch 538/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6705 - acc: 0.8354 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 539/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6688 - acc: 0.8481 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 540/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6698 - acc: 0.6709 - val_loss: 0.6855 - val_acc: 0.6500\n",
      "Epoch 541/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6717 - acc: 0.7848 - val_loss: 0.6835 - val_acc: 0.6000\n",
      "Epoch 542/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6699 - acc: 0.7595 - val_loss: 0.6863 - val_acc: 0.7000\n",
      "Epoch 543/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6712 - acc: 0.7468 - val_loss: 0.6827 - val_acc: 0.5500\n",
      "Epoch 544/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6699 - acc: 0.7215 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 545/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6692 - acc: 0.8481 - val_loss: 0.6835 - val_acc: 0.6000\n",
      "Epoch 546/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6695 - acc: 0.7722 - val_loss: 0.6863 - val_acc: 0.7500\n",
      "Epoch 547/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6715 - acc: 0.8481 - val_loss: 0.6851 - val_acc: 0.6500\n",
      "Epoch 548/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6689 - acc: 0.9241 - val_loss: 0.6857 - val_acc: 0.8000\n",
      "Epoch 549/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6688 - acc: 0.8861 - val_loss: 0.6861 - val_acc: 0.7000\n",
      "Epoch 550/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6686 - acc: 0.9241 - val_loss: 0.6888 - val_acc: 0.5000\n",
      "Epoch 551/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6685 - acc: 0.7595 - val_loss: 0.6874 - val_acc: 0.5000\n",
      "Epoch 552/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6704 - acc: 0.7468 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 553/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6682 - acc: 0.7215 - val_loss: 0.6890 - val_acc: 0.5000\n",
      "Epoch 554/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6685 - acc: 0.6456 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 555/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6681 - acc: 0.7848 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 556/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6678 - acc: 0.7595 - val_loss: 0.6860 - val_acc: 0.7500\n",
      "Epoch 557/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6676 - acc: 0.8481 - val_loss: 0.6845 - val_acc: 0.6500\n",
      "Epoch 558/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6693 - acc: 0.8354 - val_loss: 0.6827 - val_acc: 0.6000\n",
      "Epoch 559/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6677 - acc: 0.8101 - val_loss: 0.6839 - val_acc: 0.7000\n",
      "Epoch 560/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6683 - acc: 0.9367 - val_loss: 0.6830 - val_acc: 0.6000\n",
      "Epoch 561/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6674 - acc: 0.8481 - val_loss: 0.6841 - val_acc: 0.6500\n",
      "Epoch 562/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6689 - acc: 0.8481 - val_loss: 0.6819 - val_acc: 0.5500\n",
      "Epoch 563/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6678 - acc: 0.6835 - val_loss: 0.6825 - val_acc: 0.6000\n",
      "Epoch 564/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6678 - acc: 0.8228 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "Epoch 565/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6696 - acc: 0.6329 - val_loss: 0.6830 - val_acc: 0.6000\n",
      "Epoch 566/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6707 - acc: 0.6582 - val_loss: 0.6836 - val_acc: 0.7000\n",
      "Epoch 567/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6683 - acc: 0.7722 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 568/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6682 - acc: 0.6835 - val_loss: 0.6872 - val_acc: 0.5000\n",
      "Epoch 569/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6705 - acc: 0.7468 - val_loss: 0.6879 - val_acc: 0.5000\n",
      "Epoch 570/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6668 - acc: 0.7468 - val_loss: 0.6855 - val_acc: 0.7500\n",
      "Epoch 571/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6672 - acc: 0.8861 - val_loss: 0.6842 - val_acc: 0.6500\n",
      "Epoch 572/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.6672 - acc: 0.9241 - val_loss: 0.6833 - val_acc: 0.6500\n",
      "Epoch 573/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6668 - acc: 0.8481 - val_loss: 0.6844 - val_acc: 0.6500\n",
      "Epoch 574/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6671 - acc: 0.8861 - val_loss: 0.6839 - val_acc: 0.6500\n",
      "Epoch 575/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6707 - acc: 0.7722 - val_loss: 0.6825 - val_acc: 0.6000\n",
      "Epoch 576/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6696 - acc: 0.6835 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 577/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6659 - acc: 0.6582 - val_loss: 0.6870 - val_acc: 0.5000\n",
      "Epoch 578/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6663 - acc: 0.7468 - val_loss: 0.6839 - val_acc: 0.6500\n",
      "Epoch 579/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6657 - acc: 0.9241 - val_loss: 0.6847 - val_acc: 0.8000\n",
      "Epoch 580/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6654 - acc: 0.9114 - val_loss: 0.6843 - val_acc: 0.7000\n",
      "Epoch 581/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6670 - acc: 0.8734 - val_loss: 0.6847 - val_acc: 0.8000\n",
      "Epoch 582/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6658 - acc: 0.9241 - val_loss: 0.6854 - val_acc: 0.7500\n",
      "Epoch 583/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6669 - acc: 0.8101 - val_loss: 0.6823 - val_acc: 0.5500\n",
      "Epoch 584/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6658 - acc: 0.8228 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 585/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6664 - acc: 0.7468 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 586/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6648 - acc: 0.8481 - val_loss: 0.6849 - val_acc: 0.7000\n",
      "Epoch 587/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6659 - acc: 0.8734 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 588/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6666 - acc: 0.8734 - val_loss: 0.6866 - val_acc: 0.5000\n",
      "Epoch 589/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6665 - acc: 0.8101 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 590/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6671 - acc: 0.6456 - val_loss: 0.6867 - val_acc: 0.5000\n",
      "Epoch 591/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6647 - acc: 0.7595 - val_loss: 0.6852 - val_acc: 0.7500\n",
      "Epoch 592/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6650 - acc: 0.8228 - val_loss: 0.6827 - val_acc: 0.7000\n",
      "Epoch 593/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6648 - acc: 0.9241 - val_loss: 0.6821 - val_acc: 0.6000\n",
      "Epoch 594/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6654 - acc: 0.8608 - val_loss: 0.6817 - val_acc: 0.6000\n",
      "Epoch 595/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.6659 - acc: 0.7468 - val_loss: 0.6830 - val_acc: 0.6500\n",
      "Epoch 596/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6643 - acc: 0.9367 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 597/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6641 - acc: 0.9114 - val_loss: 0.6836 - val_acc: 0.7000\n",
      "Epoch 598/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6642 - acc: 0.9494 - val_loss: 0.6826 - val_acc: 0.6500\n",
      "Epoch 599/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6638 - acc: 0.9241 - val_loss: 0.6835 - val_acc: 0.7000\n",
      "Epoch 600/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6644 - acc: 0.8734 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 601/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6639 - acc: 0.8608 - val_loss: 0.6826 - val_acc: 0.6500\n",
      "Epoch 602/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6635 - acc: 0.9367 - val_loss: 0.6825 - val_acc: 0.6500\n",
      "Epoch 603/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6633 - acc: 0.9367 - val_loss: 0.6834 - val_acc: 0.7000\n",
      "Epoch 604/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6635 - acc: 0.8861 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 605/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6639 - acc: 0.9620 - val_loss: 0.6830 - val_acc: 0.6500\n",
      "Epoch 606/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6637 - acc: 0.8608 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 607/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.6638 - acc: 0.7975 - val_loss: 0.6838 - val_acc: 0.7500\n",
      "Epoch 608/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6627 - acc: 0.9241 - val_loss: 0.6833 - val_acc: 0.7000\n",
      "Epoch 609/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.6635 - acc: 0.8481 - val_loss: 0.6813 - val_acc: 0.6000\n",
      "Epoch 610/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6630 - acc: 0.8734 - val_loss: 0.6832 - val_acc: 0.7000\n",
      "Epoch 611/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6646 - acc: 0.9241 - val_loss: 0.6863 - val_acc: 0.5000\n",
      "Epoch 612/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6627 - acc: 0.7468 - val_loss: 0.6838 - val_acc: 0.8000\n",
      "Epoch 613/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6625 - acc: 0.9367 - val_loss: 0.6853 - val_acc: 0.5500\n",
      "Epoch 614/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6622 - acc: 0.7975 - val_loss: 0.6841 - val_acc: 0.7500\n",
      "Epoch 615/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.6622 - acc: 0.8987 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 616/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6621 - acc: 0.8481 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 617/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6628 - acc: 0.7595 - val_loss: 0.6831 - val_acc: 0.8000\n",
      "Epoch 618/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6617 - acc: 0.9367 - val_loss: 0.6827 - val_acc: 0.6500\n",
      "Epoch 619/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6628 - acc: 0.8861 - val_loss: 0.6826 - val_acc: 0.7000\n",
      "Epoch 620/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6622 - acc: 0.8987 - val_loss: 0.6834 - val_acc: 0.8000\n",
      "Epoch 621/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6613 - acc: 0.9367 - val_loss: 0.6838 - val_acc: 0.8000\n",
      "Epoch 622/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6623 - acc: 0.8987 - val_loss: 0.6833 - val_acc: 0.8000\n",
      "Epoch 623/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.6633 - acc: 0.8481 - val_loss: 0.6824 - val_acc: 0.7000\n",
      "Epoch 624/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6616 - acc: 0.9241 - val_loss: 0.6841 - val_acc: 0.6500\n",
      "Epoch 625/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6633 - acc: 0.8987 - val_loss: 0.6870 - val_acc: 0.5000\n",
      "Epoch 626/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6653 - acc: 0.7975 - val_loss: 0.6881 - val_acc: 0.5000\n",
      "Epoch 627/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6615 - acc: 0.6962 - val_loss: 0.6869 - val_acc: 0.5000\n",
      "Epoch 628/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6612 - acc: 0.7215 - val_loss: 0.6874 - val_acc: 0.5000\n",
      "Epoch 629/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.6612 - acc: 0.6582 - val_loss: 0.6840 - val_acc: 0.7000\n",
      "Epoch 630/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6606 - acc: 0.8608 - val_loss: 0.6853 - val_acc: 0.5000\n",
      "Epoch 631/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6604 - acc: 0.7975 - val_loss: 0.6840 - val_acc: 0.6000\n",
      "Epoch 632/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6603 - acc: 0.8987 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 633/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6609 - acc: 0.8481 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 634/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6607 - acc: 0.7722 - val_loss: 0.6846 - val_acc: 0.5500\n",
      "Epoch 635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6617 - acc: 0.8481 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 636/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6606 - acc: 0.6456 - val_loss: 0.6869 - val_acc: 0.5000\n",
      "Epoch 637/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6607 - acc: 0.6835 - val_loss: 0.6859 - val_acc: 0.5000\n",
      "Epoch 638/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6601 - acc: 0.7722 - val_loss: 0.6842 - val_acc: 0.5500\n",
      "Epoch 639/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6601 - acc: 0.8101 - val_loss: 0.6839 - val_acc: 0.5500\n",
      "Epoch 640/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6646 - acc: 0.781 - 0s 125us/sample - loss: 0.6618 - acc: 0.8734 - val_loss: 0.6880 - val_acc: 0.5000\n",
      "Epoch 641/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6623 - acc: 0.5823 - val_loss: 0.6876 - val_acc: 0.5000\n",
      "Epoch 642/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6636 - acc: 0.6329 - val_loss: 0.6903 - val_acc: 0.5000\n",
      "Epoch 643/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6611 - acc: 0.6076 - val_loss: 0.6911 - val_acc: 0.4500\n",
      "Epoch 644/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6604 - acc: 0.5316 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 645/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.6620 - acc: 0.5949 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 646/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6596 - acc: 0.6962 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 647/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6600 - acc: 0.6203 - val_loss: 0.6849 - val_acc: 0.5000\n",
      "Epoch 648/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6598 - acc: 0.7595 - val_loss: 0.6854 - val_acc: 0.5000\n",
      "Epoch 649/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6590 - acc: 0.7342 - val_loss: 0.6846 - val_acc: 0.5000\n",
      "Epoch 650/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6585 - acc: 0.8101 - val_loss: 0.6821 - val_acc: 0.8000\n",
      "Epoch 651/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6584 - acc: 0.9494 - val_loss: 0.6837 - val_acc: 0.5500\n",
      "Epoch 652/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6589 - acc: 0.7722 - val_loss: 0.6805 - val_acc: 0.6500\n",
      "Epoch 653/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6625 - acc: 0.8608 - val_loss: 0.6809 - val_acc: 0.7000\n",
      "Epoch 654/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6575 - acc: 0.9494 - val_loss: 0.6806 - val_acc: 0.6500\n",
      "Epoch 655/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6575 - acc: 0.9367 - val_loss: 0.6815 - val_acc: 0.8000\n",
      "Epoch 656/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6607 - acc: 0.8608 - val_loss: 0.6788 - val_acc: 0.6000\n",
      "Epoch 657/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6605 - acc: 0.7089 - val_loss: 0.6801 - val_acc: 0.6500\n",
      "Epoch 658/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6582 - acc: 0.9241 - val_loss: 0.6802 - val_acc: 0.6500\n",
      "Epoch 659/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6602 - acc: 0.8987 - val_loss: 0.6775 - val_acc: 0.5500\n",
      "Epoch 660/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6585 - acc: 0.7468 - val_loss: 0.6776 - val_acc: 0.5500\n",
      "Epoch 661/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6584 - acc: 0.7342 - val_loss: 0.6804 - val_acc: 0.7000\n",
      "Epoch 662/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6578 - acc: 0.9114 - val_loss: 0.6803 - val_acc: 0.7000\n",
      "Epoch 663/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6566 - acc: 0.9367 - val_loss: 0.6821 - val_acc: 0.8000\n",
      "Epoch 664/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6564 - acc: 0.8861 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 665/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6560 - acc: 0.8861 - val_loss: 0.6823 - val_acc: 0.7000\n",
      "Epoch 666/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6563 - acc: 0.8987 - val_loss: 0.6806 - val_acc: 0.7000\n",
      "Epoch 667/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6565 - acc: 0.9367 - val_loss: 0.6821 - val_acc: 0.7000\n",
      "Epoch 668/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6567 - acc: 0.8987 - val_loss: 0.6804 - val_acc: 0.6500\n",
      "Epoch 669/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.6580 - acc: 0.8354 - val_loss: 0.6798 - val_acc: 0.6500\n",
      "Epoch 670/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6557 - acc: 0.9494 - val_loss: 0.6805 - val_acc: 0.7000\n",
      "Epoch 671/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6595 - acc: 0.8228 - val_loss: 0.6817 - val_acc: 0.8000\n",
      "Epoch 672/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6570 - acc: 0.8608 - val_loss: 0.6789 - val_acc: 0.7000\n",
      "Epoch 673/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6564 - acc: 0.9241 - val_loss: 0.6789 - val_acc: 0.7000\n",
      "Epoch 674/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6557 - acc: 0.9241 - val_loss: 0.6783 - val_acc: 0.6500\n",
      "Epoch 675/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6552 - acc: 0.8861 - val_loss: 0.6785 - val_acc: 0.7000\n",
      "Epoch 676/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6554 - acc: 0.9241 - val_loss: 0.6779 - val_acc: 0.6000\n",
      "Epoch 677/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6556 - acc: 0.8734 - val_loss: 0.6791 - val_acc: 0.6500\n",
      "Epoch 678/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6544 - acc: 0.9367 - val_loss: 0.6799 - val_acc: 0.7000\n",
      "Epoch 679/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6547 - acc: 0.9494 - val_loss: 0.6796 - val_acc: 0.7000\n",
      "Epoch 680/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6543 - acc: 0.9367 - val_loss: 0.6814 - val_acc: 0.7500\n",
      "Epoch 681/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6570 - acc: 0.8861 - val_loss: 0.6820 - val_acc: 0.6500\n",
      "Epoch 682/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6554 - acc: 0.8228 - val_loss: 0.6841 - val_acc: 0.5000\n",
      "Epoch 683/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6540 - acc: 0.7722 - val_loss: 0.6820 - val_acc: 0.6000\n",
      "Epoch 684/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.6538 - acc: 0.8354 - val_loss: 0.6818 - val_acc: 0.6500\n",
      "Epoch 685/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6535 - acc: 0.8608 - val_loss: 0.6807 - val_acc: 0.8000\n",
      "Epoch 686/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6541 - acc: 0.9367 - val_loss: 0.6834 - val_acc: 0.5000\n",
      "Epoch 687/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6536 - acc: 0.7975 - val_loss: 0.6839 - val_acc: 0.5000\n",
      "Epoch 688/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6537 - acc: 0.7595 - val_loss: 0.6817 - val_acc: 0.6500\n",
      "Epoch 689/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6533 - acc: 0.8734 - val_loss: 0.6806 - val_acc: 0.8000\n",
      "Epoch 690/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6534 - acc: 0.9367 - val_loss: 0.6831 - val_acc: 0.5000\n",
      "Epoch 691/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6530 - acc: 0.7722 - val_loss: 0.6802 - val_acc: 0.8000\n",
      "Epoch 692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6531 - acc: 0.9114 - val_loss: 0.6815 - val_acc: 0.6500\n",
      "Epoch 693/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6522 - acc: 0.8608 - val_loss: 0.6813 - val_acc: 0.6500\n",
      "Epoch 694/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6522 - acc: 0.8354 - val_loss: 0.6800 - val_acc: 0.8000\n",
      "Epoch 695/3000\n",
      "79/79 [==============================] - 0s 157us/sample - loss: 0.6537 - acc: 0.8734 - val_loss: 0.6801 - val_acc: 0.8000\n",
      "Epoch 696/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6528 - acc: 0.8987 - val_loss: 0.6791 - val_acc: 0.7000\n",
      "Epoch 697/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.6528 - acc: 0.8987 - val_loss: 0.6785 - val_acc: 0.7000\n",
      "Epoch 698/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6532 - acc: 0.9114 - val_loss: 0.6761 - val_acc: 0.6000\n",
      "Epoch 699/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6527 - acc: 0.8608 - val_loss: 0.6759 - val_acc: 0.6000\n",
      "Epoch 700/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6538 - acc: 0.8481 - val_loss: 0.6769 - val_acc: 0.7000\n",
      "Epoch 701/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6519 - acc: 0.9241 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 702/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6511 - acc: 0.9494 - val_loss: 0.6788 - val_acc: 0.7000\n",
      "Epoch 703/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6516 - acc: 0.9367 - val_loss: 0.6768 - val_acc: 0.7000\n",
      "Epoch 704/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6521 - acc: 0.8861 - val_loss: 0.6789 - val_acc: 0.7500\n",
      "Epoch 705/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.6506 - acc: 0.9367 - val_loss: 0.6794 - val_acc: 0.8000\n",
      "Epoch 706/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6513 - acc: 0.8608 - val_loss: 0.6776 - val_acc: 0.6500\n",
      "Epoch 707/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6504 - acc: 0.9494 - val_loss: 0.6793 - val_acc: 0.8000\n",
      "Epoch 708/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6500 - acc: 0.9241 - val_loss: 0.6785 - val_acc: 0.7500\n",
      "Epoch 709/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6499 - acc: 0.9241 - val_loss: 0.6780 - val_acc: 0.6500\n",
      "Epoch 710/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6517 - acc: 0.9367 - val_loss: 0.6770 - val_acc: 0.6500\n",
      "Epoch 711/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6502 - acc: 0.9367 - val_loss: 0.6799 - val_acc: 0.7500\n",
      "Epoch 712/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6507 - acc: 0.9241 - val_loss: 0.6813 - val_acc: 0.5500\n",
      "Epoch 713/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6515 - acc: 0.8354 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 714/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6495 - acc: 0.9494 - val_loss: 0.6776 - val_acc: 0.7000\n",
      "Epoch 715/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6515 - acc: 0.9241 - val_loss: 0.6790 - val_acc: 0.8000\n",
      "Epoch 716/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6498 - acc: 0.8608 - val_loss: 0.6780 - val_acc: 0.7000\n",
      "Epoch 717/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6490 - acc: 0.9114 - val_loss: 0.6774 - val_acc: 0.7000\n",
      "Epoch 718/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6485 - acc: 0.9494 - val_loss: 0.6771 - val_acc: 0.7000\n",
      "Epoch 719/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.6482 - acc: 0.9494 - val_loss: 0.6778 - val_acc: 0.7000\n",
      "Epoch 720/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6482 - acc: 0.9367 - val_loss: 0.6781 - val_acc: 0.8000\n",
      "Epoch 721/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6491 - acc: 0.9367 - val_loss: 0.6776 - val_acc: 0.7000\n",
      "Epoch 722/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6479 - acc: 0.9494 - val_loss: 0.6791 - val_acc: 0.7500\n",
      "Epoch 723/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6482 - acc: 0.9367 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 724/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6478 - acc: 0.8101 - val_loss: 0.6778 - val_acc: 0.8000\n",
      "Epoch 725/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6474 - acc: 0.9367 - val_loss: 0.6764 - val_acc: 0.6500\n",
      "Epoch 726/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6472 - acc: 0.9241 - val_loss: 0.6763 - val_acc: 0.6500\n",
      "Epoch 727/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6470 - acc: 0.9367 - val_loss: 0.6762 - val_acc: 0.6500\n",
      "Epoch 728/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6468 - acc: 0.9367 - val_loss: 0.6761 - val_acc: 0.6500\n",
      "Epoch 729/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6479 - acc: 0.8987 - val_loss: 0.6801 - val_acc: 0.6000\n",
      "Epoch 730/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6478 - acc: 0.8481 - val_loss: 0.6787 - val_acc: 0.7500\n",
      "Epoch 731/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6474 - acc: 0.9114 - val_loss: 0.6780 - val_acc: 0.8000\n",
      "Epoch 732/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6473 - acc: 0.9114 - val_loss: 0.6774 - val_acc: 0.8000\n",
      "Epoch 733/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6471 - acc: 0.9241 - val_loss: 0.6752 - val_acc: 0.7000\n",
      "Epoch 734/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6546 - acc: 0.875 - 0s 114us/sample - loss: 0.6475 - acc: 0.9367 - val_loss: 0.6759 - val_acc: 0.6500\n",
      "Epoch 735/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6461 - acc: 0.9494 - val_loss: 0.6778 - val_acc: 0.8000\n",
      "Epoch 736/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6477 - acc: 0.9241 - val_loss: 0.6796 - val_acc: 0.6500\n",
      "Epoch 737/3000\n",
      "79/79 [==============================] - 0s 283us/sample - loss: 0.6484 - acc: 0.8608 - val_loss: 0.6773 - val_acc: 0.8500\n",
      "Epoch 738/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6450 - acc: 0.9241 - val_loss: 0.6765 - val_acc: 0.7000\n",
      "Epoch 739/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6460 - acc: 0.8987 - val_loss: 0.6758 - val_acc: 0.7000\n",
      "Epoch 740/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6463 - acc: 0.9114 - val_loss: 0.6800 - val_acc: 0.5500\n",
      "Epoch 741/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6455 - acc: 0.8354 - val_loss: 0.6796 - val_acc: 0.5500\n",
      "Epoch 742/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6446 - acc: 0.8354 - val_loss: 0.6790 - val_acc: 0.6500\n",
      "Epoch 743/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6441 - acc: 0.8734 - val_loss: 0.6785 - val_acc: 0.6500\n",
      "Epoch 744/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6444 - acc: 0.8734 - val_loss: 0.6761 - val_acc: 0.7000\n",
      "Epoch 745/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6437 - acc: 0.9494 - val_loss: 0.6756 - val_acc: 0.7000\n",
      "Epoch 746/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6472 - acc: 0.8987 - val_loss: 0.6750 - val_acc: 0.6500\n",
      "Epoch 747/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6435 - acc: 0.9494 - val_loss: 0.6749 - val_acc: 0.6500\n",
      "Epoch 748/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6446 - acc: 0.9367 - val_loss: 0.6778 - val_acc: 0.7000\n",
      "Epoch 749/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6473 - acc: 0.8861 - val_loss: 0.6782 - val_acc: 0.6500\n",
      "Epoch 750/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6467 - acc: 0.7468 - val_loss: 0.6768 - val_acc: 0.8000\n",
      "Epoch 751/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6457 - acc: 0.8608 - val_loss: 0.6747 - val_acc: 0.7000\n",
      "Epoch 752/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6427 - acc: 0.9494 - val_loss: 0.6765 - val_acc: 0.8000\n",
      "Epoch 753/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6424 - acc: 0.9367 - val_loss: 0.6778 - val_acc: 0.6500\n",
      "Epoch 754/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6424 - acc: 0.9241 - val_loss: 0.6788 - val_acc: 0.5500\n",
      "Epoch 755/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6420 - acc: 0.8354 - val_loss: 0.6770 - val_acc: 0.7500\n",
      "Epoch 756/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6420 - acc: 0.8861 - val_loss: 0.6757 - val_acc: 0.8500\n",
      "Epoch 757/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6422 - acc: 0.9367 - val_loss: 0.6761 - val_acc: 0.8000\n",
      "Epoch 758/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6413 - acc: 0.9241 - val_loss: 0.6753 - val_acc: 0.8000\n",
      "Epoch 759/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6426 - acc: 0.9241 - val_loss: 0.6778 - val_acc: 0.6500\n",
      "Epoch 760/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6425 - acc: 0.8987 - val_loss: 0.6800 - val_acc: 0.5000\n",
      "Epoch 761/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6416 - acc: 0.7848 - val_loss: 0.6777 - val_acc: 0.6500\n",
      "Epoch 762/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6409 - acc: 0.8734 - val_loss: 0.6785 - val_acc: 0.5500\n",
      "Epoch 763/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6412 - acc: 0.8734 - val_loss: 0.6779 - val_acc: 0.6500\n",
      "Epoch 764/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6419 - acc: 0.8734 - val_loss: 0.6813 - val_acc: 0.5000\n",
      "Epoch 765/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6412 - acc: 0.7975 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 766/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6421 - acc: 0.7342 - val_loss: 0.6802 - val_acc: 0.5000\n",
      "Epoch 767/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6408 - acc: 0.7722 - val_loss: 0.6784 - val_acc: 0.5500\n",
      "Epoch 768/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6410 - acc: 0.7722 - val_loss: 0.6732 - val_acc: 0.7000\n",
      "Epoch 769/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6391 - acc: 0.9494 - val_loss: 0.6740 - val_acc: 0.7000\n",
      "Epoch 770/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.6391 - acc: 0.9241 - val_loss: 0.6727 - val_acc: 0.6500\n",
      "Epoch 771/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6396 - acc: 0.9241 - val_loss: 0.6755 - val_acc: 0.7500\n",
      "Epoch 772/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6390 - acc: 0.9241 - val_loss: 0.6764 - val_acc: 0.6500\n",
      "Epoch 773/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6383 - acc: 0.8608 - val_loss: 0.6749 - val_acc: 0.8000\n",
      "Epoch 774/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6386 - acc: 0.9241 - val_loss: 0.6760 - val_acc: 0.7500\n",
      "Epoch 775/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.6387 - acc: 0.8481 - val_loss: 0.6736 - val_acc: 0.7500\n",
      "Epoch 776/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6397 - acc: 0.9620 - val_loss: 0.6766 - val_acc: 0.6500\n",
      "Epoch 777/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6376 - acc: 0.8861 - val_loss: 0.6760 - val_acc: 0.6500\n",
      "Epoch 778/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6391 - acc: 0.8228 - val_loss: 0.6732 - val_acc: 0.7000\n",
      "Epoch 779/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6376 - acc: 0.9494 - val_loss: 0.6760 - val_acc: 0.6500\n",
      "Epoch 780/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6370 - acc: 0.8987 - val_loss: 0.6767 - val_acc: 0.6500\n",
      "Epoch 781/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6368 - acc: 0.8354 - val_loss: 0.6758 - val_acc: 0.6500\n",
      "Epoch 782/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6367 - acc: 0.8987 - val_loss: 0.6766 - val_acc: 0.6500\n",
      "Epoch 783/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6369 - acc: 0.8354 - val_loss: 0.6755 - val_acc: 0.7000\n",
      "Epoch 784/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6364 - acc: 0.8481 - val_loss: 0.6737 - val_acc: 0.8500\n",
      "Epoch 785/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6365 - acc: 0.9367 - val_loss: 0.6721 - val_acc: 0.6500\n",
      "Epoch 786/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6368 - acc: 0.9367 - val_loss: 0.6747 - val_acc: 0.7500\n",
      "Epoch 787/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6376 - acc: 0.8987 - val_loss: 0.6737 - val_acc: 0.8000\n",
      "Epoch 788/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6372 - acc: 0.8734 - val_loss: 0.6744 - val_acc: 0.7500\n",
      "Epoch 789/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6351 - acc: 0.8861 - val_loss: 0.6721 - val_acc: 0.7000\n",
      "Epoch 790/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.6350 - acc: 0.9620 - val_loss: 0.6735 - val_acc: 0.8000\n",
      "Epoch 791/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6347 - acc: 0.9494 - val_loss: 0.6749 - val_acc: 0.7000\n",
      "Epoch 792/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6341 - acc: 0.8734 - val_loss: 0.6733 - val_acc: 0.8000\n",
      "Epoch 793/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6340 - acc: 0.9367 - val_loss: 0.6746 - val_acc: 0.7500\n",
      "Epoch 794/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6346 - acc: 0.8228 - val_loss: 0.6718 - val_acc: 0.7500\n",
      "Epoch 795/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6335 - acc: 0.9494 - val_loss: 0.6732 - val_acc: 0.7500\n",
      "Epoch 796/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6362 - acc: 0.9367 - val_loss: 0.6716 - val_acc: 0.7500\n",
      "Epoch 797/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.6329 - acc: 0.9494 - val_loss: 0.6720 - val_acc: 0.7500\n",
      "Epoch 798/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6329 - acc: 0.9494 - val_loss: 0.6703 - val_acc: 0.7000\n",
      "Epoch 799/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6323 - acc: 0.9367 - val_loss: 0.6712 - val_acc: 0.7000\n",
      "Epoch 800/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6369 - acc: 0.8987 - val_loss: 0.6694 - val_acc: 0.7000\n",
      "Epoch 801/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6332 - acc: 0.8987 - val_loss: 0.6725 - val_acc: 0.8000\n",
      "Epoch 802/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6338 - acc: 0.9367 - val_loss: 0.6739 - val_acc: 0.7500\n",
      "Epoch 803/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6344 - acc: 0.9114 - val_loss: 0.6738 - val_acc: 0.7500\n",
      "Epoch 804/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6329 - acc: 0.9114 - val_loss: 0.6775 - val_acc: 0.5000\n",
      "Epoch 805/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6318 - acc: 0.7722 - val_loss: 0.6732 - val_acc: 0.7500\n",
      "Epoch 806/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6309 - acc: 0.9241 - val_loss: 0.6741 - val_acc: 0.6500\n",
      "Epoch 807/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6330 - acc: 0.8987 - val_loss: 0.6724 - val_acc: 0.7500\n",
      "Epoch 808/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6301 - acc: 0.9241 - val_loss: 0.6713 - val_acc: 0.8000\n",
      "Epoch 809/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6321 - acc: 0.9367 - val_loss: 0.6729 - val_acc: 0.7500\n",
      "Epoch 810/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6301 - acc: 0.8861 - val_loss: 0.6703 - val_acc: 0.7500\n",
      "Epoch 811/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6295 - acc: 0.9494 - val_loss: 0.6716 - val_acc: 0.8000\n",
      "Epoch 812/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6295 - acc: 0.9241 - val_loss: 0.6695 - val_acc: 0.6500\n",
      "Epoch 813/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6301 - acc: 0.9494 - val_loss: 0.6685 - val_acc: 0.7000\n",
      "Epoch 814/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6289 - acc: 0.9367 - val_loss: 0.6701 - val_acc: 0.7500\n",
      "Epoch 815/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6300 - acc: 0.9367 - val_loss: 0.6741 - val_acc: 0.6500\n",
      "Epoch 816/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.6295 - acc: 0.8354 - val_loss: 0.6715 - val_acc: 0.7500\n",
      "Epoch 817/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6279 - acc: 0.9114 - val_loss: 0.6703 - val_acc: 0.8000\n",
      "Epoch 818/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6276 - acc: 0.9367 - val_loss: 0.6694 - val_acc: 0.7500\n",
      "Epoch 819/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.6277 - acc: 0.9620 - val_loss: 0.6690 - val_acc: 0.6500\n",
      "Epoch 820/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6274 - acc: 0.9494 - val_loss: 0.6684 - val_acc: 0.7000\n",
      "Epoch 821/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6273 - acc: 0.9620 - val_loss: 0.6700 - val_acc: 0.8000\n",
      "Epoch 822/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6265 - acc: 0.9241 - val_loss: 0.6690 - val_acc: 0.7500\n",
      "Epoch 823/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6269 - acc: 0.9241 - val_loss: 0.6693 - val_acc: 0.7500\n",
      "Epoch 824/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6259 - acc: 0.9494 - val_loss: 0.6698 - val_acc: 0.8000\n",
      "Epoch 825/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6257 - acc: 0.9367 - val_loss: 0.6687 - val_acc: 0.7500\n",
      "Epoch 826/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.6263 - acc: 0.9367 - val_loss: 0.6715 - val_acc: 0.7500\n",
      "Epoch 827/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6257 - acc: 0.8608 - val_loss: 0.6696 - val_acc: 0.8500\n",
      "Epoch 828/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6255 - acc: 0.9620 - val_loss: 0.6708 - val_acc: 0.7500\n",
      "Epoch 829/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6250 - acc: 0.9241 - val_loss: 0.6705 - val_acc: 0.7500\n",
      "Epoch 830/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6247 - acc: 0.8987 - val_loss: 0.6690 - val_acc: 0.8000\n",
      "Epoch 831/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.6277 - acc: 0.8987 - val_loss: 0.6709 - val_acc: 0.7500\n",
      "Epoch 832/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6254 - acc: 0.8987 - val_loss: 0.6695 - val_acc: 0.8000\n",
      "Epoch 833/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6239 - acc: 0.9494 - val_loss: 0.6709 - val_acc: 0.7500\n",
      "Epoch 834/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6237 - acc: 0.8987 - val_loss: 0.6712 - val_acc: 0.7500\n",
      "Epoch 835/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6257 - acc: 0.8228 - val_loss: 0.6656 - val_acc: 0.6500\n",
      "Epoch 836/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6240 - acc: 0.9494 - val_loss: 0.6650 - val_acc: 0.7000\n",
      "Epoch 837/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6260 - acc: 0.9367 - val_loss: 0.6637 - val_acc: 0.5500\n",
      "Epoch 838/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6250 - acc: 0.8987 - val_loss: 0.6633 - val_acc: 0.6000\n",
      "Epoch 839/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6235 - acc: 0.8481 - val_loss: 0.6645 - val_acc: 0.6500\n",
      "Epoch 840/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6224 - acc: 0.9494 - val_loss: 0.6649 - val_acc: 0.7000\n",
      "Epoch 841/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6222 - acc: 0.9494 - val_loss: 0.6677 - val_acc: 0.7500\n",
      "Epoch 842/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.6210 - acc: 0.9241 - val_loss: 0.6666 - val_acc: 0.6500\n",
      "Epoch 843/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6253 - acc: 0.9620 - val_loss: 0.6729 - val_acc: 0.5500\n",
      "Epoch 844/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6242 - acc: 0.7595 - val_loss: 0.6656 - val_acc: 0.7000\n",
      "Epoch 845/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6232 - acc: 0.9114 - val_loss: 0.6629 - val_acc: 0.5500\n",
      "Epoch 846/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6229 - acc: 0.8608 - val_loss: 0.6631 - val_acc: 0.6500\n",
      "Epoch 847/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6204 - acc: 0.8987 - val_loss: 0.6636 - val_acc: 0.7000\n",
      "Epoch 848/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6214 - acc: 0.9367 - val_loss: 0.6624 - val_acc: 0.5500\n",
      "Epoch 849/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6202 - acc: 0.8987 - val_loss: 0.6642 - val_acc: 0.6500\n",
      "Epoch 850/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6211 - acc: 0.9367 - val_loss: 0.6640 - val_acc: 0.6500\n",
      "Epoch 851/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6191 - acc: 0.9367 - val_loss: 0.6667 - val_acc: 0.7500\n",
      "Epoch 852/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6195 - acc: 0.9114 - val_loss: 0.6640 - val_acc: 0.7000\n",
      "Epoch 853/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6190 - acc: 0.9494 - val_loss: 0.6648 - val_acc: 0.7000\n",
      "Epoch 854/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6214 - acc: 0.9494 - val_loss: 0.6649 - val_acc: 0.6500\n",
      "Epoch 855/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.6172 - acc: 0.9494 - val_loss: 0.6637 - val_acc: 0.7000\n",
      "Epoch 856/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6168 - acc: 0.9367 - val_loss: 0.6654 - val_acc: 0.7500\n",
      "Epoch 857/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6168 - acc: 0.9241 - val_loss: 0.6656 - val_acc: 0.7500\n",
      "Epoch 858/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6164 - acc: 0.9494 - val_loss: 0.6666 - val_acc: 0.8000\n",
      "Epoch 859/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6159 - acc: 0.9114 - val_loss: 0.6645 - val_acc: 0.6500\n",
      "Epoch 860/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6164 - acc: 0.9620 - val_loss: 0.6638 - val_acc: 0.7000\n",
      "Epoch 861/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.6169 - acc: 0.9114 - val_loss: 0.6615 - val_acc: 0.6500\n",
      "Epoch 862/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.6174 - acc: 0.9620 - val_loss: 0.6606 - val_acc: 0.5500\n",
      "Epoch 863/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6164 - acc: 0.9114 - val_loss: 0.6607 - val_acc: 0.6500\n",
      "Epoch 864/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6160 - acc: 0.9114 - val_loss: 0.6606 - val_acc: 0.6500\n",
      "Epoch 865/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.6150 - acc: 0.9241 - val_loss: 0.6615 - val_acc: 0.7000\n",
      "Epoch 866/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6171 - acc: 0.9241 - val_loss: 0.6613 - val_acc: 0.7000\n",
      "Epoch 867/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6148 - acc: 0.9367 - val_loss: 0.6606 - val_acc: 0.6500\n",
      "Epoch 868/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.6149 - acc: 0.9494 - val_loss: 0.6640 - val_acc: 0.7500\n",
      "Epoch 869/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6129 - acc: 0.9494 - val_loss: 0.6639 - val_acc: 0.7500\n",
      "Epoch 870/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.6120 - acc: 0.9620 - val_loss: 0.6650 - val_acc: 0.8000\n",
      "Epoch 871/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6129 - acc: 0.9620 - val_loss: 0.6684 - val_acc: 0.6500\n",
      "Epoch 872/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6135 - acc: 0.8987 - val_loss: 0.6673 - val_acc: 0.7500\n",
      "Epoch 873/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6114 - acc: 0.8987 - val_loss: 0.6662 - val_acc: 0.7500\n",
      "Epoch 874/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.6128 - acc: 0.9241 - val_loss: 0.6637 - val_acc: 0.7500\n",
      "Epoch 875/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6104 - acc: 0.9494 - val_loss: 0.6630 - val_acc: 0.7500\n",
      "Epoch 876/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.6101 - acc: 0.9494 - val_loss: 0.6614 - val_acc: 0.7000\n",
      "Epoch 877/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.6102 - acc: 0.9367 - val_loss: 0.6641 - val_acc: 0.8000\n",
      "Epoch 878/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6099 - acc: 0.9241 - val_loss: 0.6650 - val_acc: 0.7500\n",
      "Epoch 879/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6089 - acc: 0.9241 - val_loss: 0.6645 - val_acc: 0.7500\n",
      "Epoch 880/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6125 - acc: 0.8987 - val_loss: 0.6659 - val_acc: 0.7500\n",
      "Epoch 881/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.6153 - acc: 0.8861 - val_loss: 0.6656 - val_acc: 0.7500\n",
      "Epoch 882/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6084 - acc: 0.8861 - val_loss: 0.6621 - val_acc: 0.7500\n",
      "Epoch 883/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6095 - acc: 0.9620 - val_loss: 0.6640 - val_acc: 0.7500\n",
      "Epoch 884/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.6078 - acc: 0.9114 - val_loss: 0.6645 - val_acc: 0.7500\n",
      "Epoch 885/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6070 - acc: 0.9241 - val_loss: 0.6640 - val_acc: 0.7500\n",
      "Epoch 886/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6079 - acc: 0.9367 - val_loss: 0.6673 - val_acc: 0.6500\n",
      "Epoch 887/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.5959 - acc: 0.843 - 0s 120us/sample - loss: 0.6075 - acc: 0.8354 - val_loss: 0.6653 - val_acc: 0.7500\n",
      "Epoch 888/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6062 - acc: 0.8861 - val_loss: 0.6642 - val_acc: 0.7500\n",
      "Epoch 889/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6061 - acc: 0.8734 - val_loss: 0.6632 - val_acc: 0.7500\n",
      "Epoch 890/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.6069 - acc: 0.9494 - val_loss: 0.6665 - val_acc: 0.6500\n",
      "Epoch 891/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6056 - acc: 0.8734 - val_loss: 0.6660 - val_acc: 0.6500\n",
      "Epoch 892/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6057 - acc: 0.8481 - val_loss: 0.6615 - val_acc: 0.8000\n",
      "Epoch 893/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6041 - acc: 0.9494 - val_loss: 0.6604 - val_acc: 0.7500\n",
      "Epoch 894/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.6055 - acc: 0.9367 - val_loss: 0.6633 - val_acc: 0.7500\n",
      "Epoch 895/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.6040 - acc: 0.9241 - val_loss: 0.6653 - val_acc: 0.6500\n",
      "Epoch 896/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.6055 - acc: 0.8608 - val_loss: 0.6664 - val_acc: 0.6500\n",
      "Epoch 897/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.6038 - acc: 0.8608 - val_loss: 0.6655 - val_acc: 0.6500\n",
      "Epoch 898/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.6024 - acc: 0.8861 - val_loss: 0.6627 - val_acc: 0.7500\n",
      "Epoch 899/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.6019 - acc: 0.8861 - val_loss: 0.6596 - val_acc: 0.7500\n",
      "Epoch 900/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.6012 - acc: 0.9494 - val_loss: 0.6583 - val_acc: 0.7000\n",
      "Epoch 901/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6005 - acc: 0.9494 - val_loss: 0.6579 - val_acc: 0.7000\n",
      "Epoch 902/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.6001 - acc: 0.9367 - val_loss: 0.6586 - val_acc: 0.7000\n",
      "Epoch 903/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6011 - acc: 0.9620 - val_loss: 0.6610 - val_acc: 0.8000\n",
      "Epoch 904/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.6029 - acc: 0.9367 - val_loss: 0.6633 - val_acc: 0.7500\n",
      "Epoch 905/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.6011 - acc: 0.9241 - val_loss: 0.6621 - val_acc: 0.7500\n",
      "Epoch 906/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5990 - acc: 0.9241 - val_loss: 0.6623 - val_acc: 0.7500\n",
      "Epoch 907/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.5992 - acc: 0.9367 - val_loss: 0.6614 - val_acc: 0.7500\n",
      "Epoch 908/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5982 - acc: 0.9114 - val_loss: 0.6584 - val_acc: 0.7500\n",
      "Epoch 909/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5977 - acc: 0.9494 - val_loss: 0.6584 - val_acc: 0.7500\n",
      "Epoch 910/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.6087 - acc: 0.9114 - val_loss: 0.6573 - val_acc: 0.7000\n",
      "Epoch 911/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5971 - acc: 0.9494 - val_loss: 0.6581 - val_acc: 0.7500\n",
      "Epoch 912/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.5960 - acc: 0.9620 - val_loss: 0.6591 - val_acc: 0.8000\n",
      "Epoch 913/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5985 - acc: 0.9114 - val_loss: 0.6566 - val_acc: 0.6500\n",
      "Epoch 914/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5951 - acc: 0.9367 - val_loss: 0.6582 - val_acc: 0.7500\n",
      "Epoch 915/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5952 - acc: 0.9367 - val_loss: 0.6554 - val_acc: 0.7000\n",
      "Epoch 916/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5953 - acc: 0.9494 - val_loss: 0.6570 - val_acc: 0.7500\n",
      "Epoch 917/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5938 - acc: 0.9620 - val_loss: 0.6572 - val_acc: 0.7500\n",
      "Epoch 918/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5942 - acc: 0.9367 - val_loss: 0.6550 - val_acc: 0.7000\n",
      "Epoch 919/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5953 - acc: 0.9241 - val_loss: 0.6530 - val_acc: 0.6500\n",
      "Epoch 920/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5935 - acc: 0.9494 - val_loss: 0.6546 - val_acc: 0.7000\n",
      "Epoch 921/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5922 - acc: 0.9620 - val_loss: 0.6539 - val_acc: 0.7000\n",
      "Epoch 922/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.5918 - acc: 0.9367 - val_loss: 0.6548 - val_acc: 0.7000\n",
      "Epoch 923/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5916 - acc: 0.9494 - val_loss: 0.6555 - val_acc: 0.7500\n",
      "Epoch 924/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.5925 - acc: 0.9241 - val_loss: 0.6530 - val_acc: 0.7000\n",
      "Epoch 925/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5918 - acc: 0.9367 - val_loss: 0.6546 - val_acc: 0.7000\n",
      "Epoch 926/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5910 - acc: 0.9494 - val_loss: 0.6584 - val_acc: 0.7500\n",
      "Epoch 927/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5905 - acc: 0.9241 - val_loss: 0.6601 - val_acc: 0.7500\n",
      "Epoch 928/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.5900 - acc: 0.8861 - val_loss: 0.6579 - val_acc: 0.7500\n",
      "Epoch 929/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.5883 - acc: 0.9114 - val_loss: 0.6561 - val_acc: 0.8000\n",
      "Epoch 930/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.5905 - acc: 0.9114 - val_loss: 0.6568 - val_acc: 0.8000\n",
      "Epoch 931/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5893 - acc: 0.9494 - val_loss: 0.6544 - val_acc: 0.7500\n",
      "Epoch 932/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5864 - acc: 0.9620 - val_loss: 0.6541 - val_acc: 0.7500\n",
      "Epoch 933/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5859 - acc: 0.9494 - val_loss: 0.6531 - val_acc: 0.7500\n",
      "Epoch 934/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.5857 - acc: 0.9620 - val_loss: 0.6515 - val_acc: 0.7000\n",
      "Epoch 935/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.5869 - acc: 0.9367 - val_loss: 0.6496 - val_acc: 0.7000\n",
      "Epoch 936/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5890 - acc: 0.9367 - val_loss: 0.6516 - val_acc: 0.7000\n",
      "Epoch 937/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5846 - acc: 0.9494 - val_loss: 0.6518 - val_acc: 0.7000\n",
      "Epoch 938/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5837 - acc: 0.9367 - val_loss: 0.6532 - val_acc: 0.7500\n",
      "Epoch 939/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5850 - acc: 0.9114 - val_loss: 0.6503 - val_acc: 0.7000\n",
      "Epoch 940/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5828 - acc: 0.9367 - val_loss: 0.6504 - val_acc: 0.7000\n",
      "Epoch 941/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5823 - acc: 0.9494 - val_loss: 0.6511 - val_acc: 0.7000\n",
      "Epoch 942/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5843 - acc: 0.9620 - val_loss: 0.6538 - val_acc: 0.8000\n",
      "Epoch 943/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5815 - acc: 0.9367 - val_loss: 0.6522 - val_acc: 0.7500\n",
      "Epoch 944/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5836 - acc: 0.9494 - val_loss: 0.6556 - val_acc: 0.7500\n",
      "Epoch 945/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.5808 - acc: 0.8987 - val_loss: 0.6517 - val_acc: 0.7500\n",
      "Epoch 946/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5796 - acc: 0.9494 - val_loss: 0.6505 - val_acc: 0.7500\n",
      "Epoch 947/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.5801 - acc: 0.9494 - val_loss: 0.6482 - val_acc: 0.7000\n",
      "Epoch 948/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5805 - acc: 0.9367 - val_loss: 0.6498 - val_acc: 0.7000\n",
      "Epoch 949/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5783 - acc: 0.9620 - val_loss: 0.6513 - val_acc: 0.7500\n",
      "Epoch 950/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5795 - acc: 0.9494 - val_loss: 0.6487 - val_acc: 0.7000\n",
      "Epoch 951/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5772 - acc: 0.9620 - val_loss: 0.6483 - val_acc: 0.7000\n",
      "Epoch 952/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.5767 - acc: 0.9494 - val_loss: 0.6482 - val_acc: 0.7000\n",
      "Epoch 953/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5774 - acc: 0.9494 - val_loss: 0.6502 - val_acc: 0.7500\n",
      "Epoch 954/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5766 - acc: 0.9620 - val_loss: 0.6513 - val_acc: 0.7500\n",
      "Epoch 955/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5764 - acc: 0.8987 - val_loss: 0.6476 - val_acc: 0.7000\n",
      "Epoch 956/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5757 - acc: 0.9620 - val_loss: 0.6473 - val_acc: 0.7000\n",
      "Epoch 957/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5753 - acc: 0.9367 - val_loss: 0.6471 - val_acc: 0.7000\n",
      "Epoch 958/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5761 - acc: 0.9494 - val_loss: 0.6492 - val_acc: 0.7500\n",
      "Epoch 959/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5730 - acc: 0.9620 - val_loss: 0.6491 - val_acc: 0.7500\n",
      "Epoch 960/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5751 - acc: 0.9494 - val_loss: 0.6507 - val_acc: 0.8000\n",
      "Epoch 961/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.5722 - acc: 0.9494 - val_loss: 0.6499 - val_acc: 0.7500\n",
      "Epoch 962/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5720 - acc: 0.9494 - val_loss: 0.6517 - val_acc: 0.7500\n",
      "Epoch 963/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5732 - acc: 0.9367 - val_loss: 0.6522 - val_acc: 0.7500\n",
      "Epoch 964/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.5716 - acc: 0.9241 - val_loss: 0.6508 - val_acc: 0.7500\n",
      "Epoch 965/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.5717 - acc: 0.8861 - val_loss: 0.6461 - val_acc: 0.7500\n",
      "Epoch 966/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5696 - acc: 0.9620 - val_loss: 0.6451 - val_acc: 0.7000\n",
      "Epoch 967/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5690 - acc: 0.9494 - val_loss: 0.6446 - val_acc: 0.7000\n",
      "Epoch 968/3000\n",
      "79/79 [==============================] - 0s 104us/sample - loss: 0.5694 - acc: 0.9494 - val_loss: 0.6438 - val_acc: 0.7000\n",
      "Epoch 969/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5691 - acc: 0.9494 - val_loss: 0.6427 - val_acc: 0.7500\n",
      "Epoch 970/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5687 - acc: 0.9367 - val_loss: 0.6437 - val_acc: 0.7000\n",
      "Epoch 971/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.5668 - acc: 0.9367 - val_loss: 0.6436 - val_acc: 0.7000\n",
      "Epoch 972/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.5660 - acc: 0.9494 - val_loss: 0.6449 - val_acc: 0.7000\n",
      "Epoch 973/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5663 - acc: 0.9494 - val_loss: 0.6468 - val_acc: 0.7500\n",
      "Epoch 974/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5666 - acc: 0.9367 - val_loss: 0.6430 - val_acc: 0.7000\n",
      "Epoch 975/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5651 - acc: 0.9494 - val_loss: 0.6451 - val_acc: 0.7500\n",
      "Epoch 976/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5638 - acc: 0.9620 - val_loss: 0.6454 - val_acc: 0.7500\n",
      "Epoch 977/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5634 - acc: 0.9620 - val_loss: 0.6463 - val_acc: 0.7500\n",
      "Epoch 978/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5632 - acc: 0.9494 - val_loss: 0.6452 - val_acc: 0.7500\n",
      "Epoch 979/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.5668 - acc: 0.9367 - val_loss: 0.6439 - val_acc: 0.7000\n",
      "Epoch 980/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5615 - acc: 0.9620 - val_loss: 0.6427 - val_acc: 0.7000\n",
      "Epoch 981/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5613 - acc: 0.9620 - val_loss: 0.6423 - val_acc: 0.7000\n",
      "Epoch 982/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5685 - acc: 0.9367 - val_loss: 0.6430 - val_acc: 0.7000\n",
      "Epoch 983/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5598 - acc: 0.9620 - val_loss: 0.6427 - val_acc: 0.7500\n",
      "Epoch 984/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5603 - acc: 0.9620 - val_loss: 0.6426 - val_acc: 0.7500\n",
      "Epoch 985/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5621 - acc: 0.9494 - val_loss: 0.6398 - val_acc: 0.7000\n",
      "Epoch 986/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5620 - acc: 0.9494 - val_loss: 0.6396 - val_acc: 0.7000\n",
      "Epoch 987/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5595 - acc: 0.9494 - val_loss: 0.6415 - val_acc: 0.7500\n",
      "Epoch 988/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5589 - acc: 0.9494 - val_loss: 0.6379 - val_acc: 0.7000\n",
      "Epoch 989/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.5575 - acc: 0.9494 - val_loss: 0.6375 - val_acc: 0.7000\n",
      "Epoch 990/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.5569 - acc: 0.9620 - val_loss: 0.6380 - val_acc: 0.7000\n",
      "Epoch 991/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5559 - acc: 0.9494 - val_loss: 0.6374 - val_acc: 0.7000\n",
      "Epoch 992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5545 - acc: 0.9494 - val_loss: 0.6375 - val_acc: 0.7000\n",
      "Epoch 993/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5548 - acc: 0.9620 - val_loss: 0.6380 - val_acc: 0.7000\n",
      "Epoch 994/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5544 - acc: 0.9620 - val_loss: 0.6368 - val_acc: 0.7000\n",
      "Epoch 995/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5565 - acc: 0.9494 - val_loss: 0.6399 - val_acc: 0.7500\n",
      "Epoch 996/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.5529 - acc: 0.9494 - val_loss: 0.6412 - val_acc: 0.7000\n",
      "Epoch 997/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5517 - acc: 0.9367 - val_loss: 0.6386 - val_acc: 0.7500\n",
      "Epoch 998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5503 - acc: 0.9620 - val_loss: 0.6381 - val_acc: 0.7500\n",
      "Epoch 999/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5510 - acc: 0.9620 - val_loss: 0.6355 - val_acc: 0.7000\n",
      "Epoch 1000/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5517 - acc: 0.9241 - val_loss: 0.6391 - val_acc: 0.7500\n",
      "Epoch 1001/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5483 - acc: 0.9620 - val_loss: 0.6368 - val_acc: 0.7500\n",
      "Epoch 1002/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.5474 - acc: 0.9494 - val_loss: 0.6364 - val_acc: 0.7500\n",
      "Epoch 1003/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5469 - acc: 0.9494 - val_loss: 0.6369 - val_acc: 0.7500\n",
      "Epoch 1004/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5479 - acc: 0.9620 - val_loss: 0.6378 - val_acc: 0.7500\n",
      "Epoch 1005/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5459 - acc: 0.9494 - val_loss: 0.6367 - val_acc: 0.7500\n",
      "Epoch 1006/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.5473 - acc: 0.9367 - val_loss: 0.6418 - val_acc: 0.7500\n",
      "Epoch 1007/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5459 - acc: 0.9114 - val_loss: 0.6385 - val_acc: 0.7000\n",
      "Epoch 1008/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5436 - acc: 0.9367 - val_loss: 0.6369 - val_acc: 0.7500\n",
      "Epoch 1009/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.5429 - acc: 0.9620 - val_loss: 0.6381 - val_acc: 0.7500\n",
      "Epoch 1010/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.5418 - acc: 0.9494 - val_loss: 0.6374 - val_acc: 0.7500\n",
      "Epoch 1011/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5440 - acc: 0.9494 - val_loss: 0.6424 - val_acc: 0.7500\n",
      "Epoch 1012/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5455 - acc: 0.9241 - val_loss: 0.6391 - val_acc: 0.8000\n",
      "Epoch 1013/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.5401 - acc: 0.9367 - val_loss: 0.6369 - val_acc: 0.7500\n",
      "Epoch 1014/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5392 - acc: 0.9620 - val_loss: 0.6350 - val_acc: 0.7500\n",
      "Epoch 1015/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5390 - acc: 0.9494 - val_loss: 0.6355 - val_acc: 0.7500\n",
      "Epoch 1016/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5407 - acc: 0.9494 - val_loss: 0.6359 - val_acc: 0.7000\n",
      "Epoch 1017/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5374 - acc: 0.9494 - val_loss: 0.6351 - val_acc: 0.7500\n",
      "Epoch 1018/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5364 - acc: 0.9620 - val_loss: 0.6339 - val_acc: 0.7500\n",
      "Epoch 1019/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5356 - acc: 0.9620 - val_loss: 0.6334 - val_acc: 0.7500\n",
      "Epoch 1020/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5376 - acc: 0.9620 - val_loss: 0.6316 - val_acc: 0.7500\n",
      "Epoch 1021/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5358 - acc: 0.9367 - val_loss: 0.6312 - val_acc: 0.7500\n",
      "Epoch 1022/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5339 - acc: 0.9494 - val_loss: 0.6317 - val_acc: 0.7500\n",
      "Epoch 1023/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5325 - acc: 0.9494 - val_loss: 0.6319 - val_acc: 0.7000\n",
      "Epoch 1024/3000\n",
      "79/79 [==============================] - 0s 156us/sample - loss: 0.5320 - acc: 0.9494 - val_loss: 0.6334 - val_acc: 0.7500\n",
      "Epoch 1025/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.5323 - acc: 0.9494 - val_loss: 0.6317 - val_acc: 0.7500\n",
      "Epoch 1026/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5296 - acc: 0.9494 - val_loss: 0.6321 - val_acc: 0.7500\n",
      "Epoch 1027/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5304 - acc: 0.9494 - val_loss: 0.6329 - val_acc: 0.7000\n",
      "Epoch 1028/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.5299 - acc: 0.9620 - val_loss: 0.6324 - val_acc: 0.7500\n",
      "Epoch 1029/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.5273 - acc: 0.9620 - val_loss: 0.6305 - val_acc: 0.7500\n",
      "Epoch 1030/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5272 - acc: 0.9620 - val_loss: 0.6292 - val_acc: 0.7000\n",
      "Epoch 1031/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5290 - acc: 0.9494 - val_loss: 0.6283 - val_acc: 0.7000\n",
      "Epoch 1032/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5263 - acc: 0.9367 - val_loss: 0.6292 - val_acc: 0.7500\n",
      "Epoch 1033/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5249 - acc: 0.9494 - val_loss: 0.6283 - val_acc: 0.7000\n",
      "Epoch 1034/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5237 - acc: 0.9367 - val_loss: 0.6292 - val_acc: 0.7000\n",
      "Epoch 1035/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.5230 - acc: 0.9494 - val_loss: 0.6298 - val_acc: 0.7500\n",
      "Epoch 1036/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5219 - acc: 0.9494 - val_loss: 0.6297 - val_acc: 0.7500\n",
      "Epoch 1037/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.5215 - acc: 0.9494 - val_loss: 0.6298 - val_acc: 0.7500\n",
      "Epoch 1038/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.5200 - acc: 0.9620 - val_loss: 0.6294 - val_acc: 0.7500\n",
      "Epoch 1039/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5228 - acc: 0.9494 - val_loss: 0.6278 - val_acc: 0.7000\n",
      "Epoch 1040/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.5196 - acc: 0.9494 - val_loss: 0.6263 - val_acc: 0.7000\n",
      "Epoch 1041/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5191 - acc: 0.9367 - val_loss: 0.6282 - val_acc: 0.7500\n",
      "Epoch 1042/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5169 - acc: 0.9494 - val_loss: 0.6283 - val_acc: 0.7500\n",
      "Epoch 1043/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5171 - acc: 0.9494 - val_loss: 0.6282 - val_acc: 0.7500\n",
      "Epoch 1044/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5154 - acc: 0.9620 - val_loss: 0.6281 - val_acc: 0.7500\n",
      "Epoch 1045/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5235 - acc: 0.9367 - val_loss: 0.6271 - val_acc: 0.7500\n",
      "Epoch 1046/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5141 - acc: 0.9494 - val_loss: 0.6265 - val_acc: 0.7500\n",
      "Epoch 1047/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5130 - acc: 0.9494 - val_loss: 0.6257 - val_acc: 0.7500\n",
      "Epoch 1048/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5121 - acc: 0.9494 - val_loss: 0.6259 - val_acc: 0.7500\n",
      "Epoch 1049/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.5114 - acc: 0.9494 - val_loss: 0.6244 - val_acc: 0.7500\n",
      "Epoch 1050/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.5122 - acc: 0.9494 - val_loss: 0.6233 - val_acc: 0.7500\n",
      "Epoch 1051/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5107 - acc: 0.9367 - val_loss: 0.6233 - val_acc: 0.7000\n",
      "Epoch 1052/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5092 - acc: 0.9494 - val_loss: 0.6228 - val_acc: 0.7500\n",
      "Epoch 1053/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.5084 - acc: 0.9494 - val_loss: 0.6227 - val_acc: 0.7000\n",
      "Epoch 1054/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.5084 - acc: 0.9367 - val_loss: 0.6227 - val_acc: 0.7000\n",
      "Epoch 1055/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5076 - acc: 0.9494 - val_loss: 0.6219 - val_acc: 0.7500\n",
      "Epoch 1056/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5068 - acc: 0.9367 - val_loss: 0.6221 - val_acc: 0.7000\n",
      "Epoch 1057/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5050 - acc: 0.9494 - val_loss: 0.6222 - val_acc: 0.7500\n",
      "Epoch 1058/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5069 - acc: 0.9367 - val_loss: 0.6254 - val_acc: 0.7000\n",
      "Epoch 1059/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.5035 - acc: 0.9620 - val_loss: 0.6233 - val_acc: 0.7500\n",
      "Epoch 1060/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.5052 - acc: 0.9367 - val_loss: 0.6209 - val_acc: 0.7000\n",
      "Epoch 1061/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5040 - acc: 0.9494 - val_loss: 0.6199 - val_acc: 0.7500\n",
      "Epoch 1062/3000\n",
      "79/79 [==============================] - 0s 391us/sample - loss: 0.5021 - acc: 0.9494 - val_loss: 0.6189 - val_acc: 0.7000\n",
      "Epoch 1063/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.5007 - acc: 0.9494 - val_loss: 0.6197 - val_acc: 0.7000\n",
      "Epoch 1064/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.5010 - acc: 0.9494 - val_loss: 0.6184 - val_acc: 0.7000\n",
      "Epoch 1065/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4995 - acc: 0.9494 - val_loss: 0.6218 - val_acc: 0.7000\n",
      "Epoch 1066/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4996 - acc: 0.9494 - val_loss: 0.6215 - val_acc: 0.7000\n",
      "Epoch 1067/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4967 - acc: 0.9494 - val_loss: 0.6185 - val_acc: 0.7000\n",
      "Epoch 1068/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4959 - acc: 0.9494 - val_loss: 0.6207 - val_acc: 0.7000\n",
      "Epoch 1069/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4941 - acc: 0.9620 - val_loss: 0.6204 - val_acc: 0.7000\n",
      "Epoch 1070/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4935 - acc: 0.9620 - val_loss: 0.6196 - val_acc: 0.7000\n",
      "Epoch 1071/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4935 - acc: 0.9620 - val_loss: 0.6218 - val_acc: 0.7000\n",
      "Epoch 1072/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4925 - acc: 0.9494 - val_loss: 0.6224 - val_acc: 0.8000\n",
      "Epoch 1073/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.4916 - acc: 0.9367 - val_loss: 0.6195 - val_acc: 0.7000\n",
      "Epoch 1074/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4932 - acc: 0.9494 - val_loss: 0.6178 - val_acc: 0.7500\n",
      "Epoch 1075/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.4885 - acc: 0.9494 - val_loss: 0.6183 - val_acc: 0.7000\n",
      "Epoch 1076/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.4884 - acc: 0.9620 - val_loss: 0.6159 - val_acc: 0.7500\n",
      "Epoch 1077/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4899 - acc: 0.9620 - val_loss: 0.6140 - val_acc: 0.7500\n",
      "Epoch 1078/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4863 - acc: 0.9494 - val_loss: 0.6136 - val_acc: 0.7500\n",
      "Epoch 1079/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4862 - acc: 0.9367 - val_loss: 0.6146 - val_acc: 0.7500\n",
      "Epoch 1080/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4841 - acc: 0.9494 - val_loss: 0.6134 - val_acc: 0.7500\n",
      "Epoch 1081/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4852 - acc: 0.9620 - val_loss: 0.6169 - val_acc: 0.7000\n",
      "Epoch 1082/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4854 - acc: 0.9620 - val_loss: 0.6144 - val_acc: 0.7500\n",
      "Epoch 1083/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.4945 - acc: 0.937 - 0s 139us/sample - loss: 0.4817 - acc: 0.9494 - val_loss: 0.6139 - val_acc: 0.7500\n",
      "Epoch 1084/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4801 - acc: 0.9494 - val_loss: 0.6138 - val_acc: 0.7500\n",
      "Epoch 1085/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4795 - acc: 0.9494 - val_loss: 0.6146 - val_acc: 0.7000\n",
      "Epoch 1086/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4798 - acc: 0.9494 - val_loss: 0.6147 - val_acc: 0.7000\n",
      "Epoch 1087/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4780 - acc: 0.9620 - val_loss: 0.6130 - val_acc: 0.7000\n",
      "Epoch 1088/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.4782 - acc: 0.9494 - val_loss: 0.6110 - val_acc: 0.7000\n",
      "Epoch 1089/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4764 - acc: 0.9494 - val_loss: 0.6124 - val_acc: 0.7000\n",
      "Epoch 1090/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4752 - acc: 0.9494 - val_loss: 0.6106 - val_acc: 0.7000\n",
      "Epoch 1091/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4739 - acc: 0.9494 - val_loss: 0.6092 - val_acc: 0.7500\n",
      "Epoch 1092/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4734 - acc: 0.9494 - val_loss: 0.6099 - val_acc: 0.7000\n",
      "Epoch 1093/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.4727 - acc: 0.9494 - val_loss: 0.6084 - val_acc: 0.7500\n",
      "Epoch 1094/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.4711 - acc: 0.9494 - val_loss: 0.6089 - val_acc: 0.7500\n",
      "Epoch 1095/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.4708 - acc: 0.9494 - val_loss: 0.6076 - val_acc: 0.7500\n",
      "Epoch 1096/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4694 - acc: 0.9494 - val_loss: 0.6075 - val_acc: 0.7500\n",
      "Epoch 1097/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4697 - acc: 0.9494 - val_loss: 0.6098 - val_acc: 0.7000\n",
      "Epoch 1098/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4699 - acc: 0.9620 - val_loss: 0.6081 - val_acc: 0.7500\n",
      "Epoch 1099/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.4665 - acc: 0.9494 - val_loss: 0.6069 - val_acc: 0.7000\n",
      "Epoch 1100/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4675 - acc: 0.9494 - val_loss: 0.6059 - val_acc: 0.7500\n",
      "Epoch 1101/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4643 - acc: 0.9620 - val_loss: 0.6071 - val_acc: 0.7500\n",
      "Epoch 1102/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.4641 - acc: 0.9620 - val_loss: 0.6072 - val_acc: 0.7500\n",
      "Epoch 1103/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4627 - acc: 0.9620 - val_loss: 0.6054 - val_acc: 0.7500\n",
      "Epoch 1104/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4611 - acc: 0.9494 - val_loss: 0.6069 - val_acc: 0.7000\n",
      "Epoch 1105/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4612 - acc: 0.9494 - val_loss: 0.6043 - val_acc: 0.7500\n",
      "Epoch 1106/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.4593 - acc: 0.9367 - val_loss: 0.6046 - val_acc: 0.7000\n",
      "Epoch 1107/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4577 - acc: 0.9494 - val_loss: 0.6059 - val_acc: 0.7000\n",
      "Epoch 1108/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.4582 - acc: 0.9494 - val_loss: 0.6064 - val_acc: 0.7000\n",
      "Epoch 1109/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4561 - acc: 0.9494 - val_loss: 0.6062 - val_acc: 0.7000\n",
      "Epoch 1110/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.4546 - acc: 0.9620 - val_loss: 0.6031 - val_acc: 0.7000\n",
      "Epoch 1111/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.4533 - acc: 0.9620 - val_loss: 0.6029 - val_acc: 0.7000\n",
      "Epoch 1112/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4528 - acc: 0.9620 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 1113/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4507 - acc: 0.9620 - val_loss: 0.6044 - val_acc: 0.6500\n",
      "Epoch 1114/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4512 - acc: 0.9494 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 1115/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4495 - acc: 0.9620 - val_loss: 0.6056 - val_acc: 0.7000\n",
      "Epoch 1116/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.4484 - acc: 0.9494 - val_loss: 0.6022 - val_acc: 0.7000\n",
      "Epoch 1117/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4475 - acc: 0.9494 - val_loss: 0.6033 - val_acc: 0.7000\n",
      "Epoch 1118/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4457 - acc: 0.9620 - val_loss: 0.6034 - val_acc: 0.7500\n",
      "Epoch 1119/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4482 - acc: 0.9494 - val_loss: 0.6069 - val_acc: 0.7500\n",
      "Epoch 1120/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4454 - acc: 0.9494 - val_loss: 0.6065 - val_acc: 0.7500\n",
      "Epoch 1121/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.4455 - acc: 0.9241 - val_loss: 0.6019 - val_acc: 0.7500\n",
      "Epoch 1122/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4428 - acc: 0.9620 - val_loss: 0.6015 - val_acc: 0.7000\n",
      "Epoch 1123/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4429 - acc: 0.9620 - val_loss: 0.6025 - val_acc: 0.7000\n",
      "Epoch 1124/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4406 - acc: 0.9620 - val_loss: 0.6012 - val_acc: 0.7500\n",
      "Epoch 1125/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4400 - acc: 0.9494 - val_loss: 0.5997 - val_acc: 0.7500\n",
      "Epoch 1126/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.4387 - acc: 0.9620 - val_loss: 0.6001 - val_acc: 0.7500\n",
      "Epoch 1127/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4382 - acc: 0.9494 - val_loss: 0.5995 - val_acc: 0.7500\n",
      "Epoch 1128/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.4365 - acc: 0.9494 - val_loss: 0.5995 - val_acc: 0.7500\n",
      "Epoch 1129/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.4356 - acc: 0.9494 - val_loss: 0.5993 - val_acc: 0.7500\n",
      "Epoch 1130/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4353 - acc: 0.9494 - val_loss: 0.6015 - val_acc: 0.7000\n",
      "Epoch 1131/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4361 - acc: 0.9241 - val_loss: 0.6001 - val_acc: 0.7000\n",
      "Epoch 1132/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4331 - acc: 0.9494 - val_loss: 0.5993 - val_acc: 0.7000\n",
      "Epoch 1133/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.4316 - acc: 0.9620 - val_loss: 0.6005 - val_acc: 0.7000\n",
      "Epoch 1134/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4314 - acc: 0.9620 - val_loss: 0.5978 - val_acc: 0.7500\n",
      "Epoch 1135/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.4308 - acc: 0.9494 - val_loss: 0.5978 - val_acc: 0.7500\n",
      "Epoch 1136/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4296 - acc: 0.9494 - val_loss: 0.6004 - val_acc: 0.7500\n",
      "Epoch 1137/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4282 - acc: 0.9367 - val_loss: 0.5963 - val_acc: 0.7500\n",
      "Epoch 1138/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.4258 - acc: 0.9494 - val_loss: 0.5960 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1139/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4252 - acc: 0.9494 - val_loss: 0.5969 - val_acc: 0.7500\n",
      "Epoch 1140/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4258 - acc: 0.9494 - val_loss: 0.5977 - val_acc: 0.7000\n",
      "Epoch 1141/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.4233 - acc: 0.9620 - val_loss: 0.5985 - val_acc: 0.7000\n",
      "Epoch 1142/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4220 - acc: 0.9494 - val_loss: 0.5981 - val_acc: 0.7000\n",
      "Epoch 1143/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.4203 - acc: 0.9367 - val_loss: 0.5965 - val_acc: 0.7000\n",
      "Epoch 1144/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4188 - acc: 0.9620 - val_loss: 0.5966 - val_acc: 0.7000\n",
      "Epoch 1145/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4179 - acc: 0.9620 - val_loss: 0.5972 - val_acc: 0.7000\n",
      "Epoch 1146/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.4180 - acc: 0.9494 - val_loss: 0.5955 - val_acc: 0.7000\n",
      "Epoch 1147/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4168 - acc: 0.9620 - val_loss: 0.5932 - val_acc: 0.7000\n",
      "Epoch 1148/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4150 - acc: 0.9620 - val_loss: 0.5948 - val_acc: 0.7000\n",
      "Epoch 1149/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4159 - acc: 0.9620 - val_loss: 0.5937 - val_acc: 0.6500\n",
      "Epoch 1150/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4118 - acc: 0.9620 - val_loss: 0.5921 - val_acc: 0.6500\n",
      "Epoch 1151/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.4110 - acc: 0.9620 - val_loss: 0.5900 - val_acc: 0.7500\n",
      "Epoch 1152/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.4144 - acc: 0.9494 - val_loss: 0.5913 - val_acc: 0.7000\n",
      "Epoch 1153/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.4094 - acc: 0.9620 - val_loss: 0.5927 - val_acc: 0.7000\n",
      "Epoch 1154/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.4097 - acc: 0.9620 - val_loss: 0.5901 - val_acc: 0.7500\n",
      "Epoch 1155/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4086 - acc: 0.9494 - val_loss: 0.5898 - val_acc: 0.7000\n",
      "Epoch 1156/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4080 - acc: 0.9494 - val_loss: 0.5896 - val_acc: 0.7500\n",
      "Epoch 1157/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.4060 - acc: 0.9620 - val_loss: 0.5894 - val_acc: 0.7500\n",
      "Epoch 1158/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4052 - acc: 0.9494 - val_loss: 0.5898 - val_acc: 0.6500\n",
      "Epoch 1159/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.4032 - acc: 0.9620 - val_loss: 0.5898 - val_acc: 0.6500\n",
      "Epoch 1160/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.4014 - acc: 0.9620 - val_loss: 0.5889 - val_acc: 0.7000\n",
      "Epoch 1161/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.4010 - acc: 0.9620 - val_loss: 0.5882 - val_acc: 0.7500\n",
      "Epoch 1162/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3991 - acc: 0.9494 - val_loss: 0.5884 - val_acc: 0.7000\n",
      "Epoch 1163/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3973 - acc: 0.9494 - val_loss: 0.5876 - val_acc: 0.7500\n",
      "Epoch 1164/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.3974 - acc: 0.9620 - val_loss: 0.5887 - val_acc: 0.7000\n",
      "Epoch 1165/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3968 - acc: 0.9494 - val_loss: 0.5889 - val_acc: 0.7000\n",
      "Epoch 1166/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3956 - acc: 0.9494 - val_loss: 0.5883 - val_acc: 0.7000\n",
      "Epoch 1167/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3938 - acc: 0.9494 - val_loss: 0.5875 - val_acc: 0.6500\n",
      "Epoch 1168/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3932 - acc: 0.9620 - val_loss: 0.5890 - val_acc: 0.7000\n",
      "Epoch 1169/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3918 - acc: 0.9620 - val_loss: 0.5879 - val_acc: 0.7000\n",
      "Epoch 1170/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3910 - acc: 0.9620 - val_loss: 0.5876 - val_acc: 0.6500\n",
      "Epoch 1171/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3898 - acc: 0.9620 - val_loss: 0.5856 - val_acc: 0.7000\n",
      "Epoch 1172/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3886 - acc: 0.9494 - val_loss: 0.5861 - val_acc: 0.7500\n",
      "Epoch 1173/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3896 - acc: 0.9620 - val_loss: 0.5856 - val_acc: 0.6500\n",
      "Epoch 1174/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3881 - acc: 0.9620 - val_loss: 0.5852 - val_acc: 0.7000\n",
      "Epoch 1175/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3863 - acc: 0.9494 - val_loss: 0.5862 - val_acc: 0.6500\n",
      "Epoch 1176/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3845 - acc: 0.9620 - val_loss: 0.5846 - val_acc: 0.6500\n",
      "Epoch 1177/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3832 - acc: 0.9620 - val_loss: 0.5831 - val_acc: 0.7000\n",
      "Epoch 1178/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.3828 - acc: 0.9620 - val_loss: 0.5856 - val_acc: 0.6500\n",
      "Epoch 1179/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3811 - acc: 0.9620 - val_loss: 0.5841 - val_acc: 0.6500\n",
      "Epoch 1180/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3821 - acc: 0.9620 - val_loss: 0.5835 - val_acc: 0.7000\n",
      "Epoch 1181/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3791 - acc: 0.9620 - val_loss: 0.5832 - val_acc: 0.7000\n",
      "Epoch 1182/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.3784 - acc: 0.9494 - val_loss: 0.5838 - val_acc: 0.7000\n",
      "Epoch 1183/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3768 - acc: 0.9494 - val_loss: 0.5813 - val_acc: 0.7500\n",
      "Epoch 1184/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3763 - acc: 0.9620 - val_loss: 0.5824 - val_acc: 0.7000\n",
      "Epoch 1185/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3759 - acc: 0.9620 - val_loss: 0.5832 - val_acc: 0.6500\n",
      "Epoch 1186/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.3734 - acc: 0.9620 - val_loss: 0.5831 - val_acc: 0.7000\n",
      "Epoch 1187/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3729 - acc: 0.9494 - val_loss: 0.5831 - val_acc: 0.6500\n",
      "Epoch 1188/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3720 - acc: 0.9620 - val_loss: 0.5832 - val_acc: 0.6500\n",
      "Epoch 1189/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3705 - acc: 0.9620 - val_loss: 0.5828 - val_acc: 0.6500\n",
      "Epoch 1190/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.3692 - acc: 0.9620 - val_loss: 0.5820 - val_acc: 0.6500\n",
      "Epoch 1191/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3700 - acc: 0.9494 - val_loss: 0.5852 - val_acc: 0.7000\n",
      "Epoch 1192/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3694 - acc: 0.9494 - val_loss: 0.5833 - val_acc: 0.7000\n",
      "Epoch 1193/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.3663 - acc: 0.9620 - val_loss: 0.5814 - val_acc: 0.7000\n",
      "Epoch 1194/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3668 - acc: 0.9620 - val_loss: 0.5808 - val_acc: 0.7000\n",
      "Epoch 1195/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3641 - acc: 0.9494 - val_loss: 0.5805 - val_acc: 0.7000\n",
      "Epoch 1196/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3622 - acc: 0.9620 - val_loss: 0.5801 - val_acc: 0.7000\n",
      "Epoch 1197/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.3615 - acc: 0.9494 - val_loss: 0.5809 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.3618 - acc: 0.9494 - val_loss: 0.5801 - val_acc: 0.6500\n",
      "Epoch 1199/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3599 - acc: 0.9620 - val_loss: 0.5780 - val_acc: 0.7500\n",
      "Epoch 1200/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3583 - acc: 0.9494 - val_loss: 0.5784 - val_acc: 0.7500\n",
      "Epoch 1201/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3560 - acc: 0.9620 - val_loss: 0.5799 - val_acc: 0.7000\n",
      "Epoch 1202/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3554 - acc: 0.9494 - val_loss: 0.5784 - val_acc: 0.6500\n",
      "Epoch 1203/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.3543 - acc: 0.9620 - val_loss: 0.5782 - val_acc: 0.7000\n",
      "Epoch 1204/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3547 - acc: 0.9494 - val_loss: 0.5789 - val_acc: 0.6500\n",
      "Epoch 1205/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3513 - acc: 0.9620 - val_loss: 0.5778 - val_acc: 0.7000\n",
      "Epoch 1206/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3499 - acc: 0.9494 - val_loss: 0.5780 - val_acc: 0.7000\n",
      "Epoch 1207/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3523 - acc: 0.9620 - val_loss: 0.5779 - val_acc: 0.6500\n",
      "Epoch 1208/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3480 - acc: 0.9620 - val_loss: 0.5772 - val_acc: 0.7000\n",
      "Epoch 1209/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3467 - acc: 0.9620 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 1210/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.3454 - acc: 0.9494 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 1211/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3441 - acc: 0.9494 - val_loss: 0.5766 - val_acc: 0.7000\n",
      "Epoch 1212/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.3427 - acc: 0.9620 - val_loss: 0.5770 - val_acc: 0.6500\n",
      "Epoch 1213/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3418 - acc: 0.9494 - val_loss: 0.5760 - val_acc: 0.7000\n",
      "Epoch 1214/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3406 - acc: 0.9620 - val_loss: 0.5748 - val_acc: 0.7000\n",
      "Epoch 1215/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3406 - acc: 0.9494 - val_loss: 0.5760 - val_acc: 0.7000\n",
      "Epoch 1216/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3385 - acc: 0.9494 - val_loss: 0.5785 - val_acc: 0.6500\n",
      "Epoch 1217/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3391 - acc: 0.9620 - val_loss: 0.5770 - val_acc: 0.7000\n",
      "Epoch 1218/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3374 - acc: 0.9494 - val_loss: 0.5732 - val_acc: 0.7000\n",
      "Epoch 1219/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.3366 - acc: 0.9620 - val_loss: 0.5760 - val_acc: 0.7000\n",
      "Epoch 1220/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.3356 - acc: 0.9494 - val_loss: 0.5796 - val_acc: 0.6500\n",
      "Epoch 1221/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3339 - acc: 0.9620 - val_loss: 0.5775 - val_acc: 0.6500\n",
      "Epoch 1222/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3346 - acc: 0.9620 - val_loss: 0.5777 - val_acc: 0.6500\n",
      "Epoch 1223/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3329 - acc: 0.9620 - val_loss: 0.5781 - val_acc: 0.7000\n",
      "Epoch 1224/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3341 - acc: 0.9620 - val_loss: 0.5806 - val_acc: 0.7000\n",
      "Epoch 1225/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3317 - acc: 0.9494 - val_loss: 0.5768 - val_acc: 0.6500\n",
      "Epoch 1226/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.3294 - acc: 0.9620 - val_loss: 0.5761 - val_acc: 0.6500\n",
      "Epoch 1227/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3291 - acc: 0.9620 - val_loss: 0.5743 - val_acc: 0.7000\n",
      "Epoch 1228/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3278 - acc: 0.9620 - val_loss: 0.5746 - val_acc: 0.6500\n",
      "Epoch 1229/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3279 - acc: 0.9620 - val_loss: 0.5738 - val_acc: 0.6500\n",
      "Epoch 1230/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3262 - acc: 0.9620 - val_loss: 0.5737 - val_acc: 0.6500\n",
      "Epoch 1231/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3232 - acc: 0.9620 - val_loss: 0.5738 - val_acc: 0.7000\n",
      "Epoch 1232/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3223 - acc: 0.9620 - val_loss: 0.5734 - val_acc: 0.7000\n",
      "Epoch 1233/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3226 - acc: 0.9620 - val_loss: 0.5740 - val_acc: 0.6500\n",
      "Epoch 1234/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3209 - acc: 0.9620 - val_loss: 0.5728 - val_acc: 0.7000\n",
      "Epoch 1235/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3212 - acc: 0.9620 - val_loss: 0.5734 - val_acc: 0.6500\n",
      "Epoch 1236/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.3180 - acc: 0.9620 - val_loss: 0.5725 - val_acc: 0.7000\n",
      "Epoch 1237/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3189 - acc: 0.9620 - val_loss: 0.5720 - val_acc: 0.7000\n",
      "Epoch 1238/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3163 - acc: 0.9620 - val_loss: 0.5721 - val_acc: 0.6500\n",
      "Epoch 1239/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.3147 - acc: 0.9620 - val_loss: 0.5719 - val_acc: 0.6500\n",
      "Epoch 1240/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3136 - acc: 0.9620 - val_loss: 0.5715 - val_acc: 0.6500\n",
      "Epoch 1241/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.3124 - acc: 0.9620 - val_loss: 0.5709 - val_acc: 0.7000\n",
      "Epoch 1242/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.3116 - acc: 0.9747 - val_loss: 0.5713 - val_acc: 0.6500\n",
      "Epoch 1243/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3110 - acc: 0.9620 - val_loss: 0.5707 - val_acc: 0.7000\n",
      "Epoch 1244/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3095 - acc: 0.9620 - val_loss: 0.5704 - val_acc: 0.7000\n",
      "Epoch 1245/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3084 - acc: 0.9620 - val_loss: 0.5700 - val_acc: 0.7000\n",
      "Epoch 1246/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.3073 - acc: 0.9747 - val_loss: 0.5698 - val_acc: 0.7000\n",
      "Epoch 1247/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3064 - acc: 0.9620 - val_loss: 0.5695 - val_acc: 0.7000\n",
      "Epoch 1248/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3060 - acc: 0.9747 - val_loss: 0.5699 - val_acc: 0.6500\n",
      "Epoch 1249/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.3066 - acc: 0.9620 - val_loss: 0.5692 - val_acc: 0.7000\n",
      "Epoch 1250/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.3033 - acc: 0.9747 - val_loss: 0.5689 - val_acc: 0.7000\n",
      "Epoch 1251/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.3025 - acc: 0.9747 - val_loss: 0.5687 - val_acc: 0.7000\n",
      "Epoch 1252/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.3034 - acc: 0.9620 - val_loss: 0.5690 - val_acc: 0.6500\n",
      "Epoch 1253/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.3015 - acc: 0.9747 - val_loss: 0.5683 - val_acc: 0.7000\n",
      "Epoch 1254/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2992 - acc: 0.9620 - val_loss: 0.5680 - val_acc: 0.7000\n",
      "Epoch 1255/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2980 - acc: 0.9747 - val_loss: 0.5679 - val_acc: 0.7000\n",
      "Epoch 1256/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2989 - acc: 0.9620 - val_loss: 0.5680 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1257/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.2963 - acc: 0.9620 - val_loss: 0.5674 - val_acc: 0.7000\n",
      "Epoch 1258/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.2948 - acc: 0.9747 - val_loss: 0.5672 - val_acc: 0.7000\n",
      "Epoch 1259/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2942 - acc: 0.9747 - val_loss: 0.5672 - val_acc: 0.6500\n",
      "Epoch 1260/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2954 - acc: 0.9620 - val_loss: 0.5675 - val_acc: 0.6500\n",
      "Epoch 1261/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2936 - acc: 0.9620 - val_loss: 0.5664 - val_acc: 0.7000\n",
      "Epoch 1262/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.2914 - acc: 0.9747 - val_loss: 0.5665 - val_acc: 0.6500\n",
      "Epoch 1263/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2901 - acc: 0.9620 - val_loss: 0.5660 - val_acc: 0.7000\n",
      "Epoch 1264/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2889 - acc: 0.9747 - val_loss: 0.5659 - val_acc: 0.7000\n",
      "Epoch 1265/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2885 - acc: 0.9620 - val_loss: 0.5657 - val_acc: 0.6500\n",
      "Epoch 1266/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2871 - acc: 0.9620 - val_loss: 0.5649 - val_acc: 0.7000\n",
      "Epoch 1267/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2872 - acc: 0.9747 - val_loss: 0.5646 - val_acc: 0.7000\n",
      "Epoch 1268/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.2867 - acc: 0.9620 - val_loss: 0.5633 - val_acc: 0.7000\n",
      "Epoch 1269/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2876 - acc: 0.9747 - val_loss: 0.5626 - val_acc: 0.7000\n",
      "Epoch 1270/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2852 - acc: 0.9620 - val_loss: 0.5627 - val_acc: 0.6500\n",
      "Epoch 1271/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2843 - acc: 0.9620 - val_loss: 0.5613 - val_acc: 0.7000\n",
      "Epoch 1272/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.2829 - acc: 0.9747 - val_loss: 0.5612 - val_acc: 0.7000\n",
      "Epoch 1273/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2820 - acc: 0.9747 - val_loss: 0.5615 - val_acc: 0.7000\n",
      "Epoch 1274/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2807 - acc: 0.9747 - val_loss: 0.5614 - val_acc: 0.7000\n",
      "Epoch 1275/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.2797 - acc: 0.9747 - val_loss: 0.5612 - val_acc: 0.6500\n",
      "Epoch 1276/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2789 - acc: 0.9747 - val_loss: 0.5624 - val_acc: 0.6500\n",
      "Epoch 1277/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.2802 - acc: 0.9747 - val_loss: 0.5628 - val_acc: 0.7000\n",
      "Epoch 1278/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.2772 - acc: 0.9747 - val_loss: 0.5612 - val_acc: 0.6500\n",
      "Epoch 1279/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2759 - acc: 0.9747 - val_loss: 0.5604 - val_acc: 0.6500\n",
      "Epoch 1280/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.2770 - acc: 0.9620 - val_loss: 0.5601 - val_acc: 0.7000\n",
      "Epoch 1281/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.2741 - acc: 0.9747 - val_loss: 0.5602 - val_acc: 0.6500\n",
      "Epoch 1282/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2744 - acc: 0.9620 - val_loss: 0.5606 - val_acc: 0.6500\n",
      "Epoch 1283/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2718 - acc: 0.9873 - val_loss: 0.5596 - val_acc: 0.6500\n",
      "Epoch 1284/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2713 - acc: 0.9747 - val_loss: 0.5594 - val_acc: 0.6500\n",
      "Epoch 1285/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2696 - acc: 0.9747 - val_loss: 0.5572 - val_acc: 0.6500\n",
      "Epoch 1286/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2691 - acc: 0.9747 - val_loss: 0.5568 - val_acc: 0.7000\n",
      "Epoch 1287/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.2692 - acc: 0.9747 - val_loss: 0.5555 - val_acc: 0.7000\n",
      "Epoch 1288/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.2674 - acc: 0.9747 - val_loss: 0.5570 - val_acc: 0.6500\n",
      "Epoch 1289/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.2655 - acc: 0.9747 - val_loss: 0.5583 - val_acc: 0.7000\n",
      "Epoch 1290/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2644 - acc: 0.9747 - val_loss: 0.5570 - val_acc: 0.7000\n",
      "Epoch 1291/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2651 - acc: 0.9747 - val_loss: 0.5580 - val_acc: 0.6500\n",
      "Epoch 1292/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.2636 - acc: 0.9620 - val_loss: 0.5555 - val_acc: 0.6500\n",
      "Epoch 1293/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2625 - acc: 0.9747 - val_loss: 0.5562 - val_acc: 0.7000\n",
      "Epoch 1294/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2630 - acc: 0.9747 - val_loss: 0.5544 - val_acc: 0.7500\n",
      "Epoch 1295/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.2622 - acc: 0.9620 - val_loss: 0.5543 - val_acc: 0.7000\n",
      "Epoch 1296/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2636 - acc: 0.9620 - val_loss: 0.5535 - val_acc: 0.7500\n",
      "Epoch 1297/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2620 - acc: 0.9620 - val_loss: 0.5411 - val_acc: 0.7000\n",
      "Epoch 1298/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2596 - acc: 0.9747 - val_loss: 0.5519 - val_acc: 0.7500\n",
      "Epoch 1299/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2595 - acc: 0.9620 - val_loss: 0.5564 - val_acc: 0.7000\n",
      "Epoch 1300/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2573 - acc: 0.9747 - val_loss: 0.5572 - val_acc: 0.7000\n",
      "Epoch 1301/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.2575 - acc: 0.9747 - val_loss: 0.5548 - val_acc: 0.7000\n",
      "Epoch 1302/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2562 - acc: 0.9747 - val_loss: 0.5552 - val_acc: 0.6500\n",
      "Epoch 1303/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2541 - acc: 0.9747 - val_loss: 0.5540 - val_acc: 0.6500\n",
      "Epoch 1304/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2533 - acc: 0.9747 - val_loss: 0.5542 - val_acc: 0.6500\n",
      "Epoch 1305/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2512 - acc: 0.9747 - val_loss: 0.5561 - val_acc: 0.6500\n",
      "Epoch 1306/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2530 - acc: 0.9747 - val_loss: 0.5530 - val_acc: 0.7000\n",
      "Epoch 1307/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2492 - acc: 0.9747 - val_loss: 0.5517 - val_acc: 0.6500\n",
      "Epoch 1308/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2493 - acc: 0.9747 - val_loss: 0.5515 - val_acc: 0.6500\n",
      "Epoch 1309/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2502 - acc: 0.9747 - val_loss: 0.5520 - val_acc: 0.7000\n",
      "Epoch 1310/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2479 - acc: 0.9747 - val_loss: 0.5498 - val_acc: 0.7000\n",
      "Epoch 1311/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2479 - acc: 0.9747 - val_loss: 0.5514 - val_acc: 0.6500\n",
      "Epoch 1312/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2450 - acc: 0.9747 - val_loss: 0.5457 - val_acc: 0.6500\n",
      "Epoch 1313/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2453 - acc: 0.9873 - val_loss: 0.5489 - val_acc: 0.6500\n",
      "Epoch 1314/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2429 - acc: 0.9747 - val_loss: 0.5554 - val_acc: 0.6500\n",
      "Epoch 1315/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2407 - acc: 0.9747 - val_loss: 0.5550 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1316/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2399 - acc: 0.9747 - val_loss: 0.5538 - val_acc: 0.6500\n",
      "Epoch 1317/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2390 - acc: 0.9747 - val_loss: 0.5523 - val_acc: 0.6500\n",
      "Epoch 1318/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.2409 - acc: 0.9873 - val_loss: 0.5479 - val_acc: 0.6500\n",
      "Epoch 1319/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2407 - acc: 0.9873 - val_loss: 0.5472 - val_acc: 0.6500\n",
      "Epoch 1320/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2391 - acc: 0.9747 - val_loss: 0.5490 - val_acc: 0.6500\n",
      "Epoch 1321/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2388 - acc: 0.9747 - val_loss: 0.5453 - val_acc: 0.6500\n",
      "Epoch 1322/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.2380 - acc: 0.9747 - val_loss: 0.5480 - val_acc: 0.6500\n",
      "Epoch 1323/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2354 - acc: 0.9747 - val_loss: 0.5478 - val_acc: 0.6500\n",
      "Epoch 1324/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2351 - acc: 0.9747 - val_loss: 0.5492 - val_acc: 0.7000\n",
      "Epoch 1325/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2341 - acc: 0.9873 - val_loss: 0.5461 - val_acc: 0.6500\n",
      "Epoch 1326/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2325 - acc: 0.9873 - val_loss: 0.5459 - val_acc: 0.6500\n",
      "Epoch 1327/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2318 - acc: 0.9747 - val_loss: 0.5411 - val_acc: 0.6500\n",
      "Epoch 1328/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2312 - acc: 0.9747 - val_loss: 0.5410 - val_acc: 0.6500\n",
      "Epoch 1329/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2295 - acc: 0.9747 - val_loss: 0.5471 - val_acc: 0.6500\n",
      "Epoch 1330/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2299 - acc: 0.9747 - val_loss: 0.5418 - val_acc: 0.6500\n",
      "Epoch 1331/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.2277 - acc: 0.9747 - val_loss: 0.5410 - val_acc: 0.6500\n",
      "Epoch 1332/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2270 - acc: 0.9747 - val_loss: 0.5417 - val_acc: 0.6500\n",
      "Epoch 1333/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2261 - acc: 0.9873 - val_loss: 0.5405 - val_acc: 0.6500\n",
      "Epoch 1334/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2252 - acc: 0.9747 - val_loss: 0.5408 - val_acc: 0.6500\n",
      "Epoch 1335/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2247 - acc: 0.9747 - val_loss: 0.5417 - val_acc: 0.6500\n",
      "Epoch 1336/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.2235 - acc: 0.9873 - val_loss: 0.5412 - val_acc: 0.6500\n",
      "Epoch 1337/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.2232 - acc: 0.9873 - val_loss: 0.5401 - val_acc: 0.6500\n",
      "Epoch 1338/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.2219 - acc: 0.9747 - val_loss: 0.5377 - val_acc: 0.6500\n",
      "Epoch 1339/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.2201 - acc: 0.9873 - val_loss: 0.5374 - val_acc: 0.6500\n",
      "Epoch 1340/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2193 - acc: 0.9747 - val_loss: 0.5375 - val_acc: 0.6500\n",
      "Epoch 1341/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2186 - acc: 0.9873 - val_loss: 0.5393 - val_acc: 0.6500\n",
      "Epoch 1342/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.2177 - acc: 0.9873 - val_loss: 0.5383 - val_acc: 0.6500\n",
      "Epoch 1343/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.2171 - acc: 0.9873 - val_loss: 0.5394 - val_acc: 0.6500\n",
      "Epoch 1344/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2161 - acc: 0.9873 - val_loss: 0.5382 - val_acc: 0.6500\n",
      "Epoch 1345/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2168 - acc: 0.9747 - val_loss: 0.5415 - val_acc: 0.7000\n",
      "Epoch 1346/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.2163 - acc: 0.9873 - val_loss: 0.5417 - val_acc: 0.7000\n",
      "Epoch 1347/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2148 - acc: 0.9873 - val_loss: 0.5393 - val_acc: 0.6500\n",
      "Epoch 1348/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2140 - acc: 0.9873 - val_loss: 0.5418 - val_acc: 0.7000\n",
      "Epoch 1349/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2126 - acc: 0.9873 - val_loss: 0.5390 - val_acc: 0.6500\n",
      "Epoch 1350/3000\n",
      "79/79 [==============================] - 0s 189us/sample - loss: 0.2119 - acc: 0.9873 - val_loss: 0.5388 - val_acc: 0.6500\n",
      "Epoch 1351/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.2109 - acc: 0.9873 - val_loss: 0.5399 - val_acc: 0.6500\n",
      "Epoch 1352/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2108 - acc: 0.9873 - val_loss: 0.5396 - val_acc: 0.6500\n",
      "Epoch 1353/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2092 - acc: 0.9873 - val_loss: 0.5390 - val_acc: 0.6500\n",
      "Epoch 1354/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.2080 - acc: 0.9873 - val_loss: 0.5379 - val_acc: 0.6500\n",
      "Epoch 1355/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2086 - acc: 0.9873 - val_loss: 0.5370 - val_acc: 0.6500\n",
      "Epoch 1356/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2072 - acc: 0.9873 - val_loss: 0.5368 - val_acc: 0.6500\n",
      "Epoch 1357/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2063 - acc: 0.9747 - val_loss: 0.5383 - val_acc: 0.6500\n",
      "Epoch 1358/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2054 - acc: 0.9873 - val_loss: 0.5370 - val_acc: 0.6500\n",
      "Epoch 1359/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.2041 - acc: 0.9873 - val_loss: 0.5371 - val_acc: 0.6500\n",
      "Epoch 1360/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.2036 - acc: 0.9873 - val_loss: 0.5367 - val_acc: 0.6500\n",
      "Epoch 1361/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2027 - acc: 0.9873 - val_loss: 0.5370 - val_acc: 0.6500\n",
      "Epoch 1362/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2032 - acc: 0.9873 - val_loss: 0.5365 - val_acc: 0.7000\n",
      "Epoch 1363/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2021 - acc: 0.9747 - val_loss: 0.5375 - val_acc: 0.6500\n",
      "Epoch 1364/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.2018 - acc: 0.9873 - val_loss: 0.5368 - val_acc: 0.6500\n",
      "Epoch 1365/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.2016 - acc: 0.9873 - val_loss: 0.5364 - val_acc: 0.6500\n",
      "Epoch 1366/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.2001 - acc: 0.9747 - val_loss: 0.5369 - val_acc: 0.6500\n",
      "Epoch 1367/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1976 - acc: 0.9873 - val_loss: 0.5374 - val_acc: 0.6500\n",
      "Epoch 1368/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1969 - acc: 0.9873 - val_loss: 0.5369 - val_acc: 0.6500\n",
      "Epoch 1369/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1975 - acc: 0.9873 - val_loss: 0.5368 - val_acc: 0.6500\n",
      "Epoch 1370/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1966 - acc: 0.9873 - val_loss: 0.5373 - val_acc: 0.6500\n",
      "Epoch 1371/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1950 - acc: 0.9873 - val_loss: 0.5372 - val_acc: 0.6500\n",
      "Epoch 1372/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1939 - acc: 0.9873 - val_loss: 0.5368 - val_acc: 0.6500\n",
      "Epoch 1373/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1934 - acc: 0.9873 - val_loss: 0.5363 - val_acc: 0.6500\n",
      "Epoch 1374/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1948 - acc: 0.9873 - val_loss: 0.5360 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1375/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1942 - acc: 0.9873 - val_loss: 0.5378 - val_acc: 0.6500\n",
      "Epoch 1376/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1913 - acc: 0.9873 - val_loss: 0.5368 - val_acc: 0.6500\n",
      "Epoch 1377/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.1907 - acc: 0.9873 - val_loss: 0.5388 - val_acc: 0.6500\n",
      "Epoch 1378/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1909 - acc: 0.9873 - val_loss: 0.5377 - val_acc: 0.6500\n",
      "Epoch 1379/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.1898 - acc: 0.9873 - val_loss: 0.5378 - val_acc: 0.6500\n",
      "Epoch 1380/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1896 - acc: 0.9873 - val_loss: 0.5386 - val_acc: 0.6500\n",
      "Epoch 1381/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1888 - acc: 0.9873 - val_loss: 0.5374 - val_acc: 0.6500\n",
      "Epoch 1382/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.1882 - acc: 0.9873 - val_loss: 0.5381 - val_acc: 0.6500\n",
      "Epoch 1383/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1871 - acc: 0.9873 - val_loss: 0.5400 - val_acc: 0.6500\n",
      "Epoch 1384/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1866 - acc: 0.9873 - val_loss: 0.5389 - val_acc: 0.6500\n",
      "Epoch 1385/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1858 - acc: 0.9873 - val_loss: 0.5408 - val_acc: 0.6500\n",
      "Epoch 1386/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1876 - acc: 0.9873 - val_loss: 0.5386 - val_acc: 0.6500\n",
      "Epoch 1387/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1839 - acc: 0.9873 - val_loss: 0.5385 - val_acc: 0.6500\n",
      "Epoch 1388/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1837 - acc: 0.9873 - val_loss: 0.5388 - val_acc: 0.7000\n",
      "Epoch 1389/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1834 - acc: 0.9873 - val_loss: 0.5383 - val_acc: 0.6500\n",
      "Epoch 1390/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1819 - acc: 0.9873 - val_loss: 0.5395 - val_acc: 0.6500\n",
      "Epoch 1391/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1814 - acc: 0.9873 - val_loss: 0.5385 - val_acc: 0.6500\n",
      "Epoch 1392/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1805 - acc: 0.9873 - val_loss: 0.5408 - val_acc: 0.6500\n",
      "Epoch 1393/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1804 - acc: 0.9873 - val_loss: 0.5403 - val_acc: 0.6500\n",
      "Epoch 1394/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1786 - acc: 0.9873 - val_loss: 0.5411 - val_acc: 0.6500\n",
      "Epoch 1395/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1782 - acc: 0.9873 - val_loss: 0.5393 - val_acc: 0.6500\n",
      "Epoch 1396/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.1790 - acc: 0.9873 - val_loss: 0.5421 - val_acc: 0.6500\n",
      "Epoch 1397/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1769 - acc: 0.9873 - val_loss: 0.5440 - val_acc: 0.6500\n",
      "Epoch 1398/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1769 - acc: 0.9873 - val_loss: 0.5437 - val_acc: 0.6500\n",
      "Epoch 1399/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1753 - acc: 0.9873 - val_loss: 0.5402 - val_acc: 0.6500\n",
      "Epoch 1400/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1748 - acc: 0.9873 - val_loss: 0.5412 - val_acc: 0.6500\n",
      "Epoch 1401/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.1739 - acc: 0.9873 - val_loss: 0.5431 - val_acc: 0.6500\n",
      "Epoch 1402/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.1731 - acc: 0.9873 - val_loss: 0.5440 - val_acc: 0.6500\n",
      "Epoch 1403/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1731 - acc: 0.9873 - val_loss: 0.5418 - val_acc: 0.6500\n",
      "Epoch 1404/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1718 - acc: 0.9873 - val_loss: 0.5429 - val_acc: 0.6500\n",
      "Epoch 1405/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.1709 - acc: 0.9873 - val_loss: 0.5424 - val_acc: 0.6500\n",
      "Epoch 1406/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1713 - acc: 0.9873 - val_loss: 0.5463 - val_acc: 0.6500\n",
      "Epoch 1407/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1696 - acc: 0.9873 - val_loss: 0.5446 - val_acc: 0.6500\n",
      "Epoch 1408/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1689 - acc: 0.9873 - val_loss: 0.5434 - val_acc: 0.6500\n",
      "Epoch 1409/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1683 - acc: 0.9873 - val_loss: 0.5432 - val_acc: 0.6500\n",
      "Epoch 1410/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1680 - acc: 0.9873 - val_loss: 0.5418 - val_acc: 0.6500\n",
      "Epoch 1411/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.1674 - acc: 0.9873 - val_loss: 0.5429 - val_acc: 0.6500\n",
      "Epoch 1412/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1691 - acc: 0.9873 - val_loss: 0.5409 - val_acc: 0.6500\n",
      "Epoch 1413/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1667 - acc: 0.9873 - val_loss: 0.5410 - val_acc: 0.6500\n",
      "Epoch 1414/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1664 - acc: 0.9873 - val_loss: 0.5427 - val_acc: 0.6500\n",
      "Epoch 1415/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1657 - acc: 0.9873 - val_loss: 0.5433 - val_acc: 0.6500\n",
      "Epoch 1416/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1650 - acc: 0.9873 - val_loss: 0.5452 - val_acc: 0.6500\n",
      "Epoch 1417/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.1645 - acc: 0.9873 - val_loss: 0.5461 - val_acc: 0.6500\n",
      "Epoch 1418/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1649 - acc: 0.9873 - val_loss: 0.5444 - val_acc: 0.6500\n",
      "Epoch 1419/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1631 - acc: 0.9873 - val_loss: 0.5452 - val_acc: 0.6500\n",
      "Epoch 1420/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1626 - acc: 0.9873 - val_loss: 0.5456 - val_acc: 0.6500\n",
      "Epoch 1421/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1654 - acc: 0.9873 - val_loss: 0.5444 - val_acc: 0.6500\n",
      "Epoch 1422/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1641 - acc: 0.9873 - val_loss: 0.5434 - val_acc: 0.6500\n",
      "Epoch 1423/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1993 - acc: 0.968 - 0s 139us/sample - loss: 0.1621 - acc: 0.9873 - val_loss: 0.5449 - val_acc: 0.6500\n",
      "Epoch 1424/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1613 - acc: 0.9873 - val_loss: 0.5490 - val_acc: 0.7000\n",
      "Epoch 1425/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1607 - acc: 0.9873 - val_loss: 0.5446 - val_acc: 0.6500\n",
      "Epoch 1426/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1595 - acc: 0.9873 - val_loss: 0.5449 - val_acc: 0.6500\n",
      "Epoch 1427/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1588 - acc: 0.9873 - val_loss: 0.5441 - val_acc: 0.6500\n",
      "Epoch 1428/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1587 - acc: 0.9873 - val_loss: 0.5444 - val_acc: 0.6500\n",
      "Epoch 1429/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1584 - acc: 0.9873 - val_loss: 0.5448 - val_acc: 0.6500\n",
      "Epoch 1430/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.1604 - acc: 0.9873 - val_loss: 0.5443 - val_acc: 0.6500\n",
      "Epoch 1431/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1562 - acc: 0.9873 - val_loss: 0.5492 - val_acc: 0.6500\n",
      "Epoch 1432/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1561 - acc: 0.9873 - val_loss: 0.5470 - val_acc: 0.6500\n",
      "Epoch 1433/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1555 - acc: 0.9873 - val_loss: 0.5458 - val_acc: 0.6500\n",
      "Epoch 1434/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1546 - acc: 0.9873 - val_loss: 0.5419 - val_acc: 0.6500\n",
      "Epoch 1435/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1552 - acc: 0.9873 - val_loss: 0.5493 - val_acc: 0.6500\n",
      "Epoch 1436/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1535 - acc: 0.9873 - val_loss: 0.5462 - val_acc: 0.6500\n",
      "Epoch 1437/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1523 - acc: 0.9873 - val_loss: 0.5472 - val_acc: 0.6500\n",
      "Epoch 1438/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.1516 - acc: 0.9873 - val_loss: 0.5475 - val_acc: 0.6500\n",
      "Epoch 1439/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1536 - acc: 0.9873 - val_loss: 0.5477 - val_acc: 0.6500\n",
      "Epoch 1440/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1512 - acc: 0.9873 - val_loss: 0.5486 - val_acc: 0.6500\n",
      "Epoch 1441/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1502 - acc: 0.9873 - val_loss: 0.5466 - val_acc: 0.6500\n",
      "Epoch 1442/3000\n",
      "79/79 [==============================] - 0s 158us/sample - loss: 0.1523 - acc: 0.9873 - val_loss: 0.5470 - val_acc: 0.6500\n",
      "Epoch 1443/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1507 - acc: 0.9873 - val_loss: 0.5486 - val_acc: 0.6500\n",
      "Epoch 1444/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1506 - acc: 0.9873 - val_loss: 0.5457 - val_acc: 0.6500\n",
      "Epoch 1445/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1504 - acc: 0.9873 - val_loss: 0.5458 - val_acc: 0.6500\n",
      "Epoch 1446/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1489 - acc: 0.9873 - val_loss: 0.5469 - val_acc: 0.6500\n",
      "Epoch 1447/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1486 - acc: 0.9873 - val_loss: 0.5461 - val_acc: 0.6500\n",
      "Epoch 1448/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1485 - acc: 0.9873 - val_loss: 0.5467 - val_acc: 0.6500\n",
      "Epoch 1449/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1473 - acc: 0.9873 - val_loss: 0.5472 - val_acc: 0.6500\n",
      "Epoch 1450/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.1467 - acc: 0.9873 - val_loss: 0.5487 - val_acc: 0.6500\n",
      "Epoch 1451/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.1475 - acc: 0.9873 - val_loss: 0.5485 - val_acc: 0.6500\n",
      "Epoch 1452/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1464 - acc: 0.9873 - val_loss: 0.5474 - val_acc: 0.6500\n",
      "Epoch 1453/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1453 - acc: 0.9873 - val_loss: 0.5466 - val_acc: 0.6500\n",
      "Epoch 1454/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1448 - acc: 0.9873 - val_loss: 0.5471 - val_acc: 0.6500\n",
      "Epoch 1455/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1441 - acc: 0.9873 - val_loss: 0.5495 - val_acc: 0.6500\n",
      "Epoch 1456/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.1447 - acc: 0.9873 - val_loss: 0.5534 - val_acc: 0.7000\n",
      "Epoch 1457/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1442 - acc: 0.9873 - val_loss: 0.5559 - val_acc: 0.7000\n",
      "Epoch 1458/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1439 - acc: 0.9873 - val_loss: 0.5530 - val_acc: 0.6500\n",
      "Epoch 1459/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1428 - acc: 0.9873 - val_loss: 0.5505 - val_acc: 0.6500\n",
      "Epoch 1460/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1420 - acc: 0.9873 - val_loss: 0.5531 - val_acc: 0.6500\n",
      "Epoch 1461/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1410 - acc: 0.9873 - val_loss: 0.5507 - val_acc: 0.6500\n",
      "Epoch 1462/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1413 - acc: 0.9873 - val_loss: 0.5488 - val_acc: 0.6500\n",
      "Epoch 1463/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1395 - acc: 0.9873 - val_loss: 0.5500 - val_acc: 0.6500\n",
      "Epoch 1464/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1391 - acc: 0.9873 - val_loss: 0.5489 - val_acc: 0.6500\n",
      "Epoch 1465/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1392 - acc: 0.9873 - val_loss: 0.5503 - val_acc: 0.6500\n",
      "Epoch 1466/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1382 - acc: 0.9873 - val_loss: 0.5503 - val_acc: 0.6500\n",
      "Epoch 1467/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1374 - acc: 0.9873 - val_loss: 0.5498 - val_acc: 0.6500\n",
      "Epoch 1468/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1370 - acc: 0.9873 - val_loss: 0.5521 - val_acc: 0.6500\n",
      "Epoch 1469/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.1379 - acc: 0.9873 - val_loss: 0.5537 - val_acc: 0.6500\n",
      "Epoch 1470/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1378 - acc: 0.9873 - val_loss: 0.5512 - val_acc: 0.6500\n",
      "Epoch 1471/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1355 - acc: 0.9873 - val_loss: 0.5506 - val_acc: 0.6500\n",
      "Epoch 1472/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.1348 - acc: 0.9873 - val_loss: 0.5508 - val_acc: 0.6500\n",
      "Epoch 1473/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1346 - acc: 0.9873 - val_loss: 0.5530 - val_acc: 0.6500\n",
      "Epoch 1474/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1345 - acc: 0.9873 - val_loss: 0.5540 - val_acc: 0.6500\n",
      "Epoch 1475/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1338 - acc: 0.9873 - val_loss: 0.5565 - val_acc: 0.6500\n",
      "Epoch 1476/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1336 - acc: 0.9873 - val_loss: 0.5536 - val_acc: 0.6500\n",
      "Epoch 1477/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1327 - acc: 0.9873 - val_loss: 0.5549 - val_acc: 0.6500\n",
      "Epoch 1478/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1320 - acc: 0.9873 - val_loss: 0.5533 - val_acc: 0.6500\n",
      "Epoch 1479/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1312 - acc: 0.9873 - val_loss: 0.5545 - val_acc: 0.6500\n",
      "Epoch 1480/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1306 - acc: 0.9873 - val_loss: 0.5534 - val_acc: 0.6500\n",
      "Epoch 1481/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1306 - acc: 0.9873 - val_loss: 0.5527 - val_acc: 0.6500\n",
      "Epoch 1482/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1300 - acc: 0.9873 - val_loss: 0.5545 - val_acc: 0.6500\n",
      "Epoch 1483/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.1292 - acc: 0.9873 - val_loss: 0.5543 - val_acc: 0.6500\n",
      "Epoch 1484/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.1290 - acc: 0.9873 - val_loss: 0.5550 - val_acc: 0.6500\n",
      "Epoch 1485/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.1283 - acc: 0.9873 - val_loss: 0.5569 - val_acc: 0.6500\n",
      "Epoch 1486/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1287 - acc: 0.9873 - val_loss: 0.5550 - val_acc: 0.6500\n",
      "Epoch 1487/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1276 - acc: 0.9873 - val_loss: 0.5546 - val_acc: 0.6500\n",
      "Epoch 1488/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.1268 - acc: 0.9873 - val_loss: 0.5555 - val_acc: 0.6500\n",
      "Epoch 1489/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1268 - acc: 0.9873 - val_loss: 0.5545 - val_acc: 0.6500\n",
      "Epoch 1490/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1258 - acc: 0.9873 - val_loss: 0.5559 - val_acc: 0.6500\n",
      "Epoch 1491/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.1252 - acc: 0.9873 - val_loss: 0.5556 - val_acc: 0.6500\n",
      "Epoch 1492/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1254 - acc: 0.9873 - val_loss: 0.5551 - val_acc: 0.6500\n",
      "Epoch 1493/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.1260 - acc: 0.9873 - val_loss: 0.5552 - val_acc: 0.6500\n",
      "Epoch 1494/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.1240 - acc: 0.9873 - val_loss: 0.5552 - val_acc: 0.6500\n",
      "Epoch 1495/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1235 - acc: 0.9873 - val_loss: 0.5553 - val_acc: 0.6500\n",
      "Epoch 1496/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1231 - acc: 0.9873 - val_loss: 0.5549 - val_acc: 0.6500\n",
      "Epoch 1497/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1230 - acc: 0.9873 - val_loss: 0.5590 - val_acc: 0.6500\n",
      "Epoch 1498/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1222 - acc: 0.9873 - val_loss: 0.5609 - val_acc: 0.6500\n",
      "Epoch 1499/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.1218 - acc: 0.9873 - val_loss: 0.5582 - val_acc: 0.6500\n",
      "Epoch 1500/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.1211 - acc: 0.9873 - val_loss: 0.5580 - val_acc: 0.6500\n",
      "Epoch 1501/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.1206 - acc: 0.9873 - val_loss: 0.5578 - val_acc: 0.6500\n",
      "Epoch 1502/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1201 - acc: 0.9873 - val_loss: 0.5590 - val_acc: 0.6500\n",
      "Epoch 1503/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.1202 - acc: 0.9873 - val_loss: 0.5565 - val_acc: 0.6500\n",
      "Epoch 1504/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1194 - acc: 0.9873 - val_loss: 0.5578 - val_acc: 0.6500\n",
      "Epoch 1505/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1189 - acc: 0.9873 - val_loss: 0.5585 - val_acc: 0.6500\n",
      "Epoch 1506/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.1187 - acc: 0.9873 - val_loss: 0.5597 - val_acc: 0.6500\n",
      "Epoch 1507/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.1183 - acc: 0.9873 - val_loss: 0.5587 - val_acc: 0.6500\n",
      "Epoch 1508/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1185 - acc: 0.9873 - val_loss: 0.5565 - val_acc: 0.6500\n",
      "Epoch 1509/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1173 - acc: 0.9873 - val_loss: 0.5578 - val_acc: 0.6500\n",
      "Epoch 1510/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.1181 - acc: 0.9873 - val_loss: 0.5531 - val_acc: 0.7000\n",
      "Epoch 1511/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1162 - acc: 0.9873 - val_loss: 0.5529 - val_acc: 0.7000\n",
      "Epoch 1512/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1168 - acc: 0.9873 - val_loss: 0.5567 - val_acc: 0.7000\n",
      "Epoch 1513/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.1152 - acc: 0.9873 - val_loss: 0.5548 - val_acc: 0.7000\n",
      "Epoch 1514/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1148 - acc: 0.9873 - val_loss: 0.5562 - val_acc: 0.7000\n",
      "Epoch 1515/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1146 - acc: 0.9873 - val_loss: 0.5608 - val_acc: 0.7000\n",
      "Epoch 1516/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.1140 - acc: 0.9873 - val_loss: 0.5589 - val_acc: 0.7000\n",
      "Epoch 1517/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1135 - acc: 0.9873 - val_loss: 0.5579 - val_acc: 0.7000\n",
      "Epoch 1518/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.1129 - acc: 0.9873 - val_loss: 0.5576 - val_acc: 0.7000\n",
      "Epoch 1519/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.1126 - acc: 0.9873 - val_loss: 0.5571 - val_acc: 0.7000\n",
      "Epoch 1520/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.1122 - acc: 0.9873 - val_loss: 0.5589 - val_acc: 0.7000\n",
      "Epoch 1521/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1121 - acc: 0.9873 - val_loss: 0.5559 - val_acc: 0.7000\n",
      "Epoch 1522/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.1115 - acc: 0.9873 - val_loss: 0.5566 - val_acc: 0.7000\n",
      "Epoch 1523/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1111 - acc: 0.9873 - val_loss: 0.5602 - val_acc: 0.7000\n",
      "Epoch 1524/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1104 - acc: 0.9873 - val_loss: 0.5586 - val_acc: 0.7000\n",
      "Epoch 1525/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1101 - acc: 0.9873 - val_loss: 0.5611 - val_acc: 0.7000\n",
      "Epoch 1526/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1096 - acc: 0.9873 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 1527/3000\n",
      "79/79 [==============================] - 0s 215us/sample - loss: 0.1094 - acc: 0.9873 - val_loss: 0.5592 - val_acc: 0.7000\n",
      "Epoch 1528/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.1100 - acc: 0.9873 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 1529/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1085 - acc: 0.9873 - val_loss: 0.5635 - val_acc: 0.7000\n",
      "Epoch 1530/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1082 - acc: 0.9873 - val_loss: 0.5617 - val_acc: 0.7000\n",
      "Epoch 1531/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1087 - acc: 0.9873 - val_loss: 0.5635 - val_acc: 0.7000\n",
      "Epoch 1532/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1072 - acc: 0.9873 - val_loss: 0.5564 - val_acc: 0.7000\n",
      "Epoch 1533/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.1069 - acc: 0.9873 - val_loss: 0.5550 - val_acc: 0.7000\n",
      "Epoch 1534/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1069 - acc: 0.9873 - val_loss: 0.5568 - val_acc: 0.7000\n",
      "Epoch 1535/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1067 - acc: 0.9873 - val_loss: 0.5576 - val_acc: 0.7000\n",
      "Epoch 1536/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1067 - acc: 0.9873 - val_loss: 0.5631 - val_acc: 0.7000\n",
      "Epoch 1537/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.1059 - acc: 0.9873 - val_loss: 0.5594 - val_acc: 0.7000\n",
      "Epoch 1538/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.1057 - acc: 0.9873 - val_loss: 0.5564 - val_acc: 0.7000\n",
      "Epoch 1539/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.1048 - acc: 0.9873 - val_loss: 0.5542 - val_acc: 0.7000\n",
      "Epoch 1540/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.1046 - acc: 0.9873 - val_loss: 0.5569 - val_acc: 0.7000\n",
      "Epoch 1541/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.1034 - acc: 0.9873 - val_loss: 0.5616 - val_acc: 0.7000\n",
      "Epoch 1542/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1033 - acc: 0.9873 - val_loss: 0.5626 - val_acc: 0.7000\n",
      "Epoch 1543/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1031 - acc: 0.9873 - val_loss: 0.5676 - val_acc: 0.7000\n",
      "Epoch 1544/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.1023 - acc: 0.9873 - val_loss: 0.5649 - val_acc: 0.7000\n",
      "Epoch 1545/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.1026 - acc: 0.9873 - val_loss: 0.5650 - val_acc: 0.7000\n",
      "Epoch 1546/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.1017 - acc: 0.9873 - val_loss: 0.5630 - val_acc: 0.7000\n",
      "Epoch 1547/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.1016 - acc: 0.9873 - val_loss: 0.5657 - val_acc: 0.7000\n",
      "Epoch 1548/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1007 - acc: 0.9873 - val_loss: 0.5651 - val_acc: 0.7000\n",
      "Epoch 1549/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.1003 - acc: 0.9873 - val_loss: 0.5643 - val_acc: 0.7000\n",
      "Epoch 1550/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.1000 - acc: 0.9873 - val_loss: 0.5647 - val_acc: 0.7000\n",
      "Epoch 1551/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0998 - acc: 0.9873 - val_loss: 0.5642 - val_acc: 0.7000\n",
      "Epoch 1552/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.1000 - acc: 0.9873 - val_loss: 0.5623 - val_acc: 0.6500\n",
      "Epoch 1553/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0994 - acc: 0.9873 - val_loss: 0.5623 - val_acc: 0.6500\n",
      "Epoch 1554/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0988 - acc: 0.9873 - val_loss: 0.5626 - val_acc: 0.6500\n",
      "Epoch 1555/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0989 - acc: 0.9873 - val_loss: 0.5684 - val_acc: 0.7000\n",
      "Epoch 1556/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0982 - acc: 0.9873 - val_loss: 0.5690 - val_acc: 0.7000\n",
      "Epoch 1557/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0975 - acc: 0.9873 - val_loss: 0.5680 - val_acc: 0.7000\n",
      "Epoch 1558/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0976 - acc: 0.9873 - val_loss: 0.5681 - val_acc: 0.7000\n",
      "Epoch 1559/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0968 - acc: 0.9873 - val_loss: 0.5667 - val_acc: 0.7000\n",
      "Epoch 1560/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0968 - acc: 0.9873 - val_loss: 0.5702 - val_acc: 0.7000\n",
      "Epoch 1561/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0963 - acc: 0.9873 - val_loss: 0.5694 - val_acc: 0.7000\n",
      "Epoch 1562/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0954 - acc: 0.9873 - val_loss: 0.5688 - val_acc: 0.7000\n",
      "Epoch 1563/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0951 - acc: 0.9873 - val_loss: 0.5690 - val_acc: 0.7000\n",
      "Epoch 1564/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0947 - acc: 0.9873 - val_loss: 0.5692 - val_acc: 0.7000\n",
      "Epoch 1565/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0945 - acc: 0.9873 - val_loss: 0.5674 - val_acc: 0.7000\n",
      "Epoch 1566/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0941 - acc: 0.9873 - val_loss: 0.5684 - val_acc: 0.7000\n",
      "Epoch 1567/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0939 - acc: 0.9873 - val_loss: 0.5675 - val_acc: 0.7000\n",
      "Epoch 1568/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0936 - acc: 0.9873 - val_loss: 0.5662 - val_acc: 0.6500\n",
      "Epoch 1569/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0930 - acc: 0.9873 - val_loss: 0.5674 - val_acc: 0.7000\n",
      "Epoch 1570/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0927 - acc: 0.9873 - val_loss: 0.5677 - val_acc: 0.7000\n",
      "Epoch 1571/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0929 - acc: 0.9873 - val_loss: 0.5699 - val_acc: 0.7000\n",
      "Epoch 1572/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0927 - acc: 0.9873 - val_loss: 0.5716 - val_acc: 0.7000\n",
      "Epoch 1573/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0917 - acc: 0.9873 - val_loss: 0.5697 - val_acc: 0.7000\n",
      "Epoch 1574/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0915 - acc: 0.9873 - val_loss: 0.5693 - val_acc: 0.7000\n",
      "Epoch 1575/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0910 - acc: 0.9873 - val_loss: 0.5703 - val_acc: 0.7000\n",
      "Epoch 1576/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0908 - acc: 0.9873 - val_loss: 0.5729 - val_acc: 0.7000\n",
      "Epoch 1577/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0906 - acc: 0.9873 - val_loss: 0.5748 - val_acc: 0.7000\n",
      "Epoch 1578/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0901 - acc: 0.9873 - val_loss: 0.5756 - val_acc: 0.7000\n",
      "Epoch 1579/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0895 - acc: 1.0000 - val_loss: 0.5745 - val_acc: 0.7000\n",
      "Epoch 1580/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0891 - acc: 0.9873 - val_loss: 0.5745 - val_acc: 0.7000\n",
      "Epoch 1581/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0889 - acc: 0.9873 - val_loss: 0.5726 - val_acc: 0.7000\n",
      "Epoch 1582/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0884 - acc: 0.9873 - val_loss: 0.5742 - val_acc: 0.7000\n",
      "Epoch 1583/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0889 - acc: 0.9873 - val_loss: 0.5699 - val_acc: 0.6500\n",
      "Epoch 1584/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0883 - acc: 0.9873 - val_loss: 0.5698 - val_acc: 0.6500\n",
      "Epoch 1585/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0882 - acc: 0.9873 - val_loss: 0.5737 - val_acc: 0.7000\n",
      "Epoch 1586/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0872 - acc: 0.9873 - val_loss: 0.5729 - val_acc: 0.7000\n",
      "Epoch 1587/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0868 - acc: 0.9873 - val_loss: 0.5739 - val_acc: 0.7000\n",
      "Epoch 1588/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0865 - acc: 0.9873 - val_loss: 0.5727 - val_acc: 0.7000\n",
      "Epoch 1589/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0865 - acc: 0.9873 - val_loss: 0.5756 - val_acc: 0.7000\n",
      "Epoch 1590/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0863 - acc: 1.0000 - val_loss: 0.5770 - val_acc: 0.7000\n",
      "Epoch 1591/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0860 - acc: 0.9873 - val_loss: 0.5796 - val_acc: 0.7000\n",
      "Epoch 1592/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0853 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.7000\n",
      "Epoch 1593/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.5782 - val_acc: 0.7000\n",
      "Epoch 1594/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0856 - acc: 1.0000 - val_loss: 0.5833 - val_acc: 0.7000\n",
      "Epoch 1595/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0847 - acc: 1.0000 - val_loss: 0.5779 - val_acc: 0.7000\n",
      "Epoch 1596/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0840 - acc: 1.0000 - val_loss: 0.5754 - val_acc: 0.7000\n",
      "Epoch 1597/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0835 - acc: 1.0000 - val_loss: 0.5739 - val_acc: 0.7000\n",
      "Epoch 1598/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0834 - acc: 1.0000 - val_loss: 0.5721 - val_acc: 0.6500\n",
      "Epoch 1599/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0832 - acc: 0.9873 - val_loss: 0.5745 - val_acc: 0.7000\n",
      "Epoch 1600/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0825 - acc: 1.0000 - val_loss: 0.5758 - val_acc: 0.7000\n",
      "Epoch 1601/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0822 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.7000\n",
      "Epoch 1602/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0821 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.7000\n",
      "Epoch 1603/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0830 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.7000\n",
      "Epoch 1604/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0821 - acc: 1.0000 - val_loss: 0.5814 - val_acc: 0.7000\n",
      "Epoch 1605/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.7000\n",
      "Epoch 1606/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0808 - acc: 1.0000 - val_loss: 0.5798 - val_acc: 0.7000\n",
      "Epoch 1607/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0804 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.7000\n",
      "Epoch 1608/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.7000\n",
      "Epoch 1609/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0797 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.7000\n",
      "Epoch 1610/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0799 - acc: 1.0000 - val_loss: 0.5796 - val_acc: 0.7000\n",
      "Epoch 1611/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0794 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 1612/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0788 - acc: 1.0000 - val_loss: 0.5752 - val_acc: 0.7000\n",
      "Epoch 1613/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0780 - acc: 1.0000 - val_loss: 0.5761 - val_acc: 0.7000\n",
      "Epoch 1614/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0777 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 1615/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0776 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.7000\n",
      "Epoch 1616/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.5762 - val_acc: 0.7000\n",
      "Epoch 1617/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0768 - acc: 1.0000 - val_loss: 0.5766 - val_acc: 0.7000\n",
      "Epoch 1618/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0766 - acc: 1.0000 - val_loss: 0.5768 - val_acc: 0.7000\n",
      "Epoch 1619/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0767 - acc: 1.0000 - val_loss: 0.5814 - val_acc: 0.7000\n",
      "Epoch 1620/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0763 - acc: 1.0000 - val_loss: 0.5825 - val_acc: 0.7000\n",
      "Epoch 1621/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0760 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.7000\n",
      "Epoch 1622/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0757 - acc: 1.0000 - val_loss: 0.5822 - val_acc: 0.7000\n",
      "Epoch 1623/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.5771 - val_acc: 0.7000\n",
      "Epoch 1624/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.5779 - val_acc: 0.7000\n",
      "Epoch 1625/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0750 - acc: 1.0000 - val_loss: 0.5822 - val_acc: 0.7000\n",
      "Epoch 1626/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0752 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.7000\n",
      "Epoch 1627/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.7000\n",
      "Epoch 1628/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.5784 - val_acc: 0.7000\n",
      "Epoch 1629/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.7000\n",
      "Epoch 1630/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.5856 - val_acc: 0.7000\n",
      "Epoch 1631/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0737 - acc: 1.0000 - val_loss: 0.5756 - val_acc: 0.7000\n",
      "Epoch 1632/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 0.5741 - val_acc: 0.7000\n",
      "Epoch 1633/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.5750 - val_acc: 0.7000\n",
      "Epoch 1634/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0732 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.7000\n",
      "Epoch 1635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0730 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.7000\n",
      "Epoch 1636/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0728 - acc: 1.0000 - val_loss: 0.5770 - val_acc: 0.7000\n",
      "Epoch 1637/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.7000\n",
      "Epoch 1638/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 0.5811 - val_acc: 0.7000\n",
      "Epoch 1639/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.7000\n",
      "Epoch 1640/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0715 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.7000\n",
      "Epoch 1641/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.5781 - val_acc: 0.7000\n",
      "Epoch 1642/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0709 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.7000\n",
      "Epoch 1643/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.7000\n",
      "Epoch 1644/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0703 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.7000\n",
      "Epoch 1645/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0703 - acc: 1.0000 - val_loss: 0.5757 - val_acc: 0.7000\n",
      "Epoch 1646/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0704 - acc: 1.0000 - val_loss: 0.5784 - val_acc: 0.7000\n",
      "Epoch 1647/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0696 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.7000\n",
      "Epoch 1648/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.5776 - val_acc: 0.7000\n",
      "Epoch 1649/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0691 - acc: 1.0000 - val_loss: 0.5787 - val_acc: 0.7000\n",
      "Epoch 1650/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.5795 - val_acc: 0.7000\n",
      "Epoch 1651/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.5779 - val_acc: 0.7000\n",
      "Epoch 1652/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0689 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.7000\n",
      "Epoch 1653/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.5776 - val_acc: 0.7000\n",
      "Epoch 1654/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.5795 - val_acc: 0.7000\n",
      "Epoch 1655/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0680 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.7000\n",
      "Epoch 1656/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0676 - acc: 1.0000 - val_loss: 0.5810 - val_acc: 0.7000\n",
      "Epoch 1657/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0673 - acc: 1.0000 - val_loss: 0.5800 - val_acc: 0.7000\n",
      "Epoch 1658/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0670 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.7000\n",
      "Epoch 1659/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0669 - acc: 1.0000 - val_loss: 0.5832 - val_acc: 0.7000\n",
      "Epoch 1660/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0666 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.7000\n",
      "Epoch 1661/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0664 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.7000\n",
      "Epoch 1662/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0661 - acc: 1.0000 - val_loss: 0.5810 - val_acc: 0.7000\n",
      "Epoch 1663/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.7000\n",
      "Epoch 1664/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.7000\n",
      "Epoch 1665/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0653 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.7000\n",
      "Epoch 1666/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0651 - acc: 1.0000 - val_loss: 0.5824 - val_acc: 0.7000\n",
      "Epoch 1667/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0653 - acc: 1.0000 - val_loss: 0.5843 - val_acc: 0.7000\n",
      "Epoch 1668/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0646 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.7000\n",
      "Epoch 1669/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0645 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.7000\n",
      "Epoch 1670/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0646 - acc: 1.0000 - val_loss: 0.5822 - val_acc: 0.7000\n",
      "Epoch 1671/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0638 - acc: 1.0000 - val_loss: 0.5847 - val_acc: 0.7000\n",
      "Epoch 1672/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.5897 - val_acc: 0.7000\n",
      "Epoch 1673/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.7000\n",
      "Epoch 1674/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.5876 - val_acc: 0.7000\n",
      "Epoch 1675/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.5862 - val_acc: 0.7000\n",
      "Epoch 1676/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.5891 - val_acc: 0.7000\n",
      "Epoch 1677/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0625 - acc: 1.0000 - val_loss: 0.5883 - val_acc: 0.7000\n",
      "Epoch 1678/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.5878 - val_acc: 0.7000\n",
      "Epoch 1679/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.7000\n",
      "Epoch 1680/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.5872 - val_acc: 0.7000\n",
      "Epoch 1681/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.5885 - val_acc: 0.7000\n",
      "Epoch 1682/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0616 - acc: 1.0000 - val_loss: 0.5929 - val_acc: 0.7000\n",
      "Epoch 1683/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.7000\n",
      "Epoch 1684/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0608 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.7000\n",
      "Epoch 1685/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.5885 - val_acc: 0.7000\n",
      "Epoch 1686/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.5895 - val_acc: 0.7000\n",
      "Epoch 1687/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0604 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.7000\n",
      "Epoch 1688/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0602 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.7000\n",
      "Epoch 1689/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.5929 - val_acc: 0.7000\n",
      "Epoch 1690/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.7000\n",
      "Epoch 1691/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0594 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7000\n",
      "Epoch 1692/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 0.5921 - val_acc: 0.7000\n",
      "Epoch 1693/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.7000\n",
      "Epoch 1694/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.5917 - val_acc: 0.7000\n",
      "Epoch 1695/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.5908 - val_acc: 0.7000\n",
      "Epoch 1696/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0584 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.7000\n",
      "Epoch 1697/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0583 - acc: 1.0000 - val_loss: 0.5906 - val_acc: 0.7000\n",
      "Epoch 1698/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.7000\n",
      "Epoch 1699/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.7000\n",
      "Epoch 1700/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.7000\n",
      "Epoch 1701/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0574 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.7000\n",
      "Epoch 1702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7000\n",
      "Epoch 1703/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7000\n",
      "Epoch 1704/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.7000\n",
      "Epoch 1705/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0567 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7000\n",
      "Epoch 1706/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.7000\n",
      "Epoch 1707/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0564 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.7000\n",
      "Epoch 1708/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7000\n",
      "Epoch 1709/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.7000\n",
      "Epoch 1710/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0562 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.7000\n",
      "Epoch 1711/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.7000\n",
      "Epoch 1712/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.7000\n",
      "Epoch 1713/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0552 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7000\n",
      "Epoch 1714/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.7000\n",
      "Epoch 1715/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7000\n",
      "Epoch 1716/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0550 - acc: 1.0000 - val_loss: 0.5988 - val_acc: 0.7000\n",
      "Epoch 1717/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0546 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.7000\n",
      "Epoch 1718/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0543 - acc: 1.0000 - val_loss: 0.5994 - val_acc: 0.7000\n",
      "Epoch 1719/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.7000\n",
      "Epoch 1720/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.7000\n",
      "Epoch 1721/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.7000\n",
      "Epoch 1722/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.5992 - val_acc: 0.7000\n",
      "Epoch 1723/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.5995 - val_acc: 0.7000\n",
      "Epoch 1724/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.7000\n",
      "Epoch 1725/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.7000\n",
      "Epoch 1726/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.7000\n",
      "Epoch 1727/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0528 - acc: 1.0000 - val_loss: 0.5996 - val_acc: 0.7000\n",
      "Epoch 1728/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.5998 - val_acc: 0.7000\n",
      "Epoch 1729/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.6020 - val_acc: 0.7000\n",
      "Epoch 1730/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.7000\n",
      "Epoch 1731/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.6017 - val_acc: 0.7000\n",
      "Epoch 1732/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.6026 - val_acc: 0.7000\n",
      "Epoch 1733/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.7000\n",
      "Epoch 1734/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.6034 - val_acc: 0.7000\n",
      "Epoch 1735/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.7000\n",
      "Epoch 1736/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.6007 - val_acc: 0.7000\n",
      "Epoch 1737/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.7000\n",
      "Epoch 1738/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0510 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.7000\n",
      "Epoch 1739/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7000\n",
      "Epoch 1740/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0509 - acc: 1.0000 - val_loss: 0.6032 - val_acc: 0.7000\n",
      "Epoch 1741/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.6039 - val_acc: 0.7000\n",
      "Epoch 1742/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0503 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 1743/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 1744/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.7000\n",
      "Epoch 1745/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.7000\n",
      "Epoch 1746/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0498 - acc: 1.0000 - val_loss: 0.6059 - val_acc: 0.7000\n",
      "Epoch 1747/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.7000\n",
      "Epoch 1748/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.6035 - val_acc: 0.7000\n",
      "Epoch 1749/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.6031 - val_acc: 0.7000\n",
      "Epoch 1750/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.6051 - val_acc: 0.7000\n",
      "Epoch 1751/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0490 - acc: 1.0000 - val_loss: 0.6042 - val_acc: 0.7000\n",
      "Epoch 1752/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.7000\n",
      "Epoch 1753/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0486 - acc: 1.0000 - val_loss: 0.6048 - val_acc: 0.7000\n",
      "Epoch 1754/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.7000\n",
      "Epoch 1755/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0483 - acc: 1.0000 - val_loss: 0.6048 - val_acc: 0.7000\n",
      "Epoch 1756/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.7000\n",
      "Epoch 1757/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7000\n",
      "Epoch 1758/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.7000\n",
      "Epoch 1759/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.7000\n",
      "Epoch 1760/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.6071 - val_acc: 0.7000\n",
      "Epoch 1761/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0475 - acc: 1.0000 - val_loss: 0.6081 - val_acc: 0.7000\n",
      "Epoch 1762/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.6090 - val_acc: 0.7000\n",
      "Epoch 1763/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.7000\n",
      "Epoch 1764/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0471 - acc: 1.0000 - val_loss: 0.6116 - val_acc: 0.7000\n",
      "Epoch 1765/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.6095 - val_acc: 0.7000\n",
      "Epoch 1766/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0467 - acc: 1.0000 - val_loss: 0.6117 - val_acc: 0.7000\n",
      "Epoch 1767/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.7000\n",
      "Epoch 1768/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.7000\n",
      "Epoch 1769/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.6101 - val_acc: 0.7000\n",
      "Epoch 1770/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.6110 - val_acc: 0.7000\n",
      "Epoch 1771/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.6138 - val_acc: 0.7000\n",
      "Epoch 1772/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0459 - acc: 1.0000 - val_loss: 0.6119 - val_acc: 0.7000\n",
      "Epoch 1773/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.6122 - val_acc: 0.7000\n",
      "Epoch 1774/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.6129 - val_acc: 0.7000\n",
      "Epoch 1775/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.6100 - val_acc: 0.7000\n",
      "Epoch 1776/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.6124 - val_acc: 0.7000\n",
      "Epoch 1777/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0450 - acc: 1.0000 - val_loss: 0.6118 - val_acc: 0.7000\n",
      "Epoch 1778/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.7000\n",
      "Epoch 1779/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0448 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.7000\n",
      "Epoch 1780/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.7000\n",
      "Epoch 1781/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.7000\n",
      "Epoch 1782/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.7000\n",
      "Epoch 1783/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.7000\n",
      "Epoch 1784/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.6109 - val_acc: 0.7000\n",
      "Epoch 1785/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0443 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.7000\n",
      "Epoch 1786/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.7000\n",
      "Epoch 1787/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.7000\n",
      "Epoch 1788/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.6155 - val_acc: 0.7000\n",
      "Epoch 1789/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.6161 - val_acc: 0.7000\n",
      "Epoch 1790/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.7000\n",
      "Epoch 1791/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.6145 - val_acc: 0.7000\n",
      "Epoch 1792/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0431 - acc: 1.0000 - val_loss: 0.6156 - val_acc: 0.7000\n",
      "Epoch 1793/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.6153 - val_acc: 0.7000\n",
      "Epoch 1794/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.7000\n",
      "Epoch 1795/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0428 - acc: 1.0000 - val_loss: 0.6132 - val_acc: 0.7000\n",
      "Epoch 1796/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.6138 - val_acc: 0.7000\n",
      "Epoch 1797/3000\n",
      "79/79 [==============================] - 0s 147us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.7000\n",
      "Epoch 1798/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.6167 - val_acc: 0.7000\n",
      "Epoch 1799/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0421 - acc: 1.0000 - val_loss: 0.6153 - val_acc: 0.7000\n",
      "Epoch 1800/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.6145 - val_acc: 0.7000\n",
      "Epoch 1801/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.6156 - val_acc: 0.7000\n",
      "Epoch 1802/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.7000\n",
      "Epoch 1803/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.6175 - val_acc: 0.7000\n",
      "Epoch 1804/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.7000\n",
      "Epoch 1805/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.7000\n",
      "Epoch 1806/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.7000\n",
      "Epoch 1807/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.6190 - val_acc: 0.7000\n",
      "Epoch 1808/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.6182 - val_acc: 0.7000\n",
      "Epoch 1809/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0408 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.7000\n",
      "Epoch 1810/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0408 - acc: 1.0000 - val_loss: 0.6180 - val_acc: 0.7000\n",
      "Epoch 1811/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.7000\n",
      "Epoch 1812/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0408 - acc: 1.0000 - val_loss: 0.6190 - val_acc: 0.7000\n",
      "Epoch 1813/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.7000\n",
      "Epoch 1814/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.7000\n",
      "Epoch 1815/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.7000\n",
      "Epoch 1816/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.7000\n",
      "Epoch 1817/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.7000\n",
      "Epoch 1818/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.7000\n",
      "Epoch 1819/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.7000\n",
      "Epoch 1820/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0396 - acc: 1.0000 - val_loss: 0.6198 - val_acc: 0.7000\n",
      "Epoch 1821/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.6201 - val_acc: 0.7000\n",
      "Epoch 1822/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.6198 - val_acc: 0.7000\n",
      "Epoch 1823/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.7000\n",
      "Epoch 1824/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0392 - acc: 1.0000 - val_loss: 0.6200 - val_acc: 0.7000\n",
      "Epoch 1825/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.7000\n",
      "Epoch 1826/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.6202 - val_acc: 0.7000\n",
      "Epoch 1827/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.6221 - val_acc: 0.7000\n",
      "Epoch 1828/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.6220 - val_acc: 0.7000\n",
      "Epoch 1829/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.7000\n",
      "Epoch 1830/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.7000\n",
      "Epoch 1831/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.7000\n",
      "Epoch 1832/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.7000\n",
      "Epoch 1833/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.6221 - val_acc: 0.7000\n",
      "Epoch 1834/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.7000\n",
      "Epoch 1835/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.7000\n",
      "Epoch 1836/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.6210 - val_acc: 0.7000\n",
      "Epoch 1837/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.6214 - val_acc: 0.7000\n",
      "Epoch 1838/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 0.6232 - val_acc: 0.7000\n",
      "Epoch 1839/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.6242 - val_acc: 0.7000\n",
      "Epoch 1840/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.7000\n",
      "Epoch 1841/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 0.7000\n",
      "Epoch 1842/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.6273 - val_acc: 0.7000\n",
      "Epoch 1843/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.6263 - val_acc: 0.7000\n",
      "Epoch 1844/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.6247 - val_acc: 0.7000\n",
      "Epoch 1845/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.6245 - val_acc: 0.7000\n",
      "Epoch 1846/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.7000\n",
      "Epoch 1847/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 0.7000\n",
      "Epoch 1848/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 0.7000\n",
      "Epoch 1849/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 0.7000\n",
      "Epoch 1850/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.6194 - val_acc: 0.7000\n",
      "Epoch 1851/3000\n",
      "79/79 [==============================] - 0s 166us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.6240 - val_acc: 0.7000\n",
      "Epoch 1852/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.7000\n",
      "Epoch 1853/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.6261 - val_acc: 0.7000\n",
      "Epoch 1854/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.7000\n",
      "Epoch 1855/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.6265 - val_acc: 0.7000\n",
      "Epoch 1856/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.7000\n",
      "Epoch 1857/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.7000\n",
      "Epoch 1858/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 0.7000\n",
      "Epoch 1859/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.7000\n",
      "Epoch 1860/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.6303 - val_acc: 0.7000\n",
      "Epoch 1861/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.6300 - val_acc: 0.7000\n",
      "Epoch 1862/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.6309 - val_acc: 0.7000\n",
      "Epoch 1863/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.6293 - val_acc: 0.7000\n",
      "Epoch 1864/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.7000\n",
      "Epoch 1865/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.6292 - val_acc: 0.7000\n",
      "Epoch 1866/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.7000\n",
      "Epoch 1867/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 0.7000\n",
      "Epoch 1868/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 0.7000\n",
      "Epoch 1869/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.7000\n",
      "Epoch 1870/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.6303 - val_acc: 0.7000\n",
      "Epoch 1871/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 0.7000\n",
      "Epoch 1872/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 0.7000\n",
      "Epoch 1873/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.6318 - val_acc: 0.7000\n",
      "Epoch 1874/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.7000\n",
      "Epoch 1875/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 0.7000\n",
      "Epoch 1876/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 0.7000\n",
      "Epoch 1877/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.6332 - val_acc: 0.7000\n",
      "Epoch 1878/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 0.7000\n",
      "Epoch 1879/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 0.7000\n",
      "Epoch 1880/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 0.7000\n",
      "Epoch 1881/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.7000\n",
      "Epoch 1882/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0333 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 0.7000\n",
      "Epoch 1883/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 0.6328 - val_acc: 0.7000\n",
      "Epoch 1884/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.6329 - val_acc: 0.7000\n",
      "Epoch 1885/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.7000\n",
      "Epoch 1886/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 0.7000\n",
      "Epoch 1887/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 0.7000\n",
      "Epoch 1888/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 0.7000\n",
      "Epoch 1889/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.7000\n",
      "Epoch 1890/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.7000\n",
      "Epoch 1891/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0448 - acc: 1.000 - 0s 126us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 0.7000\n",
      "Epoch 1892/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.7000\n",
      "Epoch 1893/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.7000\n",
      "Epoch 1894/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 0.7000\n",
      "Epoch 1895/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.6377 - val_acc: 0.7000\n",
      "Epoch 1896/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.7000\n",
      "Epoch 1897/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.7000\n",
      "Epoch 1898/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.7000\n",
      "Epoch 1899/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.6360 - val_acc: 0.7000\n",
      "Epoch 1900/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.7000\n",
      "Epoch 1901/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.7000\n",
      "Epoch 1902/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.7000\n",
      "Epoch 1903/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 0.7000\n",
      "Epoch 1904/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.6386 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1905/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.7000\n",
      "Epoch 1906/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.7000\n",
      "Epoch 1907/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.7000\n",
      "Epoch 1908/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.7000\n",
      "Epoch 1909/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 0.7000\n",
      "Epoch 1910/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.7000\n",
      "Epoch 1911/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.7000\n",
      "Epoch 1912/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.7000\n",
      "Epoch 1913/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.7000\n",
      "Epoch 1914/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.7000\n",
      "Epoch 1915/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 0.7000\n",
      "Epoch 1916/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.7000\n",
      "Epoch 1917/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.7000\n",
      "Epoch 1918/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.7000\n",
      "Epoch 1919/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.7000\n",
      "Epoch 1920/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.6368 - val_acc: 0.7000\n",
      "Epoch 1921/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.7000\n",
      "Epoch 1922/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 0.7000\n",
      "Epoch 1923/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 0.7000\n",
      "Epoch 1924/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.7000\n",
      "Epoch 1925/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.6408 - val_acc: 0.7000\n",
      "Epoch 1926/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.7000\n",
      "Epoch 1927/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.7000\n",
      "Epoch 1928/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.6422 - val_acc: 0.7000\n",
      "Epoch 1929/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.7000\n",
      "Epoch 1930/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.7000\n",
      "Epoch 1931/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.7000\n",
      "Epoch 1932/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.7000\n",
      "Epoch 1933/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.7000\n",
      "Epoch 1934/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.6447 - val_acc: 0.7000\n",
      "Epoch 1935/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.7000\n",
      "Epoch 1936/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.7000\n",
      "Epoch 1937/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.6465 - val_acc: 0.7000\n",
      "Epoch 1938/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.6471 - val_acc: 0.7000\n",
      "Epoch 1939/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.7000\n",
      "Epoch 1940/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.7000\n",
      "Epoch 1941/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.7000\n",
      "Epoch 1942/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 1943/3000\n",
      "79/79 [==============================] - 0s 159us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.7000\n",
      "Epoch 1944/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.6476 - val_acc: 0.7000\n",
      "Epoch 1945/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.7000\n",
      "Epoch 1946/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.7000\n",
      "Epoch 1947/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.6465 - val_acc: 0.7000\n",
      "Epoch 1948/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 1949/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.7000\n",
      "Epoch 1950/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.6471 - val_acc: 0.7000\n",
      "Epoch 1951/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.7000\n",
      "Epoch 1952/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.7000\n",
      "Epoch 1953/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.7000\n",
      "Epoch 1954/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.6464 - val_acc: 0.7000\n",
      "Epoch 1955/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.7000\n",
      "Epoch 1956/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 1957/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 1958/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.7000\n",
      "Epoch 1959/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.6468 - val_acc: 0.7000\n",
      "Epoch 1960/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.7000\n",
      "Epoch 1961/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.6492 - val_acc: 0.7000\n",
      "Epoch 1962/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.7000\n",
      "Epoch 1963/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1964/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.7000\n",
      "Epoch 1965/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.7000\n",
      "Epoch 1966/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.7000\n",
      "Epoch 1967/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.7000\n",
      "Epoch 1968/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.7000\n",
      "Epoch 1969/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.7000\n",
      "Epoch 1970/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.7000\n",
      "Epoch 1971/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.7000\n",
      "Epoch 1972/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.6502 - val_acc: 0.7000\n",
      "Epoch 1973/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.7000\n",
      "Epoch 1974/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.6491 - val_acc: 0.7000\n",
      "Epoch 1975/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.7000\n",
      "Epoch 1976/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.7000\n",
      "Epoch 1977/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.7000\n",
      "Epoch 1978/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.6521 - val_acc: 0.7000\n",
      "Epoch 1979/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.7000\n",
      "Epoch 1980/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 0.7000\n",
      "Epoch 1981/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.6531 - val_acc: 0.7000\n",
      "Epoch 1982/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.7000\n",
      "Epoch 1983/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.7000\n",
      "Epoch 1984/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.7000\n",
      "Epoch 1985/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.7000\n",
      "Epoch 1986/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.7000\n",
      "Epoch 1987/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.7000\n",
      "Epoch 1988/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.7000\n",
      "Epoch 1989/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.6548 - val_acc: 0.7000\n",
      "Epoch 1990/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.7000\n",
      "Epoch 1991/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.7000\n",
      "Epoch 1992/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.7000\n",
      "Epoch 1993/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.7000\n",
      "Epoch 1994/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6557 - val_acc: 0.7000\n",
      "Epoch 1995/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6564 - val_acc: 0.7000\n",
      "Epoch 1996/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.7000\n",
      "Epoch 1997/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.6570 - val_acc: 0.7000\n",
      "Epoch 1998/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.6572 - val_acc: 0.7000\n",
      "Epoch 1999/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.7000\n",
      "Epoch 2000/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.7000\n",
      "Epoch 2001/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.7000\n",
      "Epoch 2002/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.7000\n",
      "Epoch 2003/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6565 - val_acc: 0.7000\n",
      "Epoch 2004/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6574 - val_acc: 0.7000\n",
      "Epoch 2005/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.6574 - val_acc: 0.7000\n",
      "Epoch 2006/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.6586 - val_acc: 0.7000\n",
      "Epoch 2007/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.6592 - val_acc: 0.7000\n",
      "Epoch 2008/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.6599 - val_acc: 0.7000\n",
      "Epoch 2009/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.6587 - val_acc: 0.7000\n",
      "Epoch 2010/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.7000\n",
      "Epoch 2011/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6575 - val_acc: 0.7000\n",
      "Epoch 2012/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.7000\n",
      "Epoch 2013/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6581 - val_acc: 0.7000\n",
      "Epoch 2014/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.7000\n",
      "Epoch 2015/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.7000\n",
      "Epoch 2016/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.6580 - val_acc: 0.7000\n",
      "Epoch 2017/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 0.7000\n",
      "Epoch 2018/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.7000\n",
      "Epoch 2019/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.7000\n",
      "Epoch 2020/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.7000\n",
      "Epoch 2021/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6609 - val_acc: 0.7000\n",
      "Epoch 2022/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2023/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.7000\n",
      "Epoch 2024/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.7000\n",
      "Epoch 2025/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6634 - val_acc: 0.7000\n",
      "Epoch 2026/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.6629 - val_acc: 0.7000\n",
      "Epoch 2027/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 0.7000\n",
      "Epoch 2028/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6636 - val_acc: 0.7000\n",
      "Epoch 2029/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 0.7000\n",
      "Epoch 2030/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.7000\n",
      "Epoch 2031/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 0.7000\n",
      "Epoch 2032/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.7000\n",
      "Epoch 2033/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.7000\n",
      "Epoch 2034/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.6654 - val_acc: 0.7000\n",
      "Epoch 2035/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.7000\n",
      "Epoch 2036/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.7000\n",
      "Epoch 2037/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6647 - val_acc: 0.7000\n",
      "Epoch 2038/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6642 - val_acc: 0.7000\n",
      "Epoch 2039/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.7000\n",
      "Epoch 2040/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6646 - val_acc: 0.7000\n",
      "Epoch 2041/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.7000\n",
      "Epoch 2042/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.7000\n",
      "Epoch 2043/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.7000\n",
      "Epoch 2044/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.7000\n",
      "Epoch 2045/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6651 - val_acc: 0.7000\n",
      "Epoch 2046/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6671 - val_acc: 0.7000\n",
      "Epoch 2047/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 0.7000\n",
      "Epoch 2048/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.7000\n",
      "Epoch 2049/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.6680 - val_acc: 0.7000\n",
      "Epoch 2050/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.7000\n",
      "Epoch 2051/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.6675 - val_acc: 0.7000\n",
      "Epoch 2052/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.7000\n",
      "Epoch 2053/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.7000\n",
      "Epoch 2054/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6666 - val_acc: 0.7000\n",
      "Epoch 2055/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.7000\n",
      "Epoch 2056/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.7000\n",
      "Epoch 2057/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.7000\n",
      "Epoch 2058/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6692 - val_acc: 0.7000\n",
      "Epoch 2059/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.7000\n",
      "Epoch 2060/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.7000\n",
      "Epoch 2061/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6694 - val_acc: 0.7000\n",
      "Epoch 2062/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6702 - val_acc: 0.7000\n",
      "Epoch 2063/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.6709 - val_acc: 0.7000\n",
      "Epoch 2064/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6716 - val_acc: 0.7000\n",
      "Epoch 2065/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.7000\n",
      "Epoch 2066/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.6706 - val_acc: 0.7000\n",
      "Epoch 2067/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6706 - val_acc: 0.7000\n",
      "Epoch 2068/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.7000\n",
      "Epoch 2069/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.7000\n",
      "Epoch 2070/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.7000\n",
      "Epoch 2071/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6702 - val_acc: 0.7000\n",
      "Epoch 2072/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6705 - val_acc: 0.7000\n",
      "Epoch 2073/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6705 - val_acc: 0.7000\n",
      "Epoch 2074/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.7000\n",
      "Epoch 2075/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 0.7000\n",
      "Epoch 2076/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6731 - val_acc: 0.7000\n",
      "Epoch 2077/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6728 - val_acc: 0.7000\n",
      "Epoch 2078/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.6731 - val_acc: 0.7000\n",
      "Epoch 2079/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.6725 - val_acc: 0.7000\n",
      "Epoch 2080/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.6739 - val_acc: 0.7000\n",
      "Epoch 2081/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6747 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2082/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.7000\n",
      "Epoch 2083/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6729 - val_acc: 0.7000\n",
      "Epoch 2084/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6743 - val_acc: 0.7000\n",
      "Epoch 2085/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6754 - val_acc: 0.7000\n",
      "Epoch 2086/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6747 - val_acc: 0.7000\n",
      "Epoch 2087/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.7000\n",
      "Epoch 2088/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.7000\n",
      "Epoch 2089/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.7000\n",
      "Epoch 2090/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6776 - val_acc: 0.7000\n",
      "Epoch 2091/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.7000\n",
      "Epoch 2092/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.7000\n",
      "Epoch 2093/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.7000\n",
      "Epoch 2094/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6774 - val_acc: 0.7000\n",
      "Epoch 2095/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6765 - val_acc: 0.7000\n",
      "Epoch 2096/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 0.7000\n",
      "Epoch 2097/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.7000\n",
      "Epoch 2098/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.7000\n",
      "Epoch 2099/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.7000\n",
      "Epoch 2100/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6760 - val_acc: 0.7000\n",
      "Epoch 2101/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6760 - val_acc: 0.7000\n",
      "Epoch 2102/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 0.7000\n",
      "Epoch 2103/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6773 - val_acc: 0.7000\n",
      "Epoch 2104/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6767 - val_acc: 0.7000\n",
      "Epoch 2105/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.6763 - val_acc: 0.7000\n",
      "Epoch 2106/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6762 - val_acc: 0.7000\n",
      "Epoch 2107/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.7000\n",
      "Epoch 2108/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6778 - val_acc: 0.7000\n",
      "Epoch 2109/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 2110/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.7000\n",
      "Epoch 2111/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.7000\n",
      "Epoch 2112/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.7000\n",
      "Epoch 2113/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.7000\n",
      "Epoch 2114/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.7000\n",
      "Epoch 2115/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6783 - val_acc: 0.7000\n",
      "Epoch 2116/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6792 - val_acc: 0.7000\n",
      "Epoch 2117/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6790 - val_acc: 0.7000\n",
      "Epoch 2118/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6789 - val_acc: 0.7000\n",
      "Epoch 2119/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.7000\n",
      "Epoch 2120/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.7000\n",
      "Epoch 2121/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6785 - val_acc: 0.7000\n",
      "Epoch 2122/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 2123/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 2124/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 2125/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6784 - val_acc: 0.7000\n",
      "Epoch 2126/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 2127/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6773 - val_acc: 0.7000\n",
      "Epoch 2128/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.7000\n",
      "Epoch 2129/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 2130/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.7000\n",
      "Epoch 2131/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.7000\n",
      "Epoch 2132/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.6785 - val_acc: 0.7000\n",
      "Epoch 2133/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6797 - val_acc: 0.7000\n",
      "Epoch 2134/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.7000\n",
      "Epoch 2135/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6799 - val_acc: 0.7000\n",
      "Epoch 2136/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6808 - val_acc: 0.7000\n",
      "Epoch 2137/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6803 - val_acc: 0.7000\n",
      "Epoch 2138/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6813 - val_acc: 0.7000\n",
      "Epoch 2139/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.7000\n",
      "Epoch 2140/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6805 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2141/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6796 - val_acc: 0.7000\n",
      "Epoch 2142/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0215 - acc: 1.000 - 0s 127us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6799 - val_acc: 0.7000\n",
      "Epoch 2143/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.7000\n",
      "Epoch 2144/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6817 - val_acc: 0.7000\n",
      "Epoch 2145/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 0.7000\n",
      "Epoch 2146/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.7000\n",
      "Epoch 2147/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6819 - val_acc: 0.7000\n",
      "Epoch 2148/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6818 - val_acc: 0.7000\n",
      "Epoch 2149/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.7000\n",
      "Epoch 2150/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6819 - val_acc: 0.7000\n",
      "Epoch 2151/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 0.7000\n",
      "Epoch 2152/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.7000\n",
      "Epoch 2153/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.7000\n",
      "Epoch 2154/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 0.7000\n",
      "Epoch 2155/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6819 - val_acc: 0.7000\n",
      "Epoch 2156/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.7000\n",
      "Epoch 2157/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.7000\n",
      "Epoch 2158/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 2159/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6821 - val_acc: 0.7000\n",
      "Epoch 2160/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6818 - val_acc: 0.7000\n",
      "Epoch 2161/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 2162/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6831 - val_acc: 0.7000\n",
      "Epoch 2163/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.7000\n",
      "Epoch 2164/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6833 - val_acc: 0.7000\n",
      "Epoch 2165/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.7000\n",
      "Epoch 2166/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6846 - val_acc: 0.7000\n",
      "Epoch 2167/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6853 - val_acc: 0.7000\n",
      "Epoch 2168/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6846 - val_acc: 0.7000\n",
      "Epoch 2169/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 0.7000\n",
      "Epoch 2170/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6860 - val_acc: 0.7000\n",
      "Epoch 2171/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6862 - val_acc: 0.7000\n",
      "Epoch 2172/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6863 - val_acc: 0.7000\n",
      "Epoch 2173/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6874 - val_acc: 0.7000\n",
      "Epoch 2174/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6884 - val_acc: 0.7000\n",
      "Epoch 2175/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.7000\n",
      "Epoch 2176/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 0.7000\n",
      "Epoch 2177/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.7000\n",
      "Epoch 2178/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.7000\n",
      "Epoch 2179/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6899 - val_acc: 0.7000\n",
      "Epoch 2180/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 0.7000\n",
      "Epoch 2181/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.7000\n",
      "Epoch 2182/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6895 - val_acc: 0.7000\n",
      "Epoch 2183/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.7000\n",
      "Epoch 2184/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6898 - val_acc: 0.7000\n",
      "Epoch 2185/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6891 - val_acc: 0.7000\n",
      "Epoch 2186/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6896 - val_acc: 0.7000\n",
      "Epoch 2187/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.7000\n",
      "Epoch 2188/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.7000\n",
      "Epoch 2189/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 0.7000\n",
      "Epoch 2190/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6923 - val_acc: 0.7000\n",
      "Epoch 2191/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6923 - val_acc: 0.7000\n",
      "Epoch 2192/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6921 - val_acc: 0.7000\n",
      "Epoch 2193/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6914 - val_acc: 0.7000\n",
      "Epoch 2194/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.7000\n",
      "Epoch 2195/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.7000\n",
      "Epoch 2196/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6909 - val_acc: 0.7000\n",
      "Epoch 2197/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.7000\n",
      "Epoch 2198/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.7000\n",
      "Epoch 2199/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.7000\n",
      "Epoch 2200/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.7000\n",
      "Epoch 2201/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6931 - val_acc: 0.7000\n",
      "Epoch 2202/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.7000\n",
      "Epoch 2203/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6925 - val_acc: 0.7000\n",
      "Epoch 2204/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.7000\n",
      "Epoch 2205/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6917 - val_acc: 0.7000\n",
      "Epoch 2206/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6927 - val_acc: 0.7000\n",
      "Epoch 2207/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.7000\n",
      "Epoch 2208/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.7000\n",
      "Epoch 2209/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.7000\n",
      "Epoch 2210/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.7000\n",
      "Epoch 2211/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 0.7000\n",
      "Epoch 2212/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6942 - val_acc: 0.7000\n",
      "Epoch 2213/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6942 - val_acc: 0.7000\n",
      "Epoch 2214/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6937 - val_acc: 0.7000\n",
      "Epoch 2215/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.7000\n",
      "Epoch 2216/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.7000\n",
      "Epoch 2217/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6945 - val_acc: 0.7000\n",
      "Epoch 2218/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.7000\n",
      "Epoch 2219/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6955 - val_acc: 0.7000\n",
      "Epoch 2220/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6962 - val_acc: 0.7000\n",
      "Epoch 2221/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6962 - val_acc: 0.7000\n",
      "Epoch 2222/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.7000\n",
      "Epoch 2223/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6965 - val_acc: 0.7000\n",
      "Epoch 2224/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.7000\n",
      "Epoch 2225/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.7000\n",
      "Epoch 2226/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6979 - val_acc: 0.7000\n",
      "Epoch 2227/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6979 - val_acc: 0.7000\n",
      "Epoch 2228/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6976 - val_acc: 0.7000\n",
      "Epoch 2229/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6979 - val_acc: 0.7000\n",
      "Epoch 2230/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6988 - val_acc: 0.7000\n",
      "Epoch 2231/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6986 - val_acc: 0.7000\n",
      "Epoch 2232/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6978 - val_acc: 0.7000\n",
      "Epoch 2233/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.7000\n",
      "Epoch 2234/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6976 - val_acc: 0.7000\n",
      "Epoch 2235/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.7000\n",
      "Epoch 2236/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6970 - val_acc: 0.7000\n",
      "Epoch 2237/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6972 - val_acc: 0.7000\n",
      "Epoch 2238/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6975 - val_acc: 0.7000\n",
      "Epoch 2239/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6973 - val_acc: 0.7000\n",
      "Epoch 2240/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6978 - val_acc: 0.7000\n",
      "Epoch 2241/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.7000\n",
      "Epoch 2242/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6981 - val_acc: 0.7000\n",
      "Epoch 2243/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6985 - val_acc: 0.7000\n",
      "Epoch 2244/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6985 - val_acc: 0.7000\n",
      "Epoch 2245/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6986 - val_acc: 0.7000\n",
      "Epoch 2246/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.7000\n",
      "Epoch 2247/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.7000\n",
      "Epoch 2248/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6992 - val_acc: 0.7000\n",
      "Epoch 2249/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6994 - val_acc: 0.7000\n",
      "Epoch 2250/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.7000\n",
      "Epoch 2251/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.7000\n",
      "Epoch 2252/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.7002 - val_acc: 0.7000\n",
      "Epoch 2253/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.7005 - val_acc: 0.7000\n",
      "Epoch 2254/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.7000\n",
      "Epoch 2255/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.7000\n",
      "Epoch 2256/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.7000\n",
      "Epoch 2257/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.7010 - val_acc: 0.7000\n",
      "Epoch 2258/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7009 - val_acc: 0.7000\n",
      "Epoch 2259/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.7000\n",
      "Epoch 2260/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.7000\n",
      "Epoch 2261/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7010 - val_acc: 0.7000\n",
      "Epoch 2262/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7017 - val_acc: 0.7000\n",
      "Epoch 2263/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7010 - val_acc: 0.7000\n",
      "Epoch 2264/3000\n",
      "79/79 [==============================] - 0s 101us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7000\n",
      "Epoch 2265/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7030 - val_acc: 0.7000\n",
      "Epoch 2266/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.7000\n",
      "Epoch 2267/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.7000\n",
      "Epoch 2268/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.7000\n",
      "Epoch 2269/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.7000\n",
      "Epoch 2270/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.7017 - val_acc: 0.7000\n",
      "Epoch 2271/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.7030 - val_acc: 0.7000\n",
      "Epoch 2272/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7000\n",
      "Epoch 2273/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7000\n",
      "Epoch 2274/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.7029 - val_acc: 0.7000\n",
      "Epoch 2275/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.7000\n",
      "Epoch 2276/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.7000\n",
      "Epoch 2277/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.7000\n",
      "Epoch 2278/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.7000\n",
      "Epoch 2279/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7046 - val_acc: 0.7000\n",
      "Epoch 2280/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7052 - val_acc: 0.7000\n",
      "Epoch 2281/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.7000\n",
      "Epoch 2282/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.7064 - val_acc: 0.7000\n",
      "Epoch 2283/3000\n",
      "79/79 [==============================] - 0s 162us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.7057 - val_acc: 0.7000\n",
      "Epoch 2284/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.7069 - val_acc: 0.7000\n",
      "Epoch 2285/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.7000\n",
      "Epoch 2286/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.7000\n",
      "Epoch 2287/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.7000\n",
      "Epoch 2288/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7070 - val_acc: 0.7000\n",
      "Epoch 2289/3000\n",
      "79/79 [==============================] - 0s 105us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7070 - val_acc: 0.7000\n",
      "Epoch 2290/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.7086 - val_acc: 0.7000\n",
      "Epoch 2291/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.7000\n",
      "Epoch 2292/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.7000\n",
      "Epoch 2293/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.7093 - val_acc: 0.7000\n",
      "Epoch 2294/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7100 - val_acc: 0.7000\n",
      "Epoch 2295/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.7000\n",
      "Epoch 2296/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.7000\n",
      "Epoch 2297/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7093 - val_acc: 0.7000\n",
      "Epoch 2298/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7086 - val_acc: 0.7000\n",
      "Epoch 2299/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7085 - val_acc: 0.7000\n",
      "Epoch 2300/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.7000\n",
      "Epoch 2301/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.7000\n",
      "Epoch 2302/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.7000\n",
      "Epoch 2303/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7091 - val_acc: 0.7000\n",
      "Epoch 2304/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.7000\n",
      "Epoch 2305/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.7000\n",
      "Epoch 2306/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7096 - val_acc: 0.7000\n",
      "Epoch 2307/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 0.7000\n",
      "Epoch 2308/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7120 - val_acc: 0.7000\n",
      "Epoch 2309/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7117 - val_acc: 0.7000\n",
      "Epoch 2310/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7110 - val_acc: 0.7000\n",
      "Epoch 2311/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 0.7000\n",
      "Epoch 2312/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.7000\n",
      "Epoch 2313/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 0.7000\n",
      "Epoch 2314/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.7000\n",
      "Epoch 2315/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7122 - val_acc: 0.7000\n",
      "Epoch 2316/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7128 - val_acc: 0.7000\n",
      "Epoch 2317/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.7140 - val_acc: 0.7000\n",
      "Epoch 2318/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7137 - val_acc: 0.7000\n",
      "Epoch 2319/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7137 - val_acc: 0.7000\n",
      "Epoch 2320/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.7000\n",
      "Epoch 2321/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7139 - val_acc: 0.7000\n",
      "Epoch 2322/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7140 - val_acc: 0.7000\n",
      "Epoch 2323/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.7000\n",
      "Epoch 2324/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7151 - val_acc: 0.7000\n",
      "Epoch 2325/3000\n",
      "79/79 [==============================] - 0s 149us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.7000\n",
      "Epoch 2326/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7144 - val_acc: 0.7000\n",
      "Epoch 2327/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7155 - val_acc: 0.7000\n",
      "Epoch 2328/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7157 - val_acc: 0.7000\n",
      "Epoch 2329/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7155 - val_acc: 0.7000\n",
      "Epoch 2330/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0131 - acc: 1.000 - 0s 115us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.7172 - val_acc: 0.7000\n",
      "Epoch 2331/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7179 - val_acc: 0.7000\n",
      "Epoch 2332/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7177 - val_acc: 0.7000\n",
      "Epoch 2333/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7180 - val_acc: 0.7000\n",
      "Epoch 2334/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7170 - val_acc: 0.7000\n",
      "Epoch 2335/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7161 - val_acc: 0.7000\n",
      "Epoch 2336/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7165 - val_acc: 0.7000\n",
      "Epoch 2337/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7161 - val_acc: 0.7000\n",
      "Epoch 2338/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7162 - val_acc: 0.7000\n",
      "Epoch 2339/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7172 - val_acc: 0.7000\n",
      "Epoch 2340/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7171 - val_acc: 0.7000\n",
      "Epoch 2341/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.7179 - val_acc: 0.7000\n",
      "Epoch 2342/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.000 - 0s 126us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.7000\n",
      "Epoch 2343/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7176 - val_acc: 0.7000\n",
      "Epoch 2344/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.7000\n",
      "Epoch 2345/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.7000\n",
      "Epoch 2346/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.7000\n",
      "Epoch 2347/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.7000\n",
      "Epoch 2348/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.7000\n",
      "Epoch 2349/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7190 - val_acc: 0.7000\n",
      "Epoch 2350/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.7000\n",
      "Epoch 2351/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.7197 - val_acc: 0.7000\n",
      "Epoch 2352/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.7000\n",
      "Epoch 2353/3000\n",
      "79/79 [==============================] - 0s 173us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7199 - val_acc: 0.7000\n",
      "Epoch 2354/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7201 - val_acc: 0.7000\n",
      "Epoch 2355/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7207 - val_acc: 0.7000\n",
      "Epoch 2356/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7214 - val_acc: 0.7000\n",
      "Epoch 2357/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7223 - val_acc: 0.7000\n",
      "Epoch 2358/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7227 - val_acc: 0.7000\n",
      "Epoch 2359/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7223 - val_acc: 0.7000\n",
      "Epoch 2360/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7231 - val_acc: 0.7000\n",
      "Epoch 2361/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7230 - val_acc: 0.7000\n",
      "Epoch 2362/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.7234 - val_acc: 0.7000\n",
      "Epoch 2363/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.7228 - val_acc: 0.7000\n",
      "Epoch 2364/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.7231 - val_acc: 0.7000\n",
      "Epoch 2365/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.7236 - val_acc: 0.7000\n",
      "Epoch 2366/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7240 - val_acc: 0.7000\n",
      "Epoch 2367/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7245 - val_acc: 0.7000\n",
      "Epoch 2368/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7245 - val_acc: 0.7000\n",
      "Epoch 2369/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7244 - val_acc: 0.7000\n",
      "Epoch 2370/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 0.7000\n",
      "Epoch 2371/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 0.7000\n",
      "Epoch 2372/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 0.7000\n",
      "Epoch 2373/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 0.7000\n",
      "Epoch 2374/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.7000\n",
      "Epoch 2375/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 0.7000\n",
      "Epoch 2376/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.7000\n",
      "Epoch 2377/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.7000\n",
      "Epoch 2378/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.7000\n",
      "Epoch 2379/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.7000\n",
      "Epoch 2380/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 0.7000\n",
      "Epoch 2381/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 0.7000\n",
      "Epoch 2382/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.7000\n",
      "Epoch 2383/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.7000\n",
      "Epoch 2384/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.7000\n",
      "Epoch 2385/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7240 - val_acc: 0.7000\n",
      "Epoch 2386/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.7000\n",
      "Epoch 2387/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.7000\n",
      "Epoch 2388/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.7000\n",
      "Epoch 2389/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.7000\n",
      "Epoch 2390/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.7000\n",
      "Epoch 2391/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7306 - val_acc: 0.7000\n",
      "Epoch 2392/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.7000\n",
      "Epoch 2393/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.7000\n",
      "Epoch 2394/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7306 - val_acc: 0.7000\n",
      "Epoch 2395/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.7000\n",
      "Epoch 2396/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.7000\n",
      "Epoch 2397/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7307 - val_acc: 0.7000\n",
      "Epoch 2398/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.7000\n",
      "Epoch 2399/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.7000\n",
      "Epoch 2400/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.7000\n",
      "Epoch 2401/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.7000\n",
      "Epoch 2402/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2403/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.7000\n",
      "Epoch 2404/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7000\n",
      "Epoch 2405/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.7000\n",
      "Epoch 2406/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.7000\n",
      "Epoch 2407/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 0.7000\n",
      "Epoch 2408/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.7000\n",
      "Epoch 2409/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.7000\n",
      "Epoch 2410/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.7000\n",
      "Epoch 2411/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.7000\n",
      "Epoch 2412/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.7000\n",
      "Epoch 2413/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.7000\n",
      "Epoch 2414/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.7316 - val_acc: 0.7000\n",
      "Epoch 2415/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.7000\n",
      "Epoch 2416/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.7000\n",
      "Epoch 2417/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7000\n",
      "Epoch 2418/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.7000\n",
      "Epoch 2419/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.7000\n",
      "Epoch 2420/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7339 - val_acc: 0.7000\n",
      "Epoch 2421/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.7000\n",
      "Epoch 2422/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.7000\n",
      "Epoch 2423/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.7000\n",
      "Epoch 2424/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.7000\n",
      "Epoch 2425/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.7339 - val_acc: 0.7000\n",
      "Epoch 2426/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.7000\n",
      "Epoch 2427/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.7000\n",
      "Epoch 2428/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2429/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.7000\n",
      "Epoch 2430/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7000\n",
      "Epoch 2431/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.7000\n",
      "Epoch 2432/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.7000\n",
      "Epoch 2433/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.7000\n",
      "Epoch 2434/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7000\n",
      "Epoch 2435/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2436/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7000\n",
      "Epoch 2437/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.7000\n",
      "Epoch 2438/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.7000\n",
      "Epoch 2439/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.7000\n",
      "Epoch 2440/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.7000\n",
      "Epoch 2441/3000\n",
      "79/79 [==============================] - 0s 106us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.7000\n",
      "Epoch 2442/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 2443/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7352 - val_acc: 0.7000\n",
      "Epoch 2444/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 2445/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7354 - val_acc: 0.7000\n",
      "Epoch 2446/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7000\n",
      "Epoch 2447/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.7000\n",
      "Epoch 2448/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.7000\n",
      "Epoch 2449/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.7000\n",
      "Epoch 2450/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.7000\n",
      "Epoch 2451/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 0.7000\n",
      "Epoch 2452/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 0.7000\n",
      "Epoch 2453/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 2454/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.7000\n",
      "Epoch 2455/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 0.7000\n",
      "Epoch 2456/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.7000\n",
      "Epoch 2457/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7000\n",
      "Epoch 2458/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.7000\n",
      "Epoch 2459/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7352 - val_acc: 0.7000\n",
      "Epoch 2460/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7000\n",
      "Epoch 2461/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.7000\n",
      "Epoch 2462/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 0.7000\n",
      "Epoch 2463/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.7000\n",
      "Epoch 2464/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.7000\n",
      "Epoch 2465/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7000\n",
      "Epoch 2466/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.7000\n",
      "Epoch 2467/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.7000\n",
      "Epoch 2468/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0110 - acc: 1.000 - 0s 131us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.7000\n",
      "Epoch 2469/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7000\n",
      "Epoch 2470/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.7000\n",
      "Epoch 2471/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.7000\n",
      "Epoch 2472/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 2473/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.7000\n",
      "Epoch 2474/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7355 - val_acc: 0.7000\n",
      "Epoch 2475/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7354 - val_acc: 0.7000\n",
      "Epoch 2476/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7000\n",
      "Epoch 2477/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.7000\n",
      "Epoch 2478/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.7000\n",
      "Epoch 2479/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7348 - val_acc: 0.7000\n",
      "Epoch 2480/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7000\n",
      "Epoch 2481/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.7000\n",
      "Epoch 2482/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7364 - val_acc: 0.7000\n",
      "Epoch 2483/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7369 - val_acc: 0.7000\n",
      "Epoch 2484/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7370 - val_acc: 0.7000\n",
      "Epoch 2485/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.7000\n",
      "Epoch 2486/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7364 - val_acc: 0.7000\n",
      "Epoch 2487/3000\n",
      "79/79 [==============================] - 0s 107us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.7000\n",
      "Epoch 2488/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.7000\n",
      "Epoch 2489/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7367 - val_acc: 0.7000\n",
      "Epoch 2490/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7378 - val_acc: 0.7000\n",
      "Epoch 2491/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.7000\n",
      "Epoch 2492/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2493/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.7000\n",
      "Epoch 2494/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.7000\n",
      "Epoch 2495/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7355 - val_acc: 0.7000\n",
      "Epoch 2496/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.7000\n",
      "Epoch 2497/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7348 - val_acc: 0.7000\n",
      "Epoch 2498/3000\n",
      "79/79 [==============================] - 0s 112us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.7000\n",
      "Epoch 2499/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2500/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.7000\n",
      "Epoch 2501/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.7000\n",
      "Epoch 2502/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.7000\n",
      "Epoch 2503/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 0.7000\n",
      "Epoch 2504/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.7000\n",
      "Epoch 2505/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.7000\n",
      "Epoch 2506/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.7000\n",
      "Epoch 2507/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.7000\n",
      "Epoch 2508/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.7000\n",
      "Epoch 2509/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2510/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.7000\n",
      "Epoch 2511/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.7000\n",
      "Epoch 2512/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.7000\n",
      "Epoch 2513/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.7000\n",
      "Epoch 2514/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.7000\n",
      "Epoch 2515/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.7000\n",
      "Epoch 2516/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.7000\n",
      "Epoch 2517/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.7000\n",
      "Epoch 2518/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.7000\n",
      "Epoch 2519/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.7000\n",
      "Epoch 2520/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.7000\n",
      "Epoch 2521/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.7000\n",
      "Epoch 2522/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 0.7000\n",
      "Epoch 2523/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.7000\n",
      "Epoch 2524/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.7000\n",
      "Epoch 2525/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.7000\n",
      "Epoch 2526/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7000\n",
      "Epoch 2527/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 0.7000\n",
      "Epoch 2528/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.7000\n",
      "Epoch 2529/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7000\n",
      "Epoch 2530/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.7000\n",
      "Epoch 2531/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7000\n",
      "Epoch 2532/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7000\n",
      "Epoch 2533/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.7000\n",
      "Epoch 2534/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7367 - val_acc: 0.7000\n",
      "Epoch 2535/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.7000\n",
      "Epoch 2536/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7477 - val_acc: 0.7000\n",
      "Epoch 2537/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7473 - val_acc: 0.7000\n",
      "Epoch 2538/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.7000\n",
      "Epoch 2539/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.7000\n",
      "Epoch 2540/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7464 - val_acc: 0.7000\n",
      "Epoch 2541/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.7000\n",
      "Epoch 2542/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7452 - val_acc: 0.7000\n",
      "Epoch 2543/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.7000\n",
      "Epoch 2544/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.7000\n",
      "Epoch 2545/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.7000\n",
      "Epoch 2546/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.7000\n",
      "Epoch 2547/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.7000\n",
      "Epoch 2548/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.7000\n",
      "Epoch 2549/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7391 - val_acc: 0.7000\n",
      "Epoch 2550/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.7000\n",
      "Epoch 2551/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2552/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.7000\n",
      "Epoch 2553/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7391 - val_acc: 0.7000\n",
      "Epoch 2554/3000\n",
      "79/79 [==============================] - 0s 111us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.7000\n",
      "Epoch 2555/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.7000\n",
      "Epoch 2556/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.7000\n",
      "Epoch 2557/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.7000\n",
      "Epoch 2558/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.7000\n",
      "Epoch 2559/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.7000\n",
      "Epoch 2560/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7398 - val_acc: 0.7000\n",
      "Epoch 2561/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 0.7000\n",
      "Epoch 2562/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.7000\n",
      "Epoch 2563/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 0.7000\n",
      "Epoch 2564/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.7000\n",
      "Epoch 2565/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7409 - val_acc: 0.7000\n",
      "Epoch 2566/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.7000\n",
      "Epoch 2567/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.7000\n",
      "Epoch 2568/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.7000\n",
      "Epoch 2569/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.7000\n",
      "Epoch 2570/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7416 - val_acc: 0.7000\n",
      "Epoch 2571/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7417 - val_acc: 0.7000\n",
      "Epoch 2572/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7423 - val_acc: 0.7000\n",
      "Epoch 2573/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7422 - val_acc: 0.7000\n",
      "Epoch 2574/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7421 - val_acc: 0.7000\n",
      "Epoch 2575/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7424 - val_acc: 0.7000\n",
      "Epoch 2576/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7431 - val_acc: 0.7000\n",
      "Epoch 2577/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7443 - val_acc: 0.7000\n",
      "Epoch 2578/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.7000\n",
      "Epoch 2579/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 0.7000\n",
      "Epoch 2580/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.7000\n",
      "Epoch 2581/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7439 - val_acc: 0.7000\n",
      "Epoch 2582/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7441 - val_acc: 0.7000\n",
      "Epoch 2583/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7444 - val_acc: 0.7000\n",
      "Epoch 2584/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7451 - val_acc: 0.7000\n",
      "Epoch 2585/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7454 - val_acc: 0.7000\n",
      "Epoch 2586/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.7000\n",
      "Epoch 2587/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.7000\n",
      "Epoch 2588/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7467 - val_acc: 0.7000\n",
      "Epoch 2589/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.7000\n",
      "Epoch 2590/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.7000\n",
      "Epoch 2591/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7460 - val_acc: 0.7000\n",
      "Epoch 2592/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.7000\n",
      "Epoch 2593/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7457 - val_acc: 0.7000\n",
      "Epoch 2594/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.7445 - val_acc: 0.7000\n",
      "Epoch 2595/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7449 - val_acc: 0.7000\n",
      "Epoch 2596/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7457 - val_acc: 0.7000\n",
      "Epoch 2597/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.7000\n",
      "Epoch 2598/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.7000\n",
      "Epoch 2599/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.7000\n",
      "Epoch 2600/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.7000\n",
      "Epoch 2601/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.7000\n",
      "Epoch 2602/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.7000\n",
      "Epoch 2603/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.7000\n",
      "Epoch 2604/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.7000\n",
      "Epoch 2605/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.7000\n",
      "Epoch 2606/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.7000\n",
      "Epoch 2607/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7473 - val_acc: 0.7000\n",
      "Epoch 2608/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.7000\n",
      "Epoch 2609/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7485 - val_acc: 0.7000\n",
      "Epoch 2610/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2611/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.7000\n",
      "Epoch 2612/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7484 - val_acc: 0.7000\n",
      "Epoch 2613/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.7000\n",
      "Epoch 2614/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.7000\n",
      "Epoch 2615/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.7000\n",
      "Epoch 2616/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.7000\n",
      "Epoch 2617/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7472 - val_acc: 0.7000\n",
      "Epoch 2618/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.7000\n",
      "Epoch 2619/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.7000\n",
      "Epoch 2620/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.7000\n",
      "Epoch 2621/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.7000\n",
      "Epoch 2622/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.7000\n",
      "Epoch 2623/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7467 - val_acc: 0.7000\n",
      "Epoch 2624/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.7000\n",
      "Epoch 2625/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.7000\n",
      "Epoch 2626/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7484 - val_acc: 0.7000\n",
      "Epoch 2627/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7502 - val_acc: 0.7000\n",
      "Epoch 2628/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.000 - 0s 126us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.7000\n",
      "Epoch 2629/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.7000\n",
      "Epoch 2630/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.7000\n",
      "Epoch 2631/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.7000\n",
      "Epoch 2632/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7514 - val_acc: 0.7000\n",
      "Epoch 2633/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7540 - val_acc: 0.7000\n",
      "Epoch 2634/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.7000\n",
      "Epoch 2635/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.7000\n",
      "Epoch 2636/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7543 - val_acc: 0.7000\n",
      "Epoch 2637/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.7000\n",
      "Epoch 2638/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.7000\n",
      "Epoch 2639/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.7000\n",
      "Epoch 2640/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7537 - val_acc: 0.7000\n",
      "Epoch 2641/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.7000\n",
      "Epoch 2642/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7539 - val_acc: 0.7000\n",
      "Epoch 2643/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.7000\n",
      "Epoch 2644/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.7000\n",
      "Epoch 2645/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.7000\n",
      "Epoch 2646/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.7000\n",
      "Epoch 2647/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.7000\n",
      "Epoch 2648/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.7000\n",
      "Epoch 2649/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.7000\n",
      "Epoch 2650/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.7000\n",
      "Epoch 2651/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.7000\n",
      "Epoch 2652/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.7000\n",
      "Epoch 2653/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.7000\n",
      "Epoch 2654/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.7000\n",
      "Epoch 2655/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.7000\n",
      "Epoch 2656/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.7000\n",
      "Epoch 2657/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.7000\n",
      "Epoch 2658/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7556 - val_acc: 0.7000\n",
      "Epoch 2659/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.7000\n",
      "Epoch 2660/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.7000\n",
      "Epoch 2661/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7553 - val_acc: 0.7000\n",
      "Epoch 2662/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.7000\n",
      "Epoch 2663/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.7000\n",
      "Epoch 2664/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 0.7000\n",
      "Epoch 2665/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7555 - val_acc: 0.7000\n",
      "Epoch 2666/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7553 - val_acc: 0.7000\n",
      "Epoch 2667/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7558 - val_acc: 0.7000\n",
      "Epoch 2668/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7561 - val_acc: 0.7000\n",
      "Epoch 2669/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7559 - val_acc: 0.7000\n",
      "Epoch 2670/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7564 - val_acc: 0.7000\n",
      "Epoch 2671/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.7000\n",
      "Epoch 2672/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.7000\n",
      "Epoch 2673/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.7000\n",
      "Epoch 2674/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.7000\n",
      "Epoch 2675/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.7000\n",
      "Epoch 2676/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.7000\n",
      "Epoch 2677/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "Epoch 2678/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.7000\n",
      "Epoch 2679/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.7604 - val_acc: 0.7000\n",
      "Epoch 2680/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.7000\n",
      "Epoch 2681/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "Epoch 2682/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 0.7000\n",
      "Epoch 2683/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.7000\n",
      "Epoch 2684/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.7000\n",
      "Epoch 2685/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.7000\n",
      "Epoch 2686/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7607 - val_acc: 0.7000\n",
      "Epoch 2687/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7606 - val_acc: 0.7000\n",
      "Epoch 2688/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7607 - val_acc: 0.7000\n",
      "Epoch 2689/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.7000\n",
      "Epoch 2690/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "Epoch 2691/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7598 - val_acc: 0.7000\n",
      "Epoch 2692/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "Epoch 2693/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7603 - val_acc: 0.7000\n",
      "Epoch 2694/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7607 - val_acc: 0.7000\n",
      "Epoch 2695/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.7000\n",
      "Epoch 2696/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.7000\n",
      "Epoch 2697/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7613 - val_acc: 0.7000\n",
      "Epoch 2698/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.7000\n",
      "Epoch 2699/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7607 - val_acc: 0.7000\n",
      "Epoch 2700/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.7000\n",
      "Epoch 2701/3000\n",
      "79/79 [==============================] - 0s 169us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.7000\n",
      "Epoch 2702/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.7000\n",
      "Epoch 2703/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7613 - val_acc: 0.7000\n",
      "Epoch 2704/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.7000\n",
      "Epoch 2705/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.7000\n",
      "Epoch 2706/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7629 - val_acc: 0.7000\n",
      "Epoch 2707/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.7000\n",
      "Epoch 2708/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7622 - val_acc: 0.7000\n",
      "Epoch 2709/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.7000\n",
      "Epoch 2710/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.7000\n",
      "Epoch 2711/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.7000\n",
      "Epoch 2712/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.7000\n",
      "Epoch 2713/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.7000\n",
      "Epoch 2714/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 0.7000\n",
      "Epoch 2715/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.7000\n",
      "Epoch 2716/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.7000\n",
      "Epoch 2717/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7640 - val_acc: 0.7000\n",
      "Epoch 2718/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.7000\n",
      "Epoch 2719/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7639 - val_acc: 0.7000\n",
      "Epoch 2720/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7643 - val_acc: 0.7000\n",
      "Epoch 2721/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.7000\n",
      "Epoch 2722/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7651 - val_acc: 0.7000\n",
      "Epoch 2723/3000\n",
      "79/79 [==============================] - 0s 120us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.7000\n",
      "Epoch 2724/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7661 - val_acc: 0.7000\n",
      "Epoch 2725/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.7000\n",
      "Epoch 2726/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.7000\n",
      "Epoch 2727/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2728/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7661 - val_acc: 0.7000\n",
      "Epoch 2729/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.7000\n",
      "Epoch 2730/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.7000\n",
      "Epoch 2731/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.7000\n",
      "Epoch 2732/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.7000\n",
      "Epoch 2733/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.7000\n",
      "Epoch 2734/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.7000\n",
      "Epoch 2735/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.7000\n",
      "Epoch 2736/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.7000\n",
      "Epoch 2737/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.7000\n",
      "Epoch 2738/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.7000\n",
      "Epoch 2739/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.7000\n",
      "Epoch 2740/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.7000\n",
      "Epoch 2741/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7675 - val_acc: 0.7000\n",
      "Epoch 2742/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.7000\n",
      "Epoch 2743/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 0.7000\n",
      "Epoch 2744/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7682 - val_acc: 0.7000\n",
      "Epoch 2745/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.7000\n",
      "Epoch 2746/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.7000\n",
      "Epoch 2747/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.7000\n",
      "Epoch 2748/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.7000\n",
      "Epoch 2749/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.7000\n",
      "Epoch 2750/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.7000\n",
      "Epoch 2751/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.7000\n",
      "Epoch 2752/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.7000\n",
      "Epoch 2753/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.7000\n",
      "Epoch 2754/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.7000\n",
      "Epoch 2755/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7708 - val_acc: 0.7000\n",
      "Epoch 2756/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.7000\n",
      "Epoch 2757/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.7000\n",
      "Epoch 2758/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.7000\n",
      "Epoch 2759/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.7000\n",
      "Epoch 2760/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7700 - val_acc: 0.7000\n",
      "Epoch 2761/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.7000\n",
      "Epoch 2762/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.7000\n",
      "Epoch 2763/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.7000\n",
      "Epoch 2764/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.7000\n",
      "Epoch 2765/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7696 - val_acc: 0.7000\n",
      "Epoch 2766/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.7000\n",
      "Epoch 2767/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7698 - val_acc: 0.7000\n",
      "Epoch 2768/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.7000\n",
      "Epoch 2769/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.7000\n",
      "Epoch 2770/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7710 - val_acc: 0.7000\n",
      "Epoch 2771/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7709 - val_acc: 0.7000\n",
      "Epoch 2772/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7709 - val_acc: 0.7000\n",
      "Epoch 2773/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.7000\n",
      "Epoch 2774/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 0.7000\n",
      "Epoch 2775/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.7000\n",
      "Epoch 2776/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.7000\n",
      "Epoch 2777/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.7000\n",
      "Epoch 2778/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.7000\n",
      "Epoch 2779/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7000\n",
      "Epoch 2780/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.7000\n",
      "Epoch 2781/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.7000\n",
      "Epoch 2782/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7000\n",
      "Epoch 2783/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7000\n",
      "Epoch 2784/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.7000\n",
      "Epoch 2785/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7719 - val_acc: 0.7000\n",
      "Epoch 2786/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7719 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2787/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.7000\n",
      "Epoch 2788/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.7000\n",
      "Epoch 2789/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.7000\n",
      "Epoch 2790/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7000\n",
      "Epoch 2791/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7000\n",
      "Epoch 2792/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.7000\n",
      "Epoch 2793/3000\n",
      "79/79 [==============================] - 0s 161us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.7000\n",
      "Epoch 2794/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7000\n",
      "Epoch 2795/3000\n",
      "79/79 [==============================] - 0s 136us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7000\n",
      "Epoch 2796/3000\n",
      "79/79 [==============================] - 0s 127us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.7000\n",
      "Epoch 2797/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7000\n",
      "Epoch 2798/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.7000\n",
      "Epoch 2799/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.7000\n",
      "Epoch 2800/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7000\n",
      "Epoch 2801/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.7000\n",
      "Epoch 2802/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.7000\n",
      "Epoch 2803/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7000\n",
      "Epoch 2804/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.7000\n",
      "Epoch 2805/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.7000\n",
      "Epoch 2806/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7000\n",
      "Epoch 2807/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7000\n",
      "Epoch 2808/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7000\n",
      "Epoch 2809/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.7000\n",
      "Epoch 2810/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 0.7000\n",
      "Epoch 2811/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.7000\n",
      "Epoch 2812/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.7000\n",
      "Epoch 2813/3000\n",
      "79/79 [==============================] - 0s 109us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.7000\n",
      "Epoch 2814/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 0.7000\n",
      "Epoch 2815/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7740 - val_acc: 0.7000\n",
      "Epoch 2816/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7745 - val_acc: 0.7000\n",
      "Epoch 2817/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.7000\n",
      "Epoch 2818/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 0.7000\n",
      "Epoch 2819/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7746 - val_acc: 0.7000\n",
      "Epoch 2820/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.7000\n",
      "Epoch 2821/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7750 - val_acc: 0.7000\n",
      "Epoch 2822/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.7000\n",
      "Epoch 2823/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.7000\n",
      "Epoch 2824/3000\n",
      "79/79 [==============================] - 0s 133us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7751 - val_acc: 0.7000\n",
      "Epoch 2825/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.7000\n",
      "Epoch 2826/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7751 - val_acc: 0.7000\n",
      "Epoch 2827/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0074 - acc: 1.000 - 0s 114us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7755 - val_acc: 0.7000\n",
      "Epoch 2828/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.7000\n",
      "Epoch 2829/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7760 - val_acc: 0.7000\n",
      "Epoch 2830/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7757 - val_acc: 0.7000\n",
      "Epoch 2831/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.7000\n",
      "Epoch 2832/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.7000\n",
      "Epoch 2833/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7763 - val_acc: 0.7000\n",
      "Epoch 2834/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7765 - val_acc: 0.7000\n",
      "Epoch 2835/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7762 - val_acc: 0.7000\n",
      "Epoch 2836/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 0.7000\n",
      "Epoch 2837/3000\n",
      "79/79 [==============================] - 0s 140us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 0.7000\n",
      "Epoch 2838/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7775 - val_acc: 0.7000\n",
      "Epoch 2839/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7775 - val_acc: 0.7000\n",
      "Epoch 2840/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7781 - val_acc: 0.7000\n",
      "Epoch 2841/3000\n",
      "79/79 [==============================] - 0s 110us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.7000\n",
      "Epoch 2842/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7777 - val_acc: 0.7000\n",
      "Epoch 2843/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.7000\n",
      "Epoch 2844/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7778 - val_acc: 0.7000\n",
      "Epoch 2845/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7780 - val_acc: 0.7000\n",
      "Epoch 2846/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.7000\n",
      "Epoch 2847/3000\n",
      "79/79 [==============================] - 0s 117us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.7000\n",
      "Epoch 2848/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.7000\n",
      "Epoch 2849/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.7000\n",
      "Epoch 2850/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.7000\n",
      "Epoch 2851/3000\n",
      "79/79 [==============================] - 0s 177us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.7000\n",
      "Epoch 2852/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.7000\n",
      "Epoch 2853/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.7000\n",
      "Epoch 2854/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7789 - val_acc: 0.7000\n",
      "Epoch 2855/3000\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7793 - val_acc: 0.7000\n",
      "Epoch 2856/3000\n",
      "79/79 [==============================] - 0s 153us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.7000\n",
      "Epoch 2857/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7789 - val_acc: 0.7000\n",
      "Epoch 2858/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7790 - val_acc: 0.7000\n",
      "Epoch 2859/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7795 - val_acc: 0.7000\n",
      "Epoch 2860/3000\n",
      "79/79 [==============================] - 0s 183us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.7000\n",
      "Epoch 2861/3000\n",
      "79/79 [==============================] - 0s 155us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7796 - val_acc: 0.7000\n",
      "Epoch 2862/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7797 - val_acc: 0.7000\n",
      "Epoch 2863/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7800 - val_acc: 0.7000\n",
      "Epoch 2864/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7801 - val_acc: 0.7000\n",
      "Epoch 2865/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.7000\n",
      "Epoch 2866/3000\n",
      "79/79 [==============================] - 0s 164us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.7000\n",
      "Epoch 2867/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7810 - val_acc: 0.7000\n",
      "Epoch 2868/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.7000\n",
      "Epoch 2869/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7000\n",
      "Epoch 2870/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7000\n",
      "Epoch 2871/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.7000\n",
      "Epoch 2872/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.7000\n",
      "Epoch 2873/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7805 - val_acc: 0.7000\n",
      "Epoch 2874/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.7000\n",
      "Epoch 2875/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.7000\n",
      "Epoch 2876/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.7000\n",
      "Epoch 2877/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.7000\n",
      "Epoch 2878/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.7000\n",
      "Epoch 2879/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7000\n",
      "Epoch 2880/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.7000\n",
      "Epoch 2881/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.7000\n",
      "Epoch 2882/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.7000\n",
      "Epoch 2883/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.7000\n",
      "Epoch 2884/3000\n",
      "79/79 [==============================] - 0s 116us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7825 - val_acc: 0.7000\n",
      "Epoch 2885/3000\n",
      "79/79 [==============================] - 0s 142us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7824 - val_acc: 0.7000\n",
      "Epoch 2886/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7821 - val_acc: 0.7000\n",
      "Epoch 2887/3000\n",
      "79/79 [==============================] - 0s 130us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.7000\n",
      "Epoch 2888/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.7000\n",
      "Epoch 2889/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.7000\n",
      "Epoch 2890/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.7000\n",
      "Epoch 2891/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7829 - val_acc: 0.7000\n",
      "Epoch 2892/3000\n",
      "79/79 [==============================] - 0s 141us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7834 - val_acc: 0.7000\n",
      "Epoch 2893/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7833 - val_acc: 0.7000\n",
      "Epoch 2894/3000\n",
      "79/79 [==============================] - 0s 119us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7833 - val_acc: 0.7000\n",
      "Epoch 2895/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2896/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7834 - val_acc: 0.7000\n",
      "Epoch 2897/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7836 - val_acc: 0.7000\n",
      "Epoch 2898/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2899/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2900/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7839 - val_acc: 0.7000\n",
      "Epoch 2901/3000\n",
      "79/79 [==============================] - 0s 143us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2902/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.7000\n",
      "Epoch 2903/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7836 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2904/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.7000\n",
      "Epoch 2905/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7834 - val_acc: 0.7000\n",
      "Epoch 2906/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.7000\n",
      "Epoch 2907/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7833 - val_acc: 0.7000\n",
      "Epoch 2908/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.7000\n",
      "Epoch 2909/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2910/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2911/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.7000\n",
      "Epoch 2912/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7841 - val_acc: 0.7000\n",
      "Epoch 2913/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7842 - val_acc: 0.7000\n",
      "Epoch 2914/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7844 - val_acc: 0.7000\n",
      "Epoch 2915/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7851 - val_acc: 0.7000\n",
      "Epoch 2916/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7854 - val_acc: 0.7000\n",
      "Epoch 2917/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7854 - val_acc: 0.7000\n",
      "Epoch 2918/3000\n",
      "79/79 [==============================] - 0s 160us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7857 - val_acc: 0.7000\n",
      "Epoch 2919/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7859 - val_acc: 0.7000\n",
      "Epoch 2920/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.7000\n",
      "Epoch 2921/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7862 - val_acc: 0.7000\n",
      "Epoch 2922/3000\n",
      "79/79 [==============================] - 0s 129us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.7000\n",
      "Epoch 2923/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.7000\n",
      "Epoch 2924/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7860 - val_acc: 0.7000\n",
      "Epoch 2925/3000\n",
      "79/79 [==============================] - 0s 118us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7862 - val_acc: 0.7000\n",
      "Epoch 2926/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7866 - val_acc: 0.7000\n",
      "Epoch 2927/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7868 - val_acc: 0.7000\n",
      "Epoch 2928/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7870 - val_acc: 0.7000\n",
      "Epoch 2929/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.7000\n",
      "Epoch 2930/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7872 - val_acc: 0.7000\n",
      "Epoch 2931/3000\n",
      "79/79 [==============================] - 0s 148us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7872 - val_acc: 0.7000\n",
      "Epoch 2932/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.7000\n",
      "Epoch 2933/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.7000\n",
      "Epoch 2934/3000\n",
      "79/79 [==============================] - 0s 145us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.7000\n",
      "Epoch 2935/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7877 - val_acc: 0.7000\n",
      "Epoch 2936/3000\n",
      "79/79 [==============================] - 0s 115us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.7000\n",
      "Epoch 2937/3000\n",
      "79/79 [==============================] - 0s 137us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7880 - val_acc: 0.7000\n",
      "Epoch 2938/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.7000\n",
      "Epoch 2939/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7886 - val_acc: 0.7000\n",
      "Epoch 2940/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7888 - val_acc: 0.7000\n",
      "Epoch 2941/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7887 - val_acc: 0.7000\n",
      "Epoch 2942/3000\n",
      "79/79 [==============================] - 0s 152us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7886 - val_acc: 0.7000\n",
      "Epoch 2943/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7883 - val_acc: 0.7000\n",
      "Epoch 2944/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7881 - val_acc: 0.7000\n",
      "Epoch 2945/3000\n",
      "79/79 [==============================] - 0s 144us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.7000\n",
      "Epoch 2946/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7878 - val_acc: 0.7000\n",
      "Epoch 2947/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7877 - val_acc: 0.7000\n",
      "Epoch 2948/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7880 - val_acc: 0.7000\n",
      "Epoch 2949/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7883 - val_acc: 0.7000\n",
      "Epoch 2950/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7884 - val_acc: 0.7000\n",
      "Epoch 2951/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.7000\n",
      "Epoch 2952/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.7000\n",
      "Epoch 2953/3000\n",
      "79/79 [==============================] - 0s 132us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.7000\n",
      "Epoch 2954/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2955/3000\n",
      "79/79 [==============================] - 0s 121us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.7000\n",
      "Epoch 2956/3000\n",
      "79/79 [==============================] - 0s 172us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.7000\n",
      "Epoch 2957/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.7000\n",
      "Epoch 2958/3000\n",
      "79/79 [==============================] - 0s 131us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.7000\n",
      "Epoch 2959/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2960/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2961/3000\n",
      "79/79 [==============================] - 0s 146us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.7000\n",
      "Epoch 2962/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7892 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2963/3000\n",
      "79/79 [==============================] - 0s 113us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.7000\n",
      "Epoch 2964/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2965/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2966/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.7000\n",
      "Epoch 2967/3000\n",
      "79/79 [==============================] - 0s 151us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.7000\n",
      "Epoch 2968/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2969/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.7000\n",
      "Epoch 2970/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.7000\n",
      "Epoch 2971/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 0.7000\n",
      "Epoch 2972/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7904 - val_acc: 0.7000\n",
      "Epoch 2973/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7903 - val_acc: 0.7000\n",
      "Epoch 2974/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.7000\n",
      "Epoch 2975/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7907 - val_acc: 0.7000\n",
      "Epoch 2976/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7909 - val_acc: 0.7000\n",
      "Epoch 2977/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7909 - val_acc: 0.7000\n",
      "Epoch 2978/3000\n",
      "79/79 [==============================] - 0s 150us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7908 - val_acc: 0.7000\n",
      "Epoch 2979/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7909 - val_acc: 0.7000\n",
      "Epoch 2980/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.7000\n",
      "Epoch 2981/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7912 - val_acc: 0.7000\n",
      "Epoch 2982/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7915 - val_acc: 0.7000\n",
      "Epoch 2983/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.7000\n",
      "Epoch 2984/3000\n",
      "79/79 [==============================] - 0s 134us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7915 - val_acc: 0.7000\n",
      "Epoch 2985/3000\n",
      "79/79 [==============================] - 0s 125us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7914 - val_acc: 0.7000\n",
      "Epoch 2986/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.7000\n",
      "Epoch 2987/3000\n",
      "79/79 [==============================] - 0s 135us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.7000\n",
      "Epoch 2988/3000\n",
      "79/79 [==============================] - 0s 128us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7920 - val_acc: 0.7000\n",
      "Epoch 2989/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7926 - val_acc: 0.7000\n",
      "Epoch 2990/3000\n",
      "79/79 [==============================] - 0s 122us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7927 - val_acc: 0.7000\n",
      "Epoch 2991/3000\n",
      "79/79 [==============================] - 0s 124us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.7000\n",
      "Epoch 2992/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.7000\n",
      "Epoch 2993/3000\n",
      "79/79 [==============================] - 0s 114us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.7000\n",
      "Epoch 2994/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7928 - val_acc: 0.7000\n",
      "Epoch 2995/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7929 - val_acc: 0.7000\n",
      "Epoch 2996/3000\n",
      "79/79 [==============================] - 0s 108us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7931 - val_acc: 0.7000\n",
      "Epoch 2997/3000\n",
      "79/79 [==============================] - 0s 126us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7927 - val_acc: 0.7000\n",
      "Epoch 2998/3000\n",
      "79/79 [==============================] - 0s 139us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.7000\n",
      "Epoch 2999/3000\n",
      "79/79 [==============================] - 0s 123us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7928 - val_acc: 0.7000\n",
      "Epoch 3000/3000\n",
      "79/79 [==============================] - 0s 138us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7925 - val_acc: 0.7000\n",
      "Train on 80 samples, validate on 19 samples\n",
      "Epoch 1/3000\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.7715 - acc: 0.5000 - val_loss: 0.7497 - val_acc: 0.4737\n",
      "Epoch 2/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.7291 - acc: 0.5000 - val_loss: 0.7206 - val_acc: 0.4737\n",
      "Epoch 3/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.7083 - acc: 0.5000 - val_loss: 0.7093 - val_acc: 0.4737\n",
      "Epoch 4/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.7007 - acc: 0.5000 - val_loss: 0.7027 - val_acc: 0.4737\n",
      "Epoch 5/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6978 - acc: 0.5000 - val_loss: 0.6996 - val_acc: 0.4737\n",
      "Epoch 6/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6972 - acc: 0.5000 - val_loss: 0.6999 - val_acc: 0.4737\n",
      "Epoch 7/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6960 - acc: 0.5000 - val_loss: 0.6987 - val_acc: 0.4737\n",
      "Epoch 8/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6944 - acc: 0.5000 - val_loss: 0.6950 - val_acc: 0.4737\n",
      "Epoch 9/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4737\n",
      "Epoch 10/3000\n",
      "80/80 [==============================] - 0s 274us/sample - loss: 0.6938 - acc: 0.4000 - val_loss: 0.6926 - val_acc: 0.5789\n",
      "Epoch 11/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6920 - acc: 0.5250 - val_loss: 0.6929 - val_acc: 0.5789\n",
      "Epoch 12/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.5263\n",
      "Epoch 13/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 14/3000\n",
      "80/80 [==============================] - 0s 280us/sample - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.6842\n",
      "Epoch 15/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6931 - acc: 0.4875 - val_loss: 0.6937 - val_acc: 0.4737\n",
      "Epoch 16/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6959 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 17/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.5263\n",
      "Epoch 18/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6922 - acc: 0.5750 - val_loss: 0.6928 - val_acc: 0.5789\n",
      "Epoch 19/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6915 - acc: 0.5500 - val_loss: 0.6931 - val_acc: 0.4737\n",
      "Epoch 20/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6923 - acc: 0.4875 - val_loss: 0.6919 - val_acc: 0.5263\n",
      "Epoch 21/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6915 - acc: 0.5375 - val_loss: 0.6918 - val_acc: 0.5263\n",
      "Epoch 22/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6920 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5263\n",
      "Epoch 23/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6912 - acc: 0.5875 - val_loss: 0.6936 - val_acc: 0.4737\n",
      "Epoch 24/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.5263\n",
      "Epoch 25/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6909 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.4211\n",
      "Epoch 26/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6916 - acc: 0.5125 - val_loss: 0.6935 - val_acc: 0.4737\n",
      "Epoch 27/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6908 - acc: 0.5250 - val_loss: 0.6937 - val_acc: 0.4737\n",
      "Epoch 28/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6921 - acc: 0.6125 - val_loss: 0.6951 - val_acc: 0.4737\n",
      "Epoch 29/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6919 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.6842\n",
      "Epoch 30/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6910 - acc: 0.5500 - val_loss: 0.6925 - val_acc: 0.6316\n",
      "Epoch 31/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6914 - acc: 0.6250 - val_loss: 0.6915 - val_acc: 0.5263\n",
      "Epoch 32/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6906 - acc: 0.5000 - val_loss: 0.6915 - val_acc: 0.5263\n",
      "Epoch 33/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6906 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.5263\n",
      "Epoch 34/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6904 - acc: 0.5000 - val_loss: 0.6916 - val_acc: 0.5263\n",
      "Epoch 35/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6908 - acc: 0.5875 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 36/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6911 - acc: 0.5250 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 37/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6908 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 38/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6917 - acc: 0.5250 - val_loss: 0.6910 - val_acc: 0.5263\n",
      "Epoch 39/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6909 - acc: 0.5000 - val_loss: 0.6912 - val_acc: 0.5263\n",
      "Epoch 40/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6913 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.6316\n",
      "Epoch 41/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6901 - acc: 0.7000 - val_loss: 0.6923 - val_acc: 0.6316\n",
      "Epoch 42/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6911 - acc: 0.5750 - val_loss: 0.6926 - val_acc: 0.5789\n",
      "Epoch 43/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6906 - acc: 0.5500 - val_loss: 0.6933 - val_acc: 0.4737\n",
      "Epoch 44/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6922 - acc: 0.5250 - val_loss: 0.6953 - val_acc: 0.4737\n",
      "Epoch 45/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6943 - acc: 0.5000 - val_loss: 0.6951 - val_acc: 0.4737\n",
      "Epoch 46/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.6316\n",
      "Epoch 47/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6899 - acc: 0.7000 - val_loss: 0.6926 - val_acc: 0.5263\n",
      "Epoch 48/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6898 - acc: 0.5875 - val_loss: 0.6925 - val_acc: 0.5789\n",
      "Epoch 49/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6919 - acc: 0.6250 - val_loss: 0.6914 - val_acc: 0.5263\n",
      "Epoch 50/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6904 - acc: 0.5875 - val_loss: 0.6915 - val_acc: 0.5263\n",
      "Epoch 51/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6898 - acc: 0.5750 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 52/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6902 - acc: 0.5125 - val_loss: 0.6918 - val_acc: 0.4211\n",
      "Epoch 53/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6902 - acc: 0.6125 - val_loss: 0.6926 - val_acc: 0.5263\n",
      "Epoch 54/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6917 - acc: 0.5250 - val_loss: 0.6945 - val_acc: 0.4737\n",
      "Epoch 55/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.6922 - acc: 0.5625 - val_loss: 0.6957 - val_acc: 0.4737\n",
      "Epoch 56/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6908 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.4737\n",
      "Epoch 57/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5789\n",
      "Epoch 58/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6921 - acc: 0.4750 - val_loss: 0.6943 - val_acc: 0.4737\n",
      "Epoch 59/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6900 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4737\n",
      "Epoch 60/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6896 - acc: 0.5250 - val_loss: 0.6926 - val_acc: 0.4737\n",
      "Epoch 61/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6915 - acc: 0.4500 - val_loss: 0.6921 - val_acc: 0.6842\n",
      "Epoch 62/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6911 - acc: 0.5875 - val_loss: 0.6909 - val_acc: 0.5263\n",
      "Epoch 63/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6908 - val_acc: 0.5263\n",
      "Epoch 64/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6896 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 65/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6911 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.5789\n",
      "Epoch 66/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6893 - acc: 0.5750 - val_loss: 0.6920 - val_acc: 0.6316\n",
      "Epoch 67/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6917 - acc: 0.6125 - val_loss: 0.6908 - val_acc: 0.5263\n",
      "Epoch 68/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6894 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 69/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6897 - acc: 0.5250 - val_loss: 0.6909 - val_acc: 0.5263\n",
      "Epoch 70/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6892 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 71/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6902 - acc: 0.5375 - val_loss: 0.6918 - val_acc: 0.6842\n",
      "Epoch 72/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6895 - acc: 0.6375 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 73/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6950 - acc: 0.3500 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 74/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6890 - acc: 0.5000 - val_loss: 0.6916 - val_acc: 0.5263\n",
      "Epoch 75/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6895 - acc: 0.6750 - val_loss: 0.6915 - val_acc: 0.5263\n",
      "Epoch 76/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6888 - acc: 0.7750 - val_loss: 0.6915 - val_acc: 0.5789\n",
      "Epoch 77/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6892 - acc: 0.6375 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 78/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6901 - acc: 0.5125 - val_loss: 0.6925 - val_acc: 0.4737\n",
      "Epoch 79/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6899 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.4737\n",
      "Epoch 80/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6898 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4737\n",
      "Epoch 81/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6950 - acc: 0.4250 - val_loss: 0.6947 - val_acc: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6898 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4737\n",
      "Epoch 83/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6890 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.4737\n",
      "Epoch 84/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6892 - acc: 0.6125 - val_loss: 0.6928 - val_acc: 0.4737\n",
      "Epoch 85/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6904 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.5263\n",
      "Epoch 86/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6892 - acc: 0.5250 - val_loss: 0.6911 - val_acc: 0.5263\n",
      "Epoch 87/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6886 - acc: 0.6500 - val_loss: 0.6912 - val_acc: 0.5263\n",
      "Epoch 88/3000\n",
      "80/80 [==============================] - 0s 274us/sample - loss: 0.6889 - acc: 0.6875 - val_loss: 0.6915 - val_acc: 0.7368\n",
      "Epoch 89/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6885 - acc: 0.8375 - val_loss: 0.6919 - val_acc: 0.5789\n",
      "Epoch 90/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6885 - acc: 0.6375 - val_loss: 0.6922 - val_acc: 0.4737\n",
      "Epoch 91/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6895 - acc: 0.5125 - val_loss: 0.6915 - val_acc: 0.6316\n",
      "Epoch 92/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6890 - acc: 0.7125 - val_loss: 0.6915 - val_acc: 0.7368\n",
      "Epoch 93/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6889 - acc: 0.6250 - val_loss: 0.6908 - val_acc: 0.5263\n",
      "Epoch 94/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6914 - acc: 0.4625 - val_loss: 0.6902 - val_acc: 0.5263\n",
      "Epoch 95/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.5263\n",
      "Epoch 96/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6900 - acc: 0.5500 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 97/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6890 - acc: 0.5000 - val_loss: 0.6903 - val_acc: 0.5263\n",
      "Epoch 98/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6890 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.4737\n",
      "Epoch 99/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6911 - acc: 0.5500 - val_loss: 0.6903 - val_acc: 0.5263\n",
      "Epoch 100/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6889 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.4737\n",
      "Epoch 101/3000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.6900 - acc: 0.5625 - val_loss: 0.6925 - val_acc: 0.4737\n",
      "Epoch 102/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6907 - acc: 0.5000 - val_loss: 0.6907 - val_acc: 0.5263\n",
      "Epoch 103/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6882 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.5789\n",
      "Epoch 104/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6881 - acc: 0.8250 - val_loss: 0.6908 - val_acc: 0.5263\n",
      "Epoch 105/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6914 - acc: 0.5625 - val_loss: 0.6914 - val_acc: 0.6842\n",
      "Epoch 106/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6881 - acc: 0.8000 - val_loss: 0.6914 - val_acc: 0.6842\n",
      "Epoch 107/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6885 - acc: 0.7000 - val_loss: 0.6913 - val_acc: 0.7368\n",
      "Epoch 108/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6897 - acc: 0.6625 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 109/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6893 - acc: 0.5000 - val_loss: 0.6906 - val_acc: 0.5263\n",
      "Epoch 110/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6905 - acc: 0.4375 - val_loss: 0.6900 - val_acc: 0.5263\n",
      "Epoch 111/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6904 - val_acc: 0.5263\n",
      "Epoch 112/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6891 - acc: 0.6875 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 113/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6888 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5263\n",
      "Epoch 114/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6888 - acc: 0.5000 - val_loss: 0.6902 - val_acc: 0.5263\n",
      "Epoch 115/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6885 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.5789\n",
      "Epoch 116/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6877 - acc: 0.8625 - val_loss: 0.6910 - val_acc: 0.5789\n",
      "Epoch 117/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6883 - acc: 0.7000 - val_loss: 0.6909 - val_acc: 0.5789\n",
      "Epoch 118/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6882 - acc: 0.6250 - val_loss: 0.6918 - val_acc: 0.4737\n",
      "Epoch 119/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6879 - acc: 0.6375 - val_loss: 0.6920 - val_acc: 0.4737\n",
      "Epoch 120/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.6878 - acc: 0.5000 - val_loss: 0.6912 - val_acc: 0.6842\n",
      "Epoch 121/3000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.6877 - acc: 0.8375 - val_loss: 0.6911 - val_acc: 0.7368\n",
      "Epoch 122/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6895 - acc: 0.5500 - val_loss: 0.6926 - val_acc: 0.4737\n",
      "Epoch 123/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.4737\n",
      "Epoch 124/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6879 - acc: 0.5125 - val_loss: 0.6925 - val_acc: 0.4737\n",
      "Epoch 125/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6899 - acc: 0.7125 - val_loss: 0.6939 - val_acc: 0.4737\n",
      "Epoch 126/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6893 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.4737\n",
      "Epoch 127/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6882 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.6842\n",
      "Epoch 128/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6932 - acc: 0.5625 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 129/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6903 - val_acc: 0.5263\n",
      "Epoch 130/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6885 - acc: 0.6500 - val_loss: 0.6897 - val_acc: 0.5263\n",
      "Epoch 131/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6882 - acc: 0.5000 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 132/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6876 - acc: 0.5250 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 133/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6900 - acc: 0.5000 - val_loss: 0.6902 - val_acc: 0.5263\n",
      "Epoch 134/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6906 - acc: 0.5125 - val_loss: 0.6907 - val_acc: 0.6842\n",
      "Epoch 135/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6876 - acc: 0.7625 - val_loss: 0.6916 - val_acc: 0.4737\n",
      "Epoch 136/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6859 - acc: 0.593 - 0s 125us/sample - loss: 0.6873 - acc: 0.5250 - val_loss: 0.6909 - val_acc: 0.6842\n",
      "Epoch 137/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6882 - acc: 0.6875 - val_loss: 0.6916 - val_acc: 0.4737\n",
      "Epoch 138/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6871 - acc: 0.5375 - val_loss: 0.6913 - val_acc: 0.5263\n",
      "Epoch 139/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6882 - acc: 0.5750 - val_loss: 0.6915 - val_acc: 0.4737\n",
      "Epoch 140/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6873 - acc: 0.6250 - val_loss: 0.6916 - val_acc: 0.4737\n",
      "Epoch 141/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6893 - acc: 0.6000 - val_loss: 0.6910 - val_acc: 0.6316\n",
      "Epoch 142/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6888 - acc: 0.5625 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 143/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6871 - acc: 0.7875 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 144/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6911 - val_acc: 0.5789\n",
      "Epoch 145/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6880 - acc: 0.5250 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 146/3000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.6884 - acc: 0.5375 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 147/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6890 - acc: 0.5250 - val_loss: 0.6905 - val_acc: 0.6842\n",
      "Epoch 148/3000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.6882 - acc: 0.6500 - val_loss: 0.6919 - val_acc: 0.4737\n",
      "Epoch 149/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6880 - acc: 0.5000 - val_loss: 0.6905 - val_acc: 0.6842\n",
      "Epoch 150/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6872 - acc: 0.7625 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 151/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6874 - acc: 0.6750 - val_loss: 0.6896 - val_acc: 0.5263\n",
      "Epoch 152/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6870 - acc: 0.5125 - val_loss: 0.6896 - val_acc: 0.5263\n",
      "Epoch 153/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.4737\n",
      "Epoch 154/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6880 - acc: 0.5125 - val_loss: 0.6917 - val_acc: 0.4737\n",
      "Epoch 155/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6869 - acc: 0.5125 - val_loss: 0.6912 - val_acc: 0.4737\n",
      "Epoch 156/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6874 - acc: 0.6000 - val_loss: 0.6919 - val_acc: 0.4737\n",
      "Epoch 157/3000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.6873 - acc: 0.5625 - val_loss: 0.6920 - val_acc: 0.4737\n",
      "Epoch 158/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6914 - acc: 0.5500 - val_loss: 0.6955 - val_acc: 0.4737\n",
      "Epoch 159/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6915 - acc: 0.5000 - val_loss: 0.6955 - val_acc: 0.4737\n",
      "Epoch 160/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6943 - val_acc: 0.4737\n",
      "Epoch 161/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.4737\n",
      "Epoch 162/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6868 - acc: 0.5250 - val_loss: 0.6914 - val_acc: 0.4737\n",
      "Epoch 163/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6877 - acc: 0.6500 - val_loss: 0.6916 - val_acc: 0.4737\n",
      "Epoch 164/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6873 - acc: 0.5500 - val_loss: 0.6922 - val_acc: 0.4737\n",
      "Epoch 165/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6869 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.4737\n",
      "Epoch 166/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6876 - acc: 0.5000 - val_loss: 0.6905 - val_acc: 0.6842\n",
      "Epoch 167/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6884 - acc: 0.6625 - val_loss: 0.6909 - val_acc: 0.4737\n",
      "Epoch 168/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6865 - acc: 0.6875 - val_loss: 0.6912 - val_acc: 0.4737\n",
      "Epoch 169/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6868 - acc: 0.5125 - val_loss: 0.6901 - val_acc: 0.5263\n",
      "Epoch 170/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6864 - acc: 0.8750 - val_loss: 0.6900 - val_acc: 0.5263\n",
      "Epoch 171/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6897 - acc: 0.6625 - val_loss: 0.6898 - val_acc: 0.6316\n",
      "Epoch 172/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6863 - acc: 0.7625 - val_loss: 0.6896 - val_acc: 0.5263\n",
      "Epoch 173/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.6868 - acc: 0.5625 - val_loss: 0.6904 - val_acc: 0.7368\n",
      "Epoch 174/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6863 - acc: 0.8125 - val_loss: 0.6907 - val_acc: 0.5789\n",
      "Epoch 175/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6866 - acc: 0.5750 - val_loss: 0.6901 - val_acc: 0.6842\n",
      "Epoch 176/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6871 - acc: 0.7750 - val_loss: 0.6914 - val_acc: 0.4737\n",
      "Epoch 177/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6864 - acc: 0.5500 - val_loss: 0.6910 - val_acc: 0.4737\n",
      "Epoch 178/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6866 - acc: 0.7000 - val_loss: 0.6912 - val_acc: 0.4737\n",
      "Epoch 179/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6862 - acc: 0.5250 - val_loss: 0.6904 - val_acc: 0.7368\n",
      "Epoch 180/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6861 - acc: 0.6500 - val_loss: 0.6899 - val_acc: 0.5263\n",
      "Epoch 181/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6860 - acc: 0.8875 - val_loss: 0.6896 - val_acc: 0.5263\n",
      "Epoch 182/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6870 - acc: 0.6125 - val_loss: 0.6891 - val_acc: 0.5263\n",
      "Epoch 183/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6867 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.5263\n",
      "Epoch 184/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6871 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5263\n",
      "Epoch 185/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6866 - acc: 0.5125 - val_loss: 0.6890 - val_acc: 0.5263\n",
      "Epoch 186/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6865 - acc: 0.5250 - val_loss: 0.6894 - val_acc: 0.5263\n",
      "Epoch 187/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6878 - acc: 0.5875 - val_loss: 0.6887 - val_acc: 0.5263\n",
      "Epoch 188/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6864 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5263\n",
      "Epoch 189/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6860 - acc: 0.5125 - val_loss: 0.6890 - val_acc: 0.5263\n",
      "Epoch 190/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6905 - acc: 0.4250 - val_loss: 0.6887 - val_acc: 0.5263\n",
      "Epoch 191/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6865 - acc: 0.5000 - val_loss: 0.6894 - val_acc: 0.5263\n",
      "Epoch 192/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6868 - acc: 0.5750 - val_loss: 0.6899 - val_acc: 0.7368\n",
      "Epoch 193/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6856 - acc: 0.8875 - val_loss: 0.6898 - val_acc: 0.7368\n",
      "Epoch 194/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6876 - acc: 0.6250 - val_loss: 0.6888 - val_acc: 0.5263\n",
      "Epoch 195/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6859 - acc: 0.5375 - val_loss: 0.6888 - val_acc: 0.5263\n",
      "Epoch 196/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6859 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5263\n",
      "Epoch 197/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6868 - acc: 0.6500 - val_loss: 0.6894 - val_acc: 0.6316\n",
      "Epoch 198/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6856 - acc: 0.7750 - val_loss: 0.6898 - val_acc: 0.7368\n",
      "Epoch 199/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6861 - acc: 0.7125 - val_loss: 0.6897 - val_acc: 0.7368\n",
      "Epoch 200/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6866 - acc: 0.7750 - val_loss: 0.6894 - val_acc: 0.5789\n",
      "Epoch 201/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6884 - acc: 0.6125 - val_loss: 0.6886 - val_acc: 0.5263\n",
      "Epoch 202/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5263\n",
      "Epoch 203/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6867 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5263\n",
      "Epoch 204/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5263\n",
      "Epoch 205/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6863 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5263\n",
      "Epoch 206/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6857 - acc: 0.5625 - val_loss: 0.6899 - val_acc: 0.6842\n",
      "Epoch 207/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6864 - acc: 0.7500 - val_loss: 0.6891 - val_acc: 0.5263\n",
      "Epoch 208/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6883 - acc: 0.5750 - val_loss: 0.6886 - val_acc: 0.5263\n",
      "Epoch 209/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6856 - acc: 0.5125 - val_loss: 0.6885 - val_acc: 0.5263\n",
      "Epoch 210/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6865 - acc: 0.5125 - val_loss: 0.6893 - val_acc: 0.5789\n",
      "Epoch 211/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6856 - acc: 0.7500 - val_loss: 0.6897 - val_acc: 0.7368\n",
      "Epoch 212/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6878 - acc: 0.6250 - val_loss: 0.6898 - val_acc: 0.7368\n",
      "Epoch 213/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6883 - acc: 0.687 - 0s 116us/sample - loss: 0.6862 - acc: 0.6750 - val_loss: 0.6906 - val_acc: 0.4737\n",
      "Epoch 214/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6864 - acc: 0.6375 - val_loss: 0.6898 - val_acc: 0.6842\n",
      "Epoch 215/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6857 - acc: 0.7875 - val_loss: 0.6898 - val_acc: 0.6842\n",
      "Epoch 216/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6856 - acc: 0.8250 - val_loss: 0.6906 - val_acc: 0.4737\n",
      "Epoch 217/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6853 - acc: 0.5625 - val_loss: 0.6907 - val_acc: 0.4737\n",
      "Epoch 218/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6851 - acc: 0.5125 - val_loss: 0.6902 - val_acc: 0.4737\n",
      "Epoch 219/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6854 - acc: 0.5250 - val_loss: 0.6891 - val_acc: 0.6842\n",
      "Epoch 220/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6863 - acc: 0.7250 - val_loss: 0.6892 - val_acc: 0.6842\n",
      "Epoch 221/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6859 - acc: 0.7125 - val_loss: 0.6885 - val_acc: 0.5263\n",
      "Epoch 222/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6851 - acc: 0.6375 - val_loss: 0.6884 - val_acc: 0.5263\n",
      "Epoch 223/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6849 - acc: 0.500 - 0s 129us/sample - loss: 0.6851 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.6316\n",
      "Epoch 224/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6853 - acc: 0.8125 - val_loss: 0.6886 - val_acc: 0.5263\n",
      "Epoch 225/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6858 - acc: 0.5000 - val_loss: 0.6898 - val_acc: 0.6316\n",
      "Epoch 226/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6853 - acc: 0.5750 - val_loss: 0.6888 - val_acc: 0.6316\n",
      "Epoch 227/3000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.6854 - acc: 0.8000 - val_loss: 0.6884 - val_acc: 0.5263\n",
      "Epoch 228/3000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.6849 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.6316\n",
      "Epoch 229/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6848 - acc: 0.8250 - val_loss: 0.6892 - val_acc: 0.7368\n",
      "Epoch 230/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6847 - acc: 0.8625 - val_loss: 0.6891 - val_acc: 0.7368\n",
      "Epoch 231/3000\n",
      "80/80 [==============================] - 0s 301us/sample - loss: 0.6872 - acc: 0.6625 - val_loss: 0.6893 - val_acc: 0.7895\n",
      "Epoch 232/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6847 - acc: 0.8250 - val_loss: 0.6891 - val_acc: 0.7368\n",
      "Epoch 233/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6870 - acc: 0.6250 - val_loss: 0.6880 - val_acc: 0.5263\n",
      "Epoch 234/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6909 - acc: 0.5250 - val_loss: 0.6880 - val_acc: 0.5263\n",
      "Epoch 235/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6873 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 236/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6872 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5263\n",
      "Epoch 237/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6871 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5263\n",
      "Epoch 238/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6874 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5263\n",
      "Epoch 239/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6860 - acc: 0.5000 - val_loss: 0.6877 - val_acc: 0.5263\n",
      "Epoch 240/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6879 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 241/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6860 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 242/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6862 - acc: 0.6500 - val_loss: 0.6876 - val_acc: 0.5263\n",
      "Epoch 243/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6855 - acc: 0.5000 - val_loss: 0.6879 - val_acc: 0.5263\n",
      "Epoch 244/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6880 - acc: 0.5125 - val_loss: 0.6879 - val_acc: 0.5263\n",
      "Epoch 245/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6845 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5263\n",
      "Epoch 246/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6877 - acc: 0.5375 - val_loss: 0.6887 - val_acc: 0.7895\n",
      "Epoch 247/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6846 - acc: 0.8875 - val_loss: 0.6881 - val_acc: 0.5263\n",
      "Epoch 248/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6847 - acc: 0.7250 - val_loss: 0.6880 - val_acc: 0.5263\n",
      "Epoch 249/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6842 - acc: 0.5250 - val_loss: 0.6881 - val_acc: 0.5263\n",
      "Epoch 250/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6843 - acc: 0.6375 - val_loss: 0.6880 - val_acc: 0.5263\n",
      "Epoch 251/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6862 - acc: 0.6250 - val_loss: 0.6875 - val_acc: 0.5263\n",
      "Epoch 252/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6852 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5263\n",
      "Epoch 253/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6857 - acc: 0.5000 - val_loss: 0.6876 - val_acc: 0.5263\n",
      "Epoch 254/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6848 - acc: 0.5000 - val_loss: 0.6879 - val_acc: 0.5263\n",
      "Epoch 255/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6845 - acc: 0.7375 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 256/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6845 - acc: 0.6125 - val_loss: 0.6876 - val_acc: 0.5263\n",
      "Epoch 257/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.6842 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 258/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6858 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6842 - acc: 0.8125 - val_loss: 0.6882 - val_acc: 0.6316\n",
      "Epoch 260/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6837 - acc: 0.8750 - val_loss: 0.6883 - val_acc: 0.5789\n",
      "Epoch 261/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6838 - acc: 0.8875 - val_loss: 0.6883 - val_acc: 0.6316\n",
      "Epoch 262/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6841 - acc: 0.8500 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 263/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6883 - acc: 0.4875 - val_loss: 0.6872 - val_acc: 0.5263\n",
      "Epoch 264/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6872 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 265/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6841 - acc: 0.6500 - val_loss: 0.6882 - val_acc: 0.6316\n",
      "Epoch 266/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6846 - acc: 0.8000 - val_loss: 0.6875 - val_acc: 0.5263\n",
      "Epoch 267/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6843 - acc: 0.5250 - val_loss: 0.6875 - val_acc: 0.5263\n",
      "Epoch 268/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6842 - acc: 0.5625 - val_loss: 0.6874 - val_acc: 0.5263\n",
      "Epoch 269/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6838 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 270/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6845 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.6842\n",
      "Epoch 271/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6834 - acc: 0.8250 - val_loss: 0.6886 - val_acc: 0.7368\n",
      "Epoch 272/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6835 - acc: 0.8875 - val_loss: 0.6889 - val_acc: 0.6842\n",
      "Epoch 273/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6855 - acc: 0.6375 - val_loss: 0.6901 - val_acc: 0.4737\n",
      "Epoch 274/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6858 - acc: 0.5375 - val_loss: 0.6899 - val_acc: 0.4737\n",
      "Epoch 275/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6836 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.4737\n",
      "Epoch 276/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6838 - acc: 0.5250 - val_loss: 0.6881 - val_acc: 0.7895\n",
      "Epoch 277/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6836 - acc: 0.8000 - val_loss: 0.6878 - val_acc: 0.5789\n",
      "Epoch 278/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6843 - acc: 0.6500 - val_loss: 0.6874 - val_acc: 0.5263\n",
      "Epoch 279/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6851 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.7368\n",
      "Epoch 280/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6835 - acc: 0.8250 - val_loss: 0.6887 - val_acc: 0.6842\n",
      "Epoch 281/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6852 - acc: 0.7125 - val_loss: 0.6881 - val_acc: 0.7368\n",
      "Epoch 282/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6837 - acc: 0.7750 - val_loss: 0.6882 - val_acc: 0.7368\n",
      "Epoch 283/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6840 - acc: 0.7250 - val_loss: 0.6891 - val_acc: 0.4737\n",
      "Epoch 284/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6841 - acc: 0.5125 - val_loss: 0.6882 - val_acc: 0.7895\n",
      "Epoch 285/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6839 - acc: 0.7000 - val_loss: 0.6872 - val_acc: 0.5263\n",
      "Epoch 286/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6831 - acc: 0.5375 - val_loss: 0.6877 - val_acc: 0.6316\n",
      "Epoch 287/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6833 - acc: 0.6750 - val_loss: 0.6881 - val_acc: 0.7895\n",
      "Epoch 288/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6839 - acc: 0.7250 - val_loss: 0.6886 - val_acc: 0.6842\n",
      "Epoch 289/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6833 - acc: 0.7875 - val_loss: 0.6880 - val_acc: 0.7368\n",
      "Epoch 290/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6838 - acc: 0.8000 - val_loss: 0.6893 - val_acc: 0.4737\n",
      "Epoch 291/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6829 - acc: 0.5625 - val_loss: 0.6888 - val_acc: 0.4737\n",
      "Epoch 292/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6829 - acc: 0.6750 - val_loss: 0.6886 - val_acc: 0.6842\n",
      "Epoch 293/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6838 - acc: 0.6750 - val_loss: 0.6887 - val_acc: 0.5789\n",
      "Epoch 294/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6848 - acc: 0.6250 - val_loss: 0.6890 - val_acc: 0.4737\n",
      "Epoch 295/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6827 - acc: 0.5750 - val_loss: 0.6886 - val_acc: 0.5789\n",
      "Epoch 296/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6852 - acc: 0.6125 - val_loss: 0.6882 - val_acc: 0.6842\n",
      "Epoch 297/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6844 - acc: 0.7000 - val_loss: 0.6891 - val_acc: 0.4737\n",
      "Epoch 298/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6828 - acc: 0.6125 - val_loss: 0.6887 - val_acc: 0.4737\n",
      "Epoch 299/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6826 - acc: 0.6875 - val_loss: 0.6884 - val_acc: 0.6842\n",
      "Epoch 300/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6835 - acc: 0.6375 - val_loss: 0.6877 - val_acc: 0.7895\n",
      "Epoch 301/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6823 - acc: 0.9375 - val_loss: 0.6877 - val_acc: 0.7895\n",
      "Epoch 302/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6834 - acc: 0.7625 - val_loss: 0.6872 - val_acc: 0.6316\n",
      "Epoch 303/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6836 - acc: 0.7625 - val_loss: 0.6866 - val_acc: 0.5263\n",
      "Epoch 304/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6840 - acc: 0.5000 - val_loss: 0.6868 - val_acc: 0.5263\n",
      "Epoch 305/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6828 - acc: 0.7125 - val_loss: 0.6867 - val_acc: 0.5263\n",
      "Epoch 306/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6825 - acc: 0.5750 - val_loss: 0.6869 - val_acc: 0.5263\n",
      "Epoch 307/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6826 - acc: 0.6625 - val_loss: 0.6873 - val_acc: 0.6316\n",
      "Epoch 308/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6827 - acc: 0.7250 - val_loss: 0.6874 - val_acc: 0.7895\n",
      "Epoch 309/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6831 - acc: 0.7625 - val_loss: 0.6881 - val_acc: 0.6842\n",
      "Epoch 310/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6845 - acc: 0.6500 - val_loss: 0.6902 - val_acc: 0.4737\n",
      "Epoch 311/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6825 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.4737\n",
      "Epoch 312/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6824 - acc: 0.5375 - val_loss: 0.6892 - val_acc: 0.4737\n",
      "Epoch 313/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6823 - acc: 0.5625 - val_loss: 0.6887 - val_acc: 0.4737\n",
      "Epoch 314/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6841 - acc: 0.5875 - val_loss: 0.6886 - val_acc: 0.4737\n",
      "Epoch 315/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6830 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.7895\n",
      "Epoch 316/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6824 - acc: 0.8625 - val_loss: 0.6876 - val_acc: 0.7895\n",
      "Epoch 317/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6822 - acc: 0.8625 - val_loss: 0.6879 - val_acc: 0.6842\n",
      "Epoch 318/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6828 - acc: 0.8125 - val_loss: 0.6888 - val_acc: 0.4737\n",
      "Epoch 319/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6823 - acc: 0.6125 - val_loss: 0.6878 - val_acc: 0.6842\n",
      "Epoch 320/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6818 - acc: 0.8375 - val_loss: 0.6881 - val_acc: 0.5789\n",
      "Epoch 321/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6816 - acc: 0.7500 - val_loss: 0.6879 - val_acc: 0.6842\n",
      "Epoch 322/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6817 - acc: 0.8625 - val_loss: 0.6881 - val_acc: 0.5789\n",
      "Epoch 323/3000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.6821 - acc: 0.6125 - val_loss: 0.6870 - val_acc: 0.6842\n",
      "Epoch 324/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6814 - acc: 0.9000 - val_loss: 0.6870 - val_acc: 0.7368\n",
      "Epoch 325/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6824 - acc: 0.7750 - val_loss: 0.6862 - val_acc: 0.5263\n",
      "Epoch 326/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6821 - acc: 0.6750 - val_loss: 0.6862 - val_acc: 0.5263\n",
      "Epoch 327/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6818 - acc: 0.5375 - val_loss: 0.6861 - val_acc: 0.5263\n",
      "Epoch 328/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6848 - acc: 0.5500 - val_loss: 0.6860 - val_acc: 0.5263\n",
      "Epoch 329/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6828 - acc: 0.5625 - val_loss: 0.6864 - val_acc: 0.5263\n",
      "Epoch 330/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6823 - acc: 0.5125 - val_loss: 0.6876 - val_acc: 0.6842\n",
      "Epoch 331/3000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.6816 - acc: 0.8625 - val_loss: 0.6884 - val_acc: 0.4737\n",
      "Epoch 332/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6818 - acc: 0.5875 - val_loss: 0.6883 - val_acc: 0.4737\n",
      "Epoch 333/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6819 - acc: 0.5375 - val_loss: 0.6878 - val_acc: 0.6316\n",
      "Epoch 334/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6833 - acc: 0.6625 - val_loss: 0.6878 - val_acc: 0.5263\n",
      "Epoch 335/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6839 - acc: 0.5375 - val_loss: 0.6863 - val_acc: 0.5263\n",
      "Epoch 336/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6830 - acc: 0.6625 - val_loss: 0.6880 - val_acc: 0.4737\n",
      "Epoch 337/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6812 - acc: 0.6750 - val_loss: 0.6881 - val_acc: 0.4737\n",
      "Epoch 338/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6817 - acc: 0.6250 - val_loss: 0.6887 - val_acc: 0.4737\n",
      "Epoch 339/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.6813 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.6842\n",
      "Epoch 340/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6819 - acc: 0.6375 - val_loss: 0.6865 - val_acc: 0.6316\n",
      "Epoch 341/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6820 - acc: 0.8000 - val_loss: 0.6860 - val_acc: 0.5263\n",
      "Epoch 342/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6815 - acc: 0.5125 - val_loss: 0.6862 - val_acc: 0.5263\n",
      "Epoch 343/3000\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.6812 - acc: 0.6625 - val_loss: 0.6867 - val_acc: 0.8421\n",
      "Epoch 344/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6853 - acc: 0.6625 - val_loss: 0.6861 - val_acc: 0.5789\n",
      "Epoch 345/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6806 - acc: 0.8250 - val_loss: 0.6862 - val_acc: 0.6316\n",
      "Epoch 346/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6811 - acc: 0.8500 - val_loss: 0.6866 - val_acc: 0.8421\n",
      "Epoch 347/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6807 - acc: 0.9125 - val_loss: 0.6865 - val_acc: 0.8421\n",
      "Epoch 348/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6809 - acc: 0.8875 - val_loss: 0.6873 - val_acc: 0.6842\n",
      "Epoch 349/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6850 - acc: 0.6000 - val_loss: 0.6861 - val_acc: 0.6842\n",
      "Epoch 350/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6811 - acc: 0.9000 - val_loss: 0.6857 - val_acc: 0.5263\n",
      "Epoch 351/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6823 - acc: 0.5250 - val_loss: 0.6866 - val_acc: 0.7895\n",
      "Epoch 352/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6815 - acc: 0.8250 - val_loss: 0.6862 - val_acc: 0.7368\n",
      "Epoch 353/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6804 - acc: 0.9125 - val_loss: 0.6859 - val_acc: 0.6316\n",
      "Epoch 354/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6822 - acc: 0.6125 - val_loss: 0.6873 - val_acc: 0.6316\n",
      "Epoch 355/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6809 - acc: 0.8625 - val_loss: 0.6880 - val_acc: 0.4737\n",
      "Epoch 356/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6804 - acc: 0.5625 - val_loss: 0.6874 - val_acc: 0.5263\n",
      "Epoch 357/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6804 - acc: 0.7125 - val_loss: 0.6875 - val_acc: 0.4737\n",
      "Epoch 358/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6804 - acc: 0.7500 - val_loss: 0.6876 - val_acc: 0.4737\n",
      "Epoch 359/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6837 - acc: 0.6500 - val_loss: 0.6879 - val_acc: 0.4737\n",
      "Epoch 360/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6802 - acc: 0.5750 - val_loss: 0.6873 - val_acc: 0.5263\n",
      "Epoch 361/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6860 - acc: 0.6125 - val_loss: 0.6867 - val_acc: 0.6842\n",
      "Epoch 362/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6800 - acc: 0.8125 - val_loss: 0.6862 - val_acc: 0.8421\n",
      "Epoch 363/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6800 - acc: 0.9000 - val_loss: 0.6858 - val_acc: 0.6842\n",
      "Epoch 364/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6843 - acc: 0.6125 - val_loss: 0.6868 - val_acc: 0.6842\n",
      "Epoch 365/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6818 - acc: 0.7500 - val_loss: 0.6859 - val_acc: 0.7368\n",
      "Epoch 366/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6804 - acc: 0.8750 - val_loss: 0.6853 - val_acc: 0.5263\n",
      "Epoch 367/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6803 - acc: 0.7625 - val_loss: 0.6852 - val_acc: 0.5263\n",
      "Epoch 368/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6809 - acc: 0.6625 - val_loss: 0.6856 - val_acc: 0.6842\n",
      "Epoch 369/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6815 - acc: 0.6375 - val_loss: 0.6865 - val_acc: 0.6842\n",
      "Epoch 370/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6773 - acc: 0.875 - 0s 122us/sample - loss: 0.6806 - acc: 0.6625 - val_loss: 0.6853 - val_acc: 0.5263\n",
      "Epoch 371/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6802 - acc: 0.8750 - val_loss: 0.6849 - val_acc: 0.5263\n",
      "Epoch 372/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6819 - acc: 0.6625 - val_loss: 0.6849 - val_acc: 0.5263\n",
      "Epoch 373/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6799 - acc: 0.5375 - val_loss: 0.6850 - val_acc: 0.5263\n",
      "Epoch 374/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6802 - acc: 0.5375 - val_loss: 0.6852 - val_acc: 0.5263\n",
      "Epoch 375/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6834 - acc: 0.6625 - val_loss: 0.6846 - val_acc: 0.5263\n",
      "Epoch 376/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6826 - acc: 0.5000 - val_loss: 0.6855 - val_acc: 0.6842\n",
      "Epoch 377/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6794 - acc: 0.9250 - val_loss: 0.6855 - val_acc: 0.7368\n",
      "Epoch 378/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6811 - acc: 0.7375 - val_loss: 0.6849 - val_acc: 0.5263\n",
      "Epoch 379/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6805 - acc: 0.7125 - val_loss: 0.6845 - val_acc: 0.5263\n",
      "Epoch 380/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6799 - acc: 0.5125 - val_loss: 0.6846 - val_acc: 0.5263\n",
      "Epoch 381/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6797 - acc: 0.5000 - val_loss: 0.6847 - val_acc: 0.5263\n",
      "Epoch 382/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6824 - acc: 0.6875 - val_loss: 0.6844 - val_acc: 0.5263\n",
      "Epoch 383/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6804 - acc: 0.5000 - val_loss: 0.6844 - val_acc: 0.5263\n",
      "Epoch 384/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6801 - acc: 0.5000 - val_loss: 0.6849 - val_acc: 0.5263\n",
      "Epoch 385/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6801 - acc: 0.7750 - val_loss: 0.6845 - val_acc: 0.5263\n",
      "Epoch 386/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6794 - acc: 0.5625 - val_loss: 0.6847 - val_acc: 0.5263\n",
      "Epoch 387/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6800 - acc: 0.5375 - val_loss: 0.6852 - val_acc: 0.7368\n",
      "Epoch 388/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6789 - acc: 0.9250 - val_loss: 0.6849 - val_acc: 0.6316\n",
      "Epoch 389/3000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.6789 - acc: 0.9125 - val_loss: 0.6847 - val_acc: 0.5263\n",
      "Epoch 390/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6787 - acc: 0.7500 - val_loss: 0.6849 - val_acc: 0.6316\n",
      "Epoch 391/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6786 - acc: 0.8625 - val_loss: 0.6850 - val_acc: 0.6842\n",
      "Epoch 392/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.6805 - acc: 0.6250 - val_loss: 0.6868 - val_acc: 0.4737\n",
      "Epoch 393/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6800 - acc: 0.6500 - val_loss: 0.6874 - val_acc: 0.4737\n",
      "Epoch 394/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6800 - acc: 0.6375 - val_loss: 0.6862 - val_acc: 0.6316\n",
      "Epoch 395/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6792 - acc: 0.8625 - val_loss: 0.6870 - val_acc: 0.4737\n",
      "Epoch 396/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6809 - acc: 0.5750 - val_loss: 0.6868 - val_acc: 0.4737\n",
      "Epoch 397/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6788 - acc: 0.6250 - val_loss: 0.6867 - val_acc: 0.4737\n",
      "Epoch 398/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6789 - acc: 0.5500 - val_loss: 0.6857 - val_acc: 0.7368\n",
      "Epoch 399/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6789 - acc: 0.7750 - val_loss: 0.6855 - val_acc: 0.7895\n",
      "Epoch 400/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6788 - acc: 0.8625 - val_loss: 0.6847 - val_acc: 0.6842\n",
      "Epoch 401/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6834 - acc: 0.6625 - val_loss: 0.6844 - val_acc: 0.5263\n",
      "Epoch 402/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6789 - acc: 0.6875 - val_loss: 0.6847 - val_acc: 0.5263\n",
      "Epoch 403/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6787 - acc: 0.8000 - val_loss: 0.6846 - val_acc: 0.5263\n",
      "Epoch 404/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6787 - acc: 0.6375 - val_loss: 0.6850 - val_acc: 0.6842\n",
      "Epoch 405/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6781 - acc: 0.8500 - val_loss: 0.6854 - val_acc: 0.8421\n",
      "Epoch 406/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6781 - acc: 0.9250 - val_loss: 0.6854 - val_acc: 0.8421\n",
      "Epoch 407/3000\n",
      "80/80 [==============================] - 0s 246us/sample - loss: 0.6805 - acc: 0.7500 - val_loss: 0.6855 - val_acc: 0.8947\n",
      "Epoch 408/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6798 - acc: 0.7250 - val_loss: 0.6875 - val_acc: 0.4737\n",
      "Epoch 409/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6786 - acc: 0.5125 - val_loss: 0.6858 - val_acc: 0.7368\n",
      "Epoch 410/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6779 - acc: 0.9500 - val_loss: 0.6860 - val_acc: 0.6842\n",
      "Epoch 411/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6789 - acc: 0.8125 - val_loss: 0.6855 - val_acc: 0.8421\n",
      "Epoch 412/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6828 - acc: 0.6750 - val_loss: 0.6856 - val_acc: 0.7895\n",
      "Epoch 413/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6781 - acc: 0.8750 - val_loss: 0.6858 - val_acc: 0.6842\n",
      "Epoch 414/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6797 - acc: 0.6500 - val_loss: 0.6851 - val_acc: 0.8421\n",
      "Epoch 415/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6786 - acc: 0.9250 - val_loss: 0.6845 - val_acc: 0.5263\n",
      "Epoch 416/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6781 - acc: 0.7000 - val_loss: 0.6853 - val_acc: 0.8947\n",
      "Epoch 417/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6794 - acc: 0.7500 - val_loss: 0.6848 - val_acc: 0.7368\n",
      "Epoch 418/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6789 - acc: 0.8500 - val_loss: 0.6847 - val_acc: 0.7368\n",
      "Epoch 419/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6784 - acc: 0.7000 - val_loss: 0.6852 - val_acc: 0.8421\n",
      "Epoch 420/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6783 - acc: 0.8250 - val_loss: 0.6847 - val_acc: 0.7368\n",
      "Epoch 421/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6773 - acc: 0.8625 - val_loss: 0.6851 - val_acc: 0.8421\n",
      "Epoch 422/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6783 - acc: 0.8000 - val_loss: 0.6846 - val_acc: 0.6842\n",
      "Epoch 423/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6777 - acc: 0.8500 - val_loss: 0.6854 - val_acc: 0.6842\n",
      "Epoch 424/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.6772 - acc: 0.8750 - val_loss: 0.6853 - val_acc: 0.7895\n",
      "Epoch 425/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6789 - acc: 0.8250 - val_loss: 0.6862 - val_acc: 0.5263\n",
      "Epoch 426/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6772 - acc: 0.6125 - val_loss: 0.6853 - val_acc: 0.7895\n",
      "Epoch 427/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6773 - acc: 0.8375 - val_loss: 0.6844 - val_acc: 0.6842\n",
      "Epoch 428/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6779 - acc: 0.6750 - val_loss: 0.6853 - val_acc: 0.6842\n",
      "Epoch 429/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6770 - acc: 0.8500 - val_loss: 0.6847 - val_acc: 0.8421\n",
      "Epoch 430/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6788 - acc: 0.7750 - val_loss: 0.6852 - val_acc: 0.7368\n",
      "Epoch 431/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6799 - acc: 0.6500 - val_loss: 0.6836 - val_acc: 0.5263\n",
      "Epoch 432/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.6773 - acc: 0.5750 - val_loss: 0.6838 - val_acc: 0.5263\n",
      "Epoch 433/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.6770 - acc: 0.6875 - val_loss: 0.6839 - val_acc: 0.5263\n",
      "Epoch 434/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6813 - acc: 0.5500 - val_loss: 0.6862 - val_acc: 0.4737\n",
      "Epoch 435/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6780 - acc: 0.7000 - val_loss: 0.6853 - val_acc: 0.6842\n",
      "Epoch 436/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6777 - acc: 0.8625 - val_loss: 0.6866 - val_acc: 0.4737\n",
      "Epoch 437/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6779 - acc: 0.6000 - val_loss: 0.6850 - val_acc: 0.7368\n",
      "Epoch 438/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6770 - acc: 0.8000 - val_loss: 0.6847 - val_acc: 0.8421\n",
      "Epoch 439/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6763 - acc: 0.9125 - val_loss: 0.6846 - val_acc: 0.8947\n",
      "Epoch 440/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6768 - acc: 0.9250 - val_loss: 0.6849 - val_acc: 0.6842\n",
      "Epoch 441/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6774 - acc: 0.8125 - val_loss: 0.6856 - val_acc: 0.5789\n",
      "Epoch 442/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6765 - acc: 0.7875 - val_loss: 0.6856 - val_acc: 0.5263\n",
      "Epoch 443/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6816 - acc: 0.6750 - val_loss: 0.6849 - val_acc: 0.7368\n",
      "Epoch 444/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6761 - acc: 0.8375 - val_loss: 0.6847 - val_acc: 0.7895\n",
      "Epoch 445/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6762 - acc: 0.9125 - val_loss: 0.6846 - val_acc: 0.7895\n",
      "Epoch 446/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6764 - acc: 0.8750 - val_loss: 0.6840 - val_acc: 0.8421\n",
      "Epoch 447/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6770 - acc: 0.8750 - val_loss: 0.6834 - val_acc: 0.5263\n",
      "Epoch 448/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6762 - acc: 0.8000 - val_loss: 0.6835 - val_acc: 0.6316\n",
      "Epoch 449/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6774 - acc: 0.8125 - val_loss: 0.6836 - val_acc: 0.6842\n",
      "Epoch 450/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6762 - acc: 0.7500 - val_loss: 0.6844 - val_acc: 0.8421\n",
      "Epoch 451/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6772 - acc: 0.7875 - val_loss: 0.6842 - val_acc: 0.8947\n",
      "Epoch 452/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6761 - acc: 0.8625 - val_loss: 0.6834 - val_acc: 0.6842\n",
      "Epoch 453/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6757 - acc: 0.8625 - val_loss: 0.6835 - val_acc: 0.6842\n",
      "Epoch 454/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6762 - acc: 0.7750 - val_loss: 0.6836 - val_acc: 0.7368\n",
      "Epoch 455/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6761 - acc: 0.8750 - val_loss: 0.6843 - val_acc: 0.6842\n",
      "Epoch 456/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6761 - acc: 0.9250 - val_loss: 0.6851 - val_acc: 0.5263\n",
      "Epoch 457/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6757 - acc: 0.6750 - val_loss: 0.6842 - val_acc: 0.7895\n",
      "Epoch 458/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6765 - acc: 0.8625 - val_loss: 0.6848 - val_acc: 0.6316\n",
      "Epoch 459/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6764 - acc: 0.6625 - val_loss: 0.6833 - val_acc: 0.7368\n",
      "Epoch 460/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6757 - acc: 0.9000 - val_loss: 0.6828 - val_acc: 0.5263\n",
      "Epoch 461/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6765 - acc: 0.8375 - val_loss: 0.6824 - val_acc: 0.5263\n",
      "Epoch 462/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6789 - acc: 0.6750 - val_loss: 0.6823 - val_acc: 0.5263\n",
      "Epoch 463/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6768 - acc: 0.5000 - val_loss: 0.6823 - val_acc: 0.5263\n",
      "Epoch 464/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6758 - acc: 0.5250 - val_loss: 0.6823 - val_acc: 0.5263\n",
      "Epoch 465/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6759 - acc: 0.5500 - val_loss: 0.6827 - val_acc: 0.5263\n",
      "Epoch 466/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6760 - acc: 0.6500 - val_loss: 0.6838 - val_acc: 0.7895\n",
      "Epoch 467/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6750 - acc: 0.8500 - val_loss: 0.6832 - val_acc: 0.8421\n",
      "Epoch 468/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6748 - acc: 0.9500 - val_loss: 0.6832 - val_acc: 0.8421\n",
      "Epoch 469/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6759 - acc: 0.8875 - val_loss: 0.6826 - val_acc: 0.6842\n",
      "Epoch 470/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6752 - acc: 0.7500 - val_loss: 0.6831 - val_acc: 0.8421\n",
      "Epoch 471/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6748 - acc: 0.9125 - val_loss: 0.6831 - val_acc: 0.8421\n",
      "Epoch 472/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6752 - acc: 0.9250 - val_loss: 0.6825 - val_acc: 0.5789\n",
      "Epoch 473/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.6747 - acc: 0.8125 - val_loss: 0.6826 - val_acc: 0.7368\n",
      "Epoch 474/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6766 - acc: 0.8500 - val_loss: 0.6819 - val_acc: 0.5263\n",
      "Epoch 475/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6762 - acc: 0.6500 - val_loss: 0.6819 - val_acc: 0.5263\n",
      "Epoch 476/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6750 - acc: 0.5125 - val_loss: 0.6822 - val_acc: 0.5263\n",
      "Epoch 477/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6778 - acc: 0.6125 - val_loss: 0.6828 - val_acc: 0.8421\n",
      "Epoch 478/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6753 - acc: 0.8750 - val_loss: 0.6822 - val_acc: 0.5263\n",
      "Epoch 479/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6748 - acc: 0.8875 - val_loss: 0.6821 - val_acc: 0.5263\n",
      "Epoch 480/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6749 - acc: 0.6750 - val_loss: 0.6823 - val_acc: 0.6842\n",
      "Epoch 481/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6743 - acc: 0.8875 - val_loss: 0.6823 - val_acc: 0.7368\n",
      "Epoch 482/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6773 - acc: 0.7750 - val_loss: 0.6818 - val_acc: 0.5263\n",
      "Epoch 483/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6755 - acc: 0.5750 - val_loss: 0.6817 - val_acc: 0.5263\n",
      "Epoch 484/3000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.6755 - acc: 0.6000 - val_loss: 0.6820 - val_acc: 0.5263\n",
      "Epoch 485/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.6741 - acc: 0.8250 - val_loss: 0.6821 - val_acc: 0.7368\n",
      "Epoch 486/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6749 - acc: 0.6875 - val_loss: 0.6826 - val_acc: 0.8421\n",
      "Epoch 487/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6743 - acc: 0.8625 - val_loss: 0.6834 - val_acc: 0.6842\n",
      "Epoch 488/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6769 - acc: 0.7750 - val_loss: 0.6843 - val_acc: 0.5263\n",
      "Epoch 489/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6745 - acc: 0.6750 - val_loss: 0.6842 - val_acc: 0.5263\n",
      "Epoch 490/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6746 - acc: 0.7500 - val_loss: 0.6837 - val_acc: 0.6316\n",
      "Epoch 491/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6746 - acc: 0.6875 - val_loss: 0.6821 - val_acc: 0.7368\n",
      "Epoch 492/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6746 - acc: 0.9375 - val_loss: 0.6814 - val_acc: 0.5263\n",
      "Epoch 493/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.6758 - acc: 0.6625 - val_loss: 0.6817 - val_acc: 0.6842\n",
      "Epoch 494/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6740 - acc: 0.8000 - val_loss: 0.6825 - val_acc: 0.8947\n",
      "Epoch 495/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6744 - acc: 0.9000 - val_loss: 0.6832 - val_acc: 0.6842\n",
      "Epoch 496/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6734 - acc: 0.8625 - val_loss: 0.6834 - val_acc: 0.6316\n",
      "Epoch 497/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6739 - acc: 0.7625 - val_loss: 0.6822 - val_acc: 0.8421\n",
      "Epoch 498/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6735 - acc: 0.9375 - val_loss: 0.6816 - val_acc: 0.6842\n",
      "Epoch 499/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6741 - acc: 0.6875 - val_loss: 0.6821 - val_acc: 0.8421\n",
      "Epoch 500/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6731 - acc: 0.9500 - val_loss: 0.6817 - val_acc: 0.7368\n",
      "Epoch 501/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6750 - acc: 0.8375 - val_loss: 0.6828 - val_acc: 0.7368\n",
      "Epoch 502/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6741 - acc: 0.8250 - val_loss: 0.6834 - val_acc: 0.5789\n",
      "Epoch 503/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6731 - acc: 0.7125 - val_loss: 0.6829 - val_acc: 0.6842\n",
      "Epoch 504/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6750 - acc: 0.7750 - val_loss: 0.6840 - val_acc: 0.5263\n",
      "Epoch 505/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6731 - acc: 0.6000 - val_loss: 0.6827 - val_acc: 0.6842\n",
      "Epoch 506/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6727 - acc: 0.9125 - val_loss: 0.6829 - val_acc: 0.6316\n",
      "Epoch 507/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6741 - acc: 0.8375 - val_loss: 0.6826 - val_acc: 0.6842\n",
      "Epoch 508/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6726 - acc: 0.8250 - val_loss: 0.6822 - val_acc: 0.7368\n",
      "Epoch 509/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6725 - acc: 0.9250 - val_loss: 0.6821 - val_acc: 0.8947\n",
      "Epoch 510/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6723 - acc: 0.8500 - val_loss: 0.6815 - val_acc: 0.8421\n",
      "Epoch 511/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6742 - acc: 0.7750 - val_loss: 0.6820 - val_acc: 0.8947\n",
      "Epoch 512/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.6755 - acc: 0.8250 - val_loss: 0.6807 - val_acc: 0.5263\n",
      "Epoch 513/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6729 - acc: 0.8125 - val_loss: 0.6805 - val_acc: 0.5263\n",
      "Epoch 514/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6752 - acc: 0.5125 - val_loss: 0.6813 - val_acc: 0.7895\n",
      "Epoch 515/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6720 - acc: 0.9375 - val_loss: 0.6810 - val_acc: 0.7368\n",
      "Epoch 516/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6753 - acc: 0.8625 - val_loss: 0.6807 - val_acc: 0.5789\n",
      "Epoch 517/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6720 - acc: 0.8750 - val_loss: 0.6806 - val_acc: 0.5263\n",
      "Epoch 518/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6723 - acc: 0.8125 - val_loss: 0.6805 - val_acc: 0.5263\n",
      "Epoch 519/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6750 - acc: 0.6375 - val_loss: 0.6803 - val_acc: 0.5263\n",
      "Epoch 520/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6723 - acc: 0.5500 - val_loss: 0.6810 - val_acc: 0.7895\n",
      "Epoch 521/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6716 - acc: 0.9500 - val_loss: 0.6810 - val_acc: 0.7895\n",
      "Epoch 522/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6715 - acc: 0.9375 - val_loss: 0.6814 - val_acc: 0.8947\n",
      "Epoch 523/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6719 - acc: 0.8500 - val_loss: 0.6807 - val_acc: 0.7368\n",
      "Epoch 524/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6734 - acc: 0.7000 - val_loss: 0.6806 - val_acc: 0.7368\n",
      "Epoch 525/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6714 - acc: 0.9000 - val_loss: 0.6807 - val_acc: 0.7368\n",
      "Epoch 526/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6733 - acc: 0.8625 - val_loss: 0.6804 - val_acc: 0.6316\n",
      "Epoch 527/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6711 - acc: 0.8500 - val_loss: 0.6805 - val_acc: 0.7368\n",
      "Epoch 528/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6710 - acc: 0.8875 - val_loss: 0.6806 - val_acc: 0.7368\n",
      "Epoch 529/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6710 - acc: 0.8750 - val_loss: 0.6810 - val_acc: 0.8421\n",
      "Epoch 530/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.6713 - acc: 0.9000 - val_loss: 0.6806 - val_acc: 0.7368\n",
      "Epoch 531/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6745 - acc: 0.6375 - val_loss: 0.6831 - val_acc: 0.5263\n",
      "Epoch 532/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.6717 - acc: 0.6750 - val_loss: 0.6828 - val_acc: 0.5263\n",
      "Epoch 533/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6711 - acc: 0.7625 - val_loss: 0.6821 - val_acc: 0.6316\n",
      "Epoch 534/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6714 - acc: 0.8750 - val_loss: 0.6828 - val_acc: 0.5263\n",
      "Epoch 535/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6710 - acc: 0.7250 - val_loss: 0.6821 - val_acc: 0.6316\n",
      "Epoch 536/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.6708 - acc: 0.7750 - val_loss: 0.6815 - val_acc: 0.7368\n",
      "Epoch 537/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6717 - acc: 0.6625 - val_loss: 0.6801 - val_acc: 0.7368\n",
      "Epoch 538/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6734 - acc: 0.8375 - val_loss: 0.6796 - val_acc: 0.5263\n",
      "Epoch 539/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6719 - acc: 0.7125 - val_loss: 0.6795 - val_acc: 0.5263\n",
      "Epoch 540/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6718 - acc: 0.7000 - val_loss: 0.6794 - val_acc: 0.5263\n",
      "Epoch 541/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6719 - acc: 0.5000 - val_loss: 0.6796 - val_acc: 0.5263\n",
      "Epoch 542/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6706 - acc: 0.6750 - val_loss: 0.6800 - val_acc: 0.7368\n",
      "Epoch 543/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6711 - acc: 0.8750 - val_loss: 0.6798 - val_acc: 0.7368\n",
      "Epoch 544/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6704 - acc: 0.8000 - val_loss: 0.6802 - val_acc: 0.8421\n",
      "Epoch 545/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6719 - acc: 0.9000 - val_loss: 0.6813 - val_acc: 0.6316\n",
      "Epoch 546/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6713 - acc: 0.7250 - val_loss: 0.6809 - val_acc: 0.7368\n",
      "Epoch 547/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6696 - acc: 0.9000 - val_loss: 0.6806 - val_acc: 0.8947\n",
      "Epoch 548/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6716 - acc: 0.8875 - val_loss: 0.6798 - val_acc: 0.7368\n",
      "Epoch 549/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6696 - acc: 0.9500 - val_loss: 0.6796 - val_acc: 0.7368\n",
      "Epoch 550/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6699 - acc: 0.8625 - val_loss: 0.6800 - val_acc: 0.8947\n",
      "Epoch 551/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6708 - acc: 0.8750 - val_loss: 0.6799 - val_acc: 0.8421\n",
      "Epoch 552/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6697 - acc: 0.9250 - val_loss: 0.6802 - val_acc: 0.8947\n",
      "Epoch 553/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6743 - acc: 0.7375 - val_loss: 0.6803 - val_acc: 0.8947\n",
      "Epoch 554/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6712 - acc: 0.8375 - val_loss: 0.6804 - val_acc: 0.8421\n",
      "Epoch 555/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6702 - acc: 0.8625 - val_loss: 0.6811 - val_acc: 0.6316\n",
      "Epoch 556/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6692 - acc: 0.8250 - val_loss: 0.6811 - val_acc: 0.6316\n",
      "Epoch 557/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6701 - acc: 0.7125 - val_loss: 0.6800 - val_acc: 0.8947\n",
      "Epoch 558/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6687 - acc: 0.9250 - val_loss: 0.6799 - val_acc: 0.8947\n",
      "Epoch 559/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6698 - acc: 0.9625 - val_loss: 0.6807 - val_acc: 0.6316\n",
      "Epoch 560/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6689 - acc: 0.8250 - val_loss: 0.6804 - val_acc: 0.7368\n",
      "Epoch 561/3000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.6686 - acc: 0.8750 - val_loss: 0.6801 - val_acc: 0.8947\n",
      "Epoch 562/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6691 - acc: 0.9250 - val_loss: 0.6808 - val_acc: 0.6316\n",
      "Epoch 563/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6704 - acc: 0.6625 - val_loss: 0.6788 - val_acc: 0.7368\n",
      "Epoch 564/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6685 - acc: 0.9125 - val_loss: 0.6787 - val_acc: 0.6842\n",
      "Epoch 565/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6698 - acc: 0.8750 - val_loss: 0.6787 - val_acc: 0.7368\n",
      "Epoch 566/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6693 - acc: 0.9250 - val_loss: 0.6784 - val_acc: 0.5263\n",
      "Epoch 567/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6696 - acc: 0.7625 - val_loss: 0.6783 - val_acc: 0.5263\n",
      "Epoch 568/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6684 - acc: 0.6875 - val_loss: 0.6784 - val_acc: 0.5789\n",
      "Epoch 569/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6686 - acc: 0.6750 - val_loss: 0.6791 - val_acc: 0.8421\n",
      "Epoch 570/3000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.6683 - acc: 0.9500 - val_loss: 0.6787 - val_acc: 0.7895\n",
      "Epoch 571/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6692 - acc: 0.8625 - val_loss: 0.6789 - val_acc: 0.7895\n",
      "Epoch 572/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6697 - acc: 0.9125 - val_loss: 0.6784 - val_acc: 0.7368\n",
      "Epoch 573/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6687 - acc: 0.8000 - val_loss: 0.6789 - val_acc: 0.8421\n",
      "Epoch 574/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6676 - acc: 0.9375 - val_loss: 0.6786 - val_acc: 0.7368\n",
      "Epoch 575/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6685 - acc: 0.9000 - val_loss: 0.6784 - val_acc: 0.7895\n",
      "Epoch 576/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6675 - acc: 0.9000 - val_loss: 0.6785 - val_acc: 0.7368\n",
      "Epoch 577/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6684 - acc: 0.8375 - val_loss: 0.6790 - val_acc: 0.8947\n",
      "Epoch 578/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6704 - acc: 0.8375 - val_loss: 0.6801 - val_acc: 0.6316\n",
      "Epoch 579/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6674 - acc: 0.8500 - val_loss: 0.6802 - val_acc: 0.6316\n",
      "Epoch 580/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6653 - acc: 0.875 - 0s 115us/sample - loss: 0.6674 - acc: 0.8000 - val_loss: 0.6796 - val_acc: 0.7368\n",
      "Epoch 581/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6675 - acc: 0.8125 - val_loss: 0.6784 - val_acc: 0.7895\n",
      "Epoch 582/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6674 - acc: 0.9375 - val_loss: 0.6779 - val_acc: 0.7368\n",
      "Epoch 583/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6673 - acc: 0.8625 - val_loss: 0.6782 - val_acc: 0.7895\n",
      "Epoch 584/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6687 - acc: 0.8500 - val_loss: 0.6800 - val_acc: 0.6316\n",
      "Epoch 585/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6670 - acc: 0.8125 - val_loss: 0.6795 - val_acc: 0.6316\n",
      "Epoch 586/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6667 - acc: 0.8125 - val_loss: 0.6790 - val_acc: 0.8421\n",
      "Epoch 587/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6671 - acc: 0.9125 - val_loss: 0.6797 - val_acc: 0.6316\n",
      "Epoch 588/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6666 - acc: 0.7875 - val_loss: 0.6787 - val_acc: 0.8947\n",
      "Epoch 589/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6669 - acc: 0.9125 - val_loss: 0.6795 - val_acc: 0.6316\n",
      "Epoch 590/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6664 - acc: 0.8000 - val_loss: 0.6785 - val_acc: 0.8947\n",
      "Epoch 591/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6672 - acc: 0.8625 - val_loss: 0.6779 - val_acc: 0.7895\n",
      "Epoch 592/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6666 - acc: 0.9375 - val_loss: 0.6778 - val_acc: 0.7895\n",
      "Epoch 593/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6670 - acc: 0.8750 - val_loss: 0.6782 - val_acc: 0.8947\n",
      "Epoch 594/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6669 - acc: 0.9125 - val_loss: 0.6791 - val_acc: 0.6316\n",
      "Epoch 595/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6669 - acc: 0.8000 - val_loss: 0.6775 - val_acc: 0.7895\n",
      "Epoch 596/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6661 - acc: 0.9500 - val_loss: 0.6778 - val_acc: 0.8947\n",
      "Epoch 597/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6666 - acc: 0.9125 - val_loss: 0.6782 - val_acc: 0.8947\n",
      "Epoch 598/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6655 - acc: 0.9250 - val_loss: 0.6780 - val_acc: 0.8947\n",
      "Epoch 599/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6660 - acc: 0.9250 - val_loss: 0.6787 - val_acc: 0.6316\n",
      "Epoch 600/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6659 - acc: 0.8000 - val_loss: 0.6774 - val_acc: 0.7895\n",
      "Epoch 601/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6666 - acc: 0.8750 - val_loss: 0.6765 - val_acc: 0.5789\n",
      "Epoch 602/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6675 - acc: 0.8500 - val_loss: 0.6762 - val_acc: 0.5263\n",
      "Epoch 603/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6661 - acc: 0.5375 - val_loss: 0.6763 - val_acc: 0.5263\n",
      "Epoch 604/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6674 - acc: 0.8125 - val_loss: 0.6762 - val_acc: 0.5263\n",
      "Epoch 605/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6664 - acc: 0.5375 - val_loss: 0.6769 - val_acc: 0.7895\n",
      "Epoch 606/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6649 - acc: 0.9500 - val_loss: 0.6770 - val_acc: 0.7895\n",
      "Epoch 607/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.6668 - acc: 0.8875 - val_loss: 0.6762 - val_acc: 0.5789\n",
      "Epoch 608/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6657 - acc: 0.7000 - val_loss: 0.6770 - val_acc: 0.8947\n",
      "Epoch 609/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6651 - acc: 0.9125 - val_loss: 0.6779 - val_acc: 0.8421\n",
      "Epoch 610/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6649 - acc: 0.9250 - val_loss: 0.6780 - val_acc: 0.7368\n",
      "Epoch 611/3000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.6648 - acc: 0.8125 - val_loss: 0.6771 - val_acc: 0.8947\n",
      "Epoch 612/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6644 - acc: 0.9250 - val_loss: 0.6769 - val_acc: 0.8947\n",
      "Epoch 613/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6642 - acc: 0.9375 - val_loss: 0.6765 - val_acc: 0.7895\n",
      "Epoch 614/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6646 - acc: 0.9125 - val_loss: 0.6773 - val_acc: 0.8947\n",
      "Epoch 615/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6641 - acc: 0.8875 - val_loss: 0.6766 - val_acc: 0.8947\n",
      "Epoch 616/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6649 - acc: 0.9500 - val_loss: 0.6760 - val_acc: 0.7368\n",
      "Epoch 617/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6639 - acc: 0.9000 - val_loss: 0.6764 - val_acc: 0.8421\n",
      "Epoch 618/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6642 - acc: 0.9500 - val_loss: 0.6771 - val_acc: 0.8421\n",
      "Epoch 619/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6636 - acc: 0.9125 - val_loss: 0.6768 - val_acc: 0.8947\n",
      "Epoch 620/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6636 - acc: 0.9250 - val_loss: 0.6763 - val_acc: 0.8947\n",
      "Epoch 621/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6667 - acc: 0.8500 - val_loss: 0.6752 - val_acc: 0.5263\n",
      "Epoch 622/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6638 - acc: 0.7000 - val_loss: 0.6753 - val_acc: 0.5789\n",
      "Epoch 623/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6638 - acc: 0.7750 - val_loss: 0.6760 - val_acc: 0.7895\n",
      "Epoch 624/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6631 - acc: 0.9500 - val_loss: 0.6760 - val_acc: 0.7895\n",
      "Epoch 625/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6631 - acc: 0.9375 - val_loss: 0.6763 - val_acc: 0.8947\n",
      "Epoch 626/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6635 - acc: 0.9000 - val_loss: 0.6761 - val_acc: 0.8947\n",
      "Epoch 627/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6632 - acc: 0.9125 - val_loss: 0.6756 - val_acc: 0.7895\n",
      "Epoch 628/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.6641 - acc: 0.8750 - val_loss: 0.6770 - val_acc: 0.7368\n",
      "Epoch 629/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6639 - acc: 0.8875 - val_loss: 0.6777 - val_acc: 0.6316\n",
      "Epoch 630/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6640 - acc: 0.8250 - val_loss: 0.6766 - val_acc: 0.8421\n",
      "Epoch 631/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6635 - acc: 0.8375 - val_loss: 0.6751 - val_acc: 0.7368\n",
      "Epoch 632/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6625 - acc: 0.9250 - val_loss: 0.6750 - val_acc: 0.7368\n",
      "Epoch 633/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6625 - acc: 0.9375 - val_loss: 0.6750 - val_acc: 0.7368\n",
      "Epoch 634/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.6633 - acc: 0.9000 - val_loss: 0.6745 - val_acc: 0.5263\n",
      "Epoch 635/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6636 - acc: 0.7125 - val_loss: 0.6746 - val_acc: 0.5789\n",
      "Epoch 636/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6628 - acc: 0.6875 - val_loss: 0.6752 - val_acc: 0.7895\n",
      "Epoch 637/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6638 - acc: 0.9000 - val_loss: 0.6746 - val_acc: 0.7368\n",
      "Epoch 638/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6620 - acc: 0.8625 - val_loss: 0.6750 - val_acc: 0.7895\n",
      "Epoch 639/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6618 - acc: 0.9500 - val_loss: 0.6747 - val_acc: 0.7368\n",
      "Epoch 640/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6658 - acc: 0.8000 - val_loss: 0.6747 - val_acc: 0.7368\n",
      "Epoch 641/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6616 - acc: 0.9000 - val_loss: 0.6744 - val_acc: 0.7895\n",
      "Epoch 642/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6616 - acc: 0.9000 - val_loss: 0.6743 - val_acc: 0.7368\n",
      "Epoch 643/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6615 - acc: 0.8875 - val_loss: 0.6747 - val_acc: 0.7895\n",
      "Epoch 644/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6616 - acc: 0.8750 - val_loss: 0.6750 - val_acc: 0.8947\n",
      "Epoch 645/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6611 - acc: 0.9375 - val_loss: 0.6749 - val_acc: 0.8947\n",
      "Epoch 646/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6613 - acc: 0.9250 - val_loss: 0.6742 - val_acc: 0.7368\n",
      "Epoch 647/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.6610 - acc: 0.9000 - val_loss: 0.6743 - val_acc: 0.7895\n",
      "Epoch 648/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6612 - acc: 0.9375 - val_loss: 0.6740 - val_acc: 0.7895\n",
      "Epoch 649/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6608 - acc: 0.9125 - val_loss: 0.6738 - val_acc: 0.7368\n",
      "Epoch 650/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.6626 - acc: 0.8625 - val_loss: 0.6736 - val_acc: 0.6842\n",
      "Epoch 651/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6607 - acc: 0.8625 - val_loss: 0.6739 - val_acc: 0.7895\n",
      "Epoch 652/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6615 - acc: 0.8750 - val_loss: 0.6744 - val_acc: 0.8947\n",
      "Epoch 653/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.6606 - acc: 0.9375 - val_loss: 0.6747 - val_acc: 0.8947\n",
      "Epoch 654/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6611 - acc: 0.8250 - val_loss: 0.6737 - val_acc: 0.7895\n",
      "Epoch 655/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6606 - acc: 0.9125 - val_loss: 0.6738 - val_acc: 0.7895\n",
      "Epoch 656/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6604 - acc: 0.9250 - val_loss: 0.6733 - val_acc: 0.7368\n",
      "Epoch 657/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6602 - acc: 0.8375 - val_loss: 0.6737 - val_acc: 0.7895\n",
      "Epoch 658/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6597 - acc: 0.9500 - val_loss: 0.6737 - val_acc: 0.7895\n",
      "Epoch 659/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6596 - acc: 0.9500 - val_loss: 0.6734 - val_acc: 0.7895\n",
      "Epoch 660/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6598 - acc: 0.9125 - val_loss: 0.6738 - val_acc: 0.8947\n",
      "Epoch 661/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6596 - acc: 0.9250 - val_loss: 0.6733 - val_acc: 0.7895\n",
      "Epoch 662/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6602 - acc: 0.8625 - val_loss: 0.6742 - val_acc: 0.8947\n",
      "Epoch 663/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6594 - acc: 0.9000 - val_loss: 0.6732 - val_acc: 0.7895\n",
      "Epoch 664/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6590 - acc: 0.9375 - val_loss: 0.6735 - val_acc: 0.8947\n",
      "Epoch 665/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.6594 - acc: 0.9000 - val_loss: 0.6728 - val_acc: 0.7368\n",
      "Epoch 666/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6598 - acc: 0.9500 - val_loss: 0.6723 - val_acc: 0.5789\n",
      "Epoch 667/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6602 - acc: 0.9000 - val_loss: 0.6722 - val_acc: 0.5263\n",
      "Epoch 668/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6594 - acc: 0.6750 - val_loss: 0.6726 - val_acc: 0.7895\n",
      "Epoch 669/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6593 - acc: 0.8875 - val_loss: 0.6738 - val_acc: 0.8947\n",
      "Epoch 670/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6596 - acc: 0.8750 - val_loss: 0.6734 - val_acc: 0.8947\n",
      "Epoch 671/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6585 - acc: 0.9375 - val_loss: 0.6737 - val_acc: 0.8421\n",
      "Epoch 672/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6590 - acc: 0.8875 - val_loss: 0.6723 - val_acc: 0.7368\n",
      "Epoch 673/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6580 - acc: 0.9250 - val_loss: 0.6724 - val_acc: 0.7895\n",
      "Epoch 674/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6588 - acc: 0.9250 - val_loss: 0.6736 - val_acc: 0.8421\n",
      "Epoch 675/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6578 - acc: 0.9125 - val_loss: 0.6737 - val_acc: 0.8947\n",
      "Epoch 676/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6578 - acc: 0.8875 - val_loss: 0.6737 - val_acc: 0.8947\n",
      "Epoch 677/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6587 - acc: 0.9125 - val_loss: 0.6750 - val_acc: 0.5789\n",
      "Epoch 678/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6588 - acc: 0.7500 - val_loss: 0.6726 - val_acc: 0.8947\n",
      "Epoch 679/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6582 - acc: 0.9500 - val_loss: 0.6730 - val_acc: 0.8947\n",
      "Epoch 680/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6602 - acc: 0.8500 - val_loss: 0.6741 - val_acc: 0.6316\n",
      "Epoch 681/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6577 - acc: 0.8625 - val_loss: 0.6745 - val_acc: 0.6316\n",
      "Epoch 682/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6577 - acc: 0.8000 - val_loss: 0.6731 - val_acc: 0.8947\n",
      "Epoch 683/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6604 - acc: 0.8625 - val_loss: 0.6725 - val_acc: 0.8947\n",
      "Epoch 684/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6585 - acc: 0.9000 - val_loss: 0.6733 - val_acc: 0.8421\n",
      "Epoch 685/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6570 - acc: 0.8125 - val_loss: 0.6720 - val_acc: 0.8947\n",
      "Epoch 686/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6583 - acc: 0.9250 - val_loss: 0.6737 - val_acc: 0.6316\n",
      "Epoch 687/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6566 - acc: 0.8000 - val_loss: 0.6730 - val_acc: 0.8947\n",
      "Epoch 688/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6563 - acc: 0.8500 - val_loss: 0.6721 - val_acc: 0.8947\n",
      "Epoch 689/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6561 - acc: 0.9500 - val_loss: 0.6723 - val_acc: 0.8947\n",
      "Epoch 690/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6560 - acc: 0.9000 - val_loss: 0.6720 - val_acc: 0.8947\n",
      "Epoch 691/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6558 - acc: 0.9375 - val_loss: 0.6722 - val_acc: 0.8947\n",
      "Epoch 692/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6558 - acc: 0.9375 - val_loss: 0.6719 - val_acc: 0.8947\n",
      "Epoch 693/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6577 - acc: 0.9375 - val_loss: 0.6714 - val_acc: 0.8947\n",
      "Epoch 694/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6575 - acc: 0.8625 - val_loss: 0.6709 - val_acc: 0.7895\n",
      "Epoch 695/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6556 - acc: 0.9500 - val_loss: 0.6713 - val_acc: 0.8947\n",
      "Epoch 696/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6556 - acc: 0.9250 - val_loss: 0.6705 - val_acc: 0.7895\n",
      "Epoch 697/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6551 - acc: 0.9375 - val_loss: 0.6709 - val_acc: 0.8421\n",
      "Epoch 698/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6549 - acc: 0.9500 - val_loss: 0.6709 - val_acc: 0.8947\n",
      "Epoch 699/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6548 - acc: 0.9500 - val_loss: 0.6708 - val_acc: 0.8947\n",
      "Epoch 700/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6556 - acc: 0.9375 - val_loss: 0.6699 - val_acc: 0.7368\n",
      "Epoch 701/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6551 - acc: 0.9000 - val_loss: 0.6698 - val_acc: 0.7368\n",
      "Epoch 702/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6549 - acc: 0.9125 - val_loss: 0.6702 - val_acc: 0.7895\n",
      "Epoch 703/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6573 - acc: 0.8750 - val_loss: 0.6694 - val_acc: 0.5789\n",
      "Epoch 704/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6557 - acc: 0.8750 - val_loss: 0.6694 - val_acc: 0.5789\n",
      "Epoch 705/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6554 - acc: 0.7000 - val_loss: 0.6700 - val_acc: 0.7895\n",
      "Epoch 706/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6537 - acc: 0.9500 - val_loss: 0.6700 - val_acc: 0.7895\n",
      "Epoch 707/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6541 - acc: 0.9625 - val_loss: 0.6697 - val_acc: 0.7895\n",
      "Epoch 708/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6536 - acc: 0.9500 - val_loss: 0.6695 - val_acc: 0.7895\n",
      "Epoch 709/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6538 - acc: 0.9375 - val_loss: 0.6693 - val_acc: 0.7368\n",
      "Epoch 710/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6537 - acc: 0.9250 - val_loss: 0.6696 - val_acc: 0.7895\n",
      "Epoch 711/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6544 - acc: 0.8875 - val_loss: 0.6710 - val_acc: 0.8947\n",
      "Epoch 712/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6554 - acc: 0.8875 - val_loss: 0.6712 - val_acc: 0.7895\n",
      "Epoch 713/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6536 - acc: 0.8250 - val_loss: 0.6705 - val_acc: 0.8421\n",
      "Epoch 714/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6532 - acc: 0.8625 - val_loss: 0.6693 - val_acc: 0.7895\n",
      "Epoch 715/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6535 - acc: 0.9500 - val_loss: 0.6687 - val_acc: 0.7895\n",
      "Epoch 716/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6530 - acc: 0.9375 - val_loss: 0.6684 - val_acc: 0.7368\n",
      "Epoch 717/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6527 - acc: 0.8625 - val_loss: 0.6684 - val_acc: 0.7368\n",
      "Epoch 718/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6525 - acc: 0.8750 - val_loss: 0.6685 - val_acc: 0.7895\n",
      "Epoch 719/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6540 - acc: 0.8250 - val_loss: 0.6701 - val_acc: 0.8947\n",
      "Epoch 720/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6521 - acc: 0.9125 - val_loss: 0.6697 - val_acc: 0.8947\n",
      "Epoch 721/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6522 - acc: 0.9375 - val_loss: 0.6704 - val_acc: 0.8947\n",
      "Epoch 722/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6522 - acc: 0.8500 - val_loss: 0.6694 - val_acc: 0.8947\n",
      "Epoch 723/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6519 - acc: 0.9500 - val_loss: 0.6701 - val_acc: 0.8947\n",
      "Epoch 724/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6519 - acc: 0.9000 - val_loss: 0.6701 - val_acc: 0.8947\n",
      "Epoch 725/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6550 - acc: 0.8125 - val_loss: 0.6698 - val_acc: 0.8947\n",
      "Epoch 726/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6517 - acc: 0.8375 - val_loss: 0.6697 - val_acc: 0.8947\n",
      "Epoch 727/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6515 - acc: 0.8750 - val_loss: 0.6697 - val_acc: 0.8947\n",
      "Epoch 728/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6514 - acc: 0.8375 - val_loss: 0.6683 - val_acc: 0.8947\n",
      "Epoch 729/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6509 - acc: 0.9500 - val_loss: 0.6685 - val_acc: 0.8947\n",
      "Epoch 730/3000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.6505 - acc: 0.9375 - val_loss: 0.6680 - val_acc: 0.7895\n",
      "Epoch 731/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6506 - acc: 0.9375 - val_loss: 0.6673 - val_acc: 0.7368\n",
      "Epoch 732/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6532 - acc: 0.9375 - val_loss: 0.6669 - val_acc: 0.5789\n",
      "Epoch 733/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6539 - acc: 0.6875 - val_loss: 0.6672 - val_acc: 0.7895\n",
      "Epoch 734/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6519 - acc: 0.9625 - val_loss: 0.6668 - val_acc: 0.7368\n",
      "Epoch 735/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6532 - acc: 0.8000 - val_loss: 0.6665 - val_acc: 0.7368\n",
      "Epoch 736/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6506 - acc: 0.8875 - val_loss: 0.6664 - val_acc: 0.5789\n",
      "Epoch 737/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6504 - acc: 0.8875 - val_loss: 0.6663 - val_acc: 0.5789\n",
      "Epoch 738/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6497 - acc: 0.8125 - val_loss: 0.6663 - val_acc: 0.7368\n",
      "Epoch 739/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6497 - acc: 0.9000 - val_loss: 0.6661 - val_acc: 0.6842\n",
      "Epoch 740/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6497 - acc: 0.8250 - val_loss: 0.6661 - val_acc: 0.7368\n",
      "Epoch 741/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6502 - acc: 0.9125 - val_loss: 0.6663 - val_acc: 0.7895\n",
      "Epoch 742/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6514 - acc: 0.8750 - val_loss: 0.6672 - val_acc: 0.8947\n",
      "Epoch 743/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6488 - acc: 0.9375 - val_loss: 0.6674 - val_acc: 0.8947\n",
      "Epoch 744/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6496 - acc: 0.9000 - val_loss: 0.6661 - val_acc: 0.7895\n",
      "Epoch 745/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6496 - acc: 0.9125 - val_loss: 0.6662 - val_acc: 0.7895\n",
      "Epoch 746/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6492 - acc: 0.9375 - val_loss: 0.6675 - val_acc: 0.8947\n",
      "Epoch 747/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6482 - acc: 0.8375 - val_loss: 0.6662 - val_acc: 0.8421\n",
      "Epoch 748/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6476 - acc: 0.9500 - val_loss: 0.6661 - val_acc: 0.7895\n",
      "Epoch 749/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6488 - acc: 0.9125 - val_loss: 0.6659 - val_acc: 0.7895\n",
      "Epoch 750/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6483 - acc: 0.9375 - val_loss: 0.6652 - val_acc: 0.7368\n",
      "Epoch 751/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6484 - acc: 0.9000 - val_loss: 0.6649 - val_acc: 0.7368\n",
      "Epoch 752/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6480 - acc: 0.9000 - val_loss: 0.6650 - val_acc: 0.7368\n",
      "Epoch 753/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6474 - acc: 0.8500 - val_loss: 0.6656 - val_acc: 0.8421\n",
      "Epoch 754/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.6466 - acc: 0.9500 - val_loss: 0.6652 - val_acc: 0.7895\n",
      "Epoch 755/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6496 - acc: 0.9250 - val_loss: 0.6646 - val_acc: 0.7368\n",
      "Epoch 756/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6470 - acc: 0.9125 - val_loss: 0.6646 - val_acc: 0.7895\n",
      "Epoch 757/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6464 - acc: 0.9125 - val_loss: 0.6647 - val_acc: 0.7895\n",
      "Epoch 758/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6469 - acc: 0.9250 - val_loss: 0.6651 - val_acc: 0.8421\n",
      "Epoch 759/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6468 - acc: 0.9500 - val_loss: 0.6658 - val_acc: 0.8947\n",
      "Epoch 760/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6470 - acc: 0.8750 - val_loss: 0.6644 - val_acc: 0.7895\n",
      "Epoch 761/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6466 - acc: 0.9250 - val_loss: 0.6649 - val_acc: 0.8947\n",
      "Epoch 762/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6463 - acc: 0.9375 - val_loss: 0.6640 - val_acc: 0.7895\n",
      "Epoch 763/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6462 - acc: 0.8500 - val_loss: 0.6647 - val_acc: 0.8947\n",
      "Epoch 764/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6452 - acc: 0.9750 - val_loss: 0.6650 - val_acc: 0.8947\n",
      "Epoch 765/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6457 - acc: 0.9000 - val_loss: 0.6643 - val_acc: 0.7895\n",
      "Epoch 766/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6445 - acc: 0.9500 - val_loss: 0.6642 - val_acc: 0.7895\n",
      "Epoch 767/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6453 - acc: 0.9375 - val_loss: 0.6654 - val_acc: 0.8947\n",
      "Epoch 768/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6443 - acc: 0.8750 - val_loss: 0.6644 - val_acc: 0.8947\n",
      "Epoch 769/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6440 - acc: 0.9500 - val_loss: 0.6646 - val_acc: 0.8947\n",
      "Epoch 770/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6444 - acc: 0.9375 - val_loss: 0.6652 - val_acc: 0.8947\n",
      "Epoch 771/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6449 - acc: 0.8250 - val_loss: 0.6641 - val_acc: 0.8947\n",
      "Epoch 772/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6435 - acc: 0.9375 - val_loss: 0.6639 - val_acc: 0.8947\n",
      "Epoch 773/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6437 - acc: 0.9500 - val_loss: 0.6641 - val_acc: 0.8947\n",
      "Epoch 774/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6451 - acc: 0.8875 - val_loss: 0.6646 - val_acc: 0.8421\n",
      "Epoch 775/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6468 - acc: 0.9125 - val_loss: 0.6648 - val_acc: 0.8947\n",
      "Epoch 776/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6433 - acc: 0.8875 - val_loss: 0.6638 - val_acc: 0.8947\n",
      "Epoch 777/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6429 - acc: 0.9000 - val_loss: 0.6631 - val_acc: 0.8421\n",
      "Epoch 778/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6433 - acc: 0.9250 - val_loss: 0.6633 - val_acc: 0.8947\n",
      "Epoch 779/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6421 - acc: 0.9375 - val_loss: 0.6627 - val_acc: 0.7895\n",
      "Epoch 780/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6452 - acc: 0.9250 - val_loss: 0.6650 - val_acc: 0.7368\n",
      "Epoch 781/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6426 - acc: 0.8500 - val_loss: 0.6631 - val_acc: 0.8947\n",
      "Epoch 782/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.6425 - acc: 0.8500 - val_loss: 0.6618 - val_acc: 0.7895\n",
      "Epoch 783/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6413 - acc: 0.9500 - val_loss: 0.6615 - val_acc: 0.7895\n",
      "Epoch 784/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.6415 - acc: 0.9375 - val_loss: 0.6618 - val_acc: 0.8421\n",
      "Epoch 785/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6418 - acc: 0.9500 - val_loss: 0.6624 - val_acc: 0.8947\n",
      "Epoch 786/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6416 - acc: 0.9375 - val_loss: 0.6611 - val_acc: 0.7895\n",
      "Epoch 787/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6405 - acc: 0.9375 - val_loss: 0.6609 - val_acc: 0.7895\n",
      "Epoch 788/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6410 - acc: 0.9500 - val_loss: 0.6608 - val_acc: 0.7895\n",
      "Epoch 789/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6414 - acc: 0.9500 - val_loss: 0.6608 - val_acc: 0.7895\n",
      "Epoch 790/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6398 - acc: 0.9375 - val_loss: 0.6611 - val_acc: 0.8947\n",
      "Epoch 791/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6406 - acc: 0.9375 - val_loss: 0.6607 - val_acc: 0.7895\n",
      "Epoch 792/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.6405 - acc: 0.9250 - val_loss: 0.6609 - val_acc: 0.8947\n",
      "Epoch 793/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6402 - acc: 0.9375 - val_loss: 0.6612 - val_acc: 0.8947\n",
      "Epoch 794/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6408 - acc: 0.8875 - val_loss: 0.6601 - val_acc: 0.7895\n",
      "Epoch 795/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6389 - acc: 0.9250 - val_loss: 0.6601 - val_acc: 0.7895\n",
      "Epoch 796/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6390 - acc: 0.9375 - val_loss: 0.6596 - val_acc: 0.8421\n",
      "Epoch 797/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.6391 - acc: 0.9500 - val_loss: 0.6593 - val_acc: 0.7368\n",
      "Epoch 798/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6405 - acc: 0.8375 - val_loss: 0.6596 - val_acc: 0.7895\n",
      "Epoch 799/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6402 - acc: 0.9250 - val_loss: 0.6613 - val_acc: 0.8947\n",
      "Epoch 800/3000\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.6390 - acc: 0.8750 - val_loss: 0.6616 - val_acc: 0.8947\n",
      "Epoch 801/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6388 - acc: 0.8250 - val_loss: 0.6595 - val_acc: 0.8421\n",
      "Epoch 802/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6373 - acc: 0.9500 - val_loss: 0.6594 - val_acc: 0.8421\n",
      "Epoch 803/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6379 - acc: 0.9625 - val_loss: 0.6601 - val_acc: 0.8947\n",
      "Epoch 804/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6374 - acc: 0.9375 - val_loss: 0.6602 - val_acc: 0.8947\n",
      "Epoch 805/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6372 - acc: 0.9250 - val_loss: 0.6602 - val_acc: 0.8947\n",
      "Epoch 806/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6371 - acc: 0.9500 - val_loss: 0.6607 - val_acc: 0.8947\n",
      "Epoch 807/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6397 - acc: 0.8875 - val_loss: 0.6592 - val_acc: 0.8947\n",
      "Epoch 808/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6365 - acc: 0.9375 - val_loss: 0.6582 - val_acc: 0.7895\n",
      "Epoch 809/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6357 - acc: 0.9500 - val_loss: 0.6582 - val_acc: 0.7895\n",
      "Epoch 810/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6355 - acc: 0.9500 - val_loss: 0.6581 - val_acc: 0.7895\n",
      "Epoch 811/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6395 - acc: 0.9250 - val_loss: 0.6579 - val_acc: 0.7895\n",
      "Epoch 812/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6352 - acc: 0.9500 - val_loss: 0.6576 - val_acc: 0.7895\n",
      "Epoch 813/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6353 - acc: 0.9500 - val_loss: 0.6584 - val_acc: 0.8947\n",
      "Epoch 814/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.6351 - acc: 0.9500 - val_loss: 0.6577 - val_acc: 0.8421\n",
      "Epoch 815/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6348 - acc: 0.9500 - val_loss: 0.6573 - val_acc: 0.8421\n",
      "Epoch 816/3000\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.6357 - acc: 0.9375 - val_loss: 0.6585 - val_acc: 0.9474\n",
      "Epoch 817/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6349 - acc: 0.8875 - val_loss: 0.6574 - val_acc: 0.8947\n",
      "Epoch 818/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6353 - acc: 0.9375 - val_loss: 0.6582 - val_acc: 0.8421\n",
      "Epoch 819/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6367 - acc: 0.8125 - val_loss: 0.6555 - val_acc: 0.7895\n",
      "Epoch 820/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6348 - acc: 0.9250 - val_loss: 0.6564 - val_acc: 0.8947\n",
      "Epoch 821/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6333 - acc: 0.9375 - val_loss: 0.6557 - val_acc: 0.8421\n",
      "Epoch 822/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6329 - acc: 0.9500 - val_loss: 0.6556 - val_acc: 0.8421\n",
      "Epoch 823/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6356 - acc: 0.9000 - val_loss: 0.6549 - val_acc: 0.7895\n",
      "Epoch 824/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6345 - acc: 0.9625 - val_loss: 0.6546 - val_acc: 0.8421\n",
      "Epoch 825/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6346 - acc: 0.9250 - val_loss: 0.6545 - val_acc: 0.8421\n",
      "Epoch 826/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.6325 - acc: 0.9375 - val_loss: 0.6548 - val_acc: 0.8421\n",
      "Epoch 827/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6328 - acc: 0.9250 - val_loss: 0.6543 - val_acc: 0.7895\n",
      "Epoch 828/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6315 - acc: 0.9500 - val_loss: 0.6543 - val_acc: 0.7895\n",
      "Epoch 829/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6312 - acc: 0.9375 - val_loss: 0.6542 - val_acc: 0.8421\n",
      "Epoch 830/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.6311 - acc: 0.9375 - val_loss: 0.6540 - val_acc: 0.7895\n",
      "Epoch 831/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6309 - acc: 0.9375 - val_loss: 0.6537 - val_acc: 0.7895\n",
      "Epoch 832/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6309 - acc: 0.9500 - val_loss: 0.6540 - val_acc: 0.8421\n",
      "Epoch 833/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6324 - acc: 0.9375 - val_loss: 0.6544 - val_acc: 0.8947\n",
      "Epoch 834/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6311 - acc: 0.9500 - val_loss: 0.6539 - val_acc: 0.8421\n",
      "Epoch 835/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6298 - acc: 0.9500 - val_loss: 0.6541 - val_acc: 0.8947\n",
      "Epoch 836/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6296 - acc: 0.9500 - val_loss: 0.6543 - val_acc: 0.8947\n",
      "Epoch 837/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.6303 - acc: 0.9375 - val_loss: 0.6534 - val_acc: 0.8421\n",
      "Epoch 838/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6325 - acc: 0.9250 - val_loss: 0.6539 - val_acc: 0.8947\n",
      "Epoch 839/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6289 - acc: 0.9375 - val_loss: 0.6535 - val_acc: 0.8947\n",
      "Epoch 840/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6286 - acc: 0.9375 - val_loss: 0.6536 - val_acc: 0.8947\n",
      "Epoch 841/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6304 - acc: 0.9375 - val_loss: 0.6541 - val_acc: 0.9474\n",
      "Epoch 842/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6283 - acc: 0.9250 - val_loss: 0.6536 - val_acc: 0.8947\n",
      "Epoch 843/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6291 - acc: 0.9000 - val_loss: 0.6533 - val_acc: 0.8947\n",
      "Epoch 844/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6282 - acc: 0.9375 - val_loss: 0.6530 - val_acc: 0.8947\n",
      "Epoch 845/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6279 - acc: 0.9375 - val_loss: 0.6528 - val_acc: 0.8947\n",
      "Epoch 846/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.6281 - acc: 0.9500 - val_loss: 0.6540 - val_acc: 0.8947\n",
      "Epoch 847/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6273 - acc: 0.8875 - val_loss: 0.6535 - val_acc: 0.9474\n",
      "Epoch 848/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.6291 - acc: 0.9000 - val_loss: 0.6552 - val_acc: 0.6842\n",
      "Epoch 849/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 151us/sample - loss: 0.6274 - acc: 0.8125 - val_loss: 0.6538 - val_acc: 0.8947\n",
      "Epoch 850/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6302 - acc: 0.8625 - val_loss: 0.6526 - val_acc: 0.9474\n",
      "Epoch 851/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6264 - acc: 0.9375 - val_loss: 0.6528 - val_acc: 0.9474\n",
      "Epoch 852/3000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.6263 - acc: 0.8750 - val_loss: 0.6530 - val_acc: 0.8947\n",
      "Epoch 853/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6258 - acc: 0.8625 - val_loss: 0.6515 - val_acc: 0.8947\n",
      "Epoch 854/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6271 - acc: 0.9500 - val_loss: 0.6503 - val_acc: 0.8421\n",
      "Epoch 855/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6245 - acc: 0.9500 - val_loss: 0.6500 - val_acc: 0.7895\n",
      "Epoch 856/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.6250 - acc: 0.9500 - val_loss: 0.6500 - val_acc: 0.8421\n",
      "Epoch 857/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6254 - acc: 0.9375 - val_loss: 0.6499 - val_acc: 0.8421\n",
      "Epoch 858/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.6251 - acc: 0.9500 - val_loss: 0.6499 - val_acc: 0.8421\n",
      "Epoch 859/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.6233 - acc: 0.9500 - val_loss: 0.6501 - val_acc: 0.8421\n",
      "Epoch 860/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6229 - acc: 0.9500 - val_loss: 0.6500 - val_acc: 0.8421\n",
      "Epoch 861/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6232 - acc: 0.9375 - val_loss: 0.6499 - val_acc: 0.8947\n",
      "Epoch 862/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6236 - acc: 0.9375 - val_loss: 0.6493 - val_acc: 0.7895\n",
      "Epoch 863/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.6227 - acc: 0.9375 - val_loss: 0.6486 - val_acc: 0.8421\n",
      "Epoch 864/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6234 - acc: 0.9625 - val_loss: 0.6493 - val_acc: 0.8947\n",
      "Epoch 865/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6238 - acc: 0.9250 - val_loss: 0.6506 - val_acc: 0.8947\n",
      "Epoch 866/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6219 - acc: 0.9125 - val_loss: 0.6493 - val_acc: 0.8947\n",
      "Epoch 867/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6209 - acc: 0.9500 - val_loss: 0.6492 - val_acc: 0.8947\n",
      "Epoch 868/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6212 - acc: 0.9500 - val_loss: 0.6488 - val_acc: 0.8947\n",
      "Epoch 869/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6215 - acc: 0.9500 - val_loss: 0.6482 - val_acc: 0.8421\n",
      "Epoch 870/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6207 - acc: 0.9500 - val_loss: 0.6482 - val_acc: 0.8421\n",
      "Epoch 871/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6223 - acc: 0.9500 - val_loss: 0.6473 - val_acc: 0.7895\n",
      "Epoch 872/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6210 - acc: 0.9500 - val_loss: 0.6472 - val_acc: 0.7368\n",
      "Epoch 873/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6211 - acc: 0.9125 - val_loss: 0.6470 - val_acc: 0.7895\n",
      "Epoch 874/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.6222 - acc: 0.9250 - val_loss: 0.6468 - val_acc: 0.7368\n",
      "Epoch 875/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.6199 - acc: 0.9000 - val_loss: 0.6471 - val_acc: 0.8421\n",
      "Epoch 876/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6200 - acc: 0.9500 - val_loss: 0.6466 - val_acc: 0.7895\n",
      "Epoch 877/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6185 - acc: 0.9500 - val_loss: 0.6470 - val_acc: 0.8947\n",
      "Epoch 878/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.6179 - acc: 0.9375 - val_loss: 0.6463 - val_acc: 0.7895\n",
      "Epoch 879/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.6173 - acc: 0.9500 - val_loss: 0.6462 - val_acc: 0.8421\n",
      "Epoch 880/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.6182 - acc: 0.9375 - val_loss: 0.6457 - val_acc: 0.8421\n",
      "Epoch 881/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6184 - acc: 0.9250 - val_loss: 0.6460 - val_acc: 0.7895\n",
      "Epoch 882/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6172 - acc: 0.9500 - val_loss: 0.6456 - val_acc: 0.8421\n",
      "Epoch 883/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.6168 - acc: 0.9500 - val_loss: 0.6454 - val_acc: 0.8421\n",
      "Epoch 884/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6159 - acc: 0.9625 - val_loss: 0.6454 - val_acc: 0.7895\n",
      "Epoch 885/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6155 - acc: 0.9500 - val_loss: 0.6455 - val_acc: 0.8421\n",
      "Epoch 886/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6177 - acc: 0.9375 - val_loss: 0.6470 - val_acc: 0.8947\n",
      "Epoch 887/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6156 - acc: 0.9375 - val_loss: 0.6468 - val_acc: 0.8947\n",
      "Epoch 888/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6168 - acc: 0.8375 - val_loss: 0.6455 - val_acc: 0.8947\n",
      "Epoch 889/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6147 - acc: 0.9500 - val_loss: 0.6446 - val_acc: 0.7895\n",
      "Epoch 890/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6138 - acc: 0.9500 - val_loss: 0.6445 - val_acc: 0.8421\n",
      "Epoch 891/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.6138 - acc: 0.9500 - val_loss: 0.6441 - val_acc: 0.7895\n",
      "Epoch 892/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6154 - acc: 0.9500 - val_loss: 0.6441 - val_acc: 0.8421\n",
      "Epoch 893/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6133 - acc: 0.9500 - val_loss: 0.6435 - val_acc: 0.7895\n",
      "Epoch 894/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6143 - acc: 0.9375 - val_loss: 0.6448 - val_acc: 0.8947\n",
      "Epoch 895/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.6143 - acc: 0.8875 - val_loss: 0.6438 - val_acc: 0.8947\n",
      "Epoch 896/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6139 - acc: 0.9500 - val_loss: 0.6438 - val_acc: 0.8947\n",
      "Epoch 897/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6120 - acc: 0.9500 - val_loss: 0.6431 - val_acc: 0.8421\n",
      "Epoch 898/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6115 - acc: 0.9375 - val_loss: 0.6437 - val_acc: 0.8947\n",
      "Epoch 899/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6129 - acc: 0.9500 - val_loss: 0.6425 - val_acc: 0.8421\n",
      "Epoch 900/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6105 - acc: 0.9500 - val_loss: 0.6426 - val_acc: 0.8947\n",
      "Epoch 901/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.6100 - acc: 0.9500 - val_loss: 0.6424 - val_acc: 0.8947\n",
      "Epoch 902/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.6101 - acc: 0.9500 - val_loss: 0.6424 - val_acc: 0.8947\n",
      "Epoch 903/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6110 - acc: 0.9500 - val_loss: 0.6420 - val_acc: 0.8947\n",
      "Epoch 904/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6116 - acc: 0.9375 - val_loss: 0.6415 - val_acc: 0.8947\n",
      "Epoch 905/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6092 - acc: 0.9500 - val_loss: 0.6416 - val_acc: 0.8947\n",
      "Epoch 906/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6085 - acc: 0.9375 - val_loss: 0.6412 - val_acc: 0.8947\n",
      "Epoch 907/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6092 - acc: 0.9375 - val_loss: 0.6413 - val_acc: 0.8947\n",
      "Epoch 908/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 150us/sample - loss: 0.6084 - acc: 0.9500 - val_loss: 0.6421 - val_acc: 0.8947\n",
      "Epoch 909/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6074 - acc: 0.9375 - val_loss: 0.6414 - val_acc: 0.8947\n",
      "Epoch 910/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.6092 - acc: 0.9500 - val_loss: 0.6406 - val_acc: 0.8947\n",
      "Epoch 911/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6015 - acc: 0.968 - 0s 112us/sample - loss: 0.6071 - acc: 0.9500 - val_loss: 0.6412 - val_acc: 0.8947\n",
      "Epoch 912/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.6077 - acc: 0.9000 - val_loss: 0.6409 - val_acc: 0.8947\n",
      "Epoch 913/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.6060 - acc: 0.9375 - val_loss: 0.6399 - val_acc: 0.8947\n",
      "Epoch 914/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6055 - acc: 0.9500 - val_loss: 0.6400 - val_acc: 0.8947\n",
      "Epoch 915/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6059 - acc: 0.9250 - val_loss: 0.6392 - val_acc: 0.8421\n",
      "Epoch 916/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6050 - acc: 0.9500 - val_loss: 0.6397 - val_acc: 0.8947\n",
      "Epoch 917/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6084 - acc: 0.9375 - val_loss: 0.6418 - val_acc: 0.8421\n",
      "Epoch 918/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.6100 - acc: 0.8250 - val_loss: 0.6423 - val_acc: 0.8421\n",
      "Epoch 919/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6050 - acc: 0.8500 - val_loss: 0.6404 - val_acc: 0.9474\n",
      "Epoch 920/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.6038 - acc: 0.9000 - val_loss: 0.6393 - val_acc: 0.8947\n",
      "Epoch 921/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.6047 - acc: 0.9000 - val_loss: 0.6385 - val_acc: 0.8947\n",
      "Epoch 922/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.6034 - acc: 0.9375 - val_loss: 0.6387 - val_acc: 0.8947\n",
      "Epoch 923/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.6027 - acc: 0.9375 - val_loss: 0.6372 - val_acc: 0.8421\n",
      "Epoch 924/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.6028 - acc: 0.9500 - val_loss: 0.6366 - val_acc: 0.7895\n",
      "Epoch 925/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.6016 - acc: 0.9500 - val_loss: 0.6364 - val_acc: 0.7895\n",
      "Epoch 926/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6023 - acc: 0.9625 - val_loss: 0.6360 - val_acc: 0.7895\n",
      "Epoch 927/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6027 - acc: 0.9500 - val_loss: 0.6363 - val_acc: 0.8421\n",
      "Epoch 928/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.6012 - acc: 0.9375 - val_loss: 0.6355 - val_acc: 0.7895\n",
      "Epoch 929/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.6006 - acc: 0.9375 - val_loss: 0.6353 - val_acc: 0.7895\n",
      "Epoch 930/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.6002 - acc: 0.9500 - val_loss: 0.6356 - val_acc: 0.8421\n",
      "Epoch 931/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5991 - acc: 0.9500 - val_loss: 0.6351 - val_acc: 0.8421\n",
      "Epoch 932/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5989 - acc: 0.9375 - val_loss: 0.6355 - val_acc: 0.8947\n",
      "Epoch 933/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.5983 - acc: 0.9500 - val_loss: 0.6348 - val_acc: 0.8421\n",
      "Epoch 934/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5986 - acc: 0.9500 - val_loss: 0.6343 - val_acc: 0.7895\n",
      "Epoch 935/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5975 - acc: 0.9500 - val_loss: 0.6339 - val_acc: 0.7895\n",
      "Epoch 936/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5977 - acc: 0.9625 - val_loss: 0.6343 - val_acc: 0.8947\n",
      "Epoch 937/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.5977 - acc: 0.9500 - val_loss: 0.6336 - val_acc: 0.8421\n",
      "Epoch 938/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5966 - acc: 0.9500 - val_loss: 0.6330 - val_acc: 0.7895\n",
      "Epoch 939/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5963 - acc: 0.9625 - val_loss: 0.6334 - val_acc: 0.8947\n",
      "Epoch 940/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5958 - acc: 0.9500 - val_loss: 0.6329 - val_acc: 0.8421\n",
      "Epoch 941/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5961 - acc: 0.9625 - val_loss: 0.6329 - val_acc: 0.8947\n",
      "Epoch 942/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5947 - acc: 0.9500 - val_loss: 0.6326 - val_acc: 0.8947\n",
      "Epoch 943/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.5955 - acc: 0.9500 - val_loss: 0.6319 - val_acc: 0.7895\n",
      "Epoch 944/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5942 - acc: 0.9500 - val_loss: 0.6314 - val_acc: 0.7895\n",
      "Epoch 945/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5946 - acc: 0.9625 - val_loss: 0.6311 - val_acc: 0.7895\n",
      "Epoch 946/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5936 - acc: 0.9500 - val_loss: 0.6308 - val_acc: 0.7895\n",
      "Epoch 947/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5928 - acc: 0.9500 - val_loss: 0.6309 - val_acc: 0.8421\n",
      "Epoch 948/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5939 - acc: 0.9750 - val_loss: 0.6306 - val_acc: 0.8421\n",
      "Epoch 949/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5921 - acc: 0.9500 - val_loss: 0.6308 - val_acc: 0.8947\n",
      "Epoch 950/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5915 - acc: 0.9500 - val_loss: 0.6302 - val_acc: 0.8421\n",
      "Epoch 951/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5912 - acc: 0.9500 - val_loss: 0.6300 - val_acc: 0.8421\n",
      "Epoch 952/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.5925 - acc: 0.9500 - val_loss: 0.6308 - val_acc: 0.8947\n",
      "Epoch 953/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5930 - acc: 0.9375 - val_loss: 0.6303 - val_acc: 0.8947\n",
      "Epoch 954/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.5934 - acc: 0.8875 - val_loss: 0.6287 - val_acc: 0.7895\n",
      "Epoch 955/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.5899 - acc: 0.9375 - val_loss: 0.6285 - val_acc: 0.7895\n",
      "Epoch 956/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5889 - acc: 0.9500 - val_loss: 0.6285 - val_acc: 0.8421\n",
      "Epoch 957/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5883 - acc: 0.9500 - val_loss: 0.6284 - val_acc: 0.8947\n",
      "Epoch 958/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5908 - acc: 0.9375 - val_loss: 0.6297 - val_acc: 0.8947\n",
      "Epoch 959/3000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.5877 - acc: 0.9250 - val_loss: 0.6285 - val_acc: 0.8947\n",
      "Epoch 960/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5874 - acc: 0.9375 - val_loss: 0.6289 - val_acc: 0.8947\n",
      "Epoch 961/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5868 - acc: 0.9375 - val_loss: 0.6287 - val_acc: 0.8947\n",
      "Epoch 962/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5872 - acc: 0.9500 - val_loss: 0.6273 - val_acc: 0.8947\n",
      "Epoch 963/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5872 - acc: 0.9125 - val_loss: 0.6270 - val_acc: 0.8421\n",
      "Epoch 964/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.5855 - acc: 0.9500 - val_loss: 0.6261 - val_acc: 0.8421\n",
      "Epoch 965/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5852 - acc: 0.9500 - val_loss: 0.6258 - val_acc: 0.8421\n",
      "Epoch 966/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.5848 - acc: 0.9375 - val_loss: 0.6261 - val_acc: 0.8947\n",
      "Epoch 967/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5850 - acc: 0.9500 - val_loss: 0.6262 - val_acc: 0.8947\n",
      "Epoch 968/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5834 - acc: 0.9375 - val_loss: 0.6253 - val_acc: 0.8421\n",
      "Epoch 969/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5879 - acc: 0.9500 - val_loss: 0.6246 - val_acc: 0.8421\n",
      "Epoch 970/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.5844 - acc: 0.9500 - val_loss: 0.6242 - val_acc: 0.7895\n",
      "Epoch 971/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5827 - acc: 0.9625 - val_loss: 0.6242 - val_acc: 0.8421\n",
      "Epoch 972/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.5820 - acc: 0.9500 - val_loss: 0.6236 - val_acc: 0.7895\n",
      "Epoch 973/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5823 - acc: 0.9500 - val_loss: 0.6233 - val_acc: 0.7895\n",
      "Epoch 974/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5827 - acc: 0.9625 - val_loss: 0.6229 - val_acc: 0.7895\n",
      "Epoch 975/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5808 - acc: 0.9625 - val_loss: 0.6226 - val_acc: 0.7895\n",
      "Epoch 976/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5800 - acc: 0.9500 - val_loss: 0.6224 - val_acc: 0.7895\n",
      "Epoch 977/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5791 - acc: 0.9625 - val_loss: 0.6224 - val_acc: 0.8421\n",
      "Epoch 978/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.5804 - acc: 0.9500 - val_loss: 0.6215 - val_acc: 0.7895\n",
      "Epoch 979/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5782 - acc: 0.9500 - val_loss: 0.6211 - val_acc: 0.7895\n",
      "Epoch 980/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5779 - acc: 0.9625 - val_loss: 0.6210 - val_acc: 0.7895\n",
      "Epoch 981/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.5814 - acc: 0.9625 - val_loss: 0.6210 - val_acc: 0.7895\n",
      "Epoch 982/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5784 - acc: 0.9375 - val_loss: 0.6203 - val_acc: 0.8421\n",
      "Epoch 983/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5785 - acc: 0.9500 - val_loss: 0.6200 - val_acc: 0.8421\n",
      "Epoch 984/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5785 - acc: 0.9375 - val_loss: 0.6197 - val_acc: 0.8421\n",
      "Epoch 985/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5757 - acc: 0.9625 - val_loss: 0.6197 - val_acc: 0.8421\n",
      "Epoch 986/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.5760 - acc: 0.9500 - val_loss: 0.6196 - val_acc: 0.8947\n",
      "Epoch 987/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5744 - acc: 0.9500 - val_loss: 0.6192 - val_acc: 0.8947\n",
      "Epoch 988/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.5744 - acc: 0.9500 - val_loss: 0.6194 - val_acc: 0.8947\n",
      "Epoch 989/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5738 - acc: 0.9375 - val_loss: 0.6178 - val_acc: 0.8421\n",
      "Epoch 990/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5741 - acc: 0.9625 - val_loss: 0.6174 - val_acc: 0.7895\n",
      "Epoch 991/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5722 - acc: 0.9625 - val_loss: 0.6171 - val_acc: 0.7895\n",
      "Epoch 992/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5740 - acc: 0.9625 - val_loss: 0.6168 - val_acc: 0.7895\n",
      "Epoch 993/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5713 - acc: 0.9750 - val_loss: 0.6170 - val_acc: 0.8421\n",
      "Epoch 994/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.5710 - acc: 0.9500 - val_loss: 0.6178 - val_acc: 0.8947\n",
      "Epoch 995/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5716 - acc: 0.9375 - val_loss: 0.6176 - val_acc: 0.8947\n",
      "Epoch 996/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.5705 - acc: 0.9375 - val_loss: 0.6182 - val_acc: 0.9474\n",
      "Epoch 997/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5686 - acc: 0.9250 - val_loss: 0.6167 - val_acc: 0.8947\n",
      "Epoch 998/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5684 - acc: 0.9375 - val_loss: 0.6158 - val_acc: 0.8947\n",
      "Epoch 999/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5681 - acc: 0.9375 - val_loss: 0.6157 - val_acc: 0.8947\n",
      "Epoch 1000/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.5675 - acc: 0.9375 - val_loss: 0.6158 - val_acc: 0.9474\n",
      "Epoch 1001/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5662 - acc: 0.9375 - val_loss: 0.6152 - val_acc: 0.8947\n",
      "Epoch 1002/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5673 - acc: 0.9375 - val_loss: 0.6145 - val_acc: 0.8947\n",
      "Epoch 1003/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5649 - acc: 0.9375 - val_loss: 0.6132 - val_acc: 0.8421\n",
      "Epoch 1004/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5645 - acc: 0.9500 - val_loss: 0.6136 - val_acc: 0.8947\n",
      "Epoch 1005/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5648 - acc: 0.9375 - val_loss: 0.6146 - val_acc: 0.9474\n",
      "Epoch 1006/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.5649 - acc: 0.9250 - val_loss: 0.6128 - val_acc: 0.8947\n",
      "Epoch 1007/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5626 - acc: 0.9375 - val_loss: 0.6121 - val_acc: 0.8947\n",
      "Epoch 1008/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5644 - acc: 0.9375 - val_loss: 0.6125 - val_acc: 0.8947\n",
      "Epoch 1009/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5613 - acc: 0.9375 - val_loss: 0.6111 - val_acc: 0.8947\n",
      "Epoch 1010/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5610 - acc: 0.9500 - val_loss: 0.6113 - val_acc: 0.8947\n",
      "Epoch 1011/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5607 - acc: 0.9375 - val_loss: 0.6115 - val_acc: 0.8947\n",
      "Epoch 1012/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5601 - acc: 0.9250 - val_loss: 0.6097 - val_acc: 0.8421\n",
      "Epoch 1013/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5593 - acc: 0.9500 - val_loss: 0.6089 - val_acc: 0.8421\n",
      "Epoch 1014/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5596 - acc: 0.9500 - val_loss: 0.6084 - val_acc: 0.7895\n",
      "Epoch 1015/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5582 - acc: 0.9625 - val_loss: 0.6082 - val_acc: 0.8421\n",
      "Epoch 1016/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.5580 - acc: 0.9500 - val_loss: 0.6077 - val_acc: 0.7895\n",
      "Epoch 1017/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5587 - acc: 0.9750 - val_loss: 0.6083 - val_acc: 0.8421\n",
      "Epoch 1018/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5572 - acc: 0.9500 - val_loss: 0.6070 - val_acc: 0.7895\n",
      "Epoch 1019/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.5587 - acc: 0.9625 - val_loss: 0.6065 - val_acc: 0.7895\n",
      "Epoch 1020/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5564 - acc: 0.9500 - val_loss: 0.6064 - val_acc: 0.7895\n",
      "Epoch 1021/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5561 - acc: 0.9500 - val_loss: 0.6055 - val_acc: 0.8421\n",
      "Epoch 1022/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.5550 - acc: 0.9500 - val_loss: 0.6050 - val_acc: 0.8421\n",
      "Epoch 1023/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5549 - acc: 0.9500 - val_loss: 0.6040 - val_acc: 0.8421\n",
      "Epoch 1024/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.5538 - acc: 0.9500 - val_loss: 0.6039 - val_acc: 0.8421\n",
      "Epoch 1025/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.5527 - acc: 0.9500 - val_loss: 0.6035 - val_acc: 0.8421\n",
      "Epoch 1026/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 116us/sample - loss: 0.5520 - acc: 0.9625 - val_loss: 0.6029 - val_acc: 0.8421\n",
      "Epoch 1027/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5524 - acc: 0.9500 - val_loss: 0.6024 - val_acc: 0.8421\n",
      "Epoch 1028/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.5511 - acc: 0.9625 - val_loss: 0.6013 - val_acc: 0.7895\n",
      "Epoch 1029/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5509 - acc: 0.9625 - val_loss: 0.6008 - val_acc: 0.7895\n",
      "Epoch 1030/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.5542 - acc: 0.9500 - val_loss: 0.6008 - val_acc: 0.7895\n",
      "Epoch 1031/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.5527 - acc: 0.9375 - val_loss: 0.6002 - val_acc: 0.8421\n",
      "Epoch 1032/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.5491 - acc: 0.9625 - val_loss: 0.6004 - val_acc: 0.7895\n",
      "Epoch 1033/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5477 - acc: 0.9625 - val_loss: 0.5999 - val_acc: 0.8421\n",
      "Epoch 1034/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5468 - acc: 0.9625 - val_loss: 0.5995 - val_acc: 0.8421\n",
      "Epoch 1035/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.5475 - acc: 0.9625 - val_loss: 0.6005 - val_acc: 0.9474\n",
      "Epoch 1036/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5477 - acc: 0.9500 - val_loss: 0.5992 - val_acc: 0.8947\n",
      "Epoch 1037/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5485 - acc: 0.9375 - val_loss: 0.5983 - val_acc: 0.8421\n",
      "Epoch 1038/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5440 - acc: 0.9500 - val_loss: 0.5981 - val_acc: 0.8947\n",
      "Epoch 1039/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5435 - acc: 0.9375 - val_loss: 0.5979 - val_acc: 0.8947\n",
      "Epoch 1040/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.5432 - acc: 0.9625 - val_loss: 0.5986 - val_acc: 0.8947\n",
      "Epoch 1041/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.5424 - acc: 0.9375 - val_loss: 0.5986 - val_acc: 0.9474\n",
      "Epoch 1042/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.5422 - acc: 0.9375 - val_loss: 0.5965 - val_acc: 0.8421\n",
      "Epoch 1043/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5402 - acc: 0.9500 - val_loss: 0.5959 - val_acc: 0.8421\n",
      "Epoch 1044/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.5405 - acc: 0.9625 - val_loss: 0.5959 - val_acc: 0.8947\n",
      "Epoch 1045/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5389 - acc: 0.9500 - val_loss: 0.5955 - val_acc: 0.8947\n",
      "Epoch 1046/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5393 - acc: 0.9500 - val_loss: 0.5946 - val_acc: 0.8421\n",
      "Epoch 1047/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.5375 - acc: 0.9625 - val_loss: 0.5943 - val_acc: 0.8421\n",
      "Epoch 1048/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.5372 - acc: 0.9625 - val_loss: 0.5944 - val_acc: 0.8947\n",
      "Epoch 1049/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5368 - acc: 0.9375 - val_loss: 0.5934 - val_acc: 0.8421\n",
      "Epoch 1050/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5393 - acc: 0.9375 - val_loss: 0.5928 - val_acc: 0.8421\n",
      "Epoch 1051/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5365 - acc: 0.9500 - val_loss: 0.5921 - val_acc: 0.8421\n",
      "Epoch 1052/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5348 - acc: 0.9625 - val_loss: 0.5917 - val_acc: 0.8421\n",
      "Epoch 1053/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.5340 - acc: 0.9500 - val_loss: 0.5912 - val_acc: 0.7895\n",
      "Epoch 1054/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5342 - acc: 0.9625 - val_loss: 0.5908 - val_acc: 0.7895\n",
      "Epoch 1055/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5345 - acc: 0.9625 - val_loss: 0.5903 - val_acc: 0.8421\n",
      "Epoch 1056/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.5332 - acc: 0.9625 - val_loss: 0.5902 - val_acc: 0.8421\n",
      "Epoch 1057/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.5311 - acc: 0.9500 - val_loss: 0.5894 - val_acc: 0.8421\n",
      "Epoch 1058/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.5307 - acc: 0.9500 - val_loss: 0.5889 - val_acc: 0.8421\n",
      "Epoch 1059/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5308 - acc: 0.9625 - val_loss: 0.5887 - val_acc: 0.7895\n",
      "Epoch 1060/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5296 - acc: 0.9500 - val_loss: 0.5885 - val_acc: 0.7895\n",
      "Epoch 1061/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.5287 - acc: 0.9625 - val_loss: 0.5878 - val_acc: 0.8421\n",
      "Epoch 1062/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.5269 - acc: 0.9500 - val_loss: 0.5876 - val_acc: 0.8947\n",
      "Epoch 1063/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.5268 - acc: 0.9625 - val_loss: 0.5869 - val_acc: 0.8947\n",
      "Epoch 1064/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5252 - acc: 0.9375 - val_loss: 0.5861 - val_acc: 0.8421\n",
      "Epoch 1065/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.5250 - acc: 0.9625 - val_loss: 0.5855 - val_acc: 0.8421\n",
      "Epoch 1066/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5239 - acc: 0.9625 - val_loss: 0.5852 - val_acc: 0.8421\n",
      "Epoch 1067/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5231 - acc: 0.9625 - val_loss: 0.5850 - val_acc: 0.8947\n",
      "Epoch 1068/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.5230 - acc: 0.9375 - val_loss: 0.5841 - val_acc: 0.8421\n",
      "Epoch 1069/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5232 - acc: 0.9500 - val_loss: 0.5833 - val_acc: 0.8421\n",
      "Epoch 1070/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5217 - acc: 0.9625 - val_loss: 0.5829 - val_acc: 0.7895\n",
      "Epoch 1071/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5215 - acc: 0.9500 - val_loss: 0.5826 - val_acc: 0.8421\n",
      "Epoch 1072/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5257 - acc: 0.9625 - val_loss: 0.5829 - val_acc: 0.8421\n",
      "Epoch 1073/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5192 - acc: 0.9500 - val_loss: 0.5826 - val_acc: 0.8421\n",
      "Epoch 1074/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.5095 - acc: 0.937 - 0s 137us/sample - loss: 0.5177 - acc: 0.9500 - val_loss: 0.5816 - val_acc: 0.8421\n",
      "Epoch 1075/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.5169 - acc: 0.9625 - val_loss: 0.5811 - val_acc: 0.8421\n",
      "Epoch 1076/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5156 - acc: 0.9625 - val_loss: 0.5806 - val_acc: 0.8421\n",
      "Epoch 1077/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.5157 - acc: 0.9500 - val_loss: 0.5807 - val_acc: 0.8947\n",
      "Epoch 1078/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.5140 - acc: 0.9500 - val_loss: 0.5800 - val_acc: 0.8421\n",
      "Epoch 1079/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.5134 - acc: 0.9625 - val_loss: 0.5791 - val_acc: 0.8421\n",
      "Epoch 1080/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5139 - acc: 0.9625 - val_loss: 0.5787 - val_acc: 0.8421\n",
      "Epoch 1081/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.5130 - acc: 0.9625 - val_loss: 0.5795 - val_acc: 0.8947\n",
      "Epoch 1082/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.5114 - acc: 0.9625 - val_loss: 0.5784 - val_acc: 0.9474\n",
      "Epoch 1083/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5099 - acc: 0.9500 - val_loss: 0.5775 - val_acc: 0.8947\n",
      "Epoch 1084/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.5085 - acc: 0.9625 - val_loss: 0.5769 - val_acc: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1085/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5080 - acc: 0.9625 - val_loss: 0.5771 - val_acc: 0.8421\n",
      "Epoch 1086/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5067 - acc: 0.9625 - val_loss: 0.5773 - val_acc: 0.8421\n",
      "Epoch 1087/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.5068 - acc: 0.9625 - val_loss: 0.5757 - val_acc: 0.8421\n",
      "Epoch 1088/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.5056 - acc: 0.9625 - val_loss: 0.5741 - val_acc: 0.8421\n",
      "Epoch 1089/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.5059 - acc: 0.9500 - val_loss: 0.5751 - val_acc: 0.8947\n",
      "Epoch 1090/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5047 - acc: 0.9625 - val_loss: 0.5737 - val_acc: 0.8947\n",
      "Epoch 1091/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5048 - acc: 0.9500 - val_loss: 0.5726 - val_acc: 0.8421\n",
      "Epoch 1092/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5029 - acc: 0.9625 - val_loss: 0.5722 - val_acc: 0.8421\n",
      "Epoch 1093/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5022 - acc: 0.9625 - val_loss: 0.5717 - val_acc: 0.8421\n",
      "Epoch 1094/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.5021 - acc: 0.9625 - val_loss: 0.5731 - val_acc: 0.8947\n",
      "Epoch 1095/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4999 - acc: 0.9625 - val_loss: 0.5724 - val_acc: 0.8947\n",
      "Epoch 1096/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.4993 - acc: 0.9500 - val_loss: 0.5720 - val_acc: 0.8421\n",
      "Epoch 1097/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.4986 - acc: 0.9625 - val_loss: 0.5712 - val_acc: 0.8421\n",
      "Epoch 1098/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4983 - acc: 0.9625 - val_loss: 0.5711 - val_acc: 0.8947\n",
      "Epoch 1099/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.4977 - acc: 0.9625 - val_loss: 0.5704 - val_acc: 0.8421\n",
      "Epoch 1100/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.4952 - acc: 0.9625 - val_loss: 0.5703 - val_acc: 0.8421\n",
      "Epoch 1101/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.4948 - acc: 0.9625 - val_loss: 0.5688 - val_acc: 0.8421\n",
      "Epoch 1102/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.4935 - acc: 0.9625 - val_loss: 0.5690 - val_acc: 0.8421\n",
      "Epoch 1103/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4929 - acc: 0.9625 - val_loss: 0.5667 - val_acc: 0.8421\n",
      "Epoch 1104/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.4920 - acc: 0.9625 - val_loss: 0.5661 - val_acc: 0.8421\n",
      "Epoch 1105/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.4915 - acc: 0.9625 - val_loss: 0.5660 - val_acc: 0.8421\n",
      "Epoch 1106/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.4909 - acc: 0.9625 - val_loss: 0.5664 - val_acc: 0.9474\n",
      "Epoch 1107/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4892 - acc: 0.9625 - val_loss: 0.5652 - val_acc: 0.8947\n",
      "Epoch 1108/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.4882 - acc: 0.9625 - val_loss: 0.5648 - val_acc: 0.8947\n",
      "Epoch 1109/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4873 - acc: 0.9625 - val_loss: 0.5643 - val_acc: 0.9474\n",
      "Epoch 1110/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4891 - acc: 0.9625 - val_loss: 0.5631 - val_acc: 0.8421\n",
      "Epoch 1111/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4876 - acc: 0.9625 - val_loss: 0.5621 - val_acc: 0.8421\n",
      "Epoch 1112/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.4853 - acc: 0.9500 - val_loss: 0.5623 - val_acc: 0.8947\n",
      "Epoch 1113/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4846 - acc: 0.9625 - val_loss: 0.5620 - val_acc: 0.9474\n",
      "Epoch 1114/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.4837 - acc: 0.9500 - val_loss: 0.5604 - val_acc: 0.8421\n",
      "Epoch 1115/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.4825 - acc: 0.9625 - val_loss: 0.5598 - val_acc: 0.8421\n",
      "Epoch 1116/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4832 - acc: 0.9625 - val_loss: 0.5597 - val_acc: 0.8947\n",
      "Epoch 1117/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4801 - acc: 0.9625 - val_loss: 0.5594 - val_acc: 0.8947\n",
      "Epoch 1118/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4806 - acc: 0.9625 - val_loss: 0.5583 - val_acc: 0.8421\n",
      "Epoch 1119/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.4792 - acc: 0.9625 - val_loss: 0.5576 - val_acc: 0.8421\n",
      "Epoch 1120/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.4792 - acc: 0.9500 - val_loss: 0.5585 - val_acc: 0.9474\n",
      "Epoch 1121/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4770 - acc: 0.9500 - val_loss: 0.5567 - val_acc: 0.8947\n",
      "Epoch 1122/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4760 - acc: 0.9625 - val_loss: 0.5558 - val_acc: 0.8421\n",
      "Epoch 1123/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4748 - acc: 0.9625 - val_loss: 0.5556 - val_acc: 0.8947\n",
      "Epoch 1124/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4769 - acc: 0.9625 - val_loss: 0.5555 - val_acc: 0.9474\n",
      "Epoch 1125/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4742 - acc: 0.9625 - val_loss: 0.5560 - val_acc: 0.9474\n",
      "Epoch 1126/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.4750 - acc: 0.9500 - val_loss: 0.5533 - val_acc: 0.8947\n",
      "Epoch 1127/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.4714 - acc: 0.9625 - val_loss: 0.5518 - val_acc: 0.8421\n",
      "Epoch 1128/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4701 - acc: 0.9625 - val_loss: 0.5511 - val_acc: 0.8421\n",
      "Epoch 1129/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.4695 - acc: 0.9625 - val_loss: 0.5511 - val_acc: 0.8421\n",
      "Epoch 1130/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.4685 - acc: 0.9625 - val_loss: 0.5516 - val_acc: 0.8421\n",
      "Epoch 1131/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.4682 - acc: 0.9625 - val_loss: 0.5510 - val_acc: 0.8421\n",
      "Epoch 1132/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.4672 - acc: 0.9625 - val_loss: 0.5505 - val_acc: 0.8421\n",
      "Epoch 1133/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4663 - acc: 0.9625 - val_loss: 0.5498 - val_acc: 0.8421\n",
      "Epoch 1134/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4652 - acc: 0.9625 - val_loss: 0.5491 - val_acc: 0.8421\n",
      "Epoch 1135/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4640 - acc: 0.9625 - val_loss: 0.5485 - val_acc: 0.8421\n",
      "Epoch 1136/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4627 - acc: 0.9625 - val_loss: 0.5474 - val_acc: 0.8947\n",
      "Epoch 1137/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4621 - acc: 0.9625 - val_loss: 0.5454 - val_acc: 0.8421\n",
      "Epoch 1138/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.4615 - acc: 0.9625 - val_loss: 0.5455 - val_acc: 0.9474\n",
      "Epoch 1139/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4598 - acc: 0.9625 - val_loss: 0.5459 - val_acc: 0.8947\n",
      "Epoch 1140/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.4599 - acc: 0.9625 - val_loss: 0.5451 - val_acc: 0.9474\n",
      "Epoch 1141/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.4583 - acc: 0.9625 - val_loss: 0.5449 - val_acc: 0.9474\n",
      "Epoch 1142/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4582 - acc: 0.9625 - val_loss: 0.5452 - val_acc: 0.8947\n",
      "Epoch 1143/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.4576 - acc: 0.9625 - val_loss: 0.5436 - val_acc: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1144/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4566 - acc: 0.9625 - val_loss: 0.5427 - val_acc: 0.8421\n",
      "Epoch 1145/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4569 - acc: 0.9625 - val_loss: 0.5412 - val_acc: 0.8421\n",
      "Epoch 1146/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.4533 - acc: 0.9625 - val_loss: 0.5399 - val_acc: 0.8947\n",
      "Epoch 1147/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.4520 - acc: 0.9625 - val_loss: 0.5373 - val_acc: 0.8947\n",
      "Epoch 1148/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.4512 - acc: 0.9625 - val_loss: 0.5368 - val_acc: 0.8947\n",
      "Epoch 1149/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4504 - acc: 0.9625 - val_loss: 0.5361 - val_acc: 0.9474\n",
      "Epoch 1150/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.4493 - acc: 0.9625 - val_loss: 0.5375 - val_acc: 0.9474\n",
      "Epoch 1151/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.4487 - acc: 0.9625 - val_loss: 0.5373 - val_acc: 0.9474\n",
      "Epoch 1152/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4478 - acc: 0.9625 - val_loss: 0.5375 - val_acc: 0.9474\n",
      "Epoch 1153/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4465 - acc: 0.9625 - val_loss: 0.5358 - val_acc: 0.9474\n",
      "Epoch 1154/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4449 - acc: 0.9625 - val_loss: 0.5351 - val_acc: 0.9474\n",
      "Epoch 1155/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4455 - acc: 0.9625 - val_loss: 0.5351 - val_acc: 0.9474\n",
      "Epoch 1156/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.4439 - acc: 0.9625 - val_loss: 0.5330 - val_acc: 0.8947\n",
      "Epoch 1157/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4418 - acc: 0.9625 - val_loss: 0.5324 - val_acc: 0.8947\n",
      "Epoch 1158/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4404 - acc: 0.9625 - val_loss: 0.5321 - val_acc: 0.9474\n",
      "Epoch 1159/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4412 - acc: 0.9625 - val_loss: 0.5321 - val_acc: 0.9474\n",
      "Epoch 1160/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.4390 - acc: 0.9625 - val_loss: 0.5304 - val_acc: 0.8947\n",
      "Epoch 1161/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4385 - acc: 0.9625 - val_loss: 0.5297 - val_acc: 0.8947\n",
      "Epoch 1162/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.4363 - acc: 0.9625 - val_loss: 0.5290 - val_acc: 0.8947\n",
      "Epoch 1163/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.4352 - acc: 0.9625 - val_loss: 0.5282 - val_acc: 0.8947\n",
      "Epoch 1164/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.4374 - acc: 0.9625 - val_loss: 0.5295 - val_acc: 0.9474\n",
      "Epoch 1165/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4343 - acc: 0.9625 - val_loss: 0.5268 - val_acc: 0.9474\n",
      "Epoch 1166/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4329 - acc: 0.9625 - val_loss: 0.5263 - val_acc: 0.9474\n",
      "Epoch 1167/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4339 - acc: 0.9625 - val_loss: 0.5254 - val_acc: 0.8947\n",
      "Epoch 1168/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.4308 - acc: 0.9625 - val_loss: 0.5246 - val_acc: 0.8947\n",
      "Epoch 1169/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4298 - acc: 0.9625 - val_loss: 0.5241 - val_acc: 0.9474\n",
      "Epoch 1170/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4301 - acc: 0.9625 - val_loss: 0.5233 - val_acc: 0.8947\n",
      "Epoch 1171/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4273 - acc: 0.9625 - val_loss: 0.5225 - val_acc: 0.8947\n",
      "Epoch 1172/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4265 - acc: 0.9625 - val_loss: 0.5219 - val_acc: 0.8947\n",
      "Epoch 1173/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4270 - acc: 0.9625 - val_loss: 0.5213 - val_acc: 0.8421\n",
      "Epoch 1174/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4242 - acc: 0.9625 - val_loss: 0.5204 - val_acc: 0.8947\n",
      "Epoch 1175/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.4235 - acc: 0.9625 - val_loss: 0.5203 - val_acc: 0.9474\n",
      "Epoch 1176/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.4222 - acc: 0.9625 - val_loss: 0.5199 - val_acc: 0.9474\n",
      "Epoch 1177/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.4214 - acc: 0.9625 - val_loss: 0.5192 - val_acc: 0.9474\n",
      "Epoch 1178/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4200 - acc: 0.9625 - val_loss: 0.5178 - val_acc: 0.8947\n",
      "Epoch 1179/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.4186 - acc: 0.9625 - val_loss: 0.5172 - val_acc: 0.9474\n",
      "Epoch 1180/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4191 - acc: 0.9625 - val_loss: 0.5163 - val_acc: 0.8947\n",
      "Epoch 1181/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4197 - acc: 0.9625 - val_loss: 0.5157 - val_acc: 0.8947\n",
      "Epoch 1182/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4165 - acc: 0.9625 - val_loss: 0.5152 - val_acc: 0.8947\n",
      "Epoch 1183/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4155 - acc: 0.9625 - val_loss: 0.5143 - val_acc: 0.8947\n",
      "Epoch 1184/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4153 - acc: 0.9625 - val_loss: 0.5146 - val_acc: 0.8947\n",
      "Epoch 1185/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.4146 - acc: 0.9625 - val_loss: 0.5131 - val_acc: 0.8421\n",
      "Epoch 1186/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.4120 - acc: 0.9625 - val_loss: 0.5124 - val_acc: 0.8421\n",
      "Epoch 1187/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.4108 - acc: 0.9625 - val_loss: 0.5116 - val_acc: 0.8421\n",
      "Epoch 1188/3000\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.4100 - acc: 0.9625 - val_loss: 0.5111 - val_acc: 0.8421\n",
      "Epoch 1189/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4090 - acc: 0.9625 - val_loss: 0.5100 - val_acc: 0.8947\n",
      "Epoch 1190/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4073 - acc: 0.9625 - val_loss: 0.5093 - val_acc: 0.8947\n",
      "Epoch 1191/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4064 - acc: 0.9625 - val_loss: 0.5087 - val_acc: 0.8947\n",
      "Epoch 1192/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.4066 - acc: 0.9625 - val_loss: 0.5088 - val_acc: 0.9474\n",
      "Epoch 1193/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4057 - acc: 0.9625 - val_loss: 0.5077 - val_acc: 0.9474\n",
      "Epoch 1194/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.4037 - acc: 0.9625 - val_loss: 0.5072 - val_acc: 0.9474\n",
      "Epoch 1195/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.4026 - acc: 0.9625 - val_loss: 0.5062 - val_acc: 0.9474\n",
      "Epoch 1196/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.4028 - acc: 0.9625 - val_loss: 0.5055 - val_acc: 0.9474\n",
      "Epoch 1197/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.4011 - acc: 0.9625 - val_loss: 0.5054 - val_acc: 0.9474\n",
      "Epoch 1198/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.4001 - acc: 0.9625 - val_loss: 0.5037 - val_acc: 0.9474\n",
      "Epoch 1199/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3989 - acc: 0.9625 - val_loss: 0.5031 - val_acc: 0.9474\n",
      "Epoch 1200/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.3968 - acc: 0.9625 - val_loss: 0.5015 - val_acc: 0.9474\n",
      "Epoch 1201/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3959 - acc: 0.9625 - val_loss: 0.5001 - val_acc: 0.8947\n",
      "Epoch 1202/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.3945 - acc: 0.9625 - val_loss: 0.5005 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1203/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.3941 - acc: 0.9625 - val_loss: 0.4998 - val_acc: 0.8947\n",
      "Epoch 1204/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.3941 - acc: 0.9625 - val_loss: 0.4992 - val_acc: 0.8947\n",
      "Epoch 1205/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3926 - acc: 0.9625 - val_loss: 0.4992 - val_acc: 0.8421\n",
      "Epoch 1206/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.3911 - acc: 0.9750 - val_loss: 0.4990 - val_acc: 0.8421\n",
      "Epoch 1207/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3906 - acc: 0.9625 - val_loss: 0.4955 - val_acc: 0.8947\n",
      "Epoch 1208/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3887 - acc: 0.9625 - val_loss: 0.4946 - val_acc: 0.8947\n",
      "Epoch 1209/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.3866 - acc: 0.9625 - val_loss: 0.4937 - val_acc: 0.8947\n",
      "Epoch 1210/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3859 - acc: 0.9625 - val_loss: 0.4930 - val_acc: 0.8947\n",
      "Epoch 1211/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3857 - acc: 0.9625 - val_loss: 0.4922 - val_acc: 0.8421\n",
      "Epoch 1212/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.3852 - acc: 0.9750 - val_loss: 0.4915 - val_acc: 0.8947\n",
      "Epoch 1213/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3828 - acc: 0.9625 - val_loss: 0.4910 - val_acc: 0.8947\n",
      "Epoch 1214/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3812 - acc: 0.9625 - val_loss: 0.4900 - val_acc: 0.8947\n",
      "Epoch 1215/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3801 - acc: 0.9625 - val_loss: 0.4891 - val_acc: 0.8947\n",
      "Epoch 1216/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.3792 - acc: 0.9625 - val_loss: 0.4885 - val_acc: 0.8421\n",
      "Epoch 1217/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.3808 - acc: 0.9625 - val_loss: 0.4879 - val_acc: 0.8947\n",
      "Epoch 1218/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3769 - acc: 0.9625 - val_loss: 0.4871 - val_acc: 0.8947\n",
      "Epoch 1219/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3762 - acc: 0.9625 - val_loss: 0.4877 - val_acc: 0.8421\n",
      "Epoch 1220/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.3758 - acc: 0.9625 - val_loss: 0.4874 - val_acc: 0.8421\n",
      "Epoch 1221/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3768 - acc: 0.9625 - val_loss: 0.4855 - val_acc: 0.8947\n",
      "Epoch 1222/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.3731 - acc: 0.9625 - val_loss: 0.4854 - val_acc: 0.8947\n",
      "Epoch 1223/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3714 - acc: 0.9625 - val_loss: 0.4861 - val_acc: 0.8947\n",
      "Epoch 1224/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3719 - acc: 0.9625 - val_loss: 0.4830 - val_acc: 0.8421\n",
      "Epoch 1225/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.3722 - acc: 0.9750 - val_loss: 0.4828 - val_acc: 0.8421\n",
      "Epoch 1226/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3693 - acc: 0.9750 - val_loss: 0.4812 - val_acc: 0.8421\n",
      "Epoch 1227/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3677 - acc: 0.9750 - val_loss: 0.4815 - val_acc: 0.8947\n",
      "Epoch 1228/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3717 - acc: 0.9750 - val_loss: 0.4807 - val_acc: 0.8947\n",
      "Epoch 1229/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.3655 - acc: 0.9625 - val_loss: 0.4798 - val_acc: 0.8947\n",
      "Epoch 1230/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.3657 - acc: 0.9625 - val_loss: 0.4797 - val_acc: 0.8947\n",
      "Epoch 1231/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.3636 - acc: 0.9625 - val_loss: 0.4806 - val_acc: 0.8947\n",
      "Epoch 1232/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3660 - acc: 0.9625 - val_loss: 0.4794 - val_acc: 0.8421\n",
      "Epoch 1233/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3630 - acc: 0.9625 - val_loss: 0.4776 - val_acc: 0.8947\n",
      "Epoch 1234/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3609 - acc: 0.9625 - val_loss: 0.4770 - val_acc: 0.9474\n",
      "Epoch 1235/3000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.3595 - acc: 0.9625 - val_loss: 0.4781 - val_acc: 0.8947\n",
      "Epoch 1236/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3630 - acc: 0.9625 - val_loss: 0.4781 - val_acc: 0.9474\n",
      "Epoch 1237/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3589 - acc: 0.9625 - val_loss: 0.4773 - val_acc: 0.9474\n",
      "Epoch 1238/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.3574 - acc: 0.9625 - val_loss: 0.4760 - val_acc: 0.9474\n",
      "Epoch 1239/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3591 - acc: 0.9625 - val_loss: 0.4782 - val_acc: 0.8947\n",
      "Epoch 1240/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.3582 - acc: 0.9625 - val_loss: 0.4765 - val_acc: 0.9474\n",
      "Epoch 1241/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3591 - acc: 0.9625 - val_loss: 0.4772 - val_acc: 0.8947\n",
      "Epoch 1242/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.3554 - acc: 0.9625 - val_loss: 0.4762 - val_acc: 0.8947\n",
      "Epoch 1243/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3560 - acc: 0.9625 - val_loss: 0.4754 - val_acc: 0.9474\n",
      "Epoch 1244/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.3553 - acc: 0.9625 - val_loss: 0.4752 - val_acc: 0.9474\n",
      "Epoch 1245/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3531 - acc: 0.9625 - val_loss: 0.4736 - val_acc: 0.9474\n",
      "Epoch 1246/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3510 - acc: 0.9625 - val_loss: 0.4728 - val_acc: 0.8947\n",
      "Epoch 1247/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3499 - acc: 0.9625 - val_loss: 0.4720 - val_acc: 0.9474\n",
      "Epoch 1248/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.3495 - acc: 0.9625 - val_loss: 0.4714 - val_acc: 0.8947\n",
      "Epoch 1249/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3507 - acc: 0.9625 - val_loss: 0.4715 - val_acc: 0.9474\n",
      "Epoch 1250/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.3471 - acc: 0.9625 - val_loss: 0.4710 - val_acc: 0.9474\n",
      "Epoch 1251/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3497 - acc: 0.9750 - val_loss: 0.4673 - val_acc: 0.9474\n",
      "Epoch 1252/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3453 - acc: 0.9625 - val_loss: 0.4684 - val_acc: 0.8947\n",
      "Epoch 1253/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.3447 - acc: 0.9625 - val_loss: 0.4697 - val_acc: 0.8947\n",
      "Epoch 1254/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3431 - acc: 0.9750 - val_loss: 0.4651 - val_acc: 0.8947\n",
      "Epoch 1255/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3420 - acc: 0.9625 - val_loss: 0.4648 - val_acc: 0.8947\n",
      "Epoch 1256/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3411 - acc: 0.9625 - val_loss: 0.4657 - val_acc: 0.8947\n",
      "Epoch 1257/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.3422 - acc: 0.9625 - val_loss: 0.4666 - val_acc: 0.8947\n",
      "Epoch 1258/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.3391 - acc: 0.9625 - val_loss: 0.4663 - val_acc: 0.8421\n",
      "Epoch 1259/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3376 - acc: 0.9750 - val_loss: 0.4652 - val_acc: 0.8947\n",
      "Epoch 1260/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3375 - acc: 0.9625 - val_loss: 0.4653 - val_acc: 0.8421\n",
      "Epoch 1261/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.3372 - acc: 0.9750 - val_loss: 0.4631 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1262/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3351 - acc: 0.9625 - val_loss: 0.4636 - val_acc: 0.8421\n",
      "Epoch 1263/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.3344 - acc: 0.9750 - val_loss: 0.4610 - val_acc: 0.8947\n",
      "Epoch 1264/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3332 - acc: 0.9750 - val_loss: 0.4601 - val_acc: 0.9474\n",
      "Epoch 1265/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.3317 - acc: 0.9625 - val_loss: 0.4594 - val_acc: 0.9474\n",
      "Epoch 1266/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3301 - acc: 0.9625 - val_loss: 0.4591 - val_acc: 0.8947\n",
      "Epoch 1267/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.3293 - acc: 0.9625 - val_loss: 0.4585 - val_acc: 0.8947\n",
      "Epoch 1268/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3282 - acc: 0.9625 - val_loss: 0.4591 - val_acc: 0.9474\n",
      "Epoch 1269/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3274 - acc: 0.9625 - val_loss: 0.4591 - val_acc: 0.9474\n",
      "Epoch 1270/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3251 - acc: 0.9625 - val_loss: 0.4533 - val_acc: 0.8947\n",
      "Epoch 1271/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.3250 - acc: 0.9750 - val_loss: 0.4528 - val_acc: 0.8947\n",
      "Epoch 1272/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3220 - acc: 0.9750 - val_loss: 0.4532 - val_acc: 0.8947\n",
      "Epoch 1273/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3200 - acc: 0.9750 - val_loss: 0.4510 - val_acc: 0.8947\n",
      "Epoch 1274/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.3198 - acc: 0.9750 - val_loss: 0.4501 - val_acc: 0.8947\n",
      "Epoch 1275/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.3187 - acc: 0.9750 - val_loss: 0.4494 - val_acc: 0.8947\n",
      "Epoch 1276/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3173 - acc: 0.9750 - val_loss: 0.4487 - val_acc: 0.8947\n",
      "Epoch 1277/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3158 - acc: 0.9750 - val_loss: 0.4481 - val_acc: 0.8947\n",
      "Epoch 1278/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.3158 - acc: 0.9750 - val_loss: 0.4472 - val_acc: 0.9474\n",
      "Epoch 1279/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3146 - acc: 0.9625 - val_loss: 0.4466 - val_acc: 0.9474\n",
      "Epoch 1280/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3134 - acc: 0.9625 - val_loss: 0.4456 - val_acc: 0.8947\n",
      "Epoch 1281/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3123 - acc: 0.9625 - val_loss: 0.4453 - val_acc: 0.8947\n",
      "Epoch 1282/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3108 - acc: 0.9750 - val_loss: 0.4416 - val_acc: 0.8947\n",
      "Epoch 1283/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3115 - acc: 0.9750 - val_loss: 0.4464 - val_acc: 0.8947\n",
      "Epoch 1284/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3114 - acc: 0.9625 - val_loss: 0.4454 - val_acc: 0.8947\n",
      "Epoch 1285/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.3000 - acc: 0.968 - 0s 146us/sample - loss: 0.3113 - acc: 0.9625 - val_loss: 0.4432 - val_acc: 0.8947\n",
      "Epoch 1286/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.3088 - acc: 0.9625 - val_loss: 0.4456 - val_acc: 0.8947\n",
      "Epoch 1287/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.3095 - acc: 0.9625 - val_loss: 0.4453 - val_acc: 0.8947\n",
      "Epoch 1288/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3079 - acc: 0.9750 - val_loss: 0.4450 - val_acc: 0.8947\n",
      "Epoch 1289/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3064 - acc: 0.9625 - val_loss: 0.4425 - val_acc: 0.8947\n",
      "Epoch 1290/3000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.3060 - acc: 0.9625 - val_loss: 0.4419 - val_acc: 0.8947\n",
      "Epoch 1291/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3049 - acc: 0.9750 - val_loss: 0.4401 - val_acc: 0.9474\n",
      "Epoch 1292/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.3043 - acc: 0.9625 - val_loss: 0.4434 - val_acc: 0.8947\n",
      "Epoch 1293/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.3032 - acc: 0.9625 - val_loss: 0.4469 - val_acc: 0.8947\n",
      "Epoch 1294/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.3029 - acc: 0.9750 - val_loss: 0.4429 - val_acc: 0.9474\n",
      "Epoch 1295/3000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.3008 - acc: 0.9625 - val_loss: 0.4426 - val_acc: 0.8947\n",
      "Epoch 1296/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2996 - acc: 0.9625 - val_loss: 0.4416 - val_acc: 0.8947\n",
      "Epoch 1297/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2983 - acc: 0.9750 - val_loss: 0.4376 - val_acc: 0.8947\n",
      "Epoch 1298/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2968 - acc: 0.9750 - val_loss: 0.4369 - val_acc: 0.8947\n",
      "Epoch 1299/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2971 - acc: 0.9625 - val_loss: 0.4362 - val_acc: 0.8947\n",
      "Epoch 1300/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2949 - acc: 0.9750 - val_loss: 0.4355 - val_acc: 0.8947\n",
      "Epoch 1301/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2944 - acc: 0.9750 - val_loss: 0.4348 - val_acc: 0.8947\n",
      "Epoch 1302/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2933 - acc: 0.9625 - val_loss: 0.4348 - val_acc: 0.8947\n",
      "Epoch 1303/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2928 - acc: 0.9750 - val_loss: 0.4343 - val_acc: 0.8947\n",
      "Epoch 1304/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2914 - acc: 0.9750 - val_loss: 0.4333 - val_acc: 0.8947\n",
      "Epoch 1305/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2909 - acc: 0.9750 - val_loss: 0.4318 - val_acc: 0.8947\n",
      "Epoch 1306/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2893 - acc: 0.9750 - val_loss: 0.4316 - val_acc: 0.8947\n",
      "Epoch 1307/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2888 - acc: 0.9750 - val_loss: 0.4305 - val_acc: 0.8947\n",
      "Epoch 1308/3000\n",
      "80/80 [==============================] - 0s 171us/sample - loss: 0.2882 - acc: 0.9750 - val_loss: 0.4293 - val_acc: 0.9474\n",
      "Epoch 1309/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2861 - acc: 0.9625 - val_loss: 0.4298 - val_acc: 0.8947\n",
      "Epoch 1310/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2861 - acc: 0.9750 - val_loss: 0.4294 - val_acc: 0.8947\n",
      "Epoch 1311/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2853 - acc: 0.9750 - val_loss: 0.4284 - val_acc: 0.9474\n",
      "Epoch 1312/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2837 - acc: 0.9625 - val_loss: 0.4277 - val_acc: 0.9474\n",
      "Epoch 1313/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2829 - acc: 0.9625 - val_loss: 0.4268 - val_acc: 0.9474\n",
      "Epoch 1314/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2825 - acc: 0.9625 - val_loss: 0.4263 - val_acc: 0.9474\n",
      "Epoch 1315/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2810 - acc: 0.9625 - val_loss: 0.4264 - val_acc: 0.8947\n",
      "Epoch 1316/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2799 - acc: 0.9750 - val_loss: 0.4264 - val_acc: 0.8947\n",
      "Epoch 1317/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2786 - acc: 0.9750 - val_loss: 0.4246 - val_acc: 0.8947\n",
      "Epoch 1318/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2776 - acc: 0.9750 - val_loss: 0.4239 - val_acc: 0.8947\n",
      "Epoch 1319/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2774 - acc: 0.9750 - val_loss: 0.4233 - val_acc: 0.8947\n",
      "Epoch 1320/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2758 - acc: 0.9750 - val_loss: 0.4231 - val_acc: 0.8947\n",
      "Epoch 1321/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2750 - acc: 0.9750 - val_loss: 0.4246 - val_acc: 0.8947\n",
      "Epoch 1322/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2755 - acc: 0.9750 - val_loss: 0.4227 - val_acc: 0.8947\n",
      "Epoch 1323/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2747 - acc: 0.9750 - val_loss: 0.4213 - val_acc: 0.8947\n",
      "Epoch 1324/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2743 - acc: 0.9750 - val_loss: 0.4195 - val_acc: 0.8947\n",
      "Epoch 1325/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2735 - acc: 0.9750 - val_loss: 0.4204 - val_acc: 0.8947\n",
      "Epoch 1326/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2996 - acc: 0.937 - 0s 125us/sample - loss: 0.2722 - acc: 0.9750 - val_loss: 0.4197 - val_acc: 0.9474\n",
      "Epoch 1327/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2713 - acc: 0.9750 - val_loss: 0.4168 - val_acc: 0.9474\n",
      "Epoch 1328/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2719 - acc: 0.9625 - val_loss: 0.4182 - val_acc: 0.8421\n",
      "Epoch 1329/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2703 - acc: 0.9750 - val_loss: 0.4161 - val_acc: 0.9474\n",
      "Epoch 1330/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2689 - acc: 0.9750 - val_loss: 0.4149 - val_acc: 0.9474\n",
      "Epoch 1331/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2672 - acc: 0.9750 - val_loss: 0.4139 - val_acc: 0.9474\n",
      "Epoch 1332/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2657 - acc: 0.9750 - val_loss: 0.4151 - val_acc: 0.8947\n",
      "Epoch 1333/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2660 - acc: 0.9750 - val_loss: 0.4139 - val_acc: 0.8947\n",
      "Epoch 1334/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2651 - acc: 0.9750 - val_loss: 0.4129 - val_acc: 0.8947\n",
      "Epoch 1335/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2648 - acc: 0.9750 - val_loss: 0.4175 - val_acc: 0.8947\n",
      "Epoch 1336/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2634 - acc: 0.9750 - val_loss: 0.4195 - val_acc: 0.8947\n",
      "Epoch 1337/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2624 - acc: 0.9750 - val_loss: 0.4169 - val_acc: 0.9474\n",
      "Epoch 1338/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2635 - acc: 0.9750 - val_loss: 0.4144 - val_acc: 0.8947\n",
      "Epoch 1339/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2608 - acc: 0.9750 - val_loss: 0.4121 - val_acc: 0.8947\n",
      "Epoch 1340/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2624 - acc: 0.9750 - val_loss: 0.4135 - val_acc: 0.8947\n",
      "Epoch 1341/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2616 - acc: 0.9750 - val_loss: 0.4086 - val_acc: 0.9474\n",
      "Epoch 1342/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2600 - acc: 0.9750 - val_loss: 0.4075 - val_acc: 0.9474\n",
      "Epoch 1343/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2621 - acc: 0.9750 - val_loss: 0.4065 - val_acc: 0.9474\n",
      "Epoch 1344/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2602 - acc: 0.9750 - val_loss: 0.4057 - val_acc: 0.9474\n",
      "Epoch 1345/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2593 - acc: 0.9750 - val_loss: 0.4077 - val_acc: 0.9474\n",
      "Epoch 1346/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2571 - acc: 0.9750 - val_loss: 0.4070 - val_acc: 0.9474\n",
      "Epoch 1347/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2567 - acc: 0.9750 - val_loss: 0.4061 - val_acc: 0.9474\n",
      "Epoch 1348/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2554 - acc: 0.9750 - val_loss: 0.4056 - val_acc: 0.9474\n",
      "Epoch 1349/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2544 - acc: 0.9750 - val_loss: 0.4037 - val_acc: 0.9474\n",
      "Epoch 1350/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2534 - acc: 0.9750 - val_loss: 0.4060 - val_acc: 0.9474\n",
      "Epoch 1351/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2541 - acc: 0.9750 - val_loss: 0.4044 - val_acc: 0.9474\n",
      "Epoch 1352/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2522 - acc: 0.9750 - val_loss: 0.4036 - val_acc: 0.9474\n",
      "Epoch 1353/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2511 - acc: 0.9750 - val_loss: 0.4033 - val_acc: 0.9474\n",
      "Epoch 1354/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2500 - acc: 0.9750 - val_loss: 0.4036 - val_acc: 0.9474\n",
      "Epoch 1355/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2498 - acc: 0.9750 - val_loss: 0.4030 - val_acc: 0.9474\n",
      "Epoch 1356/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2481 - acc: 0.9750 - val_loss: 0.4025 - val_acc: 0.9474\n",
      "Epoch 1357/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2493 - acc: 0.9750 - val_loss: 0.4036 - val_acc: 0.8947\n",
      "Epoch 1358/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2469 - acc: 0.9750 - val_loss: 0.4023 - val_acc: 0.8947\n",
      "Epoch 1359/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2467 - acc: 0.9750 - val_loss: 0.4024 - val_acc: 0.8947\n",
      "Epoch 1360/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2460 - acc: 0.9750 - val_loss: 0.4020 - val_acc: 0.8947\n",
      "Epoch 1361/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2451 - acc: 0.9750 - val_loss: 0.4022 - val_acc: 0.8421\n",
      "Epoch 1362/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2437 - acc: 0.9750 - val_loss: 0.3998 - val_acc: 0.8947\n",
      "Epoch 1363/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2425 - acc: 0.9750 - val_loss: 0.3994 - val_acc: 0.8947\n",
      "Epoch 1364/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2415 - acc: 0.9750 - val_loss: 0.3985 - val_acc: 0.8947\n",
      "Epoch 1365/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2421 - acc: 0.9750 - val_loss: 0.3989 - val_acc: 0.8947\n",
      "Epoch 1366/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2400 - acc: 0.9750 - val_loss: 0.3974 - val_acc: 0.9474\n",
      "Epoch 1367/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2412 - acc: 0.9750 - val_loss: 0.3965 - val_acc: 0.9474\n",
      "Epoch 1368/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2384 - acc: 0.9750 - val_loss: 0.3965 - val_acc: 0.8947\n",
      "Epoch 1369/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2382 - acc: 0.9750 - val_loss: 0.3952 - val_acc: 0.9474\n",
      "Epoch 1370/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.2377 - acc: 0.9750 - val_loss: 0.3950 - val_acc: 0.9474\n",
      "Epoch 1371/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2365 - acc: 0.9750 - val_loss: 0.3954 - val_acc: 0.9474\n",
      "Epoch 1372/3000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2361 - acc: 0.9750 - val_loss: 0.3898 - val_acc: 0.9474\n",
      "Epoch 1373/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2350 - acc: 0.9750 - val_loss: 0.3901 - val_acc: 0.8947\n",
      "Epoch 1374/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2339 - acc: 0.9750 - val_loss: 0.3925 - val_acc: 0.8947\n",
      "Epoch 1375/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2331 - acc: 0.9750 - val_loss: 0.3906 - val_acc: 0.8947\n",
      "Epoch 1376/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2316 - acc: 0.9750 - val_loss: 0.3891 - val_acc: 0.8947\n",
      "Epoch 1377/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2309 - acc: 0.9750 - val_loss: 0.3880 - val_acc: 0.9474\n",
      "Epoch 1378/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2312 - acc: 0.9750 - val_loss: 0.3881 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1379/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2292 - acc: 0.9750 - val_loss: 0.3876 - val_acc: 0.8947\n",
      "Epoch 1380/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2289 - acc: 0.9750 - val_loss: 0.3884 - val_acc: 0.8947\n",
      "Epoch 1381/3000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2283 - acc: 0.9750 - val_loss: 0.3860 - val_acc: 0.8947\n",
      "Epoch 1382/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2270 - acc: 0.9750 - val_loss: 0.3854 - val_acc: 0.9474\n",
      "Epoch 1383/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2277 - acc: 0.9750 - val_loss: 0.3851 - val_acc: 0.9474\n",
      "Epoch 1384/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2269 - acc: 0.9750 - val_loss: 0.3859 - val_acc: 0.8947\n",
      "Epoch 1385/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2258 - acc: 0.9750 - val_loss: 0.3876 - val_acc: 0.8947\n",
      "Epoch 1386/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2243 - acc: 0.9750 - val_loss: 0.3888 - val_acc: 0.8947\n",
      "Epoch 1387/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2237 - acc: 0.9750 - val_loss: 0.3892 - val_acc: 0.8947\n",
      "Epoch 1388/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2230 - acc: 0.9750 - val_loss: 0.3878 - val_acc: 0.8947\n",
      "Epoch 1389/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2222 - acc: 0.9750 - val_loss: 0.3878 - val_acc: 0.8947\n",
      "Epoch 1390/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.2212 - acc: 0.9750 - val_loss: 0.3876 - val_acc: 0.8947\n",
      "Epoch 1391/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2201 - acc: 0.9750 - val_loss: 0.3875 - val_acc: 0.8947\n",
      "Epoch 1392/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2200 - acc: 0.9750 - val_loss: 0.3877 - val_acc: 0.8947\n",
      "Epoch 1393/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2188 - acc: 0.9750 - val_loss: 0.3864 - val_acc: 0.8947\n",
      "Epoch 1394/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2181 - acc: 0.9750 - val_loss: 0.3846 - val_acc: 0.8947\n",
      "Epoch 1395/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2169 - acc: 0.9750 - val_loss: 0.3842 - val_acc: 0.8947\n",
      "Epoch 1396/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2163 - acc: 0.9750 - val_loss: 0.3837 - val_acc: 0.8947\n",
      "Epoch 1397/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2156 - acc: 0.9750 - val_loss: 0.3864 - val_acc: 0.8947\n",
      "Epoch 1398/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2152 - acc: 0.9750 - val_loss: 0.3874 - val_acc: 0.8947\n",
      "Epoch 1399/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2143 - acc: 0.9750 - val_loss: 0.3869 - val_acc: 0.8947\n",
      "Epoch 1400/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2134 - acc: 0.9750 - val_loss: 0.3862 - val_acc: 0.8947\n",
      "Epoch 1401/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2149 - acc: 0.9750 - val_loss: 0.3851 - val_acc: 0.8947\n",
      "Epoch 1402/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2130 - acc: 0.9750 - val_loss: 0.3879 - val_acc: 0.8947\n",
      "Epoch 1403/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2106 - acc: 0.9750 - val_loss: 0.3834 - val_acc: 0.8947\n",
      "Epoch 1404/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2113 - acc: 0.9750 - val_loss: 0.3852 - val_acc: 0.8947\n",
      "Epoch 1405/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2091 - acc: 0.9750 - val_loss: 0.3835 - val_acc: 0.8947\n",
      "Epoch 1406/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2108 - acc: 0.9750 - val_loss: 0.3831 - val_acc: 0.8947\n",
      "Epoch 1407/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2062 - acc: 0.9750 - val_loss: 0.3798 - val_acc: 0.8947\n",
      "Epoch 1408/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2056 - acc: 0.9750 - val_loss: 0.3791 - val_acc: 0.8947\n",
      "Epoch 1409/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2045 - acc: 0.9750 - val_loss: 0.3794 - val_acc: 0.8947\n",
      "Epoch 1410/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2035 - acc: 0.9750 - val_loss: 0.3797 - val_acc: 0.8947\n",
      "Epoch 1411/3000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2031 - acc: 0.9750 - val_loss: 0.3788 - val_acc: 0.8947\n",
      "Epoch 1412/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.2027 - acc: 0.9750 - val_loss: 0.3779 - val_acc: 0.8947\n",
      "Epoch 1413/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2011 - acc: 0.9750 - val_loss: 0.3787 - val_acc: 0.8947\n",
      "Epoch 1414/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2019 - acc: 0.9750 - val_loss: 0.3881 - val_acc: 0.8947\n",
      "Epoch 1415/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2025 - acc: 0.9750 - val_loss: 0.3877 - val_acc: 0.8947\n",
      "Epoch 1416/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2017 - acc: 0.9750 - val_loss: 0.3862 - val_acc: 0.8947\n",
      "Epoch 1417/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2013 - acc: 0.9750 - val_loss: 0.3849 - val_acc: 0.8947\n",
      "Epoch 1418/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2015 - acc: 0.9750 - val_loss: 0.3842 - val_acc: 0.8947\n",
      "Epoch 1419/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2013 - acc: 0.9750 - val_loss: 0.3850 - val_acc: 0.8947\n",
      "Epoch 1420/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1990 - acc: 0.9750 - val_loss: 0.3845 - val_acc: 0.8947\n",
      "Epoch 1421/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1986 - acc: 0.9750 - val_loss: 0.3848 - val_acc: 0.8947\n",
      "Epoch 1422/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2008 - acc: 0.9750 - val_loss: 0.3835 - val_acc: 0.8947\n",
      "Epoch 1423/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1979 - acc: 0.9750 - val_loss: 0.3839 - val_acc: 0.8947\n",
      "Epoch 1424/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1979 - acc: 0.9750 - val_loss: 0.3820 - val_acc: 0.8947\n",
      "Epoch 1425/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1966 - acc: 0.9750 - val_loss: 0.3816 - val_acc: 0.8947\n",
      "Epoch 1426/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1959 - acc: 0.9750 - val_loss: 0.3810 - val_acc: 0.8947\n",
      "Epoch 1427/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1939 - acc: 0.9750 - val_loss: 0.3803 - val_acc: 0.8947\n",
      "Epoch 1428/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1935 - acc: 0.9750 - val_loss: 0.3806 - val_acc: 0.8947\n",
      "Epoch 1429/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1934 - acc: 0.9750 - val_loss: 0.3841 - val_acc: 0.8947\n",
      "Epoch 1430/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1925 - acc: 0.9750 - val_loss: 0.3909 - val_acc: 0.8947\n",
      "Epoch 1431/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1935 - acc: 0.9750 - val_loss: 0.3911 - val_acc: 0.8421\n",
      "Epoch 1432/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1921 - acc: 0.9750 - val_loss: 0.3879 - val_acc: 0.8947\n",
      "Epoch 1433/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1917 - acc: 0.9750 - val_loss: 0.3881 - val_acc: 0.8947\n",
      "Epoch 1434/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1899 - acc: 0.9750 - val_loss: 0.3857 - val_acc: 0.8947\n",
      "Epoch 1435/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1889 - acc: 0.9750 - val_loss: 0.3851 - val_acc: 0.8947\n",
      "Epoch 1436/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1889 - acc: 0.9750 - val_loss: 0.3879 - val_acc: 0.8421\n",
      "Epoch 1437/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1857 - acc: 0.9750 - val_loss: 0.3828 - val_acc: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1438/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1844 - acc: 0.9750 - val_loss: 0.3779 - val_acc: 0.8947\n",
      "Epoch 1439/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1834 - acc: 0.9750 - val_loss: 0.3812 - val_acc: 0.8421\n",
      "Epoch 1440/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1823 - acc: 0.9750 - val_loss: 0.3806 - val_acc: 0.8947\n",
      "Epoch 1441/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1827 - acc: 0.9750 - val_loss: 0.3761 - val_acc: 0.8947\n",
      "Epoch 1442/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1812 - acc: 0.9750 - val_loss: 0.3770 - val_acc: 0.8947\n",
      "Epoch 1443/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1807 - acc: 0.9750 - val_loss: 0.3763 - val_acc: 0.8947\n",
      "Epoch 1444/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1793 - acc: 0.9750 - val_loss: 0.3750 - val_acc: 0.9474\n",
      "Epoch 1445/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1808 - acc: 0.9750 - val_loss: 0.3740 - val_acc: 0.9474\n",
      "Epoch 1446/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.1794 - acc: 0.9750 - val_loss: 0.3752 - val_acc: 0.8947\n",
      "Epoch 1447/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1773 - acc: 0.9750 - val_loss: 0.3753 - val_acc: 0.8947\n",
      "Epoch 1448/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1767 - acc: 0.9750 - val_loss: 0.3741 - val_acc: 0.9474\n",
      "Epoch 1449/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1763 - acc: 0.9750 - val_loss: 0.3733 - val_acc: 0.9474\n",
      "Epoch 1450/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1758 - acc: 0.9750 - val_loss: 0.3733 - val_acc: 0.9474\n",
      "Epoch 1451/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1749 - acc: 0.9750 - val_loss: 0.3723 - val_acc: 0.9474\n",
      "Epoch 1452/3000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.1742 - acc: 0.9750 - val_loss: 0.3723 - val_acc: 0.9474\n",
      "Epoch 1453/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1736 - acc: 0.9750 - val_loss: 0.3729 - val_acc: 0.8947\n",
      "Epoch 1454/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1727 - acc: 0.9750 - val_loss: 0.3728 - val_acc: 0.8947\n",
      "Epoch 1455/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1731 - acc: 0.9750 - val_loss: 0.3720 - val_acc: 0.8947\n",
      "Epoch 1456/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.1717 - acc: 0.9750 - val_loss: 0.3710 - val_acc: 0.9474\n",
      "Epoch 1457/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.1709 - acc: 0.9750 - val_loss: 0.3713 - val_acc: 0.8947\n",
      "Epoch 1458/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1702 - acc: 0.9750 - val_loss: 0.3704 - val_acc: 0.9474\n",
      "Epoch 1459/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1697 - acc: 0.9750 - val_loss: 0.3699 - val_acc: 0.9474\n",
      "Epoch 1460/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1693 - acc: 0.9750 - val_loss: 0.3716 - val_acc: 0.8947\n",
      "Epoch 1461/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1688 - acc: 0.9750 - val_loss: 0.3693 - val_acc: 0.9474\n",
      "Epoch 1462/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1681 - acc: 0.9750 - val_loss: 0.3685 - val_acc: 0.9474\n",
      "Epoch 1463/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1680 - acc: 0.9750 - val_loss: 0.3670 - val_acc: 0.9474\n",
      "Epoch 1464/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1688 - acc: 0.9750 - val_loss: 0.3666 - val_acc: 0.9474\n",
      "Epoch 1465/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1666 - acc: 0.9750 - val_loss: 0.3682 - val_acc: 0.8947\n",
      "Epoch 1466/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1657 - acc: 0.9750 - val_loss: 0.3667 - val_acc: 0.9474\n",
      "Epoch 1467/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1650 - acc: 0.9750 - val_loss: 0.3682 - val_acc: 0.8947\n",
      "Epoch 1468/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1641 - acc: 0.9750 - val_loss: 0.3675 - val_acc: 0.8947\n",
      "Epoch 1469/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.1661 - acc: 0.9750 - val_loss: 0.3654 - val_acc: 0.9474\n",
      "Epoch 1470/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1646 - acc: 0.9750 - val_loss: 0.3642 - val_acc: 0.9474\n",
      "Epoch 1471/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1635 - acc: 0.9750 - val_loss: 0.3645 - val_acc: 0.9474\n",
      "Epoch 1472/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1621 - acc: 0.9750 - val_loss: 0.3657 - val_acc: 0.8947\n",
      "Epoch 1473/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1613 - acc: 0.9750 - val_loss: 0.3673 - val_acc: 0.8947\n",
      "Epoch 1474/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1607 - acc: 0.9750 - val_loss: 0.3662 - val_acc: 0.8947\n",
      "Epoch 1475/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1599 - acc: 0.9750 - val_loss: 0.3654 - val_acc: 0.8947\n",
      "Epoch 1476/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1595 - acc: 0.9750 - val_loss: 0.3656 - val_acc: 0.8947\n",
      "Epoch 1477/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1588 - acc: 0.9750 - val_loss: 0.3642 - val_acc: 0.8947\n",
      "Epoch 1478/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1585 - acc: 0.9750 - val_loss: 0.3624 - val_acc: 0.9474\n",
      "Epoch 1479/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1589 - acc: 0.9750 - val_loss: 0.3661 - val_acc: 0.8947\n",
      "Epoch 1480/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1571 - acc: 0.9750 - val_loss: 0.3654 - val_acc: 0.8947\n",
      "Epoch 1481/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1567 - acc: 0.9750 - val_loss: 0.3633 - val_acc: 0.8947\n",
      "Epoch 1482/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1564 - acc: 0.9750 - val_loss: 0.3647 - val_acc: 0.8947\n",
      "Epoch 1483/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1554 - acc: 0.9750 - val_loss: 0.3628 - val_acc: 0.8947\n",
      "Epoch 1484/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1554 - acc: 0.9750 - val_loss: 0.3658 - val_acc: 0.8947\n",
      "Epoch 1485/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1543 - acc: 0.9750 - val_loss: 0.3650 - val_acc: 0.8421\n",
      "Epoch 1486/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1548 - acc: 0.9750 - val_loss: 0.3671 - val_acc: 0.8421\n",
      "Epoch 1487/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1538 - acc: 0.9875 - val_loss: 0.3664 - val_acc: 0.8421\n",
      "Epoch 1488/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1529 - acc: 0.9875 - val_loss: 0.3641 - val_acc: 0.8421\n",
      "Epoch 1489/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1520 - acc: 0.9875 - val_loss: 0.3611 - val_acc: 0.8947\n",
      "Epoch 1490/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1514 - acc: 0.9750 - val_loss: 0.3616 - val_acc: 0.8947\n",
      "Epoch 1491/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1522 - acc: 0.9750 - val_loss: 0.3621 - val_acc: 0.8947\n",
      "Epoch 1492/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1516 - acc: 0.9875 - val_loss: 0.3612 - val_acc: 0.8947\n",
      "Epoch 1493/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1499 - acc: 0.9875 - val_loss: 0.3612 - val_acc: 0.8947\n",
      "Epoch 1494/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1490 - acc: 0.9875 - val_loss: 0.3594 - val_acc: 0.8947\n",
      "Epoch 1495/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1493 - acc: 0.9750 - val_loss: 0.3575 - val_acc: 0.9474\n",
      "Epoch 1496/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1485 - acc: 0.9750 - val_loss: 0.3590 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1497/3000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.1473 - acc: 0.9750 - val_loss: 0.3595 - val_acc: 0.8947\n",
      "Epoch 1498/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1471 - acc: 0.9875 - val_loss: 0.3568 - val_acc: 0.9474\n",
      "Epoch 1499/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1465 - acc: 0.9750 - val_loss: 0.3588 - val_acc: 0.8947\n",
      "Epoch 1500/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1467 - acc: 0.9875 - val_loss: 0.3566 - val_acc: 0.9474\n",
      "Epoch 1501/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1455 - acc: 0.9750 - val_loss: 0.3585 - val_acc: 0.8947\n",
      "Epoch 1502/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1448 - acc: 0.9875 - val_loss: 0.3580 - val_acc: 0.8947\n",
      "Epoch 1503/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.1454 - acc: 0.9750 - val_loss: 0.3589 - val_acc: 0.8947\n",
      "Epoch 1504/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1441 - acc: 0.9875 - val_loss: 0.3569 - val_acc: 0.8947\n",
      "Epoch 1505/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1431 - acc: 0.9875 - val_loss: 0.3563 - val_acc: 0.8947\n",
      "Epoch 1506/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1424 - acc: 0.9875 - val_loss: 0.3550 - val_acc: 0.9474\n",
      "Epoch 1507/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1421 - acc: 0.9875 - val_loss: 0.3566 - val_acc: 0.8947\n",
      "Epoch 1508/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1417 - acc: 0.9875 - val_loss: 0.3574 - val_acc: 0.8947\n",
      "Epoch 1509/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1415 - acc: 0.9875 - val_loss: 0.3572 - val_acc: 0.8947\n",
      "Epoch 1510/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1412 - acc: 0.9875 - val_loss: 0.3560 - val_acc: 0.8947\n",
      "Epoch 1511/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1401 - acc: 0.9875 - val_loss: 0.3551 - val_acc: 0.8947\n",
      "Epoch 1512/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1395 - acc: 0.9875 - val_loss: 0.3574 - val_acc: 0.8947\n",
      "Epoch 1513/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1389 - acc: 0.9875 - val_loss: 0.3530 - val_acc: 0.8947\n",
      "Epoch 1514/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1392 - acc: 0.9750 - val_loss: 0.3515 - val_acc: 0.9474\n",
      "Epoch 1515/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1387 - acc: 0.9875 - val_loss: 0.3535 - val_acc: 0.8947\n",
      "Epoch 1516/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1372 - acc: 0.9875 - val_loss: 0.3522 - val_acc: 0.8947\n",
      "Epoch 1517/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1371 - acc: 0.9875 - val_loss: 0.3544 - val_acc: 0.8947\n",
      "Epoch 1518/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1374 - acc: 0.9875 - val_loss: 0.3524 - val_acc: 0.8947\n",
      "Epoch 1519/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1361 - acc: 0.9875 - val_loss: 0.3516 - val_acc: 0.8947\n",
      "Epoch 1520/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1354 - acc: 0.9875 - val_loss: 0.3526 - val_acc: 0.8947\n",
      "Epoch 1521/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1358 - acc: 0.9875 - val_loss: 0.3512 - val_acc: 0.8947\n",
      "Epoch 1522/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1342 - acc: 0.9875 - val_loss: 0.3517 - val_acc: 0.8947\n",
      "Epoch 1523/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1350 - acc: 0.9875 - val_loss: 0.3511 - val_acc: 0.8947\n",
      "Epoch 1524/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1332 - acc: 0.9875 - val_loss: 0.3509 - val_acc: 0.8947\n",
      "Epoch 1525/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1326 - acc: 0.9875 - val_loss: 0.3500 - val_acc: 0.8947\n",
      "Epoch 1526/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1324 - acc: 0.9875 - val_loss: 0.3516 - val_acc: 0.9474\n",
      "Epoch 1527/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1317 - acc: 0.9875 - val_loss: 0.3478 - val_acc: 0.9474\n",
      "Epoch 1528/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1325 - acc: 0.9875 - val_loss: 0.3498 - val_acc: 0.8421\n",
      "Epoch 1529/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1322 - acc: 0.9875 - val_loss: 0.3479 - val_acc: 0.8947\n",
      "Epoch 1530/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1311 - acc: 0.9875 - val_loss: 0.3505 - val_acc: 0.8947\n",
      "Epoch 1531/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1305 - acc: 0.9875 - val_loss: 0.3476 - val_acc: 0.8947\n",
      "Epoch 1532/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1305 - acc: 0.9875 - val_loss: 0.3459 - val_acc: 0.8947\n",
      "Epoch 1533/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1288 - acc: 0.9875 - val_loss: 0.3437 - val_acc: 0.9474\n",
      "Epoch 1534/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.1300 - acc: 0.9875 - val_loss: 0.3413 - val_acc: 0.9474\n",
      "Epoch 1535/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1280 - acc: 0.9875 - val_loss: 0.3439 - val_acc: 0.9474\n",
      "Epoch 1536/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1296 - acc: 0.9875 - val_loss: 0.3457 - val_acc: 0.9474\n",
      "Epoch 1537/3000\n",
      "80/80 [==============================] - 0s 171us/sample - loss: 0.1288 - acc: 0.9875 - val_loss: 0.3523 - val_acc: 0.8947\n",
      "Epoch 1538/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1284 - acc: 0.9875 - val_loss: 0.3540 - val_acc: 0.8947\n",
      "Epoch 1539/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1280 - acc: 0.9875 - val_loss: 0.3530 - val_acc: 0.8947\n",
      "Epoch 1540/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1278 - acc: 0.9875 - val_loss: 0.3502 - val_acc: 0.8947\n",
      "Epoch 1541/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1273 - acc: 0.9875 - val_loss: 0.3515 - val_acc: 0.8947\n",
      "Epoch 1542/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1260 - acc: 0.9875 - val_loss: 0.3511 - val_acc: 0.8947\n",
      "Epoch 1543/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1256 - acc: 0.9875 - val_loss: 0.3425 - val_acc: 0.8947\n",
      "Epoch 1544/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1254 - acc: 0.9875 - val_loss: 0.3468 - val_acc: 0.8947\n",
      "Epoch 1545/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1235 - acc: 0.9875 - val_loss: 0.3497 - val_acc: 0.8947\n",
      "Epoch 1546/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1233 - acc: 0.9875 - val_loss: 0.3500 - val_acc: 0.8947\n",
      "Epoch 1547/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1236 - acc: 0.9875 - val_loss: 0.3474 - val_acc: 0.8947\n",
      "Epoch 1548/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.1212 - acc: 0.9875 - val_loss: 0.3482 - val_acc: 0.8947\n",
      "Epoch 1549/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1213 - acc: 0.9875 - val_loss: 0.3454 - val_acc: 0.9474\n",
      "Epoch 1550/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1204 - acc: 0.9875 - val_loss: 0.3449 - val_acc: 0.9474\n",
      "Epoch 1551/3000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.1199 - acc: 0.9875 - val_loss: 0.3441 - val_acc: 0.9474\n",
      "Epoch 1552/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1198 - acc: 0.9875 - val_loss: 0.3466 - val_acc: 0.8947\n",
      "Epoch 1553/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1191 - acc: 0.9875 - val_loss: 0.3476 - val_acc: 0.8947\n",
      "Epoch 1554/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1198 - acc: 0.9875 - val_loss: 0.3440 - val_acc: 0.9474\n",
      "Epoch 1555/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1190 - acc: 0.9875 - val_loss: 0.3427 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1556/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1177 - acc: 0.9875 - val_loss: 0.3433 - val_acc: 0.9474\n",
      "Epoch 1557/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1171 - acc: 0.9875 - val_loss: 0.3439 - val_acc: 0.9474\n",
      "Epoch 1558/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1167 - acc: 0.9875 - val_loss: 0.3436 - val_acc: 0.9474\n",
      "Epoch 1559/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1168 - acc: 0.9875 - val_loss: 0.3436 - val_acc: 0.9474\n",
      "Epoch 1560/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1159 - acc: 0.9875 - val_loss: 0.3439 - val_acc: 0.9474\n",
      "Epoch 1561/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1165 - acc: 0.9875 - val_loss: 0.3458 - val_acc: 0.8947\n",
      "Epoch 1562/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1165 - acc: 0.9875 - val_loss: 0.3422 - val_acc: 0.9474\n",
      "Epoch 1563/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1149 - acc: 0.9875 - val_loss: 0.3417 - val_acc: 0.9474\n",
      "Epoch 1564/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1142 - acc: 0.9875 - val_loss: 0.3427 - val_acc: 0.9474\n",
      "Epoch 1565/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1137 - acc: 0.9875 - val_loss: 0.3421 - val_acc: 0.9474\n",
      "Epoch 1566/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1134 - acc: 0.9875 - val_loss: 0.3417 - val_acc: 0.9474\n",
      "Epoch 1567/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1128 - acc: 0.9875 - val_loss: 0.3407 - val_acc: 0.9474\n",
      "Epoch 1568/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1124 - acc: 0.9875 - val_loss: 0.3412 - val_acc: 0.9474\n",
      "Epoch 1569/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1119 - acc: 0.9875 - val_loss: 0.3409 - val_acc: 0.9474\n",
      "Epoch 1570/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1120 - acc: 0.9875 - val_loss: 0.3435 - val_acc: 0.8947\n",
      "Epoch 1571/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1114 - acc: 0.9875 - val_loss: 0.3430 - val_acc: 0.8947\n",
      "Epoch 1572/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1111 - acc: 0.9875 - val_loss: 0.3414 - val_acc: 0.8947\n",
      "Epoch 1573/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1104 - acc: 0.9875 - val_loss: 0.3395 - val_acc: 0.9474\n",
      "Epoch 1574/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1102 - acc: 0.9875 - val_loss: 0.3409 - val_acc: 0.8947\n",
      "Epoch 1575/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1109 - acc: 0.9875 - val_loss: 0.3422 - val_acc: 0.8947\n",
      "Epoch 1576/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1103 - acc: 0.9875 - val_loss: 0.3414 - val_acc: 0.8947\n",
      "Epoch 1577/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1097 - acc: 0.9875 - val_loss: 0.3382 - val_acc: 0.9474\n",
      "Epoch 1578/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1088 - acc: 0.9875 - val_loss: 0.3380 - val_acc: 0.9474\n",
      "Epoch 1579/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1086 - acc: 0.9875 - val_loss: 0.3404 - val_acc: 0.9474\n",
      "Epoch 1580/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1084 - acc: 0.9875 - val_loss: 0.3379 - val_acc: 0.9474\n",
      "Epoch 1581/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1081 - acc: 0.9875 - val_loss: 0.3375 - val_acc: 0.9474\n",
      "Epoch 1582/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1069 - acc: 0.9875 - val_loss: 0.3380 - val_acc: 0.9474\n",
      "Epoch 1583/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1064 - acc: 0.9875 - val_loss: 0.3399 - val_acc: 0.9474\n",
      "Epoch 1584/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1059 - acc: 0.9875 - val_loss: 0.3405 - val_acc: 0.9474\n",
      "Epoch 1585/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1063 - acc: 0.9875 - val_loss: 0.3424 - val_acc: 0.8947\n",
      "Epoch 1586/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1052 - acc: 0.9875 - val_loss: 0.3422 - val_acc: 0.8947\n",
      "Epoch 1587/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1066 - acc: 0.9875 - val_loss: 0.3415 - val_acc: 0.8947\n",
      "Epoch 1588/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1045 - acc: 0.9875 - val_loss: 0.3409 - val_acc: 0.8947\n",
      "Epoch 1589/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1043 - acc: 0.9875 - val_loss: 0.3425 - val_acc: 0.8947\n",
      "Epoch 1590/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.1043 - acc: 0.9875 - val_loss: 0.3442 - val_acc: 0.8947\n",
      "Epoch 1591/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1052 - acc: 0.9875 - val_loss: 0.3445 - val_acc: 0.8947\n",
      "Epoch 1592/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1034 - acc: 0.9875 - val_loss: 0.3428 - val_acc: 0.8947\n",
      "Epoch 1593/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1025 - acc: 0.9875 - val_loss: 0.3411 - val_acc: 0.8947\n",
      "Epoch 1594/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1020 - acc: 0.9875 - val_loss: 0.3395 - val_acc: 0.9474\n",
      "Epoch 1595/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1015 - acc: 0.9875 - val_loss: 0.3396 - val_acc: 0.9474\n",
      "Epoch 1596/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1018 - acc: 0.9875 - val_loss: 0.3422 - val_acc: 0.8947\n",
      "Epoch 1597/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1010 - acc: 0.9875 - val_loss: 0.3400 - val_acc: 0.8947\n",
      "Epoch 1598/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1004 - acc: 0.9875 - val_loss: 0.3387 - val_acc: 0.9474\n",
      "Epoch 1599/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1002 - acc: 0.9875 - val_loss: 0.3401 - val_acc: 0.8947\n",
      "Epoch 1600/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0999 - acc: 0.9875 - val_loss: 0.3411 - val_acc: 0.8947\n",
      "Epoch 1601/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0996 - acc: 0.9875 - val_loss: 0.3394 - val_acc: 0.8947\n",
      "Epoch 1602/3000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.0990 - acc: 0.9875 - val_loss: 0.3396 - val_acc: 0.8947\n",
      "Epoch 1603/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0990 - acc: 0.9875 - val_loss: 0.3410 - val_acc: 0.8947\n",
      "Epoch 1604/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0987 - acc: 0.9875 - val_loss: 0.3414 - val_acc: 0.8947\n",
      "Epoch 1605/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0989 - acc: 0.9875 - val_loss: 0.3379 - val_acc: 0.9474\n",
      "Epoch 1606/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0976 - acc: 0.9875 - val_loss: 0.3365 - val_acc: 0.9474\n",
      "Epoch 1607/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0978 - acc: 0.9875 - val_loss: 0.3349 - val_acc: 0.8947\n",
      "Epoch 1608/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0971 - acc: 0.9875 - val_loss: 0.3360 - val_acc: 0.9474\n",
      "Epoch 1609/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0965 - acc: 0.9875 - val_loss: 0.3364 - val_acc: 0.9474\n",
      "Epoch 1610/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0961 - acc: 0.9875 - val_loss: 0.3368 - val_acc: 0.9474\n",
      "Epoch 1611/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0956 - acc: 0.9875 - val_loss: 0.3371 - val_acc: 0.9474\n",
      "Epoch 1612/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0956 - acc: 0.9875 - val_loss: 0.3357 - val_acc: 0.9474\n",
      "Epoch 1613/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0951 - acc: 0.9875 - val_loss: 0.3369 - val_acc: 0.9474\n",
      "Epoch 1614/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0947 - acc: 0.9875 - val_loss: 0.3357 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1615/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0946 - acc: 0.9875 - val_loss: 0.3376 - val_acc: 0.8947\n",
      "Epoch 1616/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0950 - acc: 0.9875 - val_loss: 0.3351 - val_acc: 0.9474\n",
      "Epoch 1617/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0936 - acc: 0.9875 - val_loss: 0.3347 - val_acc: 0.9474\n",
      "Epoch 1618/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0933 - acc: 0.9875 - val_loss: 0.3351 - val_acc: 0.9474\n",
      "Epoch 1619/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0934 - acc: 0.9875 - val_loss: 0.3336 - val_acc: 0.8947\n",
      "Epoch 1620/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0931 - acc: 0.9875 - val_loss: 0.3391 - val_acc: 0.9474\n",
      "Epoch 1621/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0923 - acc: 0.9875 - val_loss: 0.3388 - val_acc: 0.9474\n",
      "Epoch 1622/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0921 - acc: 0.9875 - val_loss: 0.3396 - val_acc: 0.8947\n",
      "Epoch 1623/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0916 - acc: 0.9875 - val_loss: 0.3363 - val_acc: 0.8947\n",
      "Epoch 1624/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0916 - acc: 0.9875 - val_loss: 0.3346 - val_acc: 0.9474\n",
      "Epoch 1625/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0914 - acc: 0.9875 - val_loss: 0.3328 - val_acc: 0.8947\n",
      "Epoch 1626/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0918 - acc: 0.9875 - val_loss: 0.3323 - val_acc: 0.8947\n",
      "Epoch 1627/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0909 - acc: 0.9875 - val_loss: 0.3322 - val_acc: 0.8947\n",
      "Epoch 1628/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0903 - acc: 0.9875 - val_loss: 0.3340 - val_acc: 0.9474\n",
      "Epoch 1629/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0895 - acc: 0.9875 - val_loss: 0.3334 - val_acc: 0.9474\n",
      "Epoch 1630/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0894 - acc: 0.9875 - val_loss: 0.3335 - val_acc: 0.9474\n",
      "Epoch 1631/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0891 - acc: 0.9875 - val_loss: 0.3349 - val_acc: 0.8947\n",
      "Epoch 1632/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0891 - acc: 0.9875 - val_loss: 0.3352 - val_acc: 0.9474\n",
      "Epoch 1633/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0881 - acc: 0.9875 - val_loss: 0.3351 - val_acc: 0.9474\n",
      "Epoch 1634/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0874 - acc: 0.9875 - val_loss: 0.3346 - val_acc: 0.9474\n",
      "Epoch 1635/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0873 - acc: 0.9875 - val_loss: 0.3340 - val_acc: 0.9474\n",
      "Epoch 1636/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0870 - acc: 0.9875 - val_loss: 0.3349 - val_acc: 0.9474\n",
      "Epoch 1637/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0866 - acc: 1.0000 - val_loss: 0.3338 - val_acc: 0.9474\n",
      "Epoch 1638/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0863 - acc: 0.9875 - val_loss: 0.3334 - val_acc: 0.8947\n",
      "Epoch 1639/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0863 - acc: 0.9875 - val_loss: 0.3334 - val_acc: 0.8947\n",
      "Epoch 1640/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0857 - acc: 0.9875 - val_loss: 0.3334 - val_acc: 0.9474\n",
      "Epoch 1641/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0854 - acc: 0.9875 - val_loss: 0.3337 - val_acc: 0.9474\n",
      "Epoch 1642/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0852 - acc: 1.0000 - val_loss: 0.3326 - val_acc: 0.8947\n",
      "Epoch 1643/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0853 - acc: 0.9875 - val_loss: 0.3322 - val_acc: 0.8947\n",
      "Epoch 1644/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0848 - acc: 0.9875 - val_loss: 0.3317 - val_acc: 0.8947\n",
      "Epoch 1645/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0844 - acc: 0.9875 - val_loss: 0.3317 - val_acc: 0.8947\n",
      "Epoch 1646/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0844 - acc: 0.9875 - val_loss: 0.3335 - val_acc: 0.9474\n",
      "Epoch 1647/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0836 - acc: 1.0000 - val_loss: 0.3330 - val_acc: 0.9474\n",
      "Epoch 1648/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0837 - acc: 0.9875 - val_loss: 0.3329 - val_acc: 0.9474\n",
      "Epoch 1649/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0834 - acc: 0.9875 - val_loss: 0.3325 - val_acc: 0.9474\n",
      "Epoch 1650/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0828 - acc: 1.0000 - val_loss: 0.3316 - val_acc: 0.8947\n",
      "Epoch 1651/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0830 - acc: 1.0000 - val_loss: 0.3320 - val_acc: 0.9474\n",
      "Epoch 1652/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0823 - acc: 1.0000 - val_loss: 0.3316 - val_acc: 0.9474\n",
      "Epoch 1653/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0821 - acc: 1.0000 - val_loss: 0.3306 - val_acc: 0.8947\n",
      "Epoch 1654/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0825 - acc: 0.9875 - val_loss: 0.3302 - val_acc: 0.8947\n",
      "Epoch 1655/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0818 - acc: 0.9875 - val_loss: 0.3312 - val_acc: 0.9474\n",
      "Epoch 1656/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0822 - acc: 0.9875 - val_loss: 0.3317 - val_acc: 0.9474\n",
      "Epoch 1657/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0808 - acc: 1.0000 - val_loss: 0.3321 - val_acc: 0.9474\n",
      "Epoch 1658/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0805 - acc: 1.0000 - val_loss: 0.3313 - val_acc: 0.9474\n",
      "Epoch 1659/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0805 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 0.9474\n",
      "Epoch 1660/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.3300 - val_acc: 0.8947\n",
      "Epoch 1661/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0801 - acc: 0.9875 - val_loss: 0.3298 - val_acc: 0.8947\n",
      "Epoch 1662/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0798 - acc: 0.9875 - val_loss: 0.3300 - val_acc: 0.8947\n",
      "Epoch 1663/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0793 - acc: 1.0000 - val_loss: 0.3310 - val_acc: 0.9474\n",
      "Epoch 1664/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0790 - acc: 1.0000 - val_loss: 0.3296 - val_acc: 0.8947\n",
      "Epoch 1665/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0789 - acc: 1.0000 - val_loss: 0.3315 - val_acc: 0.8947\n",
      "Epoch 1666/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.3328 - val_acc: 0.8947\n",
      "Epoch 1667/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0783 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 0.8947\n",
      "Epoch 1668/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0781 - acc: 1.0000 - val_loss: 0.3324 - val_acc: 0.8947\n",
      "Epoch 1669/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0779 - acc: 1.0000 - val_loss: 0.3325 - val_acc: 0.8947\n",
      "Epoch 1670/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0777 - acc: 1.0000 - val_loss: 0.3308 - val_acc: 0.8947\n",
      "Epoch 1671/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0771 - acc: 1.0000 - val_loss: 0.3301 - val_acc: 0.9474\n",
      "Epoch 1672/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0768 - acc: 1.0000 - val_loss: 0.3300 - val_acc: 0.9474\n",
      "Epoch 1673/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0767 - acc: 1.0000 - val_loss: 0.3287 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1674/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.8947\n",
      "Epoch 1675/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0761 - acc: 1.0000 - val_loss: 0.3284 - val_acc: 0.9474\n",
      "Epoch 1676/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0765 - acc: 1.0000 - val_loss: 0.3275 - val_acc: 0.8947\n",
      "Epoch 1677/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.8947\n",
      "Epoch 1678/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0753 - acc: 1.0000 - val_loss: 0.3281 - val_acc: 0.8947\n",
      "Epoch 1679/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0750 - acc: 1.0000 - val_loss: 0.3283 - val_acc: 0.9474\n",
      "Epoch 1680/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.3271 - val_acc: 0.8947\n",
      "Epoch 1681/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.3271 - val_acc: 0.8947\n",
      "Epoch 1682/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.8947\n",
      "Epoch 1683/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0740 - acc: 1.0000 - val_loss: 0.3284 - val_acc: 0.9474\n",
      "Epoch 1684/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 0.9474\n",
      "Epoch 1685/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 0.3270 - val_acc: 0.8947\n",
      "Epoch 1686/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0735 - acc: 1.0000 - val_loss: 0.3282 - val_acc: 0.9474\n",
      "Epoch 1687/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0730 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.9474\n",
      "Epoch 1688/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0733 - acc: 1.0000 - val_loss: 0.3306 - val_acc: 0.8947\n",
      "Epoch 1689/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0727 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.8947\n",
      "Epoch 1690/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.3295 - val_acc: 0.8947\n",
      "Epoch 1691/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0721 - acc: 1.0000 - val_loss: 0.3278 - val_acc: 0.9474\n",
      "Epoch 1692/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 0.8947\n",
      "Epoch 1693/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0714 - acc: 1.0000 - val_loss: 0.3283 - val_acc: 0.8947\n",
      "Epoch 1694/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0713 - acc: 1.0000 - val_loss: 0.3291 - val_acc: 0.8947\n",
      "Epoch 1695/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0710 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.9474\n",
      "Epoch 1696/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.3294 - val_acc: 0.8947\n",
      "Epoch 1697/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0707 - acc: 1.0000 - val_loss: 0.3292 - val_acc: 0.8947\n",
      "Epoch 1698/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0708 - acc: 1.0000 - val_loss: 0.3285 - val_acc: 0.8947\n",
      "Epoch 1699/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0701 - acc: 1.0000 - val_loss: 0.3289 - val_acc: 0.8947\n",
      "Epoch 1700/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0698 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.8947\n",
      "Epoch 1701/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0702 - acc: 1.0000 - val_loss: 0.3314 - val_acc: 0.8947\n",
      "Epoch 1702/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0697 - acc: 1.0000 - val_loss: 0.3292 - val_acc: 0.8947\n",
      "Epoch 1703/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0693 - acc: 1.0000 - val_loss: 0.3292 - val_acc: 0.8947\n",
      "Epoch 1704/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0689 - acc: 1.0000 - val_loss: 0.3284 - val_acc: 0.8947\n",
      "Epoch 1705/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.0691 - acc: 1.0000 - val_loss: 0.3273 - val_acc: 0.8947\n",
      "Epoch 1706/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.8947\n",
      "Epoch 1707/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0685 - acc: 1.0000 - val_loss: 0.3258 - val_acc: 0.8947\n",
      "Epoch 1708/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.3252 - val_acc: 0.8947\n",
      "Epoch 1709/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0676 - acc: 1.0000 - val_loss: 0.3257 - val_acc: 0.8947\n",
      "Epoch 1710/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0676 - acc: 1.0000 - val_loss: 0.3262 - val_acc: 0.9474\n",
      "Epoch 1711/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0672 - acc: 1.0000 - val_loss: 0.3260 - val_acc: 0.9474\n",
      "Epoch 1712/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.3259 - val_acc: 0.9474\n",
      "Epoch 1713/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0668 - acc: 1.0000 - val_loss: 0.3250 - val_acc: 0.8947\n",
      "Epoch 1714/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0663 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.8947\n",
      "Epoch 1715/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0661 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.8947\n",
      "Epoch 1716/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 0.3246 - val_acc: 0.8947\n",
      "Epoch 1717/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.3253 - val_acc: 0.9474\n",
      "Epoch 1718/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0661 - acc: 1.0000 - val_loss: 0.3281 - val_acc: 0.8947\n",
      "Epoch 1719/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.3256 - val_acc: 0.9474\n",
      "Epoch 1720/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.8947\n",
      "Epoch 1721/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.3269 - val_acc: 0.8947\n",
      "Epoch 1722/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0651 - acc: 1.0000 - val_loss: 0.3266 - val_acc: 0.8947\n",
      "Epoch 1723/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.9474\n",
      "Epoch 1724/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0643 - acc: 1.0000 - val_loss: 0.3240 - val_acc: 0.8947\n",
      "Epoch 1725/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0640 - acc: 1.0000 - val_loss: 0.3244 - val_acc: 0.8947\n",
      "Epoch 1726/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.9474\n",
      "Epoch 1727/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.8947\n",
      "Epoch 1728/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.3238 - val_acc: 0.8947\n",
      "Epoch 1729/3000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.3234 - val_acc: 0.8947\n",
      "Epoch 1730/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.8947\n",
      "Epoch 1731/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.3245 - val_acc: 0.8947\n",
      "Epoch 1732/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1733/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.8947\n",
      "Epoch 1734/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.8947\n",
      "Epoch 1735/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0620 - acc: 1.0000 - val_loss: 0.3233 - val_acc: 0.8947\n",
      "Epoch 1736/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0474 - acc: 1.000 - 0s 125us/sample - loss: 0.0623 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.9474\n",
      "Epoch 1737/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0615 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.8947\n",
      "Epoch 1738/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.9474\n",
      "Epoch 1739/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0613 - acc: 1.0000 - val_loss: 0.3237 - val_acc: 0.8947\n",
      "Epoch 1740/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0610 - acc: 1.0000 - val_loss: 0.3232 - val_acc: 0.9474\n",
      "Epoch 1741/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.3228 - val_acc: 0.8947\n",
      "Epoch 1742/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.3241 - val_acc: 0.8947\n",
      "Epoch 1743/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0604 - acc: 1.0000 - val_loss: 0.3241 - val_acc: 0.8947\n",
      "Epoch 1744/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0604 - acc: 1.0000 - val_loss: 0.3220 - val_acc: 0.8947\n",
      "Epoch 1745/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0605 - acc: 1.0000 - val_loss: 0.3214 - val_acc: 0.8947\n",
      "Epoch 1746/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 0.3225 - val_acc: 0.9474\n",
      "Epoch 1747/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.8947\n",
      "Epoch 1748/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.3215 - val_acc: 0.8947\n",
      "Epoch 1749/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0594 - acc: 1.0000 - val_loss: 0.3201 - val_acc: 0.8947\n",
      "Epoch 1750/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 0.3194 - val_acc: 0.8947\n",
      "Epoch 1751/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0588 - acc: 1.0000 - val_loss: 0.3177 - val_acc: 0.8947\n",
      "Epoch 1752/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1753/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.8947\n",
      "Epoch 1754/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.3106 - val_acc: 0.8947\n",
      "Epoch 1755/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.3106 - val_acc: 0.8947\n",
      "Epoch 1756/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.3108 - val_acc: 0.9474\n",
      "Epoch 1757/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1758/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8947\n",
      "Epoch 1759/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8947\n",
      "Epoch 1760/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0572 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1761/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0568 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.8947\n",
      "Epoch 1762/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0572 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.8947\n",
      "Epoch 1763/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0566 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1764/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0563 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8947\n",
      "Epoch 1765/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.3093 - val_acc: 0.9474\n",
      "Epoch 1766/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1767/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.8947\n",
      "Epoch 1768/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1769/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0554 - acc: 1.0000 - val_loss: 0.3108 - val_acc: 0.8947\n",
      "Epoch 1770/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.3107 - val_acc: 0.8947\n",
      "Epoch 1771/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0552 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.8947\n",
      "Epoch 1772/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.8947\n",
      "Epoch 1773/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.8947\n",
      "Epoch 1774/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0546 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.8947\n",
      "Epoch 1775/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.8947\n",
      "Epoch 1776/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8947\n",
      "Epoch 1777/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 1778/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.8947\n",
      "Epoch 1779/3000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8947\n",
      "Epoch 1780/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1781/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1782/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.8947\n",
      "Epoch 1783/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0531 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.8947\n",
      "Epoch 1784/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0529 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.8947\n",
      "Epoch 1785/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.8947\n",
      "Epoch 1786/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8947\n",
      "Epoch 1787/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.8947\n",
      "Epoch 1788/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0524 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.8947\n",
      "Epoch 1789/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 1790/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 1791/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0519 - acc: 1.0000 - val_loss: 0.3093 - val_acc: 0.8947\n",
      "Epoch 1792/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.8947\n",
      "Epoch 1793/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0515 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 1794/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 1795/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.8947\n",
      "Epoch 1796/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0510 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.8947\n",
      "Epoch 1797/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 1798/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.8947\n",
      "Epoch 1799/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0505 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 1800/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0509 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.8947\n",
      "Epoch 1801/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0506 - acc: 1.0000 - val_loss: 0.3101 - val_acc: 0.8947\n",
      "Epoch 1802/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.8947\n",
      "Epoch 1803/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0503 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.8947\n",
      "Epoch 1804/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1805/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.8947\n",
      "Epoch 1806/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.8947\n",
      "Epoch 1807/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 1808/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 1809/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.8947\n",
      "Epoch 1810/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0489 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 1811/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 1812/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 1813/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 1814/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 1815/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0483 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 1816/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0483 - acc: 1.0000 - val_loss: 0.3069 - val_acc: 0.8947\n",
      "Epoch 1817/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 1818/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8421\n",
      "Epoch 1819/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0408 - acc: 1.000 - 0s 141us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.8947\n",
      "Epoch 1820/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 1821/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 1822/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0473 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 1823/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 1824/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 1825/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0471 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.8421\n",
      "Epoch 1826/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0467 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 1827/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.8947\n",
      "Epoch 1828/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8947\n",
      "Epoch 1829/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.8947\n",
      "Epoch 1830/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8947\n",
      "Epoch 1831/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0459 - acc: 1.0000 - val_loss: 0.3060 - val_acc: 0.8947\n",
      "Epoch 1832/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.8947\n",
      "Epoch 1833/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.9474\n",
      "Epoch 1834/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 0.8947\n",
      "Epoch 1835/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.8947\n",
      "Epoch 1836/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 0.8947\n",
      "Epoch 1837/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 1838/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.8947\n",
      "Epoch 1839/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.3056 - val_acc: 0.8947\n",
      "Epoch 1840/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0448 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8947\n",
      "Epoch 1841/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.8947\n",
      "Epoch 1842/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 1843/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0443 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 1844/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.8947\n",
      "Epoch 1845/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 1846/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0441 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.8947\n",
      "Epoch 1847/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 1848/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.3056 - val_acc: 0.8947\n",
      "Epoch 1849/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1850/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.8947\n",
      "Epoch 1851/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.3043 - val_acc: 0.8947\n",
      "Epoch 1852/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.3044 - val_acc: 0.8947\n",
      "Epoch 1853/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8947\n",
      "Epoch 1854/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0431 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.8947\n",
      "Epoch 1855/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.8947\n",
      "Epoch 1856/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 1857/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.8947\n",
      "Epoch 1858/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9474\n",
      "Epoch 1859/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.9474\n",
      "Epoch 1860/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.9474\n",
      "Epoch 1861/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.9474\n",
      "Epoch 1862/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.3166 - val_acc: 0.9474\n",
      "Epoch 1863/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.3157 - val_acc: 0.9474\n",
      "Epoch 1864/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9474\n",
      "Epoch 1865/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0421 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9474\n",
      "Epoch 1866/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0421 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9474\n",
      "Epoch 1867/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.9474\n",
      "Epoch 1868/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.9474\n",
      "Epoch 1869/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.9474\n",
      "Epoch 1870/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9474\n",
      "Epoch 1871/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.9474\n",
      "Epoch 1872/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.9474\n",
      "Epoch 1873/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9474\n",
      "Epoch 1874/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0411 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.9474\n",
      "Epoch 1875/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.9474\n",
      "Epoch 1876/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9474\n",
      "Epoch 1877/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.9474\n",
      "Epoch 1878/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0416 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.9474\n",
      "Epoch 1879/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.9474\n",
      "Epoch 1880/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0409 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9474\n",
      "Epoch 1881/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0409 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9474\n",
      "Epoch 1882/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.9474\n",
      "Epoch 1883/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9474\n",
      "Epoch 1884/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.3054 - val_acc: 0.9474\n",
      "Epoch 1885/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0409 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.9474\n",
      "Epoch 1886/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9474\n",
      "Epoch 1887/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9474\n",
      "Epoch 1888/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.9474\n",
      "Epoch 1889/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.9474\n",
      "Epoch 1890/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9474\n",
      "Epoch 1891/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9474\n",
      "Epoch 1892/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.3106 - val_acc: 0.8947\n",
      "Epoch 1893/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9474\n",
      "Epoch 1894/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.3093 - val_acc: 0.9474\n",
      "Epoch 1895/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.9474\n",
      "Epoch 1896/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.9474\n",
      "Epoch 1897/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.3106 - val_acc: 0.8947\n",
      "Epoch 1898/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.9474\n",
      "Epoch 1899/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.9474\n",
      "Epoch 1900/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1901/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 0.3112 - val_acc: 0.8947\n",
      "Epoch 1902/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.8947\n",
      "Epoch 1903/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.8947\n",
      "Epoch 1904/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.3107 - val_acc: 0.8947\n",
      "Epoch 1905/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.8947\n",
      "Epoch 1906/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.8947\n",
      "Epoch 1907/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.3106 - val_acc: 0.8947\n",
      "Epoch 1908/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1909/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.3109 - val_acc: 0.8947\n",
      "Epoch 1910/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 1911/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 0.8947\n",
      "Epoch 1912/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.3111 - val_acc: 0.8947\n",
      "Epoch 1913/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.9474\n",
      "Epoch 1914/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.3105 - val_acc: 0.8947\n",
      "Epoch 1915/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9474\n",
      "Epoch 1916/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9474\n",
      "Epoch 1917/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9474\n",
      "Epoch 1918/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9474\n",
      "Epoch 1919/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9474\n",
      "Epoch 1920/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.9474\n",
      "Epoch 1921/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9474\n",
      "Epoch 1922/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.9474\n",
      "Epoch 1923/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.9474\n",
      "Epoch 1924/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9474\n",
      "Epoch 1925/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9474\n",
      "Epoch 1926/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.3101 - val_acc: 0.8947\n",
      "Epoch 1927/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.8947\n",
      "Epoch 1928/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.8947\n",
      "Epoch 1929/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9474\n",
      "Epoch 1930/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.8947\n",
      "Epoch 1931/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.3099 - val_acc: 0.8947\n",
      "Epoch 1932/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.9474\n",
      "Epoch 1933/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9474\n",
      "Epoch 1934/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 0.9474\n",
      "Epoch 1935/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9474\n",
      "Epoch 1936/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9474\n",
      "Epoch 1937/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9474\n",
      "Epoch 1938/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.9474\n",
      "Epoch 1939/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9474\n",
      "Epoch 1940/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.8947\n",
      "Epoch 1941/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0350 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.9474\n",
      "Epoch 1942/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.9474\n",
      "Epoch 1943/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8947\n",
      "Epoch 1944/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9474\n",
      "Epoch 1945/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1946/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1947/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.3100 - val_acc: 0.8947\n",
      "Epoch 1948/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.8947\n",
      "Epoch 1949/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.8947\n",
      "Epoch 1950/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9474\n",
      "Epoch 1951/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9474\n",
      "Epoch 1952/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.8947\n",
      "Epoch 1953/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9474\n",
      "Epoch 1954/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8947\n",
      "Epoch 1955/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1956/3000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.8947\n",
      "Epoch 1957/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.3093 - val_acc: 0.8947\n",
      "Epoch 1958/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.8947\n",
      "Epoch 1959/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8947\n",
      "Epoch 1960/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.8947\n",
      "Epoch 1961/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.8947\n",
      "Epoch 1962/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.8947\n",
      "Epoch 1963/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.3096 - val_acc: 0.8947\n",
      "Epoch 1964/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.9474\n",
      "Epoch 1965/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9474\n",
      "Epoch 1966/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9474\n",
      "Epoch 1967/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1968/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.8947\n",
      "Epoch 1969/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.8947\n",
      "Epoch 1970/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.8947\n",
      "Epoch 1971/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.8947\n",
      "Epoch 1972/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.8947\n",
      "Epoch 1973/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.3153 - val_acc: 0.8947\n",
      "Epoch 1974/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.3153 - val_acc: 0.8947\n",
      "Epoch 1975/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.3151 - val_acc: 0.8947\n",
      "Epoch 1976/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.8947\n",
      "Epoch 1977/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.3159 - val_acc: 0.8947\n",
      "Epoch 1978/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.3152 - val_acc: 0.8947\n",
      "Epoch 1979/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.3154 - val_acc: 0.8947\n",
      "Epoch 1980/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.3158 - val_acc: 0.8947\n",
      "Epoch 1981/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.3157 - val_acc: 0.8947\n",
      "Epoch 1982/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.8947\n",
      "Epoch 1983/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.3143 - val_acc: 0.8947\n",
      "Epoch 1984/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 1985/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.8947\n",
      "Epoch 1986/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.8947\n",
      "Epoch 1987/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 1988/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.8947\n",
      "Epoch 1989/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.8947\n",
      "Epoch 1990/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 1991/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.8947\n",
      "Epoch 1992/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.8947\n",
      "Epoch 1993/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0306 - acc: 1.0000 - val_loss: 0.3133 - val_acc: 0.8947\n",
      "Epoch 1994/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 1995/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.3132 - val_acc: 0.8947\n",
      "Epoch 1996/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 1997/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.3133 - val_acc: 0.8947\n",
      "Epoch 1998/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.3143 - val_acc: 0.8947\n",
      "Epoch 1999/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.3146 - val_acc: 0.8947\n",
      "Epoch 2000/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.3145 - val_acc: 0.8947\n",
      "Epoch 2001/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.3143 - val_acc: 0.8947\n",
      "Epoch 2002/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.8947\n",
      "Epoch 2003/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2004/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 0.8947\n",
      "Epoch 2005/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 0.8947\n",
      "Epoch 2006/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.8947\n",
      "Epoch 2007/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.8947\n",
      "Epoch 2008/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.8947\n",
      "Epoch 2009/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.8947\n",
      "Epoch 2010/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.8947\n",
      "Epoch 2011/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.8947\n",
      "Epoch 2012/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.8947\n",
      "Epoch 2013/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2014/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.8947\n",
      "Epoch 2015/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 2016/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.8947\n",
      "Epoch 2017/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0410 - acc: 1.000 - 0s 108us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 2018/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.8947\n",
      "Epoch 2019/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 2020/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.8947\n",
      "Epoch 2021/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 2022/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.8947\n",
      "Epoch 2023/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 2024/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 2025/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 2026/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.8947\n",
      "Epoch 2027/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2028/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2029/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 2030/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 2031/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.8947\n",
      "Epoch 2032/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.3127 - val_acc: 0.8947\n",
      "Epoch 2033/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.8947\n",
      "Epoch 2034/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.3125 - val_acc: 0.8947\n",
      "Epoch 2035/3000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2036/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 2037/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.8947\n",
      "Epoch 2038/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.8947\n",
      "Epoch 2039/3000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.3146 - val_acc: 0.8947\n",
      "Epoch 2040/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 0.8947\n",
      "Epoch 2041/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 2042/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 2043/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 0.8947\n",
      "Epoch 2044/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.8947\n",
      "Epoch 2045/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8947\n",
      "Epoch 2046/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.8947\n",
      "Epoch 2047/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.3191 - val_acc: 0.8947\n",
      "Epoch 2048/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.3144 - val_acc: 0.8947\n",
      "Epoch 2049/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.8947\n",
      "Epoch 2050/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.8947\n",
      "Epoch 2051/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 0.3129 - val_acc: 0.8947\n",
      "Epoch 2052/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.3127 - val_acc: 0.8947\n",
      "Epoch 2053/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.3123 - val_acc: 0.8947\n",
      "Epoch 2054/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.3118 - val_acc: 0.8947\n",
      "Epoch 2055/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.3116 - val_acc: 0.8947\n",
      "Epoch 2056/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 2057/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.8947\n",
      "Epoch 2058/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.8947\n",
      "Epoch 2059/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.3116 - val_acc: 0.8947\n",
      "Epoch 2060/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 2061/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.8947\n",
      "Epoch 2062/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.8947\n",
      "Epoch 2063/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 2064/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.8947\n",
      "Epoch 2065/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.3116 - val_acc: 0.8947\n",
      "Epoch 2066/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.8947\n",
      "Epoch 2067/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 2068/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8947\n",
      "Epoch 2069/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2070/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.3181 - val_acc: 0.8947\n",
      "Epoch 2071/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.3179 - val_acc: 0.8947\n",
      "Epoch 2072/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.3179 - val_acc: 0.8947\n",
      "Epoch 2073/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2074/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.3105 - val_acc: 0.8947\n",
      "Epoch 2075/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.3109 - val_acc: 0.8947\n",
      "Epoch 2076/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2077/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 0.8947\n",
      "Epoch 2078/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.3108 - val_acc: 0.8947\n",
      "Epoch 2079/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.3109 - val_acc: 0.8947\n",
      "Epoch 2080/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.3113 - val_acc: 0.8947\n",
      "Epoch 2081/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.8947\n",
      "Epoch 2082/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.8947\n",
      "Epoch 2083/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2084/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.8947\n",
      "Epoch 2085/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2086/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 2087/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2088/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 2089/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 2090/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.8947\n",
      "Epoch 2091/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 2092/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 2093/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 2094/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 2095/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.8947\n",
      "Epoch 2096/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.8947\n",
      "Epoch 2097/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 2098/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.8947\n",
      "Epoch 2099/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2100/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2101/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 2102/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2103/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.8947\n",
      "Epoch 2104/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8947\n",
      "Epoch 2105/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 2106/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.8947\n",
      "Epoch 2107/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2108/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.8947\n",
      "Epoch 2109/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2110/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.8947\n",
      "Epoch 2111/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2112/3000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.8947\n",
      "Epoch 2113/3000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 2114/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.3064 - val_acc: 0.8947\n",
      "Epoch 2115/3000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 2116/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.8947\n",
      "Epoch 2117/3000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.8947\n",
      "Epoch 2118/3000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2119/3000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.8947\n",
      "Epoch 2120/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.8947\n",
      "Epoch 2121/3000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.8947\n",
      "Epoch 2122/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2123/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2124/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.8947\n",
      "Epoch 2125/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2126/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2127/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 2128/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.8947\n",
      "Epoch 2129/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2130/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.8947\n",
      "Epoch 2131/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8947\n",
      "Epoch 2132/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 2133/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3070 - val_acc: 0.8947\n",
      "Epoch 2134/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2135/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.8947\n",
      "Epoch 2136/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 2137/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2138/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2139/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.8947\n",
      "Epoch 2140/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.3060 - val_acc: 0.8947\n",
      "Epoch 2141/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.3064 - val_acc: 0.8947\n",
      "Epoch 2142/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.3066 - val_acc: 0.8947\n",
      "Epoch 2143/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 2144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3065 - val_acc: 0.8947\n",
      "Epoch 2145/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.8947\n",
      "Epoch 2146/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 2147/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8947\n",
      "Epoch 2148/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 2149/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 0.8947\n",
      "Epoch 2150/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8947\n",
      "Epoch 2151/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.3057 - val_acc: 0.8947\n",
      "Epoch 2152/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.8947\n",
      "Epoch 2153/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.3054 - val_acc: 0.8947\n",
      "Epoch 2154/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 2155/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.8947\n",
      "Epoch 2156/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 0.8947\n",
      "Epoch 2157/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 0.8947\n",
      "Epoch 2158/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.8947\n",
      "Epoch 2159/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.3049 - val_acc: 0.8947\n",
      "Epoch 2160/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 0.8947\n",
      "Epoch 2161/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 0.8947\n",
      "Epoch 2162/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.3043 - val_acc: 0.8947\n",
      "Epoch 2163/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3044 - val_acc: 0.8947\n",
      "Epoch 2164/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.8947\n",
      "Epoch 2165/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.3043 - val_acc: 0.8947\n",
      "Epoch 2166/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.3042 - val_acc: 0.8947\n",
      "Epoch 2167/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2168/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.3043 - val_acc: 0.8947\n",
      "Epoch 2169/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.8947\n",
      "Epoch 2170/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2171/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2172/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2173/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2174/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2175/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.8947\n",
      "Epoch 2176/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8947\n",
      "Epoch 2177/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.3067 - val_acc: 0.8947\n",
      "Epoch 2178/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 2179/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3063 - val_acc: 0.8947\n",
      "Epoch 2180/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8947\n",
      "Epoch 2181/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3060 - val_acc: 0.8947\n",
      "Epoch 2182/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8947\n",
      "Epoch 2183/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.8947\n",
      "Epoch 2184/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2185/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.2997 - val_acc: 0.8947\n",
      "Epoch 2186/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.2999 - val_acc: 0.8947\n",
      "Epoch 2187/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.3000 - val_acc: 0.8947\n",
      "Epoch 2188/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.3002 - val_acc: 0.8947\n",
      "Epoch 2189/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.3006 - val_acc: 0.8947\n",
      "Epoch 2190/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.2996 - val_acc: 0.8947\n",
      "Epoch 2191/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.2999 - val_acc: 0.8947\n",
      "Epoch 2192/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.8947\n",
      "Epoch 2193/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.3006 - val_acc: 0.8947\n",
      "Epoch 2194/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.3002 - val_acc: 0.8947\n",
      "Epoch 2195/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.3000 - val_acc: 0.8947\n",
      "Epoch 2196/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.3006 - val_acc: 0.8947\n",
      "Epoch 2197/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.8947\n",
      "Epoch 2198/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 0.8947\n",
      "Epoch 2199/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 0.8947\n",
      "Epoch 2200/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.8947\n",
      "Epoch 2201/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.8947\n",
      "Epoch 2202/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 0.8947\n",
      "Epoch 2203/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.2997 - val_acc: 0.8947\n",
      "Epoch 2204/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2205/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2206/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2207/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2208/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2209/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2210/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2995 - val_acc: 0.8947\n",
      "Epoch 2211/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.8947\n",
      "Epoch 2212/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.8947\n",
      "Epoch 2213/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2214/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2215/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.2992 - val_acc: 0.8947\n",
      "Epoch 2216/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.8947\n",
      "Epoch 2217/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.2995 - val_acc: 0.8947\n",
      "Epoch 2218/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2995 - val_acc: 0.8947\n",
      "Epoch 2219/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.8947\n",
      "Epoch 2220/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2221/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.2988 - val_acc: 0.8947\n",
      "Epoch 2222/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2223/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2224/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2225/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2226/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.2987 - val_acc: 0.8947\n",
      "Epoch 2227/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.8947\n",
      "Epoch 2228/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.8947\n",
      "Epoch 2229/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.8947\n",
      "Epoch 2230/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.8947\n",
      "Epoch 2231/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.8947\n",
      "Epoch 2232/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.8947\n",
      "Epoch 2233/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.8947\n",
      "Epoch 2234/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.8947\n",
      "Epoch 2235/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.8947\n",
      "Epoch 2236/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.2992 - val_acc: 0.8947\n",
      "Epoch 2237/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.2992 - val_acc: 0.8947\n",
      "Epoch 2238/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.8947\n",
      "Epoch 2239/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.8947\n",
      "Epoch 2240/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.2993 - val_acc: 0.8947\n",
      "Epoch 2241/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2242/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2988 - val_acc: 0.8947\n",
      "Epoch 2243/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2988 - val_acc: 0.8947\n",
      "Epoch 2244/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.8947\n",
      "Epoch 2245/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.8947\n",
      "Epoch 2246/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2997 - val_acc: 0.8947\n",
      "Epoch 2247/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.8947\n",
      "Epoch 2248/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2249/3000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2250/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2251/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2252/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2253/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2254/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2255/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2256/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2257/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2258/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2259/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2260/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2261/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2262/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2263/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2264/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2265/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2266/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2267/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2268/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2269/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2270/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2271/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2272/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2273/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2274/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2275/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2276/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2277/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2278/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2279/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2280/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2281/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2282/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2283/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2284/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2285/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2286/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2287/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2288/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2289/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2290/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2291/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2292/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2293/3000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2294/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2295/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2296/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2297/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2298/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2299/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2300/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2301/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2302/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2303/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2304/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2305/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2306/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2307/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2308/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2309/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2310/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2311/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2312/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2313/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2314/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2315/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2316/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2317/3000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2318/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2319/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2320/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2321/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2322/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2323/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2324/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2325/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2326/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2327/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2328/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2329/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2330/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2331/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2332/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2333/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2334/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2335/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2336/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2337/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2338/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2339/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2340/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2341/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2342/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2343/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2344/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2345/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2346/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2347/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2348/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2349/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2350/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2351/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2352/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2353/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2354/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2355/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2356/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2357/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2358/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2359/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2360/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2361/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2362/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2363/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2364/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2365/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2366/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2367/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2368/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2369/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2370/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2371/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2372/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2373/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2374/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2375/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2376/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2377/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2378/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2379/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2380/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2381/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2382/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2383/3000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2384/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2385/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2386/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2387/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2388/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2389/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2390/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2391/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2392/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2393/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2394/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2395/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2396/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2397/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2398/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2399/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2400/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2401/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2402/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2403/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2404/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2405/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2406/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2407/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2408/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2409/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2410/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2411/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2412/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2413/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2414/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2415/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2416/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2417/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2418/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2419/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2420/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2421/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2422/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2423/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2424/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2425/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2426/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2427/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2428/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2429/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2430/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2431/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2432/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2433/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2434/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2435/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2436/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2437/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2438/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2440/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2441/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2442/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2443/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2444/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2445/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2446/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2447/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2448/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2449/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2450/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2451/3000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2452/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2453/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2454/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2455/3000\n",
      "80/80 [==============================] - 0s 185us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2456/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2457/3000\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2458/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2459/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2460/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2461/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2462/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2463/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2464/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2465/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2466/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2467/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2468/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2469/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2470/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2471/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2472/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2473/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2474/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2475/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2476/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2477/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2478/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2479/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2480/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2481/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2482/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2483/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2484/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2485/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2486/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2487/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2488/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2489/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2490/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2491/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0124 - acc: 1.000 - 0s 124us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2492/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2493/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2494/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2495/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2496/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2497/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2498/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2499/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2500/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2501/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2502/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2503/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2504/3000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2505/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2506/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2507/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2508/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2509/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2510/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2511/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2512/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2513/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2514/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2515/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2516/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2517/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2518/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2519/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2520/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2521/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2522/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2523/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2524/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2525/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2526/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2527/3000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2528/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2529/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2530/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2531/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2532/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2533/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2534/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2535/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2536/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2537/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2538/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2539/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2540/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2541/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2542/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2543/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2544/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2545/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2546/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2547/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2548/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2549/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2550/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2551/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2552/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2553/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2554/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2555/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2556/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2557/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2558/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2559/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2560/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2561/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2562/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2563/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2564/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2565/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2566/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2567/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2568/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2569/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2570/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2571/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2572/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2573/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2574/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2575/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2576/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2577/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2578/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2579/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2580/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2581/3000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2582/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2583/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2584/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2585/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2586/3000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2587/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2588/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2589/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2590/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2591/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2592/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2593/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2594/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2595/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2596/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2597/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2598/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2599/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2600/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2601/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2602/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2603/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2604/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2605/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2606/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2607/3000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2608/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.8947\n",
      "Epoch 2609/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.8947\n",
      "Epoch 2610/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.8947\n",
      "Epoch 2611/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3013 - val_acc: 0.8947\n",
      "Epoch 2612/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3013 - val_acc: 0.8947\n",
      "Epoch 2613/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2614/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2615/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2616/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2617/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0096 - acc: 1.000 - 0s 144us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2618/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2619/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2620/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2621/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2622/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2623/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2624/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2625/3000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 0.8947\n",
      "Epoch 2626/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2627/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2628/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2629/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2630/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2631/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2632/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2633/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2634/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2635/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2636/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2637/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2638/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2639/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2640/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2641/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2642/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2643/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2644/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2645/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2646/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2647/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2648/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2649/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2650/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2651/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2652/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2653/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2654/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2655/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2656/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2657/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2658/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2659/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2660/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2661/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2662/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2663/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2664/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2665/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2666/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2667/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2668/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2669/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2670/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2671/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2672/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2673/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2674/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2675/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2676/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2677/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2678/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2679/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2680/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2681/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2682/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2683/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2684/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2685/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2686/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2687/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2688/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2689/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2690/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2691/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2692/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2693/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2694/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2695/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2696/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2697/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2698/3000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2699/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2700/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2701/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2702/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2703/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2704/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2705/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2706/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2707/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2708/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2709/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2710/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2711/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2712/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2713/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2714/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2715/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2716/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2717/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2718/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2719/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2720/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2721/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2722/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2723/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2724/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2725/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2726/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2727/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2728/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2729/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2730/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.8947\n",
      "Epoch 2731/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2732/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2733/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2734/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2735/3000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8947\n",
      "Epoch 2736/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2737/3000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0108 - acc: 1.000 - 0s 137us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 2738/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2739/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.8947\n",
      "Epoch 2740/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 0.8947\n",
      "Epoch 2741/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.8947\n",
      "Epoch 2742/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2743/3000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2744/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2745/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2746/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2747/3000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2748/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2749/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2750/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2751/3000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2752/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2753/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2754/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2755/3000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2756/3000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2757/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2758/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.8947\n",
      "Epoch 2759/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2760/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2761/3000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2762/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2763/3000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2764/3000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2765/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2766/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2767/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2768/3000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2769/3000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2770/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2771/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2772/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2773/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2774/3000\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2775/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2776/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2777/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2778/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2779/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3023 - val_acc: 0.8947\n",
      "Epoch 2780/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2781/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2782/3000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3024 - val_acc: 0.8947\n",
      "Epoch 2783/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.8947\n",
      "Epoch 2784/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2785/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2786/3000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2787/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2788/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2789/3000\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2790/3000\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2791/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2792/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2793/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2794/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2795/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2796/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2797/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2798/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2799/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2800/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2801/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2802/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2803/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2804/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2805/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2806/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2807/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2808/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8947\n",
      "Epoch 2809/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2810/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.8947\n",
      "Epoch 2811/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 2812/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2813/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2814/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2815/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2816/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.8947\n",
      "Epoch 2817/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2818/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2819/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2820/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2821/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2822/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2823/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2824/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2825/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2826/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2827/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2828/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2829/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2830/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2831/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2832/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2833/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2834/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2835/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2836/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2837/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2838/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2839/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2840/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2841/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2842/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2843/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2844/3000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2845/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2846/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2847/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2848/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2849/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2850/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2851/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2852/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2853/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2854/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2855/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2856/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2857/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2858/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2859/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2860/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2861/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2862/3000\n",
      "80/80 [==============================] - 0s 287us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2863/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2864/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2865/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2866/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2867/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2868/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2869/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2870/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2871/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2872/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2873/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2874/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2875/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2876/3000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2877/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2878/3000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2879/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2880/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2881/3000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2882/3000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2883/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2884/3000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2885/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2886/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2887/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3030 - val_acc: 0.8947\n",
      "Epoch 2888/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.8947\n",
      "Epoch 2889/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2890/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2891/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2892/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2893/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2894/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2895/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2896/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2897/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2898/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2899/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2900/3000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2901/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2902/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2903/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2904/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2905/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2906/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2907/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.8947\n",
      "Epoch 2908/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.8947\n",
      "Epoch 2909/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2910/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2911/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2912/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3034 - val_acc: 0.8947\n",
      "Epoch 2913/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2914/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2915/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2916/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2917/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2918/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2919/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2920/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2921/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2922/3000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2923/3000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2924/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2925/3000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2926/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2927/3000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2928/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2929/3000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2930/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2931/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2932/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2933/3000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2934/3000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2935/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2936/3000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2937/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2938/3000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2939/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2940/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2941/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2942/3000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2943/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2944/3000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2945/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2946/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2947/3000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2948/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2949/3000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2950/3000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2951/3000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2952/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2953/3000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2954/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2955/3000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2956/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2957/3000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2958/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2959/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2960/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2961/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2962/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2963/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 2964/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2965/3000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2966/3000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2967/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2968/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2969/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2970/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2971/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 0.8947\n",
      "Epoch 2972/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2973/3000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2974/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.8947\n",
      "Epoch 2975/3000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2976/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3037 - val_acc: 0.8947\n",
      "Epoch 2977/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2978/3000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2979/3000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.8947\n",
      "Epoch 2980/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8947\n",
      "Epoch 2981/3000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2982/3000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8947\n",
      "Epoch 2983/3000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3042 - val_acc: 0.8947\n",
      "Epoch 2984/3000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3042 - val_acc: 0.8947\n",
      "Epoch 2985/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3042 - val_acc: 0.8947\n",
      "Epoch 2986/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 0.8947\n",
      "Epoch 2987/3000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3076 - val_acc: 0.8947\n",
      "Epoch 2988/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3078 - val_acc: 0.8947\n",
      "Epoch 2989/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.8947\n",
      "Epoch 2990/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.8947\n",
      "Epoch 2991/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3084 - val_acc: 0.8947\n",
      "Epoch 2992/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 2993/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2994/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 2995/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 2996/3000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 2997/3000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.8947\n",
      "Epoch 2998/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8947\n",
      "Epoch 2999/3000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "Epoch 3000/3000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.8947\n",
      "\n",
      "val_acc\n",
      "[0.65, 0.7, 0.85, 0.85, 0.94736844]\n",
      "0.7994736909866333\n",
      "acc\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x189e2651f08>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 3000\n",
    "BATCH_SIZE = 1\n",
    "split = 5\n",
    "\n",
    "def buildmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(768,), activation=\"sigmoid\"))\n",
    "    model.add(Dense(256, activation=\"sigmoid\"))\n",
    "    model.add(Dense(128, activation=\"sigmoid\"))\n",
    "    model.add(Dense(64, activation=\"sigmoid\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=SGD(lr=INIT_LR), metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_name(fold_num):\n",
    "    return r'model_{val_acc:.2f}.h5'\n",
    "\n",
    "kf = KFold(n_splits = split, random_state = 100, shuffle = True)\n",
    "skf = StratifiedKFold(n_splits = split, random_state = 100, shuffle = True) \n",
    "\n",
    "VALIDATION_ACCURACY, VALIDATION_LOSS, ACCURACY = [], [], []\n",
    "\n",
    "save_dir = r\"C:\\Users\\Admin\\PycharmProjects\\Kognitive NTI\\Module 1\\Task 3\\saved_models\\\\\"\n",
    "fold_var = 1\n",
    "\n",
    "for train_i, test_i in kf.split(x, y):\n",
    "    \n",
    "    train_x, train_y, test_x, test_y = x[train_i], y[train_i], x[test_i], y[test_i]\n",
    "\n",
    "    model = buildmodel()\n",
    "    checkpoint = ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_acc', verbose=0, \n",
    "                                 save_best_only=True, mode='max')\n",
    "\n",
    "    history = model.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "                        epochs=EPOCHS, \n",
    "                        callbacks=[checkpoint])\n",
    "\n",
    "    VALIDATION_ACCURACY.append(max(history.history['val_acc']))\n",
    "    ACCURACY.append(max(history.history['acc']))\n",
    "    VALIDATION_LOSS.append(history.history['loss'])\n",
    "    clear_session()\n",
    "    \n",
    "    fold_var += 1\n",
    "\n",
    "print()\n",
    "print('val_acc')\n",
    "print(VALIDATION_ACCURACY)\n",
    "print(sum(VALIDATION_ACCURACY) / len(VALIDATION_ACCURACY))\n",
    "plt.plot(VALIDATION_ACCURACY)\n",
    "print(\"acc\")\n",
    "print(ACCURACY)\n",
    "print(sum(ACCURACY) / len(ACCURACY))\n",
    "plt.plot(ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 2 2 1 2 1 2 2 2 1 1 2 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 2 1 2 1 2 2 1 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 2 2 1 2 1 2 2 2 2 1 1 2 1 2 2 2 1 2 2 2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "model = keras.models.load_model(r'C:\\Users\\Admin\\PycharmProjects\\Kognitive NTI\\Module 1\\Task 3\\saved_models\\model_0.95.h5')\n",
    "\n",
    "data = []\n",
    "file = open(\"my_sig.txt\")\n",
    "\n",
    "for sig in file.read().split('\\n\\n'):\n",
    "    arr = np.array(sig.split(), dtype='int16')\n",
    "    data.append(arr)\n",
    "\n",
    "data = np.array(list(map(getF, data)))\n",
    "\n",
    "pred = model.predict(data)\n",
    "pred = np.array(list(map(lambda p: 1 if p[0] > p[1] else 2, pred)))\n",
    "file.close()\n",
    "print(' '.join(list(map(str, pred))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}